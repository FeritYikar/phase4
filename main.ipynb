{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>334200.0</td>\n",
       "      <td>335400.0</td>\n",
       "      <td>336500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1005500</td>\n",
       "      <td>1007500</td>\n",
       "      <td>1007800</td>\n",
       "      <td>1009600</td>\n",
       "      <td>1013300</td>\n",
       "      <td>1018700</td>\n",
       "      <td>1024400</td>\n",
       "      <td>1030700</td>\n",
       "      <td>1033800</td>\n",
       "      <td>1030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90668</td>\n",
       "      <td>75070</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>Collin</td>\n",
       "      <td>2</td>\n",
       "      <td>235700.0</td>\n",
       "      <td>236900.0</td>\n",
       "      <td>236700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>308000</td>\n",
       "      <td>310000</td>\n",
       "      <td>312500</td>\n",
       "      <td>314100</td>\n",
       "      <td>315000</td>\n",
       "      <td>316600</td>\n",
       "      <td>318100</td>\n",
       "      <td>319600</td>\n",
       "      <td>321100</td>\n",
       "      <td>321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris</td>\n",
       "      <td>3</td>\n",
       "      <td>210400.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321000</td>\n",
       "      <td>320600</td>\n",
       "      <td>320200</td>\n",
       "      <td>320400</td>\n",
       "      <td>320800</td>\n",
       "      <td>321200</td>\n",
       "      <td>321200</td>\n",
       "      <td>323000</td>\n",
       "      <td>326900</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>4</td>\n",
       "      <td>498100.0</td>\n",
       "      <td>500900.0</td>\n",
       "      <td>503100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1289800</td>\n",
       "      <td>1287700</td>\n",
       "      <td>1287400</td>\n",
       "      <td>1291500</td>\n",
       "      <td>1296600</td>\n",
       "      <td>1299000</td>\n",
       "      <td>1302700</td>\n",
       "      <td>1306400</td>\n",
       "      <td>1308500</td>\n",
       "      <td>1307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93144</td>\n",
       "      <td>79936</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>5</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119100</td>\n",
       "      <td>119400</td>\n",
       "      <td>120000</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120500</td>\n",
       "      <td>121000</td>\n",
       "      <td>121500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14718</th>\n",
       "      <td>58333</td>\n",
       "      <td>1338</td>\n",
       "      <td>Ashfield</td>\n",
       "      <td>MA</td>\n",
       "      <td>Greenfield Town</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>14719</td>\n",
       "      <td>94600.0</td>\n",
       "      <td>94300.0</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>216800</td>\n",
       "      <td>217700</td>\n",
       "      <td>218600</td>\n",
       "      <td>218500</td>\n",
       "      <td>218100</td>\n",
       "      <td>216400</td>\n",
       "      <td>213100</td>\n",
       "      <td>209800</td>\n",
       "      <td>209200</td>\n",
       "      <td>209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14719</th>\n",
       "      <td>59107</td>\n",
       "      <td>3293</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>NH</td>\n",
       "      <td>Claremont</td>\n",
       "      <td>Grafton</td>\n",
       "      <td>14720</td>\n",
       "      <td>92700.0</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>92400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>202100</td>\n",
       "      <td>208400</td>\n",
       "      <td>212200</td>\n",
       "      <td>215200</td>\n",
       "      <td>214300</td>\n",
       "      <td>213100</td>\n",
       "      <td>213700</td>\n",
       "      <td>218300</td>\n",
       "      <td>222700</td>\n",
       "      <td>225800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14720</th>\n",
       "      <td>75672</td>\n",
       "      <td>40404</td>\n",
       "      <td>Berea</td>\n",
       "      <td>KY</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Madison</td>\n",
       "      <td>14721</td>\n",
       "      <td>57100.0</td>\n",
       "      <td>57300.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121800</td>\n",
       "      <td>122800</td>\n",
       "      <td>124600</td>\n",
       "      <td>126700</td>\n",
       "      <td>128800</td>\n",
       "      <td>130600</td>\n",
       "      <td>131700</td>\n",
       "      <td>132500</td>\n",
       "      <td>133000</td>\n",
       "      <td>133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14721</th>\n",
       "      <td>93733</td>\n",
       "      <td>81225</td>\n",
       "      <td>Mount Crested Butte</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunnison</td>\n",
       "      <td>14722</td>\n",
       "      <td>191100.0</td>\n",
       "      <td>192400.0</td>\n",
       "      <td>193700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>662800</td>\n",
       "      <td>671200</td>\n",
       "      <td>682400</td>\n",
       "      <td>695600</td>\n",
       "      <td>695500</td>\n",
       "      <td>694700</td>\n",
       "      <td>706400</td>\n",
       "      <td>705300</td>\n",
       "      <td>681500</td>\n",
       "      <td>664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14722</th>\n",
       "      <td>95851</td>\n",
       "      <td>89155</td>\n",
       "      <td>Mesquite</td>\n",
       "      <td>NV</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Clark</td>\n",
       "      <td>14723</td>\n",
       "      <td>176400.0</td>\n",
       "      <td>176300.0</td>\n",
       "      <td>176100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>333800</td>\n",
       "      <td>336400</td>\n",
       "      <td>339700</td>\n",
       "      <td>343800</td>\n",
       "      <td>346800</td>\n",
       "      <td>348900</td>\n",
       "      <td>350400</td>\n",
       "      <td>353000</td>\n",
       "      <td>356000</td>\n",
       "      <td>357200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14723 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RegionID  RegionName                 City State              Metro  \\\n",
       "0         84654       60657              Chicago    IL            Chicago   \n",
       "1         90668       75070             McKinney    TX  Dallas-Fort Worth   \n",
       "2         91982       77494                 Katy    TX            Houston   \n",
       "3         84616       60614              Chicago    IL            Chicago   \n",
       "4         93144       79936              El Paso    TX            El Paso   \n",
       "...         ...         ...                  ...   ...                ...   \n",
       "14718     58333        1338             Ashfield    MA    Greenfield Town   \n",
       "14719     59107        3293            Woodstock    NH          Claremont   \n",
       "14720     75672       40404                Berea    KY           Richmond   \n",
       "14721     93733       81225  Mount Crested Butte    CO                NaN   \n",
       "14722     95851       89155             Mesquite    NV          Las Vegas   \n",
       "\n",
       "      CountyName  SizeRank   1996-04   1996-05   1996-06  ...  2017-07  \\\n",
       "0           Cook         1  334200.0  335400.0  336500.0  ...  1005500   \n",
       "1         Collin         2  235700.0  236900.0  236700.0  ...   308000   \n",
       "2         Harris         3  210400.0  212200.0  212200.0  ...   321000   \n",
       "3           Cook         4  498100.0  500900.0  503100.0  ...  1289800   \n",
       "4        El Paso         5   77300.0   77300.0   77300.0  ...   119100   \n",
       "...          ...       ...       ...       ...       ...  ...      ...   \n",
       "14718   Franklin     14719   94600.0   94300.0   94000.0  ...   216800   \n",
       "14719    Grafton     14720   92700.0   92500.0   92400.0  ...   202100   \n",
       "14720    Madison     14721   57100.0   57300.0   57500.0  ...   121800   \n",
       "14721   Gunnison     14722  191100.0  192400.0  193700.0  ...   662800   \n",
       "14722      Clark     14723  176400.0  176300.0  176100.0  ...   333800   \n",
       "\n",
       "       2017-08  2017-09  2017-10  2017-11  2017-12  2018-01  2018-02  2018-03  \\\n",
       "0      1007500  1007800  1009600  1013300  1018700  1024400  1030700  1033800   \n",
       "1       310000   312500   314100   315000   316600   318100   319600   321100   \n",
       "2       320600   320200   320400   320800   321200   321200   323000   326900   \n",
       "3      1287700  1287400  1291500  1296600  1299000  1302700  1306400  1308500   \n",
       "4       119400   120000   120300   120300   120300   120300   120500   121000   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "14718   217700   218600   218500   218100   216400   213100   209800   209200   \n",
       "14719   208400   212200   215200   214300   213100   213700   218300   222700   \n",
       "14720   122800   124600   126700   128800   130600   131700   132500   133000   \n",
       "14721   671200   682400   695600   695500   694700   706400   705300   681500   \n",
       "14722   336400   339700   343800   346800   348900   350400   353000   356000   \n",
       "\n",
       "       2018-04  \n",
       "0      1030600  \n",
       "1       321800  \n",
       "2       329900  \n",
       "3      1307000  \n",
       "4       121500  \n",
       "...        ...  \n",
       "14718   209300  \n",
       "14719   225800  \n",
       "14720   133400  \n",
       "14721   664400  \n",
       "14722   357200  \n",
       "\n",
       "[14723 rows x 272 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/zillow_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_converter = dict(zip(list(df[df['State']=='NV']['RegionID']),list(df[df['State']=='NV']['RegionName'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>84654</th>\n",
       "      <th>90668</th>\n",
       "      <th>91982</th>\n",
       "      <th>84616</th>\n",
       "      <th>93144</th>\n",
       "      <th>91733</th>\n",
       "      <th>61807</th>\n",
       "      <th>84640</th>\n",
       "      <th>91940</th>\n",
       "      <th>97564</th>\n",
       "      <th>...</th>\n",
       "      <th>59187</th>\n",
       "      <th>94711</th>\n",
       "      <th>62556</th>\n",
       "      <th>99032</th>\n",
       "      <th>62697</th>\n",
       "      <th>58333</th>\n",
       "      <th>59107</th>\n",
       "      <th>75672</th>\n",
       "      <th>93733</th>\n",
       "      <th>95851</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01</th>\n",
       "      <td>334200</td>\n",
       "      <td>235700</td>\n",
       "      <td>210400</td>\n",
       "      <td>498100</td>\n",
       "      <td>77300</td>\n",
       "      <td>95000</td>\n",
       "      <td>152900</td>\n",
       "      <td>216500</td>\n",
       "      <td>95400</td>\n",
       "      <td>766000</td>\n",
       "      <td>...</td>\n",
       "      <td>80800</td>\n",
       "      <td>135900</td>\n",
       "      <td>78300</td>\n",
       "      <td>136200</td>\n",
       "      <td>62500</td>\n",
       "      <td>94600</td>\n",
       "      <td>92700</td>\n",
       "      <td>57100</td>\n",
       "      <td>191100</td>\n",
       "      <td>176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01</th>\n",
       "      <td>335400</td>\n",
       "      <td>236900</td>\n",
       "      <td>212200</td>\n",
       "      <td>500900</td>\n",
       "      <td>77300</td>\n",
       "      <td>95200</td>\n",
       "      <td>152700</td>\n",
       "      <td>216700</td>\n",
       "      <td>95600</td>\n",
       "      <td>771100</td>\n",
       "      <td>...</td>\n",
       "      <td>80100</td>\n",
       "      <td>136300</td>\n",
       "      <td>78300</td>\n",
       "      <td>136600</td>\n",
       "      <td>62600</td>\n",
       "      <td>94300</td>\n",
       "      <td>92500</td>\n",
       "      <td>57300</td>\n",
       "      <td>192400</td>\n",
       "      <td>176300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01</th>\n",
       "      <td>336500</td>\n",
       "      <td>236700</td>\n",
       "      <td>212200</td>\n",
       "      <td>503100</td>\n",
       "      <td>77300</td>\n",
       "      <td>95400</td>\n",
       "      <td>152600</td>\n",
       "      <td>216900</td>\n",
       "      <td>95800</td>\n",
       "      <td>776500</td>\n",
       "      <td>...</td>\n",
       "      <td>79400</td>\n",
       "      <td>136600</td>\n",
       "      <td>78200</td>\n",
       "      <td>136800</td>\n",
       "      <td>62700</td>\n",
       "      <td>94000</td>\n",
       "      <td>92400</td>\n",
       "      <td>57500</td>\n",
       "      <td>193700</td>\n",
       "      <td>176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01</th>\n",
       "      <td>337600</td>\n",
       "      <td>235400</td>\n",
       "      <td>210700</td>\n",
       "      <td>504600</td>\n",
       "      <td>77300</td>\n",
       "      <td>95700</td>\n",
       "      <td>152400</td>\n",
       "      <td>217000</td>\n",
       "      <td>96100</td>\n",
       "      <td>781900</td>\n",
       "      <td>...</td>\n",
       "      <td>78600</td>\n",
       "      <td>136900</td>\n",
       "      <td>78200</td>\n",
       "      <td>136800</td>\n",
       "      <td>62700</td>\n",
       "      <td>93700</td>\n",
       "      <td>92200</td>\n",
       "      <td>57700</td>\n",
       "      <td>195000</td>\n",
       "      <td>176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01</th>\n",
       "      <td>338500</td>\n",
       "      <td>233300</td>\n",
       "      <td>208300</td>\n",
       "      <td>505500</td>\n",
       "      <td>77400</td>\n",
       "      <td>95900</td>\n",
       "      <td>152300</td>\n",
       "      <td>217100</td>\n",
       "      <td>96400</td>\n",
       "      <td>787300</td>\n",
       "      <td>...</td>\n",
       "      <td>77900</td>\n",
       "      <td>137100</td>\n",
       "      <td>78100</td>\n",
       "      <td>136700</td>\n",
       "      <td>62700</td>\n",
       "      <td>93400</td>\n",
       "      <td>92100</td>\n",
       "      <td>58000</td>\n",
       "      <td>196300</td>\n",
       "      <td>175900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>1018700</td>\n",
       "      <td>316600</td>\n",
       "      <td>321200</td>\n",
       "      <td>1299000</td>\n",
       "      <td>120300</td>\n",
       "      <td>162800</td>\n",
       "      <td>414300</td>\n",
       "      <td>777900</td>\n",
       "      <td>172300</td>\n",
       "      <td>3778700</td>\n",
       "      <td>...</td>\n",
       "      <td>123400</td>\n",
       "      <td>257600</td>\n",
       "      <td>171300</td>\n",
       "      <td>341000</td>\n",
       "      <td>122800</td>\n",
       "      <td>216400</td>\n",
       "      <td>213100</td>\n",
       "      <td>130600</td>\n",
       "      <td>694700</td>\n",
       "      <td>348900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>1024400</td>\n",
       "      <td>318100</td>\n",
       "      <td>321200</td>\n",
       "      <td>1302700</td>\n",
       "      <td>120300</td>\n",
       "      <td>162800</td>\n",
       "      <td>413900</td>\n",
       "      <td>778500</td>\n",
       "      <td>173300</td>\n",
       "      <td>3770800</td>\n",
       "      <td>...</td>\n",
       "      <td>124400</td>\n",
       "      <td>258000</td>\n",
       "      <td>172400</td>\n",
       "      <td>342300</td>\n",
       "      <td>123200</td>\n",
       "      <td>213100</td>\n",
       "      <td>213700</td>\n",
       "      <td>131700</td>\n",
       "      <td>706400</td>\n",
       "      <td>350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>1030700</td>\n",
       "      <td>319600</td>\n",
       "      <td>323000</td>\n",
       "      <td>1306400</td>\n",
       "      <td>120500</td>\n",
       "      <td>162900</td>\n",
       "      <td>411400</td>\n",
       "      <td>780500</td>\n",
       "      <td>174200</td>\n",
       "      <td>3763100</td>\n",
       "      <td>...</td>\n",
       "      <td>125500</td>\n",
       "      <td>260600</td>\n",
       "      <td>173600</td>\n",
       "      <td>345000</td>\n",
       "      <td>123200</td>\n",
       "      <td>209800</td>\n",
       "      <td>218300</td>\n",
       "      <td>132500</td>\n",
       "      <td>705300</td>\n",
       "      <td>353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>1033800</td>\n",
       "      <td>321100</td>\n",
       "      <td>326900</td>\n",
       "      <td>1308500</td>\n",
       "      <td>121000</td>\n",
       "      <td>163500</td>\n",
       "      <td>413200</td>\n",
       "      <td>782800</td>\n",
       "      <td>175400</td>\n",
       "      <td>3779800</td>\n",
       "      <td>...</td>\n",
       "      <td>126600</td>\n",
       "      <td>264700</td>\n",
       "      <td>175800</td>\n",
       "      <td>348000</td>\n",
       "      <td>120700</td>\n",
       "      <td>209200</td>\n",
       "      <td>222700</td>\n",
       "      <td>133000</td>\n",
       "      <td>681500</td>\n",
       "      <td>356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>1030600</td>\n",
       "      <td>321800</td>\n",
       "      <td>329900</td>\n",
       "      <td>1307000</td>\n",
       "      <td>121500</td>\n",
       "      <td>164300</td>\n",
       "      <td>417900</td>\n",
       "      <td>782800</td>\n",
       "      <td>176200</td>\n",
       "      <td>3813500</td>\n",
       "      <td>...</td>\n",
       "      <td>127500</td>\n",
       "      <td>266800</td>\n",
       "      <td>177500</td>\n",
       "      <td>349300</td>\n",
       "      <td>117700</td>\n",
       "      <td>209300</td>\n",
       "      <td>225800</td>\n",
       "      <td>133400</td>\n",
       "      <td>664400</td>\n",
       "      <td>357200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 14723 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              84654   90668   91982    84616   93144   91733   61807   84640  \\\n",
       "1996-04-01   334200  235700  210400   498100   77300   95000  152900  216500   \n",
       "1996-05-01   335400  236900  212200   500900   77300   95200  152700  216700   \n",
       "1996-06-01   336500  236700  212200   503100   77300   95400  152600  216900   \n",
       "1996-07-01   337600  235400  210700   504600   77300   95700  152400  217000   \n",
       "1996-08-01   338500  233300  208300   505500   77400   95900  152300  217100   \n",
       "...             ...     ...     ...      ...     ...     ...     ...     ...   \n",
       "2017-12-01  1018700  316600  321200  1299000  120300  162800  414300  777900   \n",
       "2018-01-01  1024400  318100  321200  1302700  120300  162800  413900  778500   \n",
       "2018-02-01  1030700  319600  323000  1306400  120500  162900  411400  780500   \n",
       "2018-03-01  1033800  321100  326900  1308500  121000  163500  413200  782800   \n",
       "2018-04-01  1030600  321800  329900  1307000  121500  164300  417900  782800   \n",
       "\n",
       "             91940    97564  ...   59187   94711   62556   99032   62697  \\\n",
       "1996-04-01   95400   766000  ...   80800  135900   78300  136200   62500   \n",
       "1996-05-01   95600   771100  ...   80100  136300   78300  136600   62600   \n",
       "1996-06-01   95800   776500  ...   79400  136600   78200  136800   62700   \n",
       "1996-07-01   96100   781900  ...   78600  136900   78200  136800   62700   \n",
       "1996-08-01   96400   787300  ...   77900  137100   78100  136700   62700   \n",
       "...            ...      ...  ...     ...     ...     ...     ...     ...   \n",
       "2017-12-01  172300  3778700  ...  123400  257600  171300  341000  122800   \n",
       "2018-01-01  173300  3770800  ...  124400  258000  172400  342300  123200   \n",
       "2018-02-01  174200  3763100  ...  125500  260600  173600  345000  123200   \n",
       "2018-03-01  175400  3779800  ...  126600  264700  175800  348000  120700   \n",
       "2018-04-01  176200  3813500  ...  127500  266800  177500  349300  117700   \n",
       "\n",
       "             58333   59107   75672   93733   95851  \n",
       "1996-04-01   94600   92700   57100  191100  176400  \n",
       "1996-05-01   94300   92500   57300  192400  176300  \n",
       "1996-06-01   94000   92400   57500  193700  176100  \n",
       "1996-07-01   93700   92200   57700  195000  176000  \n",
       "1996-08-01   93400   92100   58000  196300  175900  \n",
       "...            ...     ...     ...     ...     ...  \n",
       "2017-12-01  216400  213100  130600  694700  348900  \n",
       "2018-01-01  213100  213700  131700  706400  350400  \n",
       "2018-02-01  209800  218300  132500  705300  353000  \n",
       "2018-03-01  209200  222700  133000  681500  356000  \n",
       "2018-04-01  209300  225800  133400  664400  357200  \n",
       "\n",
       "[265 rows x 14723 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series = pd.DataFrame(index=pd.to_datetime(df.columns[7:]), data=np.ones(len(df.columns)-7))\n",
    "for i in range(df.shape[0]):\n",
    "    df_time_series[df['RegionID'][i]] = df.iloc[i,7:]\n",
    "df_time_series.drop(df_time_series.columns[0],axis=1, inplace=True)\n",
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156891"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95804"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nv = df[df['State'] == 'NV']\n",
    "nv_zipcodes = list(df_nv.RegionID)\n",
    "nv_zipcodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these zipcodes have different characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_time_series.iloc[:,0].plot(figsize=(16,9))\n",
    "df_time_series.iloc[:,1].plot()\n",
    "df_time_series.iloc[:,2].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(df_time_series)*.8)\n",
    "train = df_time_series.iloc[:size]\n",
    "test = df_time_series.iloc[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = df_time_series[nv_zipcodes]\n",
    "train = train[nv_zipcodes]\n",
    "test = test[nv_zipcodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying a RNN model to see how it does on our first zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "train_data = train.iloc[:,x:x+1].values.astype(int)\n",
    "test_data = test.iloc[:,x:x+1].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.16841344e-03],\n",
       "       [1.80701120e-03],\n",
       "       [1.08420672e-03],\n",
       "       [7.22804481e-04],\n",
       "       [3.61402241e-04],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [7.22804481e-04],\n",
       "       [1.44560896e-03],\n",
       "       [2.52981568e-03],\n",
       "       [3.25262017e-03],\n",
       "       [3.61402241e-03],\n",
       "       [3.61402241e-03],\n",
       "       [3.97542465e-03],\n",
       "       [4.33682689e-03],\n",
       "       [4.69822913e-03],\n",
       "       [5.05963137e-03],\n",
       "       [5.78243585e-03],\n",
       "       [6.50524033e-03],\n",
       "       [7.58944705e-03],\n",
       "       [9.03505602e-03],\n",
       "       [1.12034695e-02],\n",
       "       [1.22876762e-02],\n",
       "       [1.30104807e-02],\n",
       "       [1.37332851e-02],\n",
       "       [1.40946874e-02],\n",
       "       [1.48174919e-02],\n",
       "       [1.55402963e-02],\n",
       "       [1.62631008e-02],\n",
       "       [1.73473076e-02],\n",
       "       [1.84315143e-02],\n",
       "       [1.98771232e-02],\n",
       "       [2.20455367e-02],\n",
       "       [2.42139501e-02],\n",
       "       [2.56595591e-02],\n",
       "       [2.67437658e-02],\n",
       "       [2.78279725e-02],\n",
       "       [2.92735815e-02],\n",
       "       [3.07191905e-02],\n",
       "       [3.21647994e-02],\n",
       "       [3.39718106e-02],\n",
       "       [3.61402241e-02],\n",
       "       [3.83086375e-02],\n",
       "       [4.11998554e-02],\n",
       "       [4.44524756e-02],\n",
       "       [4.80664980e-02],\n",
       "       [5.13191182e-02],\n",
       "       [5.38489339e-02],\n",
       "       [5.67401518e-02],\n",
       "       [5.92699675e-02],\n",
       "       [6.21611854e-02],\n",
       "       [6.50524033e-02],\n",
       "       [6.86664257e-02],\n",
       "       [7.19190459e-02],\n",
       "       [7.58944705e-02],\n",
       "       [8.02312974e-02],\n",
       "       [8.49295266e-02],\n",
       "       [8.99891579e-02],\n",
       "       [9.43259848e-02],\n",
       "       [9.83014095e-02],\n",
       "       [1.02276834e-01],\n",
       "       [1.05890857e-01],\n",
       "       [1.09866281e-01],\n",
       "       [1.14203108e-01],\n",
       "       [1.18178533e-01],\n",
       "       [1.23238164e-01],\n",
       "       [1.28297795e-01],\n",
       "       [1.34080231e-01],\n",
       "       [1.39862667e-01],\n",
       "       [1.45645103e-01],\n",
       "       [1.50704734e-01],\n",
       "       [1.55041561e-01],\n",
       "       [1.59016986e-01],\n",
       "       [1.63353813e-01],\n",
       "       [1.67329237e-01],\n",
       "       [1.71304662e-01],\n",
       "       [1.75641489e-01],\n",
       "       [1.79978316e-01],\n",
       "       [1.85399349e-01],\n",
       "       [1.90097579e-01],\n",
       "       [1.94073003e-01],\n",
       "       [1.99132635e-01],\n",
       "       [2.05276473e-01],\n",
       "       [2.12143115e-01],\n",
       "       [2.20455367e-01],\n",
       "       [2.30213227e-01],\n",
       "       [2.42500904e-01],\n",
       "       [2.57318395e-01],\n",
       "       [2.73942898e-01],\n",
       "       [2.93458619e-01],\n",
       "       [3.16226961e-01],\n",
       "       [3.41886520e-01],\n",
       "       [3.71882906e-01],\n",
       "       [4.04047705e-01],\n",
       "       [4.38742320e-01],\n",
       "       [4.76689555e-01],\n",
       "       [5.18612215e-01],\n",
       "       [5.63064691e-01],\n",
       "       [6.08962776e-01],\n",
       "       [6.55222262e-01],\n",
       "       [6.98229129e-01],\n",
       "       [7.36899169e-01],\n",
       "       [7.70148175e-01],\n",
       "       [7.98337550e-01],\n",
       "       [8.23997109e-01],\n",
       "       [8.47849657e-01],\n",
       "       [8.70617998e-01],\n",
       "       [8.91579328e-01],\n",
       "       [9.09649440e-01],\n",
       "       [9.23382725e-01],\n",
       "       [9.33140585e-01],\n",
       "       [9.40368630e-01],\n",
       "       [9.45428262e-01],\n",
       "       [9.50487893e-01],\n",
       "       [9.56270329e-01],\n",
       "       [9.62052765e-01],\n",
       "       [9.68558005e-01],\n",
       "       [9.74340441e-01],\n",
       "       [9.80122877e-01],\n",
       "       [9.86628117e-01],\n",
       "       [9.93133357e-01],\n",
       "       [9.98192989e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.97470184e-01],\n",
       "       [9.90603542e-01],\n",
       "       [9.81568486e-01],\n",
       "       [9.71087821e-01],\n",
       "       [9.60245754e-01],\n",
       "       [9.49403686e-01],\n",
       "       [9.38923021e-01],\n",
       "       [9.26996747e-01],\n",
       "       [9.12902060e-01],\n",
       "       [8.98084568e-01],\n",
       "       [8.83267076e-01],\n",
       "       [8.68088182e-01],\n",
       "       [8.52186484e-01],\n",
       "       [8.34839176e-01],\n",
       "       [8.15684857e-01],\n",
       "       [7.92916516e-01],\n",
       "       [7.66172750e-01],\n",
       "       [7.34369353e-01],\n",
       "       [6.99674738e-01],\n",
       "       [6.64257318e-01],\n",
       "       [6.28839899e-01],\n",
       "       [5.95952295e-01],\n",
       "       [5.64871702e-01],\n",
       "       [5.34875316e-01],\n",
       "       [5.06685941e-01],\n",
       "       [4.80664980e-01],\n",
       "       [4.55728226e-01],\n",
       "       [4.31875678e-01],\n",
       "       [4.08384532e-01],\n",
       "       [3.84531984e-01],\n",
       "       [3.60679436e-01],\n",
       "       [3.36465486e-01],\n",
       "       [3.10805927e-01],\n",
       "       [2.84784966e-01],\n",
       "       [2.59125407e-01],\n",
       "       [2.34911456e-01],\n",
       "       [2.15757138e-01],\n",
       "       [2.02385255e-01],\n",
       "       [1.92988797e-01],\n",
       "       [1.86844958e-01],\n",
       "       [1.84315143e-01],\n",
       "       [1.84315143e-01],\n",
       "       [1.85399349e-01],\n",
       "       [1.85760752e-01],\n",
       "       [1.87929165e-01],\n",
       "       [1.87206361e-01],\n",
       "       [1.83592338e-01],\n",
       "       [1.80701120e-01],\n",
       "       [1.75280087e-01],\n",
       "       [1.67329237e-01],\n",
       "       [1.60823997e-01],\n",
       "       [1.53234550e-01],\n",
       "       [1.46367907e-01],\n",
       "       [1.40224069e-01],\n",
       "       [1.32634622e-01],\n",
       "       [1.27574991e-01],\n",
       "       [1.22876762e-01],\n",
       "       [1.18539935e-01],\n",
       "       [1.13118901e-01],\n",
       "       [1.07336465e-01],\n",
       "       [1.00831225e-01],\n",
       "       [9.46873871e-02],\n",
       "       [8.74593422e-02],\n",
       "       [8.31225154e-02],\n",
       "       [7.95084930e-02],\n",
       "       [7.58944705e-02],\n",
       "       [7.87856885e-02],\n",
       "       [8.16769064e-02],\n",
       "       [8.42067221e-02],\n",
       "       [8.56523310e-02],\n",
       "       [8.96277557e-02],\n",
       "       [9.54101915e-02],\n",
       "       [1.05890857e-01],\n",
       "       [1.17455728e-01],\n",
       "       [1.27936393e-01],\n",
       "       [1.35525840e-01],\n",
       "       [1.42031081e-01],\n",
       "       [1.53595952e-01],\n",
       "       [1.64799422e-01],\n",
       "       [1.75280087e-01],\n",
       "       [1.85399349e-01],\n",
       "       [1.99132635e-01],\n",
       "       [2.16479942e-01],\n",
       "       [2.35995663e-01],\n",
       "       [2.51897362e-01],\n",
       "       [2.64907842e-01],\n",
       "       [2.77918323e-01],\n",
       "       [2.93097217e-01],\n",
       "       [3.04662089e-01]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset with 60 timesteps (5 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60,len(train_data_scaled)):\n",
    "    X_train.append(train_data_scaled[i-60:i])\n",
    "    y_train.append(train_data_scaled[i])\n",
    "\n",
    "data_total = pd.concat((train.iloc[:,x:x+1], test.iloc[:,x:x+1]),axis=0)\n",
    "inputs = data_total[len(train)-60:].values\n",
    "inputs = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(60,len(inputs)):\n",
    "    X_test.append(inputs[i-60:i])\n",
    "    y_test.append(inputs[i])\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn data into arrays for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60)                14880     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 14,941\n",
      "Trainable params: 14,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(units= 60, return_sequences = False, input_shape=((60,1))))\n",
    "rnn_model.add(Dense(units=1))\n",
    "rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1800\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0610\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0283\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0209\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0129\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0138\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0104\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0085\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0070\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0054\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0042\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0028\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0017\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0014\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0015\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0014\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0013\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0011\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0012\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0011\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0011\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0011\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0010\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0010\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.7653e-04\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.7046e-04\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.5560e-04\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3822e-04\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 9.4218e-04\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8758e-04\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3800e-04\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.3793e-04\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.0161e-04\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.8296e-04\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6561e-04\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5745e-04\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.4442e-04\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3239e-04\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2540e-04\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2107e-04\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0897e-04\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0878e-04\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0019e-04\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.9774e-04\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8967e-04\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7020e-04\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5947e-04\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5615e-04\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.5834e-04\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3402e-04\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5048e-04\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5186e-04\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1722e-04\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0393e-04\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.9652e-04\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8885e-04\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 6.7986e-04\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7359e-04\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7265e-04\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7560e-04\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9193e-04\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7077e-04\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7955e-04\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3817e-04\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3208e-04\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3412e-04\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1149e-04\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1001e-04\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0136e-04\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1294e-04\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9483e-04\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8112e-04\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8181e-04\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9544e-04\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.9005e-04\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.7343e-04\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.8056e-04\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4621e-04\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.4275e-04\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5337e-04\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2372e-04\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 5.2326e-04\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5823e-04\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7360e-04\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1046e-04\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1144e-04\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9033e-04\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8977e-04\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7945e-04\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8604e-04\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7940e-04\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 4.8674e-04\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 4.7264e-04\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.9217e-04\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.6844e-04\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.4436e-04\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3616e-04\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.3048e-04\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.2804e-04\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 4.3640e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe91a5c6a60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(X_train, y_train, epochs=100, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_raw = rnn_model.predict(X_test)\n",
    "y_hat = scaler.inverse_transform(y_hat_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test, color='red', label='Real Prices')\n",
    "plt.plot(y_hat, color='blue', label='Predicted Prices')\n",
    "plt.title('Unseen Data Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although our model was successful on the first zipcode, when we check its success on other zipcodes we see that the results are not always good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_in = open('jupyter_files/rnn_mape.pickle','rb')\n",
    "rnn_mape = pickle.load(print_in)\n",
    "print_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average our first RNN model has MAPE value of 20%. We can use this model for some zipcodes but not all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.201744244348875"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_in = open('jupyter_files/rnn_mape2.pickle','rb')\n",
    "rnn_mape2 = pickle.load(print_in)\n",
    "print_in.close()\n",
    "print_in = open('jupyter_files/rnn_mape3.pickle','rb')\n",
    "rnn_mape3 = pickle.load(print_in)\n",
    "print_in.close()\n",
    "print_in = open('jupyter_files/rnn_mape4.pickle','rb')\n",
    "rnn_mape4 = pickle.load(print_in)\n",
    "print_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_in = open('jupyter_files/rnn_dict.pickle','rb')\n",
    "rnn_dict = pickle.load(print_in)\n",
    "print_in.close()\n",
    "print_in = open('jupyter_files/rnn_dict2.pickle','rb')\n",
    "rnn_dict2 = pickle.load(print_in)\n",
    "print_in.close()\n",
    "print_in = open('jupyter_files/rnn_dict3.pickle','rb')\n",
    "rnn_dict3 = pickle.load(print_in)\n",
    "print_in.close()\n",
    "print_in = open('jupyter_files/rnn_dict4.pickle','rb')\n",
    "rnn_dict4 = pickle.load(print_in)\n",
    "print_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2113528638887323, 0.20615423245296247, 0.2119248143820323)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_mape2), np.mean(rnn_mape3), np.mean(rnn_mape4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_dict_keys = []\n",
    "for key in rnn_dict.keys():\n",
    "    rnn_dict_keys.append(zipcode_converter[key])\n",
    "rnn_model_dict = dict(zip(rnn_dict_keys, rnn_dict.values()))\n",
    "rnn_dict_keys2 = []\n",
    "for key in rnn_dict2.keys():\n",
    "    rnn_dict_keys2.append(zipcode_converter[key])\n",
    "rnn_model_dict2 = dict(zip(rnn_dict_keys2, rnn_dict2.values()))\n",
    "rnn_dict_keys3 = []\n",
    "for key in rnn_dict3.keys():\n",
    "    rnn_dict_keys3.append(zipcode_converter[key])\n",
    "rnn_model_dict3 = dict(zip(rnn_dict_keys3, rnn_dict3.values()))\n",
    "rnn_dict_keys4 = []\n",
    "for key in rnn_dict4.keys():\n",
    "    rnn_dict_keys4.append(zipcode_converter[key])\n",
    "rnn_model_dict4 = dict(zip(rnn_dict_keys4, rnn_dict4.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook Prophet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model below iterates over every zipcode in Nevada and predecits the prices in May 2018. It cross validates the model fitted with 17 years of training data, one year of validation set (horizon) and the model makes predictions per zipcode for each year between 2013 and 2017. It returns average Mean Absolute Percentage Error (MAPE) for each zipcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_in = open('jupyter_files/fbp_mape2.pickle','rb')\n",
    "fbp_mape2_ = pickle.load(print_in)\n",
    "print_in.close()\n",
    "print_in = open('jupyter_files/fbp_mape.pickle','rb')\n",
    "fbp_mape_ = pickle.load(print_in)\n",
    "print_in.close()\n",
    "print_in = open('jupyter_files/fbp_pred2.pickle','rb')\n",
    "fbp_pred2_ = pickle.load(print_in)\n",
    "print_in.close()\n",
    "print_in = open('jupyter_files/fbp_pred.pickle','rb')\n",
    "fbp_pred_ = pickle.load(print_in)\n",
    "print_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbp_keys = list(fbp_mape_.keys())\n",
    "fbp_mape = list(fbp_mape_.values())\n",
    "fbp_pred = []\n",
    "fbp_dict = {}\n",
    "for zipcode in fbp_pred_.keys():\n",
    "    fbp_pred.append(fbp_pred_[zipcode].astype(int))\n",
    "for zc in fbp_keys:\n",
    "    a = []\n",
    "    a.append(fbp_mape_[zc])\n",
    "    a.append(fbp_pred_[zc].astype(float))\n",
    "    a.append('FBP_scale=0.5')\n",
    "    fbp_dict[zipcode_converter[zc]] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbp_keys2 = list(fbp_mape2_.keys())\n",
    "fbp_mape2 = list(fbp_mape2_.values())\n",
    "fbp_pred2 = []\n",
    "fbp_dict2 = {}\n",
    "for zipcode2 in fbp_pred2_.keys():\n",
    "    fbp_pred2.append(fbp_pred2_[zipcode].astype(int))\n",
    "for zc in fbp_keys2:\n",
    "    a = []\n",
    "    a.append(fbp_mape2_[zc])\n",
    "    a.append(fbp_pred2_[zc].astype(float))\n",
    "    a.append('FBP_scale=0.25')\n",
    "    fbp_dict2[zipcode_converter[zc]] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89005: [0.06201812204786679, 306424.2937773095, 'FBP_scale=0.25'],\n",
       " 89011: [0.07365250988633827, 261756.02208454325, 'FBP_scale=0.25'],\n",
       " 89012: [0.05968572468179214, 339800.2000154268, 'FBP_scale=0.25'],\n",
       " 89014: [0.04821833597534795, 285310.6731272519, 'FBP_scale=0.25'],\n",
       " 89015: [0.06071354411346397, 249675.968724543, 'FBP_scale=0.25'],\n",
       " 89021: [0.055411917518816696, 314914.61125532206, 'FBP_scale=0.25'],\n",
       " 89027: [0.03519882691258607, 232696.08040677305, 'FBP_scale=0.25'],\n",
       " 89029: [0.051091422023326595, 182731.03140031238, 'FBP_scale=0.25'],\n",
       " 89030: [0.06394259446634014, 149729.67426600133, 'FBP_scale=0.25'],\n",
       " 89031: [0.07358537937188435, 239500.18036715218, 'FBP_scale=0.25'],\n",
       " 89032: [0.08398816189546444, 224538.93967787863, 'FBP_scale=0.25'],\n",
       " 89040: [0.05651007004529196, 202263.96185782555, 'FBP_scale=0.25'],\n",
       " 89044: [0.05480307208535111, 346865.3214184451, 'FBP_scale=0.25'],\n",
       " 89048: [0.07346922582325782, 192268.57160478728, 'FBP_scale=0.25'],\n",
       " 89052: [0.05160073139390173, 408455.1007084131, 'FBP_scale=0.25'],\n",
       " 89060: [0.07508041860474877, 140046.4636205087, 'FBP_scale=0.25'],\n",
       " 89061: [0.04173793453097183, 210962.23877813178, 'FBP_scale=0.25'],\n",
       " 89074: [0.05823448469209629, 307245.97453323455, 'FBP_scale=0.25'],\n",
       " 89081: [0.07988008212600535, 247859.00479385388, 'FBP_scale=0.25'],\n",
       " 89084: [0.05196108107054192, 292415.17779619165, 'FBP_scale=0.25'],\n",
       " 89085: [0.054902119390825274, 319237.34369887144, 'FBP_scale=0.25'],\n",
       " 89086: [0.05734459616612111, 271210.5025689838, 'FBP_scale=0.25'],\n",
       " 89102: [0.08882821624225642, 216268.46477319358, 'FBP_scale=0.25'],\n",
       " 89103: [0.0613755436701972, 249944.97786231022, 'FBP_scale=0.25'],\n",
       " 89104: [0.06752024184066739, 203336.29925138075, 'FBP_scale=0.25'],\n",
       " 89107: [0.08941555258984855, 190346.98033598132, 'FBP_scale=0.25'],\n",
       " 89108: [0.10638600185284454, 203670.28393893747, 'FBP_scale=0.25'],\n",
       " 89109: [0.08402851797249046, 309304.6507585303, 'FBP_scale=0.25'],\n",
       " 89110: [0.08245133784860126, 193807.67767045673, 'FBP_scale=0.25'],\n",
       " 89113: [0.057094809818976994, 302848.42046248016, 'FBP_scale=0.25'],\n",
       " 89115: [0.06287084763476343, 174528.31786223126, 'FBP_scale=0.25'],\n",
       " 89117: [0.054988136193373525, 334395.65624192916, 'FBP_scale=0.25'],\n",
       " 89118: [0.04863608486027711, 264896.0680533635, 'FBP_scale=0.25'],\n",
       " 89119: [0.08240098918024064, 233409.14541616835, 'FBP_scale=0.25'],\n",
       " 89120: [0.05339732999418989, 259329.23385056897, 'FBP_scale=0.25'],\n",
       " 89121: [0.08306947511056705, 205007.90166042143, 'FBP_scale=0.25'],\n",
       " 89122: [0.08467782113882713, 206026.4801507274, 'FBP_scale=0.25'],\n",
       " 89123: [0.054470105801516795, 296447.8469940399, 'FBP_scale=0.25'],\n",
       " 89124: [0.046574614652851516, 335929.51985472924, 'FBP_scale=0.25'],\n",
       " 89128: [0.061293277666275785, 273203.0960221163, 'FBP_scale=0.25'],\n",
       " 89129: [0.06323378930456068, 279396.1125703646, 'FBP_scale=0.25'],\n",
       " 89130: [0.061530143896382006, 268902.2289005707, 'FBP_scale=0.25'],\n",
       " 89131: [0.055759532116926976, 332228.8241706238, 'FBP_scale=0.25'],\n",
       " 89134: [0.07344383541323186, 315147.59170003945, 'FBP_scale=0.25'],\n",
       " 89135: [0.04759228470055685, 412621.0246881532, 'FBP_scale=0.25'],\n",
       " 89138: [0.053430251618437036, 428910.64611480746, 'FBP_scale=0.25'],\n",
       " 89139: [0.0529232197439818, 279655.9738728567, 'FBP_scale=0.25'],\n",
       " 89141: [0.061909412922645964, 312064.6268908113, 'FBP_scale=0.25'],\n",
       " 89142: [0.08298236375922931, 207443.960892111, 'FBP_scale=0.25'],\n",
       " 89143: [0.07356271971832927, 271709.0598639721, 'FBP_scale=0.25'],\n",
       " 89144: [0.04344865692138911, 341922.52354961145, 'FBP_scale=0.25'],\n",
       " 89145: [0.059492338948251476, 239542.6193352032, 'FBP_scale=0.25'],\n",
       " 89146: [0.055205242548861326, 312416.64989647374, 'FBP_scale=0.25'],\n",
       " 89147: [0.03973859389875722, 266905.8837731588, 'FBP_scale=0.25'],\n",
       " 89148: [0.0668088512223091, 297591.0814638458, 'FBP_scale=0.25'],\n",
       " 89149: [0.05640106722711147, 301516.0896666878, 'FBP_scale=0.25'],\n",
       " 89155: [0.0457850831021565, 355044.22728155495, 'FBP_scale=0.25'],\n",
       " 89156: [0.08931563087100948, 201471.3184378717, 'FBP_scale=0.25'],\n",
       " 89166: [0.05348085316738132, 282464.2600328771, 'FBP_scale=0.25'],\n",
       " 89178: [0.06033124724441829, 287182.42096580623, 'FBP_scale=0.25'],\n",
       " 89179: [0.058057410554357695, 295028.95570716244, 'FBP_scale=0.25'],\n",
       " 89403: [0.03880388276284462, 273950.0728692895, 'FBP_scale=0.25'],\n",
       " 89408: [0.04165883311524539, 238263.91578616147, 'FBP_scale=0.25'],\n",
       " 89410: [0.04090713892601458, 377871.0361325551, 'FBP_scale=0.25'],\n",
       " 89411: [0.03344194059900488, 657652.3265985141, 'FBP_scale=0.25'],\n",
       " 89413: [0.0679511941859865, 2165940.3018131847, 'FBP_scale=0.25'],\n",
       " 89423: [0.030391062037521174, 407064.4738203172, 'FBP_scale=0.25'],\n",
       " 89429: [0.04978372874681996, 186215.36970146015, 'FBP_scale=0.25'],\n",
       " 89431: [0.05300231286132883, 248235.6692823612, 'FBP_scale=0.25'],\n",
       " 89433: [0.046913910071627506, 271196.09146320523, 'FBP_scale=0.25'],\n",
       " 89434: [0.06461519991308802, 296467.117629874, 'FBP_scale=0.25'],\n",
       " 89436: [0.03994476848346224, 365970.6940819523, 'FBP_scale=0.25'],\n",
       " 89439: [0.04142406284432444, 455025.7395764808, 'FBP_scale=0.25'],\n",
       " 89440: [0.08435104402860281, 206695.5881689991, 'FBP_scale=0.25'],\n",
       " 89444: [0.05328603140495205, 278693.85905661684, 'FBP_scale=0.25'],\n",
       " 89447: [0.052468306294546775, 163523.22849060956, 'FBP_scale=0.25'],\n",
       " 89448: [0.05168981628344627, 710021.985714725, 'FBP_scale=0.25'],\n",
       " 89449: [0.04503455722459935, 382032.7263551991, 'FBP_scale=0.25'],\n",
       " 89451: [0.02873060561227232, 977813.6054862305, 'FBP_scale=0.25'],\n",
       " 89460: [0.06120082481968843, 326006.0615921337, 'FBP_scale=0.25'],\n",
       " 89501: [0.07997789617539307, 335395.78277561127, 'FBP_scale=0.25'],\n",
       " 89502: [0.045274175110813025, 278678.39763927174, 'FBP_scale=0.25'],\n",
       " 89503: [0.05928133495508902, 305224.8080268096, 'FBP_scale=0.25'],\n",
       " 89506: [0.04082243623549185, 278613.76532849367, 'FBP_scale=0.25'],\n",
       " 89509: [0.041183689849330775, 443886.93189735134, 'FBP_scale=0.25'],\n",
       " 89510: [0.04520739319913953, 429507.99603171286, 'FBP_scale=0.25'],\n",
       " 89511: [0.0330339383781686, 660782.3885315718, 'FBP_scale=0.25'],\n",
       " 89512: [0.045846573810187925, 229820.05549287627, 'FBP_scale=0.25'],\n",
       " 89521: [0.02981839064430213, 412283.3134966297, 'FBP_scale=0.25'],\n",
       " 89523: [0.0403277213099636, 393012.9235382653, 'FBP_scale=0.25'],\n",
       " 89701: [0.02865404703766908, 272239.1639304633, 'FBP_scale=0.25'],\n",
       " 89703: [0.029916086829161328, 409777.3809141829, 'FBP_scale=0.25'],\n",
       " 89704: [0.06478984928930635, 417174.74155748467, 'FBP_scale=0.25'],\n",
       " 89705: [0.06007935977686581, 319463.1876422947, 'FBP_scale=0.25'],\n",
       " 89706: [0.02828238783701966, 270680.19014534075, 'FBP_scale=0.25'],\n",
       " 89801: [0.04094683357836647, 240523.77163825525, 'FBP_scale=0.25'],\n",
       " 89815: [0.04115115899088693, 235806.43680779455, 'FBP_scale=0.25'],\n",
       " 89002: [0.05268053822109995, 298518.7159311843, 'FBP_scale=0.25'],\n",
       " 89034: [0.047640505805931495, 314865.9754130793, 'FBP_scale=0.25'],\n",
       " 89183: [0.07111863616379589, 269956.81227986765, 'FBP_scale=0.25'],\n",
       " 89441: [0.04559293428386412, 413714.6903747773, 'FBP_scale=0.25'],\n",
       " 89508: [0.03874466758011615, 300945.2924840348, 'FBP_scale=0.25'],\n",
       " 89519: [0.03862505604319328, 536543.3302232787, 'FBP_scale=0.25']}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbp_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.037575237987934114, 0.056519773001086626)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(fbp_mape), np.mean(fbp_mape2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA - SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_in = open('jupyter_files/SARIMAX_summary.pickl','rb')\n",
    "sarimax_dict = pickle.load(print_in)\n",
    "print_in.close()\n",
    "print_in = open('jupyter_files/SARIMA_summary.pickl','rb')\n",
    "sarima_dict = pickle.load(print_in)\n",
    "print_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14147840001613393"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sarima_dict.values())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_model_dict = {}\n",
    "for z in range(len(sarima_dict.keys())):\n",
    "    a = []\n",
    "    a.append(list(sarima_dict.values())[z][1])\n",
    "    a.append(list(sarima_dict.values())[z][0])\n",
    "    a.append(list(sarima_dict.values())[z][2])\n",
    "    sarima_model_dict[list(sarima_dict.keys())[z]] = a\n",
    "\n",
    "sarimax_model_dict = {}\n",
    "for z in range(len(sarimax_dict.keys())):\n",
    "    a = []\n",
    "    a.append(list(sarimax_dict.values())[z][1])\n",
    "    a.append(list(sarimax_dict.values())[z][0])\n",
    "    a.append(list(sarimax_dict.values())[z][2])\n",
    "    sarimax_model_dict[list(sarimax_dict.keys())[z]] = a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_mape_list = []\n",
    "for z in range(len(sarima_dict.keys())):\n",
    "    sarima_mape_list.append(list(sarima_dict.values())[z][1])\n",
    "\n",
    "sarimax_mape_list = []\n",
    "for z in range(len(sarimax_dict.keys())):\n",
    "    sarimax_mape_list.append(list(sarimax_dict.values())[z][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rnn_model_dict, rnn_model_dict2, rnn_model_dict3, rnn_model_dict4, fbp_dict, fbp_dict2, sarima_model_dict, sarimax_model_dict]\n",
    "best_model_dict = {}\n",
    "for zipcode in sarima_model_dict.keys():\n",
    "    best_model = [1,1]\n",
    "    for model in models:\n",
    "        if model[zipcode][0]<best_model[0]:\n",
    "            best_model = model[zipcode]\n",
    "    best_model_dict[zipcode] = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89102: [0.040796909553926605, 220765.39635029866, 'FBP_scale=0.5'],\n",
       " 89103: [0.013505008741549612, 251018.2237947004, 'Sarimax'],\n",
       " 89104: [0.03320603155912621, 212632.1144190938, 'FBP_scale=0.5'],\n",
       " 89107: [0.05935506051263894, 198917.1941191062, 'FBP_scale=0.5'],\n",
       " 89108: [0.053552150532358844, 212876.99612153973, 'FBP_scale=0.5'],\n",
       " 89109: [0.06120353804433491, 310200.0, 'Sarimax'],\n",
       " 89110: [0.04725188507969076, 200482.01372467002, 'FBP_scale=0.5'],\n",
       " 89113: [0.008562374309784411, 308646.96875, 'RNN_2_Layers'],\n",
       " 89115: [0.047750494294313994, 177213.75103653304, 'SARIMA'],\n",
       " 89117: [0.010808055744779672, 343835.59375, 'RNN_2_Layers'],\n",
       " 89118: [0.030271458421119, 271179.49889021384, 'FBP_scale=0.5'],\n",
       " 89119: [0.026782273794856256, 241955.26361875163, 'FBP_scale=0.5'],\n",
       " 89120: [0.04554779842216769, 267252.62681162066, 'FBP_scale=0.5'],\n",
       " 89121: [0.03251929889460807, 212357.25585671476, 'FBP_scale=0.5'],\n",
       " 89122: [0.014471367203184187, 207761.12401967685, 'Sarimax'],\n",
       " 89123: [0.011060594461016884, 303811.84375, 'RNN_w/_D.o.'],\n",
       " 89124: [0.026793016022013318, 333740.6875, 'RNN'],\n",
       " 89128: [0.029905361981916723, 280846.724090128, 'FBP_scale=0.5'],\n",
       " 89129: [0.026517157639345555, 286423.08475005795, 'FBP_scale=0.5'],\n",
       " 89130: [0.002526419421375282, 275900.0, 'SARIMA'],\n",
       " 89131: [0.007603622823857905, 336967.1875, 'RNN_w/_D.o.'],\n",
       " 89134: [0.010556710001477967, 318089.5, 'RNN_2_Layers'],\n",
       " 89135: [0.010588402896257164, 421104.15625, 'RNN_2_Layers'],\n",
       " 89138: [0.010040520321775439, 439585.46875, 'RNN_2_Layers'],\n",
       " 89139: [0.022660792941314484, 292820.991054985, 'Sarimax'],\n",
       " 89141: [0.007663622906824243, 320045.84375, 'RNN_w/_D.o.'],\n",
       " 89142: [0.04194677994191061, 213715.51190621968, 'FBP_scale=0.5'],\n",
       " 89143: [0.013403365697682666, 286015.15625, 'RNN_2_layer_w/_D.o.'],\n",
       " 89144: [0.01030218372133625, 347827.71875, 'RNN'],\n",
       " 89145: [0.0008142248100808708, 246600.0, 'SARIMA'],\n",
       " 89146: [0.042324631114278415, 320103.6004428028, 'FBP_scale=0.5'],\n",
       " 89147: [0.007487177291230405, 275289.6117730886, 'Sarimax'],\n",
       " 89148: [0.009709705808756491, 305326.5625, 'RNN_w/_D.o.'],\n",
       " 89149: [0.03378183762916275, 308219.1848478401, 'FBP_scale=0.5'],\n",
       " 89155: [0.00911636346264891, 361679.90625, 'RNN_2_Layers'],\n",
       " 89156: [0.02674436424617439, 198687.54447183444, 'Sarimax'],\n",
       " 89166: [0.008910244261769715, 292220.53125, 'RNN_2_Layers'],\n",
       " 89178: [0.0060464769748770665, 294301.125, 'RNN'],\n",
       " 89179: [0.006428252410216056, 306795.75, 'RNN_w/_D.o.'],\n",
       " 89183: [0.02214623716054758, 277100.0, 'SARIMA'],\n",
       " 89701: [0.009495231708585497, 266254.875, 'RNN'],\n",
       " 89703: [0.010090192830097204, 399326.6875, 'RNN'],\n",
       " 89704: [0.02124960986573491, 423724.21875, 'RNN'],\n",
       " 89705: [0.02446487880320502, 315065.6875, 'RNN'],\n",
       " 89706: [0.012981924290519522, 267417.28125, 'RNN'],\n",
       " 89801: [0.006187413739119031, 241320.45774415805, 'Sarimax'],\n",
       " 89815: [0.006400237419689217, 240515.54386007288, 'SARIMA'],\n",
       " 89403: [0.000157528604278399, 261200.0, 'Sarimax'],\n",
       " 89408: [0.025500668117786097, 247600.0, 'SARIMA'],\n",
       " 89410: [0.01847956218986767, 367463.875, 'RNN'],\n",
       " 89413: [0.023259901004509066, 2082682.875, 'RNN_2_Layers'],\n",
       " 89423: [0.015790881595813135, 398780.40625, 'RNN'],\n",
       " 89429: [0.028895784389672496, 180100.0, 'Sarimax'],\n",
       " 89431: [0.040307572198368696, 251931.37670638357, 'FBP_scale=0.5'],\n",
       " 89433: [0.0005108429453951003, 266219.3103974229, 'Sarimax'],\n",
       " 89434: [0.029842591764519064, 298900.0, 'SARIMA'],\n",
       " 89436: [0.008542734632539075, 350383.1195393214, 'Sarimax'],\n",
       " 89439: [0.010913525910615451, 453697.84375, 'RNN_w/_D.o.'],\n",
       " 89440: [0.007772845367175855, 190700.0, 'SARIMA'],\n",
       " 89441: [0.012774884508413867, 423790.8125, 'RNN_w/_D.o.'],\n",
       " 89444: [0.018229440515598945, 279638.8125, 'RNN_2_Layers'],\n",
       " 89447: [0.03528869275268434, 168143.63871695238, 'FBP_scale=0.5'],\n",
       " 89451: [0.018112257056903527, 924405.6875, 'RNN_w/_D.o.'],\n",
       " 89460: [0.010941537657845212, 323434.82118251105, 'Sarimax'],\n",
       " 89501: [0.03876847845117795, 338159.3125, 'RNN'],\n",
       " 89502: [0.020103747985949223, 284076.71654429485, 'FBP_scale=0.5'],\n",
       " 89503: [0.03637168547020822, 308500.0, 'SARIMA'],\n",
       " 89506: [0.030989881767913532, 280461.8992750567, 'FBP_scale=0.5'],\n",
       " 89508: [0.017187629795996175, 301861.70888802106, 'FBP_scale=0.5'],\n",
       " 89509: [0.0020215231923034213, 448300.0, 'SARIMA'],\n",
       " 89510: [0.023540595917550224, 426174.78125, 'RNN_w/_D.o.'],\n",
       " 89511: [0.003694680749998023, 645335.5207436061, 'Sarimax'],\n",
       " 89512: [0.026809410226305137, 221200.0, 'Sarimax'],\n",
       " 89002: [0.014149467428044914, 302807.65625, 'RNN'],\n",
       " 89005: [0.00984138429584488, 318896.78125, 'RNN'],\n",
       " 89519: [0.013792924062759431, 540005.875, 'RNN'],\n",
       " 89521: [0.00899301301814151, 411977.78125, 'RNN_2_Layers'],\n",
       " 89011: [0.012161211967476323, 269634.9375, 'RNN_2_Layers'],\n",
       " 89012: [0.006466971191703606, 348101.21875, 'RNN_w/_D.o.'],\n",
       " 89523: [0.009420181348985288, 393342.9375, 'RNN'],\n",
       " 89014: [0.02982231867033438, 290775.76827606466, 'FBP_scale=0.5'],\n",
       " 89015: [0.020673062452361255, 255266.9013634051, 'FBP_scale=0.5'],\n",
       " 89027: [0.00854011861571219, 239586.078125, 'RNN'],\n",
       " 89029: [0.0280397544224704, 182509.39476487262, 'FBP_scale=0.5'],\n",
       " 89030: [0.03602921269009029, 153247.78988254067, 'FBP_scale=0.5'],\n",
       " 89031: [0.03434730300348244, 246300.94475486007, 'FBP_scale=0.5'],\n",
       " 89032: [0.045912141431496335, 234114.60925612983, 'FBP_scale=0.5'],\n",
       " 89040: [0.01355241057158235, 208000.671875, 'RNN_w/_D.o.'],\n",
       " 89044: [0.010431262544918843, 354796.84375, 'RNN_2_Layers'],\n",
       " 89048: [0.021176351320032483, 203400.0, 'SARIMA'],\n",
       " 89052: [0.010358055443760965, 421466.875, 'RNN_w/_D.o.'],\n",
       " 89060: [0.010881303950512667, 160181.2983059608, 'SARIMA'],\n",
       " 89061: [0.026594641129514852, 226000.0, 'SARIMA'],\n",
       " 89074: [0.007388430655138559, 312865.75, 'RNN'],\n",
       " 89081: [0.04179429582249042, 255788.3319140967, 'FBP_scale=0.5'],\n",
       " 89084: [0.009597087395329643, 296469.84375, 'RNN'],\n",
       " 89085: [0.0014712542353133935, 330100.0, 'SARIMA'],\n",
       " 89086: [0.022623376705750278, 279634.99856473086, 'FBP_scale=0.5']}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'FBP_scale=0.5',\n",
       "  'RNN',\n",
       "  'RNN_2_Layers',\n",
       "  'RNN_2_layer_w/_D.o.',\n",
       "  'RNN_w/_D.o.',\n",
       "  'SARIMA',\n",
       "  'Sarimax'},\n",
       " [27, 14, 12, 14, 12, 1, 18])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_types = []\n",
    "for item in best_model_dict.values():\n",
    "    model_types.append([item[2]])\n",
    "list = []\n",
    "for item in model_types:\n",
    "    list.append(item[0])\n",
    "labels = set(list)\n",
    "sizes = []\n",
    "#list.count(labels[0])\n",
    "for i in labels:\n",
    "    sizes.append(list.count(i))\n",
    "labels, sizes\n",
    "labels2 = x = ['FB Prophet 50% Scaler', 'SARIMA','RNN w/ Dropout', 'SARIMAX','RNN 2 Layers','RNN 2 Layers w/ Dropout','RNN']\n",
    "labels, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1584x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explode = (0.1, 0.1, 0, 0.1, 0, 0, 0.1) \n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(22,10))\n",
    "ax1.pie(sizes, explode=explode, labels=labels2, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.xticks(fontsize= 50)\n",
    "plt.show()\n",
    "fig1.savefig('pie.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_mape_list = []\n",
    "for item in best_model_dict.values():\n",
    "    best_model_mape_list.append(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_1_mape = np.mean(rnn_mape)\n",
    "rnn_2_mape = np.mean(rnn_mape2)\n",
    "rnn_3_mape = np.mean(rnn_mape3)\n",
    "rnn_4_mape = np.mean(rnn_mape4)\n",
    "fbp_1_mape = np.mean(fbp_mape)\n",
    "fbp_2_mape = np.mean(fbp_mape2)\n",
    "sarima_mape = np.mean(sarima_mape_list)\n",
    "sarimax_mape = np.mean(sarimax_mape_list)\n",
    "best_model_mape = np.mean(best_model_mape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-223-de4837f53625>:7: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(['0%','2.5%','5%','7.5%','10%','12.5%','15%','17.5%','20%'])\n",
      "<ipython-input-223-de4837f53625>:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(labels = x, rotation=40)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1872x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(26,10))\n",
    "\n",
    "\n",
    "y = [rnn_1_mape,rnn_2_mape,rnn_3_mape,rnn_4_mape, fbp_1_mape, fbp_2_mape, sarima_mape, sarimax_mape, best_model_mape]\n",
    "x = ['RNN','RNN 2 Layers','RNN w/ Dropout','RNN 2 Layer w/ Dropout', 'FB Prophet 50% Scaler', 'FB Prophet 25% Scaler', 'SARIMA', 'SARIMAX', 'Fusion Model']\n",
    "ax.set_title('Model MAPE Improvement Chart')\n",
    "ax.set_yticklabels(['0%','2.5%','5%','7.5%','10%','12.5%','15%','17.5%','20%'])\n",
    "ax.set_xticklabels(labels = x, rotation=40)\n",
    "ax.set_ylabel('MAPE')\n",
    "ax.set_xlabel('Models')\n",
    "sns.barplot(x=x, y=y, palette=\"coolwarm\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_context(\"talk\");\n",
    "fig.savefig('model_improvement.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding our Best Models predictions to our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_columns = []\n",
    "for column in df_time_series.columns:\n",
    "    zipcode_columns.append(zipcode_converter[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.columns = zipcode_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>89108</th>\n",
       "      <th>89121</th>\n",
       "      <th>89117</th>\n",
       "      <th>89052</th>\n",
       "      <th>89123</th>\n",
       "      <th>89031</th>\n",
       "      <th>89110</th>\n",
       "      <th>89074</th>\n",
       "      <th>89103</th>\n",
       "      <th>89148</th>\n",
       "      <th>...</th>\n",
       "      <th>89444</th>\n",
       "      <th>89085</th>\n",
       "      <th>89034</th>\n",
       "      <th>89021</th>\n",
       "      <th>89439</th>\n",
       "      <th>89411</th>\n",
       "      <th>89124</th>\n",
       "      <th>89440</th>\n",
       "      <th>89413</th>\n",
       "      <th>89155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01</th>\n",
       "      <td>102500.0</td>\n",
       "      <td>106800.0</td>\n",
       "      <td>165100.0</td>\n",
       "      <td>185700.0</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>122800.0</td>\n",
       "      <td>95800.0</td>\n",
       "      <td>148000.0</td>\n",
       "      <td>118900.0</td>\n",
       "      <td>157300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>116800.0</td>\n",
       "      <td>170900.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153200.0</td>\n",
       "      <td>184200.0</td>\n",
       "      <td>299200.0</td>\n",
       "      <td>166100.0</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.0</td>\n",
       "      <td>176400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01</th>\n",
       "      <td>102500.0</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>164500.0</td>\n",
       "      <td>186300.0</td>\n",
       "      <td>143500.0</td>\n",
       "      <td>122800.0</td>\n",
       "      <td>95800.0</td>\n",
       "      <td>147800.0</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>156000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>170800.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153700.0</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>299600.0</td>\n",
       "      <td>166600.0</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562800.0</td>\n",
       "      <td>176300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01</th>\n",
       "      <td>102500.0</td>\n",
       "      <td>107200.0</td>\n",
       "      <td>164000.0</td>\n",
       "      <td>186900.0</td>\n",
       "      <td>143100.0</td>\n",
       "      <td>122700.0</td>\n",
       "      <td>95800.0</td>\n",
       "      <td>147600.0</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>154700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117200.0</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195900.0</td>\n",
       "      <td>154100.0</td>\n",
       "      <td>185800.0</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>167300.0</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562700.0</td>\n",
       "      <td>176100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01</th>\n",
       "      <td>102600.0</td>\n",
       "      <td>107400.0</td>\n",
       "      <td>163500.0</td>\n",
       "      <td>187400.0</td>\n",
       "      <td>142700.0</td>\n",
       "      <td>122700.0</td>\n",
       "      <td>95900.0</td>\n",
       "      <td>147300.0</td>\n",
       "      <td>119100.0</td>\n",
       "      <td>153500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117400.0</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195700.0</td>\n",
       "      <td>154400.0</td>\n",
       "      <td>186400.0</td>\n",
       "      <td>300200.0</td>\n",
       "      <td>167900.0</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.0</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01</th>\n",
       "      <td>102700.0</td>\n",
       "      <td>107600.0</td>\n",
       "      <td>163200.0</td>\n",
       "      <td>187700.0</td>\n",
       "      <td>142400.0</td>\n",
       "      <td>122700.0</td>\n",
       "      <td>96100.0</td>\n",
       "      <td>147100.0</td>\n",
       "      <td>119200.0</td>\n",
       "      <td>152600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117600.0</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195400.0</td>\n",
       "      <td>154700.0</td>\n",
       "      <td>186900.0</td>\n",
       "      <td>300500.0</td>\n",
       "      <td>168600.0</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562300.0</td>\n",
       "      <td>175900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>197300.0</td>\n",
       "      <td>198700.0</td>\n",
       "      <td>327100.0</td>\n",
       "      <td>403800.0</td>\n",
       "      <td>290400.0</td>\n",
       "      <td>231600.0</td>\n",
       "      <td>186600.0</td>\n",
       "      <td>300100.0</td>\n",
       "      <td>240400.0</td>\n",
       "      <td>291400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>266200.0</td>\n",
       "      <td>313100.0</td>\n",
       "      <td>311700.0</td>\n",
       "      <td>298300.0</td>\n",
       "      <td>444500.0</td>\n",
       "      <td>639300.0</td>\n",
       "      <td>316800.0</td>\n",
       "      <td>199800.0</td>\n",
       "      <td>2098400.0</td>\n",
       "      <td>348900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>200700.0</td>\n",
       "      <td>201500.0</td>\n",
       "      <td>330700.0</td>\n",
       "      <td>407300.0</td>\n",
       "      <td>294300.0</td>\n",
       "      <td>234600.0</td>\n",
       "      <td>189200.0</td>\n",
       "      <td>303500.0</td>\n",
       "      <td>243700.0</td>\n",
       "      <td>294100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>316500.0</td>\n",
       "      <td>315500.0</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>449500.0</td>\n",
       "      <td>642500.0</td>\n",
       "      <td>317600.0</td>\n",
       "      <td>201600.0</td>\n",
       "      <td>2121300.0</td>\n",
       "      <td>350400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>203500.0</td>\n",
       "      <td>204000.0</td>\n",
       "      <td>334600.0</td>\n",
       "      <td>410400.0</td>\n",
       "      <td>297400.0</td>\n",
       "      <td>237200.0</td>\n",
       "      <td>191700.0</td>\n",
       "      <td>306700.0</td>\n",
       "      <td>246300.0</td>\n",
       "      <td>296900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>275600.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>302500.0</td>\n",
       "      <td>450100.0</td>\n",
       "      <td>653800.0</td>\n",
       "      <td>323400.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>2153600.0</td>\n",
       "      <td>353000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>206600.0</td>\n",
       "      <td>206700.0</td>\n",
       "      <td>338800.0</td>\n",
       "      <td>413700.0</td>\n",
       "      <td>300200.0</td>\n",
       "      <td>239800.0</td>\n",
       "      <td>194500.0</td>\n",
       "      <td>309800.0</td>\n",
       "      <td>249500.0</td>\n",
       "      <td>299400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>282100.0</td>\n",
       "      <td>322400.0</td>\n",
       "      <td>323600.0</td>\n",
       "      <td>305700.0</td>\n",
       "      <td>451100.0</td>\n",
       "      <td>666000.0</td>\n",
       "      <td>334700.0</td>\n",
       "      <td>216500.0</td>\n",
       "      <td>2167100.0</td>\n",
       "      <td>356000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>209300.0</td>\n",
       "      <td>208600.0</td>\n",
       "      <td>342000.0</td>\n",
       "      <td>416100.0</td>\n",
       "      <td>302400.0</td>\n",
       "      <td>241900.0</td>\n",
       "      <td>196600.0</td>\n",
       "      <td>312200.0</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>300800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>286000.0</td>\n",
       "      <td>324700.0</td>\n",
       "      <td>326600.0</td>\n",
       "      <td>307800.0</td>\n",
       "      <td>455300.0</td>\n",
       "      <td>672600.0</td>\n",
       "      <td>344300.0</td>\n",
       "      <td>222800.0</td>\n",
       "      <td>2161900.0</td>\n",
       "      <td>357200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               89108     89121     89117     89052     89123     89031  \\\n",
       "1996-04-01  102500.0  106800.0  165100.0  185700.0  144000.0  122800.0   \n",
       "1996-05-01  102500.0  107000.0  164500.0  186300.0  143500.0  122800.0   \n",
       "1996-06-01  102500.0  107200.0  164000.0  186900.0  143100.0  122700.0   \n",
       "1996-07-01  102600.0  107400.0  163500.0  187400.0  142700.0  122700.0   \n",
       "1996-08-01  102700.0  107600.0  163200.0  187700.0  142400.0  122700.0   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2017-12-01  197300.0  198700.0  327100.0  403800.0  290400.0  231600.0   \n",
       "2018-01-01  200700.0  201500.0  330700.0  407300.0  294300.0  234600.0   \n",
       "2018-02-01  203500.0  204000.0  334600.0  410400.0  297400.0  237200.0   \n",
       "2018-03-01  206600.0  206700.0  338800.0  413700.0  300200.0  239800.0   \n",
       "2018-04-01  209300.0  208600.0  342000.0  416100.0  302400.0  241900.0   \n",
       "\n",
       "               89110     89074     89103     89148  ...     89444     89085  \\\n",
       "1996-04-01   95800.0  148000.0  118900.0  157300.0  ...  116800.0  170900.0   \n",
       "1996-05-01   95800.0  147800.0  119000.0  156000.0  ...  117000.0  170800.0   \n",
       "1996-06-01   95800.0  147600.0  119000.0  154700.0  ...  117200.0  170700.0   \n",
       "1996-07-01   95900.0  147300.0  119100.0  153500.0  ...  117400.0  170700.0   \n",
       "1996-08-01   96100.0  147100.0  119200.0  152600.0  ...  117600.0  170700.0   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2017-12-01  186600.0  300100.0  240400.0  291400.0  ...  266200.0  313100.0   \n",
       "2018-01-01  189200.0  303500.0  243700.0  294100.0  ...  270000.0  316500.0   \n",
       "2018-02-01  191700.0  306700.0  246300.0  296900.0  ...  275600.0  319500.0   \n",
       "2018-03-01  194500.0  309800.0  249500.0  299400.0  ...  282100.0  322400.0   \n",
       "2018-04-01  196600.0  312200.0  252000.0  300800.0  ...  286000.0  324700.0   \n",
       "\n",
       "               89034     89021     89439     89411     89124     89440  \\\n",
       "1996-04-01  196000.0  153200.0  184200.0  299200.0  166100.0  293200.0   \n",
       "1996-05-01  196000.0  153700.0  185000.0  299600.0  166600.0  293200.0   \n",
       "1996-06-01  195900.0  154100.0  185800.0  299900.0  167300.0  293200.0   \n",
       "1996-07-01  195700.0  154400.0  186400.0  300200.0  167900.0  293200.0   \n",
       "1996-08-01  195400.0  154700.0  186900.0  300500.0  168600.0  293200.0   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2017-12-01  311700.0  298300.0  444500.0  639300.0  316800.0  199800.0   \n",
       "2018-01-01  315500.0  299900.0  449500.0  642500.0  317600.0  201600.0   \n",
       "2018-02-01  319500.0  302500.0  450100.0  653800.0  323400.0  207000.0   \n",
       "2018-03-01  323600.0  305700.0  451100.0  666000.0  334700.0  216500.0   \n",
       "2018-04-01  326600.0  307800.0  455300.0  672600.0  344300.0  222800.0   \n",
       "\n",
       "                89413     89155  \n",
       "1996-04-01   562400.0  176400.0  \n",
       "1996-05-01   562800.0  176300.0  \n",
       "1996-06-01   562700.0  176100.0  \n",
       "1996-07-01   562400.0  176000.0  \n",
       "1996-08-01   562300.0  175900.0  \n",
       "...               ...       ...  \n",
       "2017-12-01  2098400.0  348900.0  \n",
       "2018-01-01  2121300.0  350400.0  \n",
       "2018-02-01  2153600.0  353000.0  \n",
       "2018-03-01  2167100.0  356000.0  \n",
       "2018-04-01  2161900.0  357200.0  \n",
       "\n",
       "[265 rows x 103 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_05_18 = []\n",
    "for zipcode in df_time_series.columns:\n",
    "    if zipcode in best_model_dict.keys():\n",
    "        predictions_05_18.append(best_model_dict[zipcode][1])\n",
    "    else:\n",
    "        predictions_05_18.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_05_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ferityikar/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df_time_series.loc['2018-05-01_pred'] = predictions_05_18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>89108</th>\n",
       "      <th>89121</th>\n",
       "      <th>89117</th>\n",
       "      <th>89052</th>\n",
       "      <th>89123</th>\n",
       "      <th>89031</th>\n",
       "      <th>89110</th>\n",
       "      <th>89074</th>\n",
       "      <th>89103</th>\n",
       "      <th>89148</th>\n",
       "      <th>...</th>\n",
       "      <th>89444</th>\n",
       "      <th>89085</th>\n",
       "      <th>89034</th>\n",
       "      <th>89021</th>\n",
       "      <th>89439</th>\n",
       "      <th>89411</th>\n",
       "      <th>89124</th>\n",
       "      <th>89440</th>\n",
       "      <th>89413</th>\n",
       "      <th>89155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>106800.000000</td>\n",
       "      <td>165100.00000</td>\n",
       "      <td>185700.000</td>\n",
       "      <td>144000.00000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>148000.00</td>\n",
       "      <td>118900.000000</td>\n",
       "      <td>157300.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>116800.0000</td>\n",
       "      <td>170900.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153200.0</td>\n",
       "      <td>184200.00000</td>\n",
       "      <td>299200.0</td>\n",
       "      <td>166100.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.000</td>\n",
       "      <td>176400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107000.000000</td>\n",
       "      <td>164500.00000</td>\n",
       "      <td>186300.000</td>\n",
       "      <td>143500.00000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147800.00</td>\n",
       "      <td>119000.000000</td>\n",
       "      <td>156000.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117000.0000</td>\n",
       "      <td>170800.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153700.0</td>\n",
       "      <td>185000.00000</td>\n",
       "      <td>299600.0</td>\n",
       "      <td>166600.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562800.000</td>\n",
       "      <td>176300.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107200.000000</td>\n",
       "      <td>164000.00000</td>\n",
       "      <td>186900.000</td>\n",
       "      <td>143100.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147600.00</td>\n",
       "      <td>119000.000000</td>\n",
       "      <td>154700.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117200.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195900.0</td>\n",
       "      <td>154100.0</td>\n",
       "      <td>185800.00000</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>167300.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562700.000</td>\n",
       "      <td>176100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01 00:00:00</th>\n",
       "      <td>102600.000000</td>\n",
       "      <td>107400.000000</td>\n",
       "      <td>163500.00000</td>\n",
       "      <td>187400.000</td>\n",
       "      <td>142700.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95900.000000</td>\n",
       "      <td>147300.00</td>\n",
       "      <td>119100.000000</td>\n",
       "      <td>153500.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117400.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195700.0</td>\n",
       "      <td>154400.0</td>\n",
       "      <td>186400.00000</td>\n",
       "      <td>300200.0</td>\n",
       "      <td>167900.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.000</td>\n",
       "      <td>176000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01 00:00:00</th>\n",
       "      <td>102700.000000</td>\n",
       "      <td>107600.000000</td>\n",
       "      <td>163200.00000</td>\n",
       "      <td>187700.000</td>\n",
       "      <td>142400.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>96100.000000</td>\n",
       "      <td>147100.00</td>\n",
       "      <td>119200.000000</td>\n",
       "      <td>152600.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117600.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195400.0</td>\n",
       "      <td>154700.0</td>\n",
       "      <td>186900.00000</td>\n",
       "      <td>300500.0</td>\n",
       "      <td>168600.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562300.000</td>\n",
       "      <td>175900.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>200700.000000</td>\n",
       "      <td>201500.000000</td>\n",
       "      <td>330700.00000</td>\n",
       "      <td>407300.000</td>\n",
       "      <td>294300.00000</td>\n",
       "      <td>234600.000000</td>\n",
       "      <td>189200.000000</td>\n",
       "      <td>303500.00</td>\n",
       "      <td>243700.000000</td>\n",
       "      <td>294100.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>270000.0000</td>\n",
       "      <td>316500.0</td>\n",
       "      <td>315500.0</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>449500.00000</td>\n",
       "      <td>642500.0</td>\n",
       "      <td>317600.0000</td>\n",
       "      <td>201600.0</td>\n",
       "      <td>2121300.000</td>\n",
       "      <td>350400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>203500.000000</td>\n",
       "      <td>204000.000000</td>\n",
       "      <td>334600.00000</td>\n",
       "      <td>410400.000</td>\n",
       "      <td>297400.00000</td>\n",
       "      <td>237200.000000</td>\n",
       "      <td>191700.000000</td>\n",
       "      <td>306700.00</td>\n",
       "      <td>246300.000000</td>\n",
       "      <td>296900.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>275600.0000</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>302500.0</td>\n",
       "      <td>450100.00000</td>\n",
       "      <td>653800.0</td>\n",
       "      <td>323400.0000</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>2153600.000</td>\n",
       "      <td>353000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>206600.000000</td>\n",
       "      <td>206700.000000</td>\n",
       "      <td>338800.00000</td>\n",
       "      <td>413700.000</td>\n",
       "      <td>300200.00000</td>\n",
       "      <td>239800.000000</td>\n",
       "      <td>194500.000000</td>\n",
       "      <td>309800.00</td>\n",
       "      <td>249500.000000</td>\n",
       "      <td>299400.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>282100.0000</td>\n",
       "      <td>322400.0</td>\n",
       "      <td>323600.0</td>\n",
       "      <td>305700.0</td>\n",
       "      <td>451100.00000</td>\n",
       "      <td>666000.0</td>\n",
       "      <td>334700.0000</td>\n",
       "      <td>216500.0</td>\n",
       "      <td>2167100.000</td>\n",
       "      <td>356000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>209300.000000</td>\n",
       "      <td>208600.000000</td>\n",
       "      <td>342000.00000</td>\n",
       "      <td>416100.000</td>\n",
       "      <td>302400.00000</td>\n",
       "      <td>241900.000000</td>\n",
       "      <td>196600.000000</td>\n",
       "      <td>312200.00</td>\n",
       "      <td>252000.000000</td>\n",
       "      <td>300800.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>286000.0000</td>\n",
       "      <td>324700.0</td>\n",
       "      <td>326600.0</td>\n",
       "      <td>307800.0</td>\n",
       "      <td>455300.00000</td>\n",
       "      <td>672600.0</td>\n",
       "      <td>344300.0000</td>\n",
       "      <td>222800.0</td>\n",
       "      <td>2161900.000</td>\n",
       "      <td>357200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01_pred</th>\n",
       "      <td>212876.996122</td>\n",
       "      <td>212357.255857</td>\n",
       "      <td>343835.59375</td>\n",
       "      <td>421466.875</td>\n",
       "      <td>303811.84375</td>\n",
       "      <td>246300.944755</td>\n",
       "      <td>200482.013725</td>\n",
       "      <td>312865.75</td>\n",
       "      <td>251018.223795</td>\n",
       "      <td>305326.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>279638.8125</td>\n",
       "      <td>330100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>453697.84375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333740.6875</td>\n",
       "      <td>190700.0</td>\n",
       "      <td>2082682.875</td>\n",
       "      <td>361679.90625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             89108          89121         89117       89052  \\\n",
       "1996-04-01 00:00:00  102500.000000  106800.000000  165100.00000  185700.000   \n",
       "1996-05-01 00:00:00  102500.000000  107000.000000  164500.00000  186300.000   \n",
       "1996-06-01 00:00:00  102500.000000  107200.000000  164000.00000  186900.000   \n",
       "1996-07-01 00:00:00  102600.000000  107400.000000  163500.00000  187400.000   \n",
       "1996-08-01 00:00:00  102700.000000  107600.000000  163200.00000  187700.000   \n",
       "...                            ...            ...           ...         ...   \n",
       "2018-01-01 00:00:00  200700.000000  201500.000000  330700.00000  407300.000   \n",
       "2018-02-01 00:00:00  203500.000000  204000.000000  334600.00000  410400.000   \n",
       "2018-03-01 00:00:00  206600.000000  206700.000000  338800.00000  413700.000   \n",
       "2018-04-01 00:00:00  209300.000000  208600.000000  342000.00000  416100.000   \n",
       "2018-05-01_pred      212876.996122  212357.255857  343835.59375  421466.875   \n",
       "\n",
       "                            89123          89031          89110      89074  \\\n",
       "1996-04-01 00:00:00  144000.00000  122800.000000   95800.000000  148000.00   \n",
       "1996-05-01 00:00:00  143500.00000  122800.000000   95800.000000  147800.00   \n",
       "1996-06-01 00:00:00  143100.00000  122700.000000   95800.000000  147600.00   \n",
       "1996-07-01 00:00:00  142700.00000  122700.000000   95900.000000  147300.00   \n",
       "1996-08-01 00:00:00  142400.00000  122700.000000   96100.000000  147100.00   \n",
       "...                           ...            ...            ...        ...   \n",
       "2018-01-01 00:00:00  294300.00000  234600.000000  189200.000000  303500.00   \n",
       "2018-02-01 00:00:00  297400.00000  237200.000000  191700.000000  306700.00   \n",
       "2018-03-01 00:00:00  300200.00000  239800.000000  194500.000000  309800.00   \n",
       "2018-04-01 00:00:00  302400.00000  241900.000000  196600.000000  312200.00   \n",
       "2018-05-01_pred      303811.84375  246300.944755  200482.013725  312865.75   \n",
       "\n",
       "                             89103        89148  ...        89444     89085  \\\n",
       "1996-04-01 00:00:00  118900.000000  157300.0000  ...  116800.0000  170900.0   \n",
       "1996-05-01 00:00:00  119000.000000  156000.0000  ...  117000.0000  170800.0   \n",
       "1996-06-01 00:00:00  119000.000000  154700.0000  ...  117200.0000  170700.0   \n",
       "1996-07-01 00:00:00  119100.000000  153500.0000  ...  117400.0000  170700.0   \n",
       "1996-08-01 00:00:00  119200.000000  152600.0000  ...  117600.0000  170700.0   \n",
       "...                            ...          ...  ...          ...       ...   \n",
       "2018-01-01 00:00:00  243700.000000  294100.0000  ...  270000.0000  316500.0   \n",
       "2018-02-01 00:00:00  246300.000000  296900.0000  ...  275600.0000  319500.0   \n",
       "2018-03-01 00:00:00  249500.000000  299400.0000  ...  282100.0000  322400.0   \n",
       "2018-04-01 00:00:00  252000.000000  300800.0000  ...  286000.0000  324700.0   \n",
       "2018-05-01_pred      251018.223795  305326.5625  ...  279638.8125  330100.0   \n",
       "\n",
       "                        89034     89021         89439     89411        89124  \\\n",
       "1996-04-01 00:00:00  196000.0  153200.0  184200.00000  299200.0  166100.0000   \n",
       "1996-05-01 00:00:00  196000.0  153700.0  185000.00000  299600.0  166600.0000   \n",
       "1996-06-01 00:00:00  195900.0  154100.0  185800.00000  299900.0  167300.0000   \n",
       "1996-07-01 00:00:00  195700.0  154400.0  186400.00000  300200.0  167900.0000   \n",
       "1996-08-01 00:00:00  195400.0  154700.0  186900.00000  300500.0  168600.0000   \n",
       "...                       ...       ...           ...       ...          ...   \n",
       "2018-01-01 00:00:00  315500.0  299900.0  449500.00000  642500.0  317600.0000   \n",
       "2018-02-01 00:00:00  319500.0  302500.0  450100.00000  653800.0  323400.0000   \n",
       "2018-03-01 00:00:00  323600.0  305700.0  451100.00000  666000.0  334700.0000   \n",
       "2018-04-01 00:00:00  326600.0  307800.0  455300.00000  672600.0  344300.0000   \n",
       "2018-05-01_pred           0.0       0.0  453697.84375       0.0  333740.6875   \n",
       "\n",
       "                        89440        89413         89155  \n",
       "1996-04-01 00:00:00  293200.0   562400.000  176400.00000  \n",
       "1996-05-01 00:00:00  293200.0   562800.000  176300.00000  \n",
       "1996-06-01 00:00:00  293200.0   562700.000  176100.00000  \n",
       "1996-07-01 00:00:00  293200.0   562400.000  176000.00000  \n",
       "1996-08-01 00:00:00  293200.0   562300.000  175900.00000  \n",
       "...                       ...          ...           ...  \n",
       "2018-01-01 00:00:00  201600.0  2121300.000  350400.00000  \n",
       "2018-02-01 00:00:00  207000.0  2153600.000  353000.00000  \n",
       "2018-03-01 00:00:00  216500.0  2167100.000  356000.00000  \n",
       "2018-04-01 00:00:00  222800.0  2161900.000  357200.00000  \n",
       "2018-05-01_pred      190700.0  2082682.875  361679.90625  \n",
       "\n",
       "[266 rows x 103 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_return = {}\n",
    "for i in df_time_series.columns:\n",
    "    investment_return[i] = (df_time_series[i][-1]-df_time_series[i][-2])/df_time_series[i][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89448: -1.0,\n",
       " 89449: -1.0,\n",
       " 89034: -1.0,\n",
       " 89021: -1.0,\n",
       " 89411: -1.0,\n",
       " 89440: -0.1440754039497307,\n",
       " 89109: -0.06368849984907939,\n",
       " 89403: -0.05772005772005772,\n",
       " 89436: -0.05225015001536002,\n",
       " 89512: -0.047372954349698536,\n",
       " 89413: -0.03664236319903788,\n",
       " 89429: -0.03379828326180258,\n",
       " 89124: -0.030668929712460064,\n",
       " 89511: -0.02986241620023129,\n",
       " 89156: -0.028897632102470983,\n",
       " 89451: -0.02755555701662108,\n",
       " 89122: -0.02687998117247378,\n",
       " 89410: -0.024777401804670914,\n",
       " 89433: -0.023406785042469288,\n",
       " 89444: -0.022241914335664335,\n",
       " 89423: -0.01899039052890529,\n",
       " 89703: -0.016678927604038413,\n",
       " 89701: -0.016057372505543236,\n",
       " 89519: -0.013868014974433893,\n",
       " 89705: -0.013570170632435817,\n",
       " 89801: -0.011791737329410124,\n",
       " 89521: -0.010857668067226892,\n",
       " 89144: -0.009602167568337129,\n",
       " 89434: -0.008952254641909815,\n",
       " 89509: -0.008843687817820032,\n",
       " 89815: -0.00859215226680593,\n",
       " 89706: -0.0077280844155844155,\n",
       " 89503: -0.00548033526756931,\n",
       " 89523: -0.0052024848254931715,\n",
       " 89103: -0.0038959373226174474,\n",
       " 89704: -0.0037051052198448153,\n",
       " 89439: -0.0035189023720623765,\n",
       " 89447: -0.0021149037569591664,\n",
       " 89134: 0.0002814465408805031,\n",
       " 89135: 0.0007228047766159696,\n",
       " 89501: 0.0007674237940218999,\n",
       " 89118: 0.0014013991514543684,\n",
       " 89074: 0.0021324471492632927,\n",
       " 89460: 0.002898670333367592,\n",
       " 89138: 0.0033907070303583657,\n",
       " 89506: 0.0038006416430090436,\n",
       " 89040: 0.003864246500965251,\n",
       " 89431: 0.004110708275741608,\n",
       " 89123: 0.004668795469576719,\n",
       " 89128: 0.004818333059491853,\n",
       " 89084: 0.004982521186440678,\n",
       " 89117: 0.005367233187134503,\n",
       " 89002: 0.006339834662678631,\n",
       " 89508: 0.0068769475917980815,\n",
       " 89115: 0.00689631270757408,\n",
       " 89029: 0.007226240424241816,\n",
       " 89441: 0.007586334997622444,\n",
       " 89044: 0.007659311985231469,\n",
       " 89131: 0.007676996112440191,\n",
       " 89102: 0.008061170549308945,\n",
       " 89146: 0.008200316355284487,\n",
       " 89178: 0.00960934819897084,\n",
       " 89502: 0.010230144183125343,\n",
       " 89014: 0.011042309722060698,\n",
       " 89142: 0.011910567737782554,\n",
       " 89113: 0.011957274590163934,\n",
       " 89129: 0.01209570583059348,\n",
       " 89048: 0.012444001991040319,\n",
       " 89155: 0.012541730823068309,\n",
       " 89030: 0.012873693870063938,\n",
       " 89052: 0.012898041336217256,\n",
       " 89107: 0.013849103563232377,\n",
       " 89120: 0.014241467975789993,\n",
       " 89141: 0.014408379556259905,\n",
       " 89179: 0.014536210317460318,\n",
       " 89027: 0.014765261012282932,\n",
       " 89148: 0.015048412566489361,\n",
       " 89145: 0.015232606010703994,\n",
       " 89012: 0.015464465431738622,\n",
       " 89149: 0.015549208724349615,\n",
       " 89130: 0.016206261510128914,\n",
       " 89085: 0.016630736064059133,\n",
       " 89108: 0.017090282472717315,\n",
       " 89015: 0.01740494764210884,\n",
       " 89121: 0.018011773042736167,\n",
       " 89031: 0.01819323999528761,\n",
       " 89183: 0.01949963208241354,\n",
       " 89110: 0.019745746310630814,\n",
       " 89104: 0.01981829457598941,\n",
       " 89086: 0.020193354851261818,\n",
       " 89408: 0.020610057708161583,\n",
       " 89147: 0.021103901235491745,\n",
       " 89119: 0.021339230134029687,\n",
       " 89032: 0.021442448761473946,\n",
       " 89061: 0.02262443438914027,\n",
       " 89005: 0.022760683932007697,\n",
       " 89011: 0.022894300075872533,\n",
       " 89081: 0.02315332765638677,\n",
       " 89143: 0.023676292949176808,\n",
       " 89166: 0.02389814733707078,\n",
       " 89510: 0.025691410950661853,\n",
       " 89139: 0.027802706405703665,\n",
       " 89060: 0.05800064931281908}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_return = dict(sorted(investment_return.items(), key=lambda item: item[1]))\n",
    "investment_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in investment_return.keys():\n",
    "    list.append(i)\n",
    "best_5_investments = list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89143, 89166, 89510, 89139, 89060]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_5_investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>89143</th>\n",
       "      <th>89166</th>\n",
       "      <th>89510</th>\n",
       "      <th>89139</th>\n",
       "      <th>89060</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-01 00:00:00</th>\n",
       "      <td>244600.00000</td>\n",
       "      <td>255300.00000</td>\n",
       "      <td>400200.00000</td>\n",
       "      <td>254200.000000</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01 00:00:00</th>\n",
       "      <td>247300.00000</td>\n",
       "      <td>258600.00000</td>\n",
       "      <td>408000.00000</td>\n",
       "      <td>256600.000000</td>\n",
       "      <td>121800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01 00:00:00</th>\n",
       "      <td>250700.00000</td>\n",
       "      <td>262000.00000</td>\n",
       "      <td>412500.00000</td>\n",
       "      <td>258900.000000</td>\n",
       "      <td>125100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01 00:00:00</th>\n",
       "      <td>255000.00000</td>\n",
       "      <td>265800.00000</td>\n",
       "      <td>415700.00000</td>\n",
       "      <td>261900.000000</td>\n",
       "      <td>127600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 00:00:00</th>\n",
       "      <td>259500.00000</td>\n",
       "      <td>270100.00000</td>\n",
       "      <td>415100.00000</td>\n",
       "      <td>265800.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 00:00:00</th>\n",
       "      <td>262500.00000</td>\n",
       "      <td>273500.00000</td>\n",
       "      <td>416500.00000</td>\n",
       "      <td>269300.000000</td>\n",
       "      <td>134600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:00:00</th>\n",
       "      <td>265500.00000</td>\n",
       "      <td>276500.00000</td>\n",
       "      <td>419500.00000</td>\n",
       "      <td>273100.000000</td>\n",
       "      <td>140100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>268500.00000</td>\n",
       "      <td>279200.00000</td>\n",
       "      <td>421800.00000</td>\n",
       "      <td>276700.000000</td>\n",
       "      <td>143500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>271700.00000</td>\n",
       "      <td>281700.00000</td>\n",
       "      <td>420600.00000</td>\n",
       "      <td>280100.000000</td>\n",
       "      <td>146700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>275800.00000</td>\n",
       "      <td>283900.00000</td>\n",
       "      <td>418300.00000</td>\n",
       "      <td>283100.000000</td>\n",
       "      <td>149700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>279400.00000</td>\n",
       "      <td>285400.00000</td>\n",
       "      <td>415500.00000</td>\n",
       "      <td>284900.000000</td>\n",
       "      <td>151400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01_pred</th>\n",
       "      <td>286015.15625</td>\n",
       "      <td>292220.53125</td>\n",
       "      <td>426174.78125</td>\n",
       "      <td>292820.991055</td>\n",
       "      <td>160181.298306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            89143         89166         89510          89139  \\\n",
       "2017-06-01 00:00:00  244600.00000  255300.00000  400200.00000  254200.000000   \n",
       "2017-07-01 00:00:00  247300.00000  258600.00000  408000.00000  256600.000000   \n",
       "2017-08-01 00:00:00  250700.00000  262000.00000  412500.00000  258900.000000   \n",
       "2017-09-01 00:00:00  255000.00000  265800.00000  415700.00000  261900.000000   \n",
       "2017-10-01 00:00:00  259500.00000  270100.00000  415100.00000  265800.000000   \n",
       "2017-11-01 00:00:00  262500.00000  273500.00000  416500.00000  269300.000000   \n",
       "2017-12-01 00:00:00  265500.00000  276500.00000  419500.00000  273100.000000   \n",
       "2018-01-01 00:00:00  268500.00000  279200.00000  421800.00000  276700.000000   \n",
       "2018-02-01 00:00:00  271700.00000  281700.00000  420600.00000  280100.000000   \n",
       "2018-03-01 00:00:00  275800.00000  283900.00000  418300.00000  283100.000000   \n",
       "2018-04-01 00:00:00  279400.00000  285400.00000  415500.00000  284900.000000   \n",
       "2018-05-01_pred      286015.15625  292220.53125  426174.78125  292820.991055   \n",
       "\n",
       "                             89060  \n",
       "2017-06-01 00:00:00  119600.000000  \n",
       "2017-07-01 00:00:00  121800.000000  \n",
       "2017-08-01 00:00:00  125100.000000  \n",
       "2017-09-01 00:00:00  127600.000000  \n",
       "2017-10-01 00:00:00  130000.000000  \n",
       "2017-11-01 00:00:00  134600.000000  \n",
       "2017-12-01 00:00:00  140100.000000  \n",
       "2018-01-01 00:00:00  143500.000000  \n",
       "2018-02-01 00:00:00  146700.000000  \n",
       "2018-03-01 00:00:00  149700.000000  \n",
       "2018-04-01 00:00:00  151400.000000  \n",
       "2018-05-01_pred      160181.298306  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_chart_data = df_time_series[best_5_investments][-12:]\n",
    "investment_chart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1584x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "months = [\"June '17\", \"July '17\",\"Aug '17\",\"Sep '17\",\"Oct '17\",\"Nov '17\",\"Dec '18\",\"Jan '18\",\"Feb '18\",\"Mar '18\",\"Apr '18\", \"May '18\"]\n",
    "fig, ax = plt.subplots(figsize=(22,7))\n",
    "fig = plt.figure()\n",
    "\n",
    "ax.plot(months, investment_chart_data[89143])\n",
    "ax.plot(months, investment_chart_data[89166])\n",
    "ax.plot(months, investment_chart_data[89510])\n",
    "ax.plot(months, investment_chart_data[89139])\n",
    "ax.plot(months, investment_chart_data[89060])\n",
    "\n",
    "\n",
    "\n",
    "ax.set_title('Top 5 Profitable Zipcodes')\n",
    "ax.legend(['89143','89166','89510','89139','89060'], loc=('upper left'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>89108</th>\n",
       "      <th>89121</th>\n",
       "      <th>89117</th>\n",
       "      <th>89052</th>\n",
       "      <th>89123</th>\n",
       "      <th>89031</th>\n",
       "      <th>89110</th>\n",
       "      <th>89074</th>\n",
       "      <th>89103</th>\n",
       "      <th>89148</th>\n",
       "      <th>...</th>\n",
       "      <th>89444</th>\n",
       "      <th>89085</th>\n",
       "      <th>89034</th>\n",
       "      <th>89021</th>\n",
       "      <th>89439</th>\n",
       "      <th>89411</th>\n",
       "      <th>89124</th>\n",
       "      <th>89440</th>\n",
       "      <th>89413</th>\n",
       "      <th>89155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>106800.000000</td>\n",
       "      <td>165100.00000</td>\n",
       "      <td>185700.000</td>\n",
       "      <td>144000.00000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>148000.00</td>\n",
       "      <td>118900.000000</td>\n",
       "      <td>157300.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>116800.0000</td>\n",
       "      <td>170900.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153200.0</td>\n",
       "      <td>184200.00000</td>\n",
       "      <td>299200.0</td>\n",
       "      <td>166100.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.000</td>\n",
       "      <td>176400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107000.000000</td>\n",
       "      <td>164500.00000</td>\n",
       "      <td>186300.000</td>\n",
       "      <td>143500.00000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147800.00</td>\n",
       "      <td>119000.000000</td>\n",
       "      <td>156000.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117000.0000</td>\n",
       "      <td>170800.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153700.0</td>\n",
       "      <td>185000.00000</td>\n",
       "      <td>299600.0</td>\n",
       "      <td>166600.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562800.000</td>\n",
       "      <td>176300.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107200.000000</td>\n",
       "      <td>164000.00000</td>\n",
       "      <td>186900.000</td>\n",
       "      <td>143100.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147600.00</td>\n",
       "      <td>119000.000000</td>\n",
       "      <td>154700.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117200.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195900.0</td>\n",
       "      <td>154100.0</td>\n",
       "      <td>185800.00000</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>167300.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562700.000</td>\n",
       "      <td>176100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01 00:00:00</th>\n",
       "      <td>102600.000000</td>\n",
       "      <td>107400.000000</td>\n",
       "      <td>163500.00000</td>\n",
       "      <td>187400.000</td>\n",
       "      <td>142700.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95900.000000</td>\n",
       "      <td>147300.00</td>\n",
       "      <td>119100.000000</td>\n",
       "      <td>153500.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117400.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195700.0</td>\n",
       "      <td>154400.0</td>\n",
       "      <td>186400.00000</td>\n",
       "      <td>300200.0</td>\n",
       "      <td>167900.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.000</td>\n",
       "      <td>176000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01 00:00:00</th>\n",
       "      <td>102700.000000</td>\n",
       "      <td>107600.000000</td>\n",
       "      <td>163200.00000</td>\n",
       "      <td>187700.000</td>\n",
       "      <td>142400.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>96100.000000</td>\n",
       "      <td>147100.00</td>\n",
       "      <td>119200.000000</td>\n",
       "      <td>152600.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117600.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195400.0</td>\n",
       "      <td>154700.0</td>\n",
       "      <td>186900.00000</td>\n",
       "      <td>300500.0</td>\n",
       "      <td>168600.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562300.000</td>\n",
       "      <td>175900.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>200700.000000</td>\n",
       "      <td>201500.000000</td>\n",
       "      <td>330700.00000</td>\n",
       "      <td>407300.000</td>\n",
       "      <td>294300.00000</td>\n",
       "      <td>234600.000000</td>\n",
       "      <td>189200.000000</td>\n",
       "      <td>303500.00</td>\n",
       "      <td>243700.000000</td>\n",
       "      <td>294100.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>270000.0000</td>\n",
       "      <td>316500.0</td>\n",
       "      <td>315500.0</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>449500.00000</td>\n",
       "      <td>642500.0</td>\n",
       "      <td>317600.0000</td>\n",
       "      <td>201600.0</td>\n",
       "      <td>2121300.000</td>\n",
       "      <td>350400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>203500.000000</td>\n",
       "      <td>204000.000000</td>\n",
       "      <td>334600.00000</td>\n",
       "      <td>410400.000</td>\n",
       "      <td>297400.00000</td>\n",
       "      <td>237200.000000</td>\n",
       "      <td>191700.000000</td>\n",
       "      <td>306700.00</td>\n",
       "      <td>246300.000000</td>\n",
       "      <td>296900.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>275600.0000</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>302500.0</td>\n",
       "      <td>450100.00000</td>\n",
       "      <td>653800.0</td>\n",
       "      <td>323400.0000</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>2153600.000</td>\n",
       "      <td>353000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>206600.000000</td>\n",
       "      <td>206700.000000</td>\n",
       "      <td>338800.00000</td>\n",
       "      <td>413700.000</td>\n",
       "      <td>300200.00000</td>\n",
       "      <td>239800.000000</td>\n",
       "      <td>194500.000000</td>\n",
       "      <td>309800.00</td>\n",
       "      <td>249500.000000</td>\n",
       "      <td>299400.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>282100.0000</td>\n",
       "      <td>322400.0</td>\n",
       "      <td>323600.0</td>\n",
       "      <td>305700.0</td>\n",
       "      <td>451100.00000</td>\n",
       "      <td>666000.0</td>\n",
       "      <td>334700.0000</td>\n",
       "      <td>216500.0</td>\n",
       "      <td>2167100.000</td>\n",
       "      <td>356000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>209300.000000</td>\n",
       "      <td>208600.000000</td>\n",
       "      <td>342000.00000</td>\n",
       "      <td>416100.000</td>\n",
       "      <td>302400.00000</td>\n",
       "      <td>241900.000000</td>\n",
       "      <td>196600.000000</td>\n",
       "      <td>312200.00</td>\n",
       "      <td>252000.000000</td>\n",
       "      <td>300800.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>286000.0000</td>\n",
       "      <td>324700.0</td>\n",
       "      <td>326600.0</td>\n",
       "      <td>307800.0</td>\n",
       "      <td>455300.00000</td>\n",
       "      <td>672600.0</td>\n",
       "      <td>344300.0000</td>\n",
       "      <td>222800.0</td>\n",
       "      <td>2161900.000</td>\n",
       "      <td>357200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01_pred</th>\n",
       "      <td>212876.996122</td>\n",
       "      <td>212357.255857</td>\n",
       "      <td>343835.59375</td>\n",
       "      <td>421466.875</td>\n",
       "      <td>303811.84375</td>\n",
       "      <td>246300.944755</td>\n",
       "      <td>200482.013725</td>\n",
       "      <td>312865.75</td>\n",
       "      <td>251018.223795</td>\n",
       "      <td>305326.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>279638.8125</td>\n",
       "      <td>330100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>453697.84375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333740.6875</td>\n",
       "      <td>190700.0</td>\n",
       "      <td>2082682.875</td>\n",
       "      <td>361679.90625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             89108          89121         89117       89052  \\\n",
       "1996-04-01 00:00:00  102500.000000  106800.000000  165100.00000  185700.000   \n",
       "1996-05-01 00:00:00  102500.000000  107000.000000  164500.00000  186300.000   \n",
       "1996-06-01 00:00:00  102500.000000  107200.000000  164000.00000  186900.000   \n",
       "1996-07-01 00:00:00  102600.000000  107400.000000  163500.00000  187400.000   \n",
       "1996-08-01 00:00:00  102700.000000  107600.000000  163200.00000  187700.000   \n",
       "...                            ...            ...           ...         ...   \n",
       "2018-01-01 00:00:00  200700.000000  201500.000000  330700.00000  407300.000   \n",
       "2018-02-01 00:00:00  203500.000000  204000.000000  334600.00000  410400.000   \n",
       "2018-03-01 00:00:00  206600.000000  206700.000000  338800.00000  413700.000   \n",
       "2018-04-01 00:00:00  209300.000000  208600.000000  342000.00000  416100.000   \n",
       "2018-05-01_pred      212876.996122  212357.255857  343835.59375  421466.875   \n",
       "\n",
       "                            89123          89031          89110      89074  \\\n",
       "1996-04-01 00:00:00  144000.00000  122800.000000   95800.000000  148000.00   \n",
       "1996-05-01 00:00:00  143500.00000  122800.000000   95800.000000  147800.00   \n",
       "1996-06-01 00:00:00  143100.00000  122700.000000   95800.000000  147600.00   \n",
       "1996-07-01 00:00:00  142700.00000  122700.000000   95900.000000  147300.00   \n",
       "1996-08-01 00:00:00  142400.00000  122700.000000   96100.000000  147100.00   \n",
       "...                           ...            ...            ...        ...   \n",
       "2018-01-01 00:00:00  294300.00000  234600.000000  189200.000000  303500.00   \n",
       "2018-02-01 00:00:00  297400.00000  237200.000000  191700.000000  306700.00   \n",
       "2018-03-01 00:00:00  300200.00000  239800.000000  194500.000000  309800.00   \n",
       "2018-04-01 00:00:00  302400.00000  241900.000000  196600.000000  312200.00   \n",
       "2018-05-01_pred      303811.84375  246300.944755  200482.013725  312865.75   \n",
       "\n",
       "                             89103        89148  ...        89444     89085  \\\n",
       "1996-04-01 00:00:00  118900.000000  157300.0000  ...  116800.0000  170900.0   \n",
       "1996-05-01 00:00:00  119000.000000  156000.0000  ...  117000.0000  170800.0   \n",
       "1996-06-01 00:00:00  119000.000000  154700.0000  ...  117200.0000  170700.0   \n",
       "1996-07-01 00:00:00  119100.000000  153500.0000  ...  117400.0000  170700.0   \n",
       "1996-08-01 00:00:00  119200.000000  152600.0000  ...  117600.0000  170700.0   \n",
       "...                            ...          ...  ...          ...       ...   \n",
       "2018-01-01 00:00:00  243700.000000  294100.0000  ...  270000.0000  316500.0   \n",
       "2018-02-01 00:00:00  246300.000000  296900.0000  ...  275600.0000  319500.0   \n",
       "2018-03-01 00:00:00  249500.000000  299400.0000  ...  282100.0000  322400.0   \n",
       "2018-04-01 00:00:00  252000.000000  300800.0000  ...  286000.0000  324700.0   \n",
       "2018-05-01_pred      251018.223795  305326.5625  ...  279638.8125  330100.0   \n",
       "\n",
       "                        89034     89021         89439     89411        89124  \\\n",
       "1996-04-01 00:00:00  196000.0  153200.0  184200.00000  299200.0  166100.0000   \n",
       "1996-05-01 00:00:00  196000.0  153700.0  185000.00000  299600.0  166600.0000   \n",
       "1996-06-01 00:00:00  195900.0  154100.0  185800.00000  299900.0  167300.0000   \n",
       "1996-07-01 00:00:00  195700.0  154400.0  186400.00000  300200.0  167900.0000   \n",
       "1996-08-01 00:00:00  195400.0  154700.0  186900.00000  300500.0  168600.0000   \n",
       "...                       ...       ...           ...       ...          ...   \n",
       "2018-01-01 00:00:00  315500.0  299900.0  449500.00000  642500.0  317600.0000   \n",
       "2018-02-01 00:00:00  319500.0  302500.0  450100.00000  653800.0  323400.0000   \n",
       "2018-03-01 00:00:00  323600.0  305700.0  451100.00000  666000.0  334700.0000   \n",
       "2018-04-01 00:00:00  326600.0  307800.0  455300.00000  672600.0  344300.0000   \n",
       "2018-05-01_pred           0.0       0.0  453697.84375       0.0  333740.6875   \n",
       "\n",
       "                        89440        89413         89155  \n",
       "1996-04-01 00:00:00  293200.0   562400.000  176400.00000  \n",
       "1996-05-01 00:00:00  293200.0   562800.000  176300.00000  \n",
       "1996-06-01 00:00:00  293200.0   562700.000  176100.00000  \n",
       "1996-07-01 00:00:00  293200.0   562400.000  176000.00000  \n",
       "1996-08-01 00:00:00  293200.0   562300.000  175900.00000  \n",
       "...                       ...          ...           ...  \n",
       "2018-01-01 00:00:00  201600.0  2121300.000  350400.00000  \n",
       "2018-02-01 00:00:00  207000.0  2153600.000  353000.00000  \n",
       "2018-03-01 00:00:00  216500.0  2167100.000  356000.00000  \n",
       "2018-04-01 00:00:00  222800.0  2161900.000  357200.00000  \n",
       "2018-05-01_pred      190700.0  2082682.875  361679.90625  \n",
       "\n",
       "[266 rows x 103 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 48085.5508 - val_loss: 70.4427\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 132760.1406 - val_loss: 70.2606\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 83623.4375 - val_loss: 77.6148\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16281.0430 - val_loss: 79.2507\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4100.2905 - val_loss: 77.4637\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 70966.1016 - val_loss: 77.3141\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54380.8008 - val_loss: 80.6926\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17259.9961 - val_loss: 81.6933\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7471.9990 - val_loss: 80.0082\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 55874.8086 - val_loss: 79.7206\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33641.9766 - val_loss: 81.3715\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27480.5762 - val_loss: 83.6959\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17681.2930 - val_loss: 82.4140\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21191.7324 - val_loss: 82.5766\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13569.1592 - val_loss: 83.4720\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8530.3281 - val_loss: 84.3346\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13691.3613 - val_loss: 83.6648\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21160.4219 - val_loss: 83.4899\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4673.2422 - val_loss: 84.8462\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30500.9238 - val_loss: 85.5635\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26431.3613 - val_loss: 84.5232\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2644.3977 - val_loss: 85.0466\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7191.6299 - val_loss: 84.2816\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14878.9160 - val_loss: 84.9828\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3943.1587 - val_loss: 84.8064\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16847.7852 - val_loss: 84.9109\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2616.3237 - val_loss: 86.2734\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35914.9219 - val_loss: 86.7591\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27253.4531 - val_loss: 86.1380\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5131.1235 - val_loss: 84.1875\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 62452.5938 - val_loss: 83.5330\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 58700.8750 - val_loss: 84.8473\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23360.2363 - val_loss: 86.5859\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3693.9766 - val_loss: 89.2188\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 85035.7109 - val_loss: 90.5022\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 72314.6719 - val_loss: 90.2431\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33161.1562 - val_loss: 89.1218\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9052.6055 - val_loss: 87.0567\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 62542.1250 - val_loss: 86.4001\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 69204.7500 - val_loss: 87.2910\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51822.3555 - val_loss: 88.3313\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19332.3750 - val_loss: 89.4425\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11744.0225 - val_loss: 90.5121\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14191.7168 - val_loss: 90.1349\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3656.2295 - val_loss: 90.3574\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7948.5322 - val_loss: 90.2888\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 601.0316 - val_loss: 89.3877\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29169.0723 - val_loss: 89.4420\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24290.5371 - val_loss: 90.0256\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1489.8262 - val_loss: 90.8719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 0 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 109346.1250 - val_loss: 110.0506\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 147550.9531 - val_loss: 105.7346\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 66764.4062 - val_loss: 106.5142\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 58314.0117 - val_loss: 110.3191\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 208475.2969 - val_loss: 107.2347\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 74132.5938 - val_loss: 101.7326\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 223629.0000 - val_loss: 100.0141\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 141416.0469 - val_loss: 103.1070\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 92367.4141 - val_loss: 106.2805\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 143432.3906 - val_loss: 104.2293\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45207.4492 - val_loss: 101.9201\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 122365.9844 - val_loss: 102.9886\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 53778.3711 - val_loss: 106.2193\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 196343.1094 - val_loss: 106.8525\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 120794.7500 - val_loss: 104.3534\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39095.1758 - val_loss: 103.3664\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23567.3750 - val_loss: 104.0257\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24152.8008 - val_loss: 103.1609\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11612.9590 - val_loss: 102.8549\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7647.1333 - val_loss: 102.6429\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7336.5732 - val_loss: 102.7357\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21894.1504 - val_loss: 102.2689\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47039.7930 - val_loss: 102.0769\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9010.8369 - val_loss: 102.6413\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18529.8652 - val_loss: 103.1552\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34614.7500 - val_loss: 104.1159\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 58685.3477 - val_loss: 103.1019\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11822.0391 - val_loss: 102.6107\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18632.1543 - val_loss: 103.0826\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24711.2402 - val_loss: 102.3591\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35754.2500 - val_loss: 101.7047\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31786.0781 - val_loss: 102.5519\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19561.6055 - val_loss: 101.7361\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24974.7695 - val_loss: 102.3831\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38869.0234 - val_loss: 102.4058\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19743.2578 - val_loss: 101.4325\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8262.8154 - val_loss: 101.8102\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22733.8867 - val_loss: 101.3125\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28166.1191 - val_loss: 101.3769\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31717.3164 - val_loss: 102.6816\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 73777.2734 - val_loss: 101.8668\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21870.4961 - val_loss: 100.8936\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 77222.9375 - val_loss: 101.6067\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31175.2793 - val_loss: 102.8830\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29081.9629 - val_loss: 102.2317\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11030.8926 - val_loss: 102.8061\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30958.6641 - val_loss: 102.4581\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15530.6846 - val_loss: 102.4660\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16757.1543 - val_loss: 102.3256\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19381.2422 - val_loss: 102.5926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 1 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 57.7800 - val_loss: 38.7170\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47.7402 - val_loss: 29.1224\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.9042 - val_loss: 37.6954\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32.6638 - val_loss: 33.0170\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27.6202 - val_loss: 19.6893\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24.5426 - val_loss: 12.7351\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20.5773 - val_loss: 17.0647\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.2276 - val_loss: 7.6647\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.2309 - val_loss: 7.9649\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.5134 - val_loss: 3.1358\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.7345 - val_loss: 4.1382\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.1945 - val_loss: 3.2758\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.3860 - val_loss: 3.2250\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.2269 - val_loss: 3.3523\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.6959 - val_loss: 4.3220\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.5364 - val_loss: 4.2952\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.3206 - val_loss: 3.6108\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1737 - val_loss: 4.1865\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.9154 - val_loss: 2.8963\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.9555 - val_loss: 2.7851\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1922 - val_loss: 3.3643\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7951 - val_loss: 3.5323\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5698 - val_loss: 3.1342\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.4127 - val_loss: 3.7309\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.0911 - val_loss: 3.9261\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5672 - val_loss: 3.2349\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6393 - val_loss: 3.1375\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2719 - val_loss: 3.6234\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.6874 - val_loss: 5.6890\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9913 - val_loss: 1.3568\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3143 - val_loss: 3.2321\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5163 - val_loss: 3.2041\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6665 - val_loss: 3.2308\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7309 - val_loss: 3.4179\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.3764 - val_loss: 2.8847\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3306 - val_loss: 3.9104\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4901 - val_loss: 1.7017\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4642 - val_loss: 5.4694\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4671 - val_loss: 1.8831\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9132 - val_loss: 3.3267\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9844 - val_loss: 2.7028\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9894 - val_loss: 2.4549\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8054 - val_loss: 5.0506\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2226 - val_loss: 1.5944\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6545 - val_loss: 3.6213\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5004 - val_loss: 2.6501\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4742 - val_loss: 2.5832\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4375 - val_loss: 4.1670\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5028 - val_loss: 1.4440\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3592 - val_loss: 3.5887\n",
      "Iteration number 2 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 121.5051 - val_loss: 98.1408\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 69.8706 - val_loss: 52.8936\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33.6626 - val_loss: 12.6598\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31.6024 - val_loss: 24.3897\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.6426 - val_loss: 35.0597\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23.0239 - val_loss: 31.8119\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.5397 - val_loss: 19.4544\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.0029 - val_loss: 11.9570\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.2919 - val_loss: 15.2965\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.5507 - val_loss: 13.8847\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.7442 - val_loss: 9.7035\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1657 - val_loss: 5.1673\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9794 - val_loss: 4.5045\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.7045 - val_loss: 6.2826\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4863 - val_loss: 4.3956\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7229 - val_loss: 5.3275\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5248 - val_loss: 4.8954\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5808 - val_loss: 6.2427\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4102 - val_loss: 3.2227\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.2143 - val_loss: 6.4173\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9911 - val_loss: 2.5714\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9056 - val_loss: 5.3130\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5369 - val_loss: 2.9524\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2636 - val_loss: 3.8850\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0913 - val_loss: 4.8019\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9966 - val_loss: 3.5707\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8496 - val_loss: 2.8522\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.6344 - val_loss: 3.4213\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5272 - val_loss: 2.3893\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5236 - val_loss: 4.1486\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5960 - val_loss: 2.4846\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0835 - val_loss: 4.1698\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2015 - val_loss: 2.3473\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3006 - val_loss: 3.4400\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0146 - val_loss: 2.6533\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0618 - val_loss: 3.7348\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8336 - val_loss: 2.6351\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0808 - val_loss: 3.8175\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8894 - val_loss: 2.4410\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0216 - val_loss: 2.7733\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4634 - val_loss: 2.4836\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.1897 - val_loss: 2.4220\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2449 - val_loss: 2.9221\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.0298 - val_loss: 2.6046\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2752 - val_loss: 3.3456\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4389 - val_loss: 2.5416\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6579 - val_loss: 2.7945\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0188 - val_loss: 2.1996\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5487 - val_loss: 2.1385\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.4989 - val_loss: 2.1491\n",
      "Iteration number 3 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 77.7590 - val_loss: 62.2216\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52.8757 - val_loss: 32.5403\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.3793 - val_loss: 32.4866\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28.4981 - val_loss: 25.9237\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24.3893 - val_loss: 10.9301\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.3096 - val_loss: 12.3044\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18.8514 - val_loss: 5.8748\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.7729 - val_loss: 8.5945\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.1014 - val_loss: 5.2465\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.6711 - val_loss: 6.9480\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.4464 - val_loss: 6.2344\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.8733 - val_loss: 6.2258\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.0257 - val_loss: 5.4233\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.5675 - val_loss: 5.6769\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0420 - val_loss: 4.7492\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.7571 - val_loss: 6.6264\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.5149 - val_loss: 4.7006\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.3851 - val_loss: 5.2099\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.0838 - val_loss: 6.0328\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7229 - val_loss: 4.7526\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2819 - val_loss: 5.6426\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8099 - val_loss: 4.7364\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5478 - val_loss: 5.5266\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7376 - val_loss: 4.2110\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1953 - val_loss: 4.5155\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0600 - val_loss: 6.6158\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3006 - val_loss: 2.9273\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2837 - val_loss: 7.6977\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7427 - val_loss: 2.9116\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9320 - val_loss: 5.4538\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.2993 - val_loss: 3.6150\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6132 - val_loss: 4.3487\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8866 - val_loss: 3.5119\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6111 - val_loss: 4.7978\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7177 - val_loss: 2.7650\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6389 - val_loss: 6.5308\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0376 - val_loss: 2.7883\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4135 - val_loss: 4.9035\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9966 - val_loss: 2.6206\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1756 - val_loss: 5.0159\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3034 - val_loss: 3.3395\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1236 - val_loss: 3.5082\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2660 - val_loss: 4.1668\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9947 - val_loss: 3.8021\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1060 - val_loss: 2.7649\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8246 - val_loss: 3.4127\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3429 - val_loss: 3.0853\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1831 - val_loss: 4.1254\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4432 - val_loss: 2.3130\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9195 - val_loss: 3.8350\n",
      "Iteration number 4 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 21822.1758 - val_loss: 66.6627\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 278095.0000 - val_loss: 61.0409\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 243388.0469 - val_loss: 73.0938\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19088.5039 - val_loss: 80.1178\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 98212.2812 - val_loss: 84.6682\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85591.3672 - val_loss: 83.2650\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29839.6113 - val_loss: 80.4944\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17158.7500 - val_loss: 80.3800\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32677.5566 - val_loss: 80.9825\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1766.8317 - val_loss: 84.6360\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 68457.9844 - val_loss: 86.2526\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73539.0625 - val_loss: 86.0142\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 52387.8711 - val_loss: 82.7192\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37307.6680 - val_loss: 81.3724\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36557.4258 - val_loss: 83.0757\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2394.5566 - val_loss: 85.7901\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50162.1758 - val_loss: 86.2957\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48637.4141 - val_loss: 84.7273\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10677.4463 - val_loss: 82.4272\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 58390.6992 - val_loss: 81.3686\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 36485.7812 - val_loss: 83.0803\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8574.5234 - val_loss: 85.0163\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13072.9834 - val_loss: 84.6329\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9898.4336 - val_loss: 84.6160\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 272.7167 - val_loss: 83.8581\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30285.3262 - val_loss: 83.6725\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16258.2109 - val_loss: 86.4272\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44953.3242 - val_loss: 87.3630\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 44230.2773 - val_loss: 86.2764\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15095.3945 - val_loss: 84.2313\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30413.2441 - val_loss: 84.0591\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28699.4238 - val_loss: 85.4346\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4390.5928 - val_loss: 87.8748\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60047.9141 - val_loss: 88.7170\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52304.8633 - val_loss: 87.9274\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25767.5781 - val_loss: 85.9350\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28364.9629 - val_loss: 84.9669\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26296.1504 - val_loss: 85.5686\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3798.3250 - val_loss: 86.6740\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1733.9213 - val_loss: 85.8244\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32979.0469 - val_loss: 85.3226\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27823.3789 - val_loss: 87.6184\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28147.6875 - val_loss: 88.1971\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25543.9941 - val_loss: 86.9976\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15363.8799 - val_loss: 86.6796\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5257.8311 - val_loss: 88.6821\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29687.6309 - val_loss: 88.9374\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34145.5352 - val_loss: 88.5834\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19429.6934 - val_loss: 86.8757\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20260.4941 - val_loss: 86.6655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 5 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 49257.1445 - val_loss: 75.1683\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 174727.6406 - val_loss: 84.2641\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 85958.7344 - val_loss: 80.4554\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 55797.0273 - val_loss: 72.5885\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 130791.7500 - val_loss: 71.1461\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 131899.7500 - val_loss: 72.8724\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 88555.0078 - val_loss: 78.7432\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15554.0703 - val_loss: 81.7803\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13656.5234 - val_loss: 80.5230\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15254.9111 - val_loss: 81.3196\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1163.7451 - val_loss: 82.4682\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12201.6885 - val_loss: 83.1782\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26822.4883 - val_loss: 82.6898\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6725.0737 - val_loss: 82.2745\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1490.1140 - val_loss: 81.1490\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27325.3555 - val_loss: 81.8193\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5645.5376 - val_loss: 82.2886\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3249.4192 - val_loss: 82.5550\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1530.6379 - val_loss: 81.4564\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21088.8379 - val_loss: 82.1136\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5914.4551 - val_loss: 83.3900\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40788.2617 - val_loss: 84.5884\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23223.3965 - val_loss: 82.2919\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38253.2383 - val_loss: 81.2315\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33000.8828 - val_loss: 82.8365\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4512.6631 - val_loss: 83.2635\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9473.4541 - val_loss: 83.4883\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15611.6582 - val_loss: 84.2471\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11768.6895 - val_loss: 82.7854\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22944.1113 - val_loss: 83.0757\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7327.7222 - val_loss: 84.0421\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4092.2727 - val_loss: 84.6444\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17391.3359 - val_loss: 83.9798\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4412.9126 - val_loss: 84.3902\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13334.8135 - val_loss: 84.1739\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2182.9956 - val_loss: 81.6623\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55193.2422 - val_loss: 81.6113\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49904.8281 - val_loss: 82.9430\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8279.4443 - val_loss: 84.7449\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37103.9375 - val_loss: 86.6305\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41189.8516 - val_loss: 85.9113\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14032.0547 - val_loss: 84.4070\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12615.0176 - val_loss: 84.4464\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14344.5957 - val_loss: 85.5959\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12077.3799 - val_loss: 85.4175\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 682.0203 - val_loss: 84.0292\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42138.1836 - val_loss: 83.6379\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32827.3164 - val_loss: 85.0254\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10237.7568 - val_loss: 85.8917\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2236.0781 - val_loss: 85.9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 6 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 70.4585 - val_loss: 52.4626\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 59.8631 - val_loss: 31.5861\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 49.1708 - val_loss: 41.0355\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40.6009 - val_loss: 43.9696\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.5320 - val_loss: 34.5629\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29.5127 - val_loss: 18.7960\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27.6072 - val_loss: 16.7483\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24.6715 - val_loss: 20.5479\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21.0080 - val_loss: 10.8983\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19.0879 - val_loss: 9.2620\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.7670 - val_loss: 4.8063\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.5454 - val_loss: 3.8681\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.3197 - val_loss: 3.5730\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.6006 - val_loss: 4.4237\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.3417 - val_loss: 3.2173\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.3563 - val_loss: 5.5764\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.1957 - val_loss: 2.6943\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.7386 - val_loss: 5.2321\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.9650 - val_loss: 2.5592\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.7345 - val_loss: 3.6024\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.3038 - val_loss: 6.9486\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.6672 - val_loss: 2.7378\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.2256 - val_loss: 5.4476\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9362 - val_loss: 2.4694\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1893 - val_loss: 4.4058\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7607 - val_loss: 4.6274\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9782 - val_loss: 3.8548\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9902 - val_loss: 5.3803\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9153 - val_loss: 3.5704\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5732 - val_loss: 4.7788\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5802 - val_loss: 4.3089\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4157 - val_loss: 2.9695\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9720 - val_loss: 6.7014\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.8376 - val_loss: 2.4598\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6624 - val_loss: 6.6105\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8076 - val_loss: 5.0773\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9316 - val_loss: 3.9931\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3465 - val_loss: 3.9850\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9208 - val_loss: 4.8455\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1502 - val_loss: 3.8232\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5770 - val_loss: 3.5053\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4641 - val_loss: 4.4907\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5535 - val_loss: 4.8769\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7550 - val_loss: 2.6664\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7338 - val_loss: 4.9406\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0641 - val_loss: 4.7119\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4256 - val_loss: 2.7555\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2633 - val_loss: 4.7368\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4631 - val_loss: 3.9255\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1849 - val_loss: 3.4388\n",
      "Iteration number 7 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 43704.4375 - val_loss: 99.1301\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 220012.8594 - val_loss: 99.6690\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 133430.6562 - val_loss: 102.6879\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 84371.6484 - val_loss: 110.8555\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46256.4219 - val_loss: 112.6356\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 64769.5273 - val_loss: 111.5170\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37436.0469 - val_loss: 107.0152\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32868.8789 - val_loss: 106.1037\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31703.7637 - val_loss: 107.0353\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1259.1360 - val_loss: 107.2674\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9532.0947 - val_loss: 108.5089\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14963.8486 - val_loss: 107.2787\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8444.9297 - val_loss: 108.0279\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20027.4336 - val_loss: 107.6932\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 737.0588 - val_loss: 108.1886\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27881.3945 - val_loss: 108.1619\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16709.0996 - val_loss: 104.6144\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 60539.0195 - val_loss: 103.4673\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 54766.1133 - val_loss: 105.8723\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10115.4873 - val_loss: 109.2828\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 73259.6875 - val_loss: 110.2494\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 65283.1836 - val_loss: 108.2023\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20526.3184 - val_loss: 105.4549\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30624.6289 - val_loss: 103.6722\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30094.3887 - val_loss: 104.9450\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4468.0742 - val_loss: 104.8408\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12634.7305 - val_loss: 104.7301\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8520.0107 - val_loss: 105.2020\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1680.6644 - val_loss: 104.4063\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38242.4961 - val_loss: 102.8238\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31916.7266 - val_loss: 104.6564\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16577.8574 - val_loss: 105.2571\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12480.1367 - val_loss: 103.3047\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25847.0176 - val_loss: 103.3332\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15101.6064 - val_loss: 104.2155\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4745.9741 - val_loss: 104.2926\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1090.4459 - val_loss: 104.5574\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31230.4570 - val_loss: 105.6407\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18603.3262 - val_loss: 104.1961\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10664.7783 - val_loss: 103.4821\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8962.1270 - val_loss: 104.5885\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12737.6465 - val_loss: 104.1285\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4153.5698 - val_loss: 102.7772\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31693.1719 - val_loss: 102.3420\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24643.5020 - val_loss: 103.7663\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11454.1133 - val_loss: 103.9680\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6854.0239 - val_loss: 102.4371\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21573.7949 - val_loss: 102.7130\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13294.9170 - val_loss: 103.6464\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16605.9375 - val_loss: 104.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 8 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 87.3541 - val_loss: 72.9971\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 66.2597 - val_loss: 51.4525\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 50.9399 - val_loss: 54.0616\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 44.4303 - val_loss: 43.8415\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.9074 - val_loss: 23.3005\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32.1542 - val_loss: 22.6162\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 28.0417 - val_loss: 21.8710\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25.1126 - val_loss: 7.8102\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24.0170 - val_loss: 11.4138\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22.6644 - val_loss: 7.3767\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21.0039 - val_loss: 5.7574\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20.0011 - val_loss: 6.5669\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.6573 - val_loss: 3.9642\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.0647 - val_loss: 5.4969\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.9454 - val_loss: 4.1710\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.7678 - val_loss: 5.0573\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.2534 - val_loss: 4.9751\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.5106 - val_loss: 4.4392\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.2483 - val_loss: 4.5322\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.2924 - val_loss: 5.7460\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.3490 - val_loss: 5.5891\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.6679 - val_loss: 4.1939\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.5113 - val_loss: 3.9765\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.5851 - val_loss: 3.5263\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.6658 - val_loss: 5.0527\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.8604 - val_loss: 4.3459\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.6830 - val_loss: 3.6877\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.3302 - val_loss: 3.0715\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.2126 - val_loss: 3.9627\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9290 - val_loss: 3.3355\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9314 - val_loss: 3.5394\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4699 - val_loss: 2.9690\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.2564 - val_loss: 4.6300\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4297 - val_loss: 2.7556\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7864 - val_loss: 2.9279\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8689 - val_loss: 2.5131\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5521 - val_loss: 2.4654\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7299 - val_loss: 2.7864\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9957 - val_loss: 3.3180\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3431 - val_loss: 2.3160\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1101 - val_loss: 2.5390\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.2042 - val_loss: 2.4922\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8314 - val_loss: 2.6316\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6041 - val_loss: 3.4282\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7687 - val_loss: 3.6547\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9132 - val_loss: 2.6088\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2923 - val_loss: 3.8149\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7974 - val_loss: 2.5594\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4599 - val_loss: 2.4905\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7840 - val_loss: 2.4944\n",
      "Iteration number 9 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 194146.2031 - val_loss: 91.2233\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37392.7891 - val_loss: 105.5105\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 78061.4297 - val_loss: 109.6370\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 99360.8750 - val_loss: 107.0429\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39949.4023 - val_loss: 102.7615\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48901.6094 - val_loss: 100.6551\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37036.6914 - val_loss: 102.3920\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8329.1133 - val_loss: 103.0695\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3161.9983 - val_loss: 104.2536\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34915.9414 - val_loss: 104.0986\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20275.1309 - val_loss: 100.5845\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 54855.2734 - val_loss: 100.1002\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 42309.0391 - val_loss: 102.6091\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 764.4224 - val_loss: 102.1079\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8228.2998 - val_loss: 103.7323\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42674.8477 - val_loss: 104.3194\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24975.6543 - val_loss: 100.4705\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44221.5312 - val_loss: 99.6667\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 46403.6484 - val_loss: 100.4861\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15732.7930 - val_loss: 103.3634\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24073.8359 - val_loss: 103.7193\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34591.6484 - val_loss: 103.3048\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23806.3262 - val_loss: 99.3253\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 77842.7734 - val_loss: 97.8311\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 74366.2266 - val_loss: 98.7125\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44996.5742 - val_loss: 101.1795\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16431.8379 - val_loss: 102.4123\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13777.9795 - val_loss: 101.5985\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 979.8381 - val_loss: 101.7888\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5672.4331 - val_loss: 101.4346\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31771.2207 - val_loss: 100.2361\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27669.8848 - val_loss: 102.3042\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27697.6152 - val_loss: 102.6141\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21277.8848 - val_loss: 101.2202\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20485.4512 - val_loss: 100.7854\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10477.2188 - val_loss: 102.0625\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12798.6953 - val_loss: 101.9669\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10226.9053 - val_loss: 101.5012\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20448.4336 - val_loss: 100.5384\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18521.5430 - val_loss: 101.6593\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10130.0703 - val_loss: 101.4895\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 647.6997 - val_loss: 100.1820\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26081.6992 - val_loss: 100.4125\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19970.2617 - val_loss: 101.5379\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20045.1641 - val_loss: 102.0066\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9888.8154 - val_loss: 100.1273\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49885.9023 - val_loss: 99.2055\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39684.8438 - val_loss: 100.5360\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5745.2241 - val_loss: 101.3284\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4448.2510 - val_loss: 101.4091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 10 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 89954.0078 - val_loss: 91.2521\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 99238.4531 - val_loss: 99.0914\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 201925.3125 - val_loss: 100.8140\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 85286.3672 - val_loss: 96.2172\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 64518.0117 - val_loss: 89.8943\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 223559.5469 - val_loss: 90.6342\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 140403.8281 - val_loss: 94.7843\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57481.1719 - val_loss: 98.8798\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 100805.9766 - val_loss: 97.8058\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37408.0117 - val_loss: 94.1452\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 67701.1641 - val_loss: 94.0391\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 67356.7969 - val_loss: 95.2350\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47401.3438 - val_loss: 98.6151\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 82666.4375 - val_loss: 98.1280\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34458.4883 - val_loss: 95.9142\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56328.3281 - val_loss: 95.6354\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 51091.1289 - val_loss: 97.0188\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37198.7695 - val_loss: 99.0919\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 84553.9531 - val_loss: 97.8873\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37153.9805 - val_loss: 95.1163\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 100535.7891 - val_loss: 94.6236\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 68811.6875 - val_loss: 96.0318\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18022.1211 - val_loss: 96.8512\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25667.2559 - val_loss: 95.7576\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41196.1797 - val_loss: 97.2602\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 48640.0898 - val_loss: 97.7349\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23794.7031 - val_loss: 96.3353\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52417.3633 - val_loss: 96.9998\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15565.4932 - val_loss: 99.2835\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 90627.4219 - val_loss: 99.4782\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 72094.8750 - val_loss: 98.0480\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38005.1328 - val_loss: 96.4539\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 70629.4297 - val_loss: 97.0574\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21435.8301 - val_loss: 99.2424\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 78648.5703 - val_loss: 99.7715\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 73722.3984 - val_loss: 98.6897\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15869.5391 - val_loss: 96.4520\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 89753.6250 - val_loss: 96.1995\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83566.0859 - val_loss: 96.8861\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15400.4375 - val_loss: 99.2814\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 77460.9766 - val_loss: 100.2577\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77339.0234 - val_loss: 98.9139\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20880.8457 - val_loss: 97.0213\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40489.1680 - val_loss: 97.4451\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1371.6830 - val_loss: 97.0177\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21183.4121 - val_loss: 97.3123\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15556.4092 - val_loss: 97.5631\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1886.7164 - val_loss: 97.6034\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30989.3086 - val_loss: 97.9399\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7025.7095 - val_loss: 97.6318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 11 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 69382.6797 - val_loss: 115.0790\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 606383.5625 - val_loss: 114.7181\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 439804.6875 - val_loss: 102.6088\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 111621.2891 - val_loss: 90.8820\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 267555.8750 - val_loss: 88.5235\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 230514.0000 - val_loss: 91.4206\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 82716.3828 - val_loss: 96.3592\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14539.1484 - val_loss: 95.2976\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49433.7656 - val_loss: 96.6296\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4999.0210 - val_loss: 96.0011\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40207.2656 - val_loss: 96.8227\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5155.4731 - val_loss: 97.6214\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14337.0967 - val_loss: 96.3619\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50128.8164 - val_loss: 96.9181\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6374.0264 - val_loss: 97.2677\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23100.2949 - val_loss: 98.2296\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49986.2578 - val_loss: 98.4613\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3094.9084 - val_loss: 98.1470\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13498.7266 - val_loss: 97.5598\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11093.8408 - val_loss: 98.5925\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25429.2793 - val_loss: 96.6683\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61704.2812 - val_loss: 97.5327\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10719.7734 - val_loss: 98.8768\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18933.4844 - val_loss: 97.5069\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 65030.8438 - val_loss: 97.6344\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29782.9961 - val_loss: 99.3203\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36990.1133 - val_loss: 97.9376\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23704.3984 - val_loss: 98.0210\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10543.5967 - val_loss: 101.2127\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 119640.4375 - val_loss: 101.0668\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 95706.9531 - val_loss: 99.5676\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54881.2500 - val_loss: 96.9135\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 76294.5078 - val_loss: 98.1825\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12300.8418 - val_loss: 98.9801\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23939.7070 - val_loss: 99.0696\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12855.0967 - val_loss: 100.0510\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14493.3154 - val_loss: 98.7366\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 75727.9844 - val_loss: 98.2645\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 51535.2617 - val_loss: 101.5468\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 110216.2344 - val_loss: 102.6536\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 76458.8281 - val_loss: 101.0045\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19351.8184 - val_loss: 99.8118\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5967.8481 - val_loss: 100.3505\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13746.6309 - val_loss: 99.7553\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13342.8574 - val_loss: 100.1054\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7535.4312 - val_loss: 97.9607\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 80911.8125 - val_loss: 98.0222\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36020.7930 - val_loss: 99.7872\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26950.5996 - val_loss: 100.5058\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25204.7930 - val_loss: 98.9528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 12 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 92802.8828 - val_loss: 74.1958\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 79310.2578 - val_loss: 70.2526\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 58440.7109 - val_loss: 80.2672\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 231945.5312 - val_loss: 84.1281\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 171110.0156 - val_loss: 78.5308\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35661.2188 - val_loss: 77.9873\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19114.3809 - val_loss: 79.6024\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8762.4482 - val_loss: 80.5365\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16172.6436 - val_loss: 81.2652\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16745.9844 - val_loss: 82.7680\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20170.5469 - val_loss: 81.9175\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15817.8916 - val_loss: 83.4123\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30248.7734 - val_loss: 80.8918\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 52323.8164 - val_loss: 81.3577\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7677.7954 - val_loss: 82.6473\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35935.1875 - val_loss: 85.0846\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40099.7070 - val_loss: 83.6986\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 66056.7734 - val_loss: 82.9283\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35682.3555 - val_loss: 85.2492\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5878.4404 - val_loss: 84.9858\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21627.7324 - val_loss: 86.1649\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17887.1211 - val_loss: 85.1048\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13143.5889 - val_loss: 86.1922\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39629.9531 - val_loss: 83.6556\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45731.8086 - val_loss: 83.8715\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30116.0820 - val_loss: 86.1606\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35117.4102 - val_loss: 84.9647\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29380.2500 - val_loss: 85.8719\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15584.5439 - val_loss: 84.8599\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 70919.7422 - val_loss: 84.7225\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 46809.1875 - val_loss: 89.8191\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 197815.2031 - val_loss: 91.9163\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 170675.6719 - val_loss: 90.6500\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 67999.2734 - val_loss: 88.0335\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 62281.5977 - val_loss: 86.8159\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 71681.0312 - val_loss: 87.8457\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10962.0225 - val_loss: 89.9913\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 52373.9297 - val_loss: 90.8108\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 53263.1133 - val_loss: 90.0997\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30943.3555 - val_loss: 89.0669\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39850.9688 - val_loss: 89.9086\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18836.3496 - val_loss: 92.5290\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 90397.4766 - val_loss: 92.4925\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 84265.0000 - val_loss: 91.0737\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33904.8867 - val_loss: 89.5997\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40763.3984 - val_loss: 91.6551\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24331.0762 - val_loss: 91.7257\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20184.0234 - val_loss: 91.1431\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29601.2344 - val_loss: 92.3118\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22858.5391 - val_loss: 92.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 13 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 57503.3672 - val_loss: 112.4765\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 140512.6875 - val_loss: 118.7352\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 75079.7891 - val_loss: 111.9488\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48358.2812 - val_loss: 107.3479\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18020.6621 - val_loss: 109.9244\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 61944.6914 - val_loss: 113.4867\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57475.7969 - val_loss: 110.0753\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8094.8267 - val_loss: 110.0736\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6239.7852 - val_loss: 109.4091\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 28057.2988 - val_loss: 108.8209\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15113.0918 - val_loss: 111.5793\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45503.3359 - val_loss: 112.0193\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38122.7188 - val_loss: 109.2179\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7562.8066 - val_loss: 109.7677\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8200.1348 - val_loss: 109.4004\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2836.8308 - val_loss: 109.1595\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7920.9434 - val_loss: 110.0022\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32287.6582 - val_loss: 110.9653\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24986.0645 - val_loss: 107.3160\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36978.7891 - val_loss: 107.2400\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37840.6953 - val_loss: 108.8817\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10026.5186 - val_loss: 109.5256\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20847.9590 - val_loss: 108.5125\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3520.1304 - val_loss: 111.0477\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39781.0234 - val_loss: 111.5789\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40927.2852 - val_loss: 110.7424\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14593.7744 - val_loss: 108.1394\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36874.8633 - val_loss: 107.1504\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35710.8398 - val_loss: 107.9029\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21354.9004 - val_loss: 110.8227\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54767.1758 - val_loss: 111.7659\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 47657.0234 - val_loss: 110.6987\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25837.1875 - val_loss: 108.0095\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25404.7031 - val_loss: 107.4397\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27756.7109 - val_loss: 108.0257\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 809.8970 - val_loss: 109.9070\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29026.0918 - val_loss: 110.4357\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31221.4414 - val_loss: 108.9121\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5256.5688 - val_loss: 106.7544\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40512.9805 - val_loss: 106.5961\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34218.7188 - val_loss: 107.5695\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 317.1206 - val_loss: 109.2530\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20405.2637 - val_loss: 109.5175\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29354.2637 - val_loss: 109.0191\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8433.9502 - val_loss: 107.2303\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37155.2812 - val_loss: 106.4088\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33347.9414 - val_loss: 107.4062\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1341.8766 - val_loss: 109.0574\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46505.7734 - val_loss: 110.2940\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38791.7852 - val_loss: 108.3601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 14 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 181269.4062 - val_loss: 93.4778\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38251.5156 - val_loss: 106.1953\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 198152.3906 - val_loss: 108.3581\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 167681.2812 - val_loss: 105.2836\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 92015.1016 - val_loss: 101.0465\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33380.8438 - val_loss: 95.8060\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 101150.6406 - val_loss: 94.3402\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 98898.3438 - val_loss: 95.9631\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47243.5391 - val_loss: 98.2394\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14596.7314 - val_loss: 99.1021\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12108.1680 - val_loss: 97.7024\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 42535.4102 - val_loss: 97.5412\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20937.9844 - val_loss: 98.6468\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15691.8057 - val_loss: 99.7843\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22384.0801 - val_loss: 99.4257\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2316.1912 - val_loss: 97.4796\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60094.0977 - val_loss: 97.0265\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55923.1445 - val_loss: 98.1014\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33130.2383 - val_loss: 100.4285\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37927.3047 - val_loss: 101.0056\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34967.0078 - val_loss: 99.7806\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14906.5029 - val_loss: 99.4324\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7394.0576 - val_loss: 99.8743\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4613.1665 - val_loss: 100.0491\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17461.1562 - val_loss: 100.2434\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6938.7983 - val_loss: 98.8122\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26859.6914 - val_loss: 98.9335\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23641.7656 - val_loss: 99.5317\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5925.1367 - val_loss: 99.9793\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3449.3630 - val_loss: 100.3796\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14296.5908 - val_loss: 100.0711\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2281.6531 - val_loss: 98.6124\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45335.5742 - val_loss: 98.5025\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36699.1250 - val_loss: 99.7607\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11065.6904 - val_loss: 100.3337\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3301.9729 - val_loss: 100.3016\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4274.8398 - val_loss: 99.5992\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21524.6641 - val_loss: 99.6693\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12916.7373 - val_loss: 101.3061\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28429.3555 - val_loss: 101.2613\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26093.1289 - val_loss: 100.4036\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8382.4355 - val_loss: 100.1997\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6404.1729 - val_loss: 100.2953\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11638.8975 - val_loss: 100.0162\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6087.7373 - val_loss: 100.8247\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26468.0176 - val_loss: 101.1883\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16400.5996 - val_loss: 100.4519\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4093.1636 - val_loss: 100.3102\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2131.9023 - val_loss: 101.3180\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34186.7266 - val_loss: 101.4847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 15 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 165662.0312 - val_loss: 89.5539\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22987.8359 - val_loss: 82.0533\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 218758.7031 - val_loss: 81.3942\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 160197.0781 - val_loss: 86.5392\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20985.9648 - val_loss: 90.4471\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 110703.3828 - val_loss: 89.6232\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24847.2344 - val_loss: 85.9972\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 143979.3906 - val_loss: 84.5754\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 103860.0156 - val_loss: 88.2952\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34326.7109 - val_loss: 91.6093\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 107706.2422 - val_loss: 91.0607\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 59671.9336 - val_loss: 88.3576\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 79010.8281 - val_loss: 87.4041\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57116.7773 - val_loss: 89.7572\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28860.3359 - val_loss: 89.9716\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10972.4541 - val_loss: 89.7152\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6050.2070 - val_loss: 90.0402\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6600.6060 - val_loss: 89.7196\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7075.7979 - val_loss: 91.3796\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54415.6094 - val_loss: 90.9605\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12434.9541 - val_loss: 90.2189\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19800.0918 - val_loss: 90.9441\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10186.9355 - val_loss: 91.0482\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14701.0215 - val_loss: 90.1751\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20939.1094 - val_loss: 90.9361\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32271.2012 - val_loss: 91.2210\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12622.9814 - val_loss: 90.3498\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14683.0605 - val_loss: 90.7522\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10520.0010 - val_loss: 89.1666\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 79710.2031 - val_loss: 89.1097\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 63142.1523 - val_loss: 91.4904\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 60691.2773 - val_loss: 92.2406\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19749.7891 - val_loss: 91.2792\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8792.4971 - val_loss: 91.7651\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11254.5576 - val_loss: 90.6971\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23642.8672 - val_loss: 91.5519\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36785.9492 - val_loss: 91.3722\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10445.9102 - val_loss: 90.7818\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15492.1230 - val_loss: 91.6000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49757.4805 - val_loss: 92.1979\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21861.9883 - val_loss: 91.4414\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18453.2441 - val_loss: 92.6958\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24300.5508 - val_loss: 92.4122\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4360.3535 - val_loss: 92.3767\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25850.8906 - val_loss: 92.7766\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21672.9609 - val_loss: 93.4065\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3130.8105 - val_loss: 92.9912\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12533.4727 - val_loss: 94.1524\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37842.4492 - val_loss: 94.0706\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2017.2957 - val_loss: 93.2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 16 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 56.6403 - val_loss: 38.5349\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47.0222 - val_loss: 29.0525\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36.1224 - val_loss: 39.8124\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31.3014 - val_loss: 37.2615\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26.4646 - val_loss: 21.7475\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24.3540 - val_loss: 16.6117\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19.9016 - val_loss: 17.6374\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.4000 - val_loss: 8.5512\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.3573 - val_loss: 3.8554\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.4430 - val_loss: 2.1764\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.4738 - val_loss: 6.8646\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.5602 - val_loss: 2.2738\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.8602 - val_loss: 4.1685\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.9464 - val_loss: 1.7787\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.9484 - val_loss: 2.0863\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.2016 - val_loss: 2.3784\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.0979 - val_loss: 2.4877\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5704 - val_loss: 2.0369\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.3276 - val_loss: 2.2946\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8293 - val_loss: 4.3706\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.0359 - val_loss: 2.2407\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.5671 - val_loss: 3.7208\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4346 - val_loss: 2.2124\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.0771 - val_loss: 2.3772\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3163 - val_loss: 3.7769\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.0393 - val_loss: 2.4280\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2948 - val_loss: 2.4721\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.8190 - val_loss: 2.2260\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3791 - val_loss: 4.2531\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2290 - val_loss: 2.3133\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3656 - val_loss: 3.5666\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2757 - val_loss: 2.0080\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0940 - val_loss: 2.8312\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6766 - val_loss: 2.4075\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7081 - val_loss: 2.3537\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9647 - val_loss: 2.9894\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9905 - val_loss: 2.3907\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9183 - val_loss: 2.1651\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9344 - val_loss: 2.2981\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2832 - val_loss: 3.2092\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1289 - val_loss: 1.7615\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1213 - val_loss: 3.5796\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9175 - val_loss: 1.8194\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6987 - val_loss: 2.4773\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5538 - val_loss: 2.6456\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4264 - val_loss: 3.1707\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5033 - val_loss: 2.3314\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5923 - val_loss: 2.3442\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0366 - val_loss: 2.3033\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.0193 - val_loss: 1.7270\n",
      "Iteration number 17 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 82.9693 - val_loss: 67.7449\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37.8758 - val_loss: 28.5071\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31.3375 - val_loss: 14.9678\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25.4427 - val_loss: 29.4740\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.6078 - val_loss: 33.2744\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.6038 - val_loss: 23.8983\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.2140 - val_loss: 14.3847\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.6174 - val_loss: 19.2649\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.6607 - val_loss: 15.8071\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.9025 - val_loss: 8.7374\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9471 - val_loss: 10.9226\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.8633 - val_loss: 3.2552\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7188 - val_loss: 6.6629\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.8860 - val_loss: 2.0467\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0069 - val_loss: 3.6591\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.7234 - val_loss: 2.6772\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6325 - val_loss: 2.7850\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1619 - val_loss: 2.9718\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7056 - val_loss: 2.1532\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1294 - val_loss: 4.1967\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1159 - val_loss: 2.1347\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6398 - val_loss: 3.3226\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0681 - val_loss: 2.0680\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.7365 - val_loss: 2.8831\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6002 - val_loss: 2.4211\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0604 - val_loss: 2.4258\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1470 - val_loss: 2.2988\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8722 - val_loss: 2.7458\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2527 - val_loss: 2.4808\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1295 - val_loss: 2.2608\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9340 - val_loss: 2.6272\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8846 - val_loss: 2.7510\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5321 - val_loss: 2.8783\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6769 - val_loss: 2.6133\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4484 - val_loss: 3.4073\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7520 - val_loss: 2.6732\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9297 - val_loss: 2.5074\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5704 - val_loss: 2.6941\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4040 - val_loss: 2.3325\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9185 - val_loss: 2.6529\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.1933 - val_loss: 3.0217\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0493 - val_loss: 3.0031\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2192 - val_loss: 2.1616\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4867 - val_loss: 2.4190\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4442 - val_loss: 2.3656\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4609 - val_loss: 2.2206\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3691 - val_loss: 2.6509\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5911 - val_loss: 2.9378\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5055 - val_loss: 2.5908\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8459 - val_loss: 2.5808\n",
      "Iteration number 18 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 80945.3906 - val_loss: 101.9984\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 173535.4531 - val_loss: 104.8891\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 140482.6719 - val_loss: 98.0541\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21123.2344 - val_loss: 91.5310\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 150528.4531 - val_loss: 88.8923\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 123232.6328 - val_loss: 92.1886\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73168.3672 - val_loss: 96.5290\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19275.8594 - val_loss: 97.2834\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30485.6875 - val_loss: 96.7745\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4416.9946 - val_loss: 96.9043\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15617.7910 - val_loss: 96.8475\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12403.3398 - val_loss: 96.7258\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11298.9805 - val_loss: 96.9636\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26036.1504 - val_loss: 96.2422\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9207.9678 - val_loss: 97.9465\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25606.8203 - val_loss: 98.1694\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29974.0371 - val_loss: 97.3326\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3612.6045 - val_loss: 95.4945\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 76649.2578 - val_loss: 94.8108\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 65443.0859 - val_loss: 96.7023\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7257.9390 - val_loss: 98.6983\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 57851.3555 - val_loss: 99.7375\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56846.9023 - val_loss: 99.3027\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36678.6562 - val_loss: 97.6912\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33720.3242 - val_loss: 96.9171\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29686.8066 - val_loss: 98.4038\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23959.5488 - val_loss: 98.6678\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18994.0918 - val_loss: 97.6361\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13240.1230 - val_loss: 97.9116\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3518.9177 - val_loss: 98.6448\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30817.5156 - val_loss: 98.9754\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22063.9648 - val_loss: 98.1584\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19856.7168 - val_loss: 97.6658\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1232.0435 - val_loss: 98.4970\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36310.3594 - val_loss: 99.4354\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40581.1758 - val_loss: 99.2964\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14368.2686 - val_loss: 98.0654\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30356.4570 - val_loss: 97.2955\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32200.4961 - val_loss: 97.6242\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9472.6025 - val_loss: 98.5715\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27442.0898 - val_loss: 99.1873\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25867.0332 - val_loss: 98.6902\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5370.4956 - val_loss: 98.3867\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3560.1768 - val_loss: 98.3335\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2896.8704 - val_loss: 98.8859\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21885.7637 - val_loss: 98.8931\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6840.7715 - val_loss: 98.2088\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19692.6660 - val_loss: 97.8976\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18404.4453 - val_loss: 98.6400\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8894.8359 - val_loss: 98.5118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 19 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 132811.0469 - val_loss: 104.2077\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12482.8828 - val_loss: 116.7451\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 143918.1250 - val_loss: 116.2581\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 136116.2031 - val_loss: 113.3111\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90635.6094 - val_loss: 107.4156\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34679.5156 - val_loss: 106.0415\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22227.7559 - val_loss: 107.3698\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1941.7555 - val_loss: 107.0395\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3081.8630 - val_loss: 108.6687\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 30979.2012 - val_loss: 107.7766\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14869.6104 - val_loss: 105.1557\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61133.1914 - val_loss: 104.2278\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31660.6484 - val_loss: 106.5773\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8869.8535 - val_loss: 107.3134\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13700.0420 - val_loss: 105.5421\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28692.9082 - val_loss: 105.6943\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14910.1592 - val_loss: 108.1849\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50168.1406 - val_loss: 108.4163\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34953.8242 - val_loss: 107.3354\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22297.9590 - val_loss: 103.2650\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 96161.6016 - val_loss: 101.3935\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 83235.7266 - val_loss: 102.5829\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 55676.1719 - val_loss: 105.1734\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3588.2703 - val_loss: 105.7246\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9916.7656 - val_loss: 105.2208\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11905.5947 - val_loss: 105.0609\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 899.2670 - val_loss: 104.8108\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17577.9844 - val_loss: 104.8017\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6454.1367 - val_loss: 106.2462\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39720.0117 - val_loss: 106.7012\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34892.9414 - val_loss: 105.0170\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14593.6533 - val_loss: 104.5718\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4873.1724 - val_loss: 105.7140\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17840.3379 - val_loss: 105.5898\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15228.1123 - val_loss: 105.1345\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20502.9668 - val_loss: 104.0545\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17173.5605 - val_loss: 105.6466\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20641.8809 - val_loss: 105.4518\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17357.2656 - val_loss: 104.2334\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13647.0098 - val_loss: 104.4060\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1553.8468 - val_loss: 105.3803\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 37334.1367 - val_loss: 105.9586\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21726.3867 - val_loss: 104.6967\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4843.1680 - val_loss: 102.3730\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 56060.7500 - val_loss: 101.8358\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60890.3750 - val_loss: 102.1178\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 46434.4766 - val_loss: 103.5554\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14064.5098 - val_loss: 105.4402\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33137.8516 - val_loss: 105.5942\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39166.3281 - val_loss: 104.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 20 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 153036.5938 - val_loss: 91.0811\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 51344.8867 - val_loss: 94.5889\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11474.7021 - val_loss: 88.9247\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 82364.7734 - val_loss: 87.4663\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 67666.9844 - val_loss: 91.1752\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13824.7666 - val_loss: 96.8132\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 99244.3750 - val_loss: 98.1420\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 82364.0781 - val_loss: 97.0751\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27235.7461 - val_loss: 93.0124\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 43126.6914 - val_loss: 91.0889\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 52095.1719 - val_loss: 91.8878\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27680.6914 - val_loss: 95.1971\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25640.0547 - val_loss: 95.3093\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27548.8945 - val_loss: 93.4797\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11939.5547 - val_loss: 93.9073\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8529.1758 - val_loss: 93.6507\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21257.2461 - val_loss: 93.1275\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9183.7842 - val_loss: 94.0099\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2601.6189 - val_loss: 94.2404\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8991.8965 - val_loss: 93.2996\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15834.4111 - val_loss: 93.8337\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5786.2026 - val_loss: 93.6783\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13946.8389 - val_loss: 93.7883\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4582.2695 - val_loss: 93.6678\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18321.9551 - val_loss: 93.4856\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 501.6021 - val_loss: 94.9518\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27122.6504 - val_loss: 95.3608\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25960.1309 - val_loss: 94.6539\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5346.0771 - val_loss: 94.1289\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 422.6141 - val_loss: 93.1363\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20072.6680 - val_loss: 94.0515\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2995.4751 - val_loss: 93.6216\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24235.1660 - val_loss: 93.3483\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4822.7593 - val_loss: 95.6259\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52947.9102 - val_loss: 96.8026\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51594.9062 - val_loss: 95.3953\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20711.9512 - val_loss: 93.2889\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41898.3945 - val_loss: 92.6731\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36621.5547 - val_loss: 94.0834\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4758.2710 - val_loss: 96.1020\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32284.0918 - val_loss: 96.3121\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35852.3438 - val_loss: 95.4982\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16415.5059 - val_loss: 93.7548\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28512.2930 - val_loss: 93.6651\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23748.3945 - val_loss: 94.1376\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2148.8240 - val_loss: 96.1643\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28889.4609 - val_loss: 96.6882\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43679.6875 - val_loss: 96.5427\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31596.6211 - val_loss: 95.1401\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8989.8730 - val_loss: 94.8020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 21 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 75.9538 - val_loss: 60.6610\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40.7564 - val_loss: 24.6694\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39.0600 - val_loss: 30.1170\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.8222 - val_loss: 37.0989\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27.7230 - val_loss: 26.6163\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22.9384 - val_loss: 14.0634\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21.1100 - val_loss: 21.6008\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.9889 - val_loss: 12.6067\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.4311 - val_loss: 9.6227\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.9490 - val_loss: 6.7772\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.7686 - val_loss: 2.6990\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.6687 - val_loss: 2.8650\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.2264 - val_loss: 3.9233\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.0804 - val_loss: 2.9657\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.5235 - val_loss: 2.6963\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7011 - val_loss: 5.1280\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.6088 - val_loss: 3.0294\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8011 - val_loss: 5.2022\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7435 - val_loss: 2.5318\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1217 - val_loss: 3.7389\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7477 - val_loss: 3.1432\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4798 - val_loss: 2.5673\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2318 - val_loss: 3.3795\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9180 - val_loss: 2.3858\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4996 - val_loss: 3.0501\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4637 - val_loss: 2.2873\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2991 - val_loss: 3.8701\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4176 - val_loss: 2.3273\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0281 - val_loss: 3.0360\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.7423 - val_loss: 2.3380\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8912 - val_loss: 4.8183\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0586 - val_loss: 2.2085\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5351 - val_loss: 4.5080\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7744 - val_loss: 3.0554\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5258 - val_loss: 3.9048\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.7518 - val_loss: 2.2900\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5565 - val_loss: 2.5077\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3140 - val_loss: 2.5011\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1454 - val_loss: 2.4475\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9997 - val_loss: 2.6700\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9923 - val_loss: 2.2124\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2377 - val_loss: 2.9641\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2035 - val_loss: 2.5913\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.1334 - val_loss: 2.2243\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.3441 - val_loss: 2.6879\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.9933 - val_loss: 2.1881\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.0846 - val_loss: 2.1943\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.7495 - val_loss: 2.2020\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.0662 - val_loss: 2.0579\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4184 - val_loss: 2.8046\n",
      "Iteration number 22 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 97703.3984 - val_loss: 90.5917\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 69955.1797 - val_loss: 91.3402\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21140.0059 - val_loss: 87.9083\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 70272.4688 - val_loss: 85.6569\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47313.2227 - val_loss: 88.8724\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 562.6105 - val_loss: 89.6084\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8805.2471 - val_loss: 90.5145\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7208.7993 - val_loss: 91.1042\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16695.1309 - val_loss: 89.3401\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41527.7344 - val_loss: 88.2318\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 963.4958 - val_loss: 89.9162\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22845.2637 - val_loss: 89.8558\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10794.1875 - val_loss: 93.5922\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53410.9922 - val_loss: 93.5703\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 41877.8789 - val_loss: 90.6227\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33042.1367 - val_loss: 89.7141\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10477.8447 - val_loss: 93.2828\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 61056.6367 - val_loss: 95.1065\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54088.7578 - val_loss: 94.2108\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41316.5312 - val_loss: 89.3217\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52419.6406 - val_loss: 88.5771\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 57517.5000 - val_loss: 89.9088\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19497.6797 - val_loss: 91.8789\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6209.1792 - val_loss: 96.5124\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 96286.2734 - val_loss: 98.0424\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 98651.6250 - val_loss: 97.6083\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 73982.9688 - val_loss: 95.6794\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42787.2812 - val_loss: 92.6479\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39201.4805 - val_loss: 92.0541\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33792.8164 - val_loss: 93.5600\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11177.8623 - val_loss: 94.0801\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5484.7769 - val_loss: 93.7719\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1428.1842 - val_loss: 92.9170\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24386.5391 - val_loss: 92.8093\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7314.2148 - val_loss: 93.8518\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26563.5059 - val_loss: 95.1511\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27656.9609 - val_loss: 94.2224\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3884.5281 - val_loss: 93.8752\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6085.3193 - val_loss: 93.8830\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 349.9977 - val_loss: 92.7577\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21629.6465 - val_loss: 93.0600\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15999.8027 - val_loss: 94.3629\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13698.9453 - val_loss: 94.2165\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6369.7007 - val_loss: 92.8673\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32834.5117 - val_loss: 92.5890\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24090.9844 - val_loss: 93.7588\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4907.4702 - val_loss: 95.8762\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44394.1328 - val_loss: 96.2619\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45107.2266 - val_loss: 95.6647\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17918.8066 - val_loss: 94.6573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 23 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 80.4739 - val_loss: 57.8881\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.6353 - val_loss: 11.9251\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.7496 - val_loss: 22.0174\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25.3321 - val_loss: 34.3443\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24.0986 - val_loss: 27.9146\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.1588 - val_loss: 14.7260\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17.9839 - val_loss: 11.8057\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.6866 - val_loss: 14.7944\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.8731 - val_loss: 5.3641\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.5403 - val_loss: 4.8095\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.2412 - val_loss: 3.0450\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.4839 - val_loss: 6.5515\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.6204 - val_loss: 3.9796\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1988 - val_loss: 6.5109\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2192 - val_loss: 5.9679\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6833 - val_loss: 4.3373\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3515 - val_loss: 6.3587\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5797 - val_loss: 2.1597\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6649 - val_loss: 6.7958\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6589 - val_loss: 2.4987\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2238 - val_loss: 4.8147\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5199 - val_loss: 2.9518\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3293 - val_loss: 4.3269\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1513 - val_loss: 2.5175\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2316 - val_loss: 5.3111\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0192 - val_loss: 2.9308\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8134 - val_loss: 3.5135\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6118 - val_loss: 3.1251\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4887 - val_loss: 2.2262\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3452 - val_loss: 5.7725\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7685 - val_loss: 2.1298\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5721 - val_loss: 4.8364\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1460 - val_loss: 2.2188\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4811 - val_loss: 5.1095\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9227 - val_loss: 1.9450\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4253 - val_loss: 4.1645\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6448 - val_loss: 1.8674\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2691 - val_loss: 4.0077\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.3070 - val_loss: 1.9824\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0650 - val_loss: 5.1746\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6745 - val_loss: 1.8749\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9762 - val_loss: 3.2440\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5695 - val_loss: 2.4354\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5530 - val_loss: 2.2184\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4932 - val_loss: 2.0068\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4919 - val_loss: 4.1385\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5007 - val_loss: 2.0069\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4550 - val_loss: 2.5580\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1995 - val_loss: 2.0589\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.4513 - val_loss: 2.7858\n",
      "Iteration number 24 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 2636116.2500 - val_loss: 95.4007\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4853628.0000 - val_loss: 93.7893\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3844320.7500 - val_loss: 92.6838\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2058236.6250 - val_loss: 91.6880\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1898743.3750 - val_loss: 90.8270\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1327176.3750 - val_loss: 90.1421\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1175817.2500 - val_loss: 89.3573\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1512773.3750 - val_loss: 88.5174\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 901658.4375 - val_loss: 87.6250\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 603991.2500 - val_loss: 86.9198\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 176071.0312 - val_loss: 86.1455\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 198488.6562 - val_loss: 85.2728\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 173589.6875 - val_loss: 84.4111\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 199097.9219 - val_loss: 83.5481\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 200652.3906 - val_loss: 82.6773\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 165238.2031 - val_loss: 81.9148\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 158930.8906 - val_loss: 81.2121\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 212487.5781 - val_loss: 80.4408\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 161701.8125 - val_loss: 79.6025\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 210251.0469 - val_loss: 78.8511\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 196460.5312 - val_loss: 77.9091\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 168045.2500 - val_loss: 76.9904\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 171737.7344 - val_loss: 76.2393\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 191277.0000 - val_loss: 75.5300\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 191711.0312 - val_loss: 74.6395\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 174409.3438 - val_loss: 73.9019\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 170968.3438 - val_loss: 73.0158\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 185510.2500 - val_loss: 72.2170\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 175447.1250 - val_loss: 71.4107\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 181165.6250 - val_loss: 70.7857\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 171836.2969 - val_loss: 70.0617\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 183571.7500 - val_loss: 69.3277\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 184945.1406 - val_loss: 68.5633\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 164777.9219 - val_loss: 67.7053\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 155166.4531 - val_loss: 66.9896\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 190561.7969 - val_loss: 66.2642\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 182635.7812 - val_loss: 65.5894\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 164220.9375 - val_loss: 64.8633\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 141276.4844 - val_loss: 64.1770\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 190606.0000 - val_loss: 63.4645\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 142864.0156 - val_loss: 62.8265\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 187450.5781 - val_loss: 62.2553\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 182137.3906 - val_loss: 61.7899\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 391377.4062 - val_loss: 61.1379\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 703898.5000 - val_loss: 60.9345\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 986813.2500 - val_loss: 60.8561\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 382976.6250 - val_loss: 60.7890\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 234275.9688 - val_loss: 60.6519\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 307744.1250 - val_loss: 60.4758\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 70031.6719 - val_loss: 60.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 25 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 122910.2266 - val_loss: 106.6814\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 127596.5625 - val_loss: 105.4160\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 62446.4336 - val_loss: 100.5896\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7725.1836 - val_loss: 100.5872\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 860.6899 - val_loss: 103.1105\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 83630.2500 - val_loss: 103.8015\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 47875.1328 - val_loss: 101.9382\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26568.8398 - val_loss: 96.3695\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 98973.7266 - val_loss: 95.5603\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 122627.0781 - val_loss: 96.5474\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 88380.5234 - val_loss: 99.4495\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18501.1797 - val_loss: 102.9756\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76352.1172 - val_loss: 103.9834\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73703.3047 - val_loss: 102.4749\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21435.9492 - val_loss: 100.7890\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14475.0117 - val_loss: 100.2441\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17063.4863 - val_loss: 101.2210\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26398.4668 - val_loss: 101.4495\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10317.4053 - val_loss: 100.1424\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43708.4375 - val_loss: 99.5432\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37304.5508 - val_loss: 100.8390\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14612.9033 - val_loss: 101.2603\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5401.4229 - val_loss: 99.9545\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37523.8828 - val_loss: 99.9638\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28810.0566 - val_loss: 100.8935\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4872.0376 - val_loss: 102.9106\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 75832.5234 - val_loss: 103.5892\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 68244.8750 - val_loss: 102.8975\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38255.5312 - val_loss: 101.2621\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14813.2568 - val_loss: 100.6284\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16251.1436 - val_loss: 101.0381\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12121.0332 - val_loss: 101.3529\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1990.8654 - val_loss: 100.4069\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34418.8320 - val_loss: 100.1533\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28463.8262 - val_loss: 101.0987\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13206.1992 - val_loss: 101.3796\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5141.0410 - val_loss: 100.2991\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36535.4922 - val_loss: 100.1154\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25956.6660 - val_loss: 100.6011\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16241.2109 - val_loss: 102.6349\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 69940.3125 - val_loss: 103.4240\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69522.4375 - val_loss: 102.8604\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36126.2188 - val_loss: 101.9940\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15228.2998 - val_loss: 100.0634\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 67910.2266 - val_loss: 99.0711\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 61023.1172 - val_loss: 99.5137\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44988.1641 - val_loss: 101.0871\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3569.3035 - val_loss: 102.7711\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 63577.1133 - val_loss: 103.3013\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 67400.6484 - val_loss: 103.0770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 26 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 107363.6328 - val_loss: 100.0468\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 75528.2500 - val_loss: 102.7378\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25727.3027 - val_loss: 100.0184\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 58383.7695 - val_loss: 96.3767\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 55118.4570 - val_loss: 98.9474\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7265.3379 - val_loss: 100.0708\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6989.7461 - val_loss: 101.5237\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18502.2773 - val_loss: 100.0611\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10129.7227 - val_loss: 101.5715\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 20554.9551 - val_loss: 100.6932\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4599.6597 - val_loss: 102.0027\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 23227.5723 - val_loss: 101.0759\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1841.7446 - val_loss: 97.5608\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 64649.8828 - val_loss: 97.8437\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 52760.9141 - val_loss: 100.6006\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13522.6826 - val_loss: 104.8428\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 72047.1875 - val_loss: 105.9622\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 66419.8906 - val_loss: 104.3529\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10638.6465 - val_loss: 102.5615\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42129.4062 - val_loss: 100.5951\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 45938.6953 - val_loss: 101.5193\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12278.3359 - val_loss: 103.2264\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17486.5059 - val_loss: 103.7146\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 18877.8125 - val_loss: 102.2372\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14890.4541 - val_loss: 102.7203\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2613.5786 - val_loss: 102.2574\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25440.2871 - val_loss: 101.9796\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18163.2910 - val_loss: 104.8247\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43467.7773 - val_loss: 105.2958\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 41938.3906 - val_loss: 104.4279\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11712.4941 - val_loss: 102.4018\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46741.3984 - val_loss: 101.4666\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 39508.6055 - val_loss: 103.1196\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5743.7773 - val_loss: 103.5602\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3749.8125 - val_loss: 103.8779\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15998.8506 - val_loss: 103.9100\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8651.8232 - val_loss: 102.2501\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 44022.8711 - val_loss: 101.7902\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 36127.7305 - val_loss: 102.8527\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10518.6846 - val_loss: 104.6735\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 48953.3398 - val_loss: 105.5494\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45653.8242 - val_loss: 104.0257\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7055.4160 - val_loss: 103.4655\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7396.3667 - val_loss: 103.7166\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 2247.3738 - val_loss: 102.3815\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28795.5039 - val_loss: 102.5860\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 23152.5273 - val_loss: 103.1330\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3817.5625 - val_loss: 104.5272\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 37153.1523 - val_loss: 105.2300\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 35253.7773 - val_loss: 104.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 27 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 196378.4219 - val_loss: 92.3783\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84537.9375 - val_loss: 97.5313\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63485.2695 - val_loss: 88.9814\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 111916.2891 - val_loss: 87.3583\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 99307.3594 - val_loss: 90.7091\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33813.1953 - val_loss: 95.3416\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73675.5547 - val_loss: 97.2720\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66865.6016 - val_loss: 95.0586\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 657.3619 - val_loss: 94.4063\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19031.0391 - val_loss: 94.2279\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17845.2207 - val_loss: 93.6416\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15914.8818 - val_loss: 94.4732\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 307.0338 - val_loss: 92.9196\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33248.5977 - val_loss: 92.6269\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27722.1191 - val_loss: 94.1076\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15719.8848 - val_loss: 94.3579\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3291.5652 - val_loss: 92.1994\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38340.6836 - val_loss: 92.5796\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 27757.2793 - val_loss: 93.7024\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15105.7842 - val_loss: 94.5232\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1045.6958 - val_loss: 94.5910\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42843.5312 - val_loss: 95.9311\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36749.0195 - val_loss: 93.0591\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51365.0547 - val_loss: 91.9551\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25354.8066 - val_loss: 93.6567\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25733.2012 - val_loss: 95.5717\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29296.2832 - val_loss: 94.5082\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7900.2021 - val_loss: 94.3403\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 946.1033 - val_loss: 93.5532\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21029.8594 - val_loss: 94.0797\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3091.5520 - val_loss: 93.9248\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8856.3877 - val_loss: 94.8075\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19521.1309 - val_loss: 94.8602\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15563.4668 - val_loss: 93.9016\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10367.6494 - val_loss: 96.2335\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46802.3477 - val_loss: 96.4353\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42259.6094 - val_loss: 95.1946\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 556.3193 - val_loss: 93.6367\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51253.9609 - val_loss: 92.4475\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35413.8789 - val_loss: 93.5233\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23864.6621 - val_loss: 96.6537\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45904.0273 - val_loss: 97.2991\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 63447.2812 - val_loss: 97.1562\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49222.1133 - val_loss: 95.5723\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3524.4536 - val_loss: 94.9789\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 598.0298 - val_loss: 94.3254\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 20319.3457 - val_loss: 94.6566\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5742.9575 - val_loss: 95.6900\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 30294.6914 - val_loss: 96.1848\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 23509.7480 - val_loss: 95.3075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 28 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 73398.9375 - val_loss: 117.6777\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 146707.6250 - val_loss: 113.6285\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 91152.2188 - val_loss: 105.7094\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35239.8906 - val_loss: 105.8260\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14744.4736 - val_loss: 111.0109\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63356.9922 - val_loss: 109.8432\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46074.7617 - val_loss: 105.4575\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19472.8750 - val_loss: 106.4617\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5163.8818 - val_loss: 105.9675\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47343.9023 - val_loss: 103.7852\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36639.7109 - val_loss: 105.7857\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27274.5137 - val_loss: 107.6734\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4295.0078 - val_loss: 103.6346\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77102.5391 - val_loss: 101.5934\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69266.9297 - val_loss: 103.8053\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35908.1719 - val_loss: 108.6165\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 72275.0547 - val_loss: 110.2166\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67734.4375 - val_loss: 107.2589\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7140.7681 - val_loss: 104.0432\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52759.2656 - val_loss: 102.8664\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50211.9180 - val_loss: 104.7380\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17686.8418 - val_loss: 108.3225\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44091.0859 - val_loss: 108.1338\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41906.6758 - val_loss: 107.3646\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30405.7656 - val_loss: 102.9991\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54754.6797 - val_loss: 102.0125\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58535.6562 - val_loss: 103.2540\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16316.7090 - val_loss: 105.2300\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20159.9453 - val_loss: 105.6796\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18308.4805 - val_loss: 104.0369\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12838.1953 - val_loss: 104.5359\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2645.2388 - val_loss: 106.4778\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50946.2383 - val_loss: 106.8374\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31798.2109 - val_loss: 105.6212\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1337.4749 - val_loss: 104.3646\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5851.7764 - val_loss: 105.4086\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20514.7051 - val_loss: 105.0084\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2573.5410 - val_loss: 103.8470\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21424.0566 - val_loss: 103.6010\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18867.8594 - val_loss: 105.1418\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12278.4844 - val_loss: 104.5921\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2783.4395 - val_loss: 104.9355\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8655.4053 - val_loss: 104.4641\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4356.4380 - val_loss: 104.8518\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20714.3242 - val_loss: 105.1812\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11297.0234 - val_loss: 103.3843\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38589.6367 - val_loss: 102.7497\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30120.7832 - val_loss: 104.0651\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9959.9307 - val_loss: 104.6629\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5478.3301 - val_loss: 102.8833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 29 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 25973.3496 - val_loss: 105.7352\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 231964.0312 - val_loss: 104.3488\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 169784.6250 - val_loss: 97.8519\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38734.7188 - val_loss: 90.9839\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 100655.0625 - val_loss: 89.3774\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 82152.9844 - val_loss: 92.0611\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8911.4619 - val_loss: 95.5398\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67644.9609 - val_loss: 97.6525\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66125.1797 - val_loss: 95.5910\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14647.7373 - val_loss: 92.8173\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65687.9062 - val_loss: 91.8415\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60698.4258 - val_loss: 94.2792\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13909.7930 - val_loss: 97.4707\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66956.1875 - val_loss: 98.2083\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 62425.0117 - val_loss: 96.3972\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6704.3140 - val_loss: 94.5658\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27266.2246 - val_loss: 94.0226\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30841.9844 - val_loss: 94.7477\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1686.8558 - val_loss: 95.3202\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5091.3750 - val_loss: 96.3915\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24899.2148 - val_loss: 96.2963\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1113.5056 - val_loss: 94.6536\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38391.6094 - val_loss: 93.9079\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36827.1680 - val_loss: 95.6072\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14206.7842 - val_loss: 96.1215\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14995.2939 - val_loss: 95.3995\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9055.4736 - val_loss: 97.9284\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43173.4023 - val_loss: 98.0023\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43304.8203 - val_loss: 97.1365\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18306.9727 - val_loss: 95.0293\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43607.6250 - val_loss: 94.2254\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40706.7188 - val_loss: 95.8769\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5960.1865 - val_loss: 96.2441\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3217.3464 - val_loss: 96.8435\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21565.0703 - val_loss: 96.9976\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2814.4973 - val_loss: 96.4133\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2826.4932 - val_loss: 95.6992\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21285.9941 - val_loss: 95.9100\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3184.0667 - val_loss: 97.0317\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13273.7402 - val_loss: 97.1338\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15406.5596 - val_loss: 96.3958\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1802.6851 - val_loss: 96.7665\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6089.5591 - val_loss: 95.7818\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24454.3359 - val_loss: 95.7692\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10108.3037 - val_loss: 97.2204\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21433.7480 - val_loss: 97.4940\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19977.6211 - val_loss: 96.3091\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14496.2686 - val_loss: 96.3883\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6023.7432 - val_loss: 97.9835\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45987.6797 - val_loss: 98.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 30 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 34930.6211 - val_loss: 84.6999\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 340086.2500 - val_loss: 79.1136\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 252168.3125 - val_loss: 88.6945\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 126351.1562 - val_loss: 97.7109\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11111.7139 - val_loss: 99.9667\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27546.0234 - val_loss: 98.5993\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9395.9346 - val_loss: 99.1554\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7589.9624 - val_loss: 97.2627\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42934.8008 - val_loss: 96.9396\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21026.2754 - val_loss: 101.3425\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47019.1602 - val_loss: 101.7861\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 57937.8867 - val_loss: 100.4210\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25248.6035 - val_loss: 96.8738\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40837.6562 - val_loss: 96.3050\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38432.3359 - val_loss: 97.3422\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4270.3999 - val_loss: 100.5748\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80623.1953 - val_loss: 102.5213\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58244.9531 - val_loss: 100.6798\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16411.5059 - val_loss: 96.2248\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76336.1797 - val_loss: 93.8803\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80398.6406 - val_loss: 95.1282\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45509.6758 - val_loss: 97.3301\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11275.8760 - val_loss: 98.4040\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3011.8569 - val_loss: 97.5297\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8681.9316 - val_loss: 97.0028\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18504.3691 - val_loss: 98.3822\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18451.7480 - val_loss: 98.4154\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5771.9473 - val_loss: 98.0644\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2125.1753 - val_loss: 97.8747\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3384.9563 - val_loss: 98.3018\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31360.5371 - val_loss: 99.4612\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29010.3789 - val_loss: 97.5837\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24695.7871 - val_loss: 97.0010\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17888.2852 - val_loss: 99.8993\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46225.6523 - val_loss: 100.2507\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44682.0234 - val_loss: 98.8742\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18265.6582 - val_loss: 96.2926\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32143.1641 - val_loss: 96.2882\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31765.2168 - val_loss: 96.7642\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5995.3345 - val_loss: 99.4814\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42065.9297 - val_loss: 100.3434\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 52581.1328 - val_loss: 99.9524\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41114.3086 - val_loss: 97.5771\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19770.8672 - val_loss: 97.0804\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14825.8154 - val_loss: 98.1205\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15401.5234 - val_loss: 98.3083\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6021.4072 - val_loss: 97.1098\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26550.4473 - val_loss: 96.8201\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18792.6973 - val_loss: 97.9395\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2038.9739 - val_loss: 97.7512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 31 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 76.6168 - val_loss: 57.0204\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.1868 - val_loss: 32.5022\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.7768 - val_loss: 38.5178\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.7367 - val_loss: 35.2200\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27.7363 - val_loss: 22.5146\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24.3326 - val_loss: 15.1913\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21.3988 - val_loss: 15.5885\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 17.3572 - val_loss: 4.6548\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.0866 - val_loss: 7.5897\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.0613 - val_loss: 3.7297\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.6577 - val_loss: 3.9644\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.5900 - val_loss: 5.9709\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.7653 - val_loss: 4.4164\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.9338 - val_loss: 3.4671\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.7166 - val_loss: 4.1819\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.4539 - val_loss: 3.7730\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.5574 - val_loss: 4.1037\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.1911 - val_loss: 4.3082\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.0074 - val_loss: 3.1025\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.6251 - val_loss: 4.2070\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.8368 - val_loss: 3.0731\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.9241 - val_loss: 4.1180\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.7485 - val_loss: 2.8524\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.2236 - val_loss: 3.6857\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2427 - val_loss: 2.7589\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.8084 - val_loss: 2.5270\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.6054 - val_loss: 3.3580\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.9453 - val_loss: 2.4220\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.4031 - val_loss: 4.1646\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.7603 - val_loss: 3.1531\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.3636 - val_loss: 3.5978\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.9390 - val_loss: 2.8113\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.0146 - val_loss: 3.4249\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.4097 - val_loss: 2.4919\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.0516 - val_loss: 2.7335\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.8205 - val_loss: 1.7402\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4115 - val_loss: 2.7650\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.9397 - val_loss: 3.0964\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.5883 - val_loss: 1.9794\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.2926 - val_loss: 2.2030\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.2489 - val_loss: 1.8769\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.8124 - val_loss: 2.9184\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.8347 - val_loss: 2.3636\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.4615 - val_loss: 2.3959\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.2634 - val_loss: 1.6898\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3233 - val_loss: 2.5650\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0554 - val_loss: 2.3495\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.8661 - val_loss: 2.9872\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.1185 - val_loss: 1.5651\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.8713 - val_loss: 3.2777\n",
      "Iteration number 32 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 81.4237 - val_loss: 68.4334\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 50.5618 - val_loss: 38.6314\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43.4994 - val_loss: 40.0330\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 35.2657 - val_loss: 41.0430\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 31.0584 - val_loss: 28.8019\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25.6536 - val_loss: 18.3314\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21.7105 - val_loss: 18.1929\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18.0834 - val_loss: 9.6156\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.3307 - val_loss: 9.1515\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.1411 - val_loss: 5.5007\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.6479 - val_loss: 5.9282\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.6296 - val_loss: 5.2528\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.0906 - val_loss: 5.9466\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.5698 - val_loss: 6.1855\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.2014 - val_loss: 4.4614\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.6139 - val_loss: 4.9446\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.9319 - val_loss: 5.4537\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.6655 - val_loss: 4.7489\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.6411 - val_loss: 4.0158\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2552 - val_loss: 5.2576\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8862 - val_loss: 4.0702\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4500 - val_loss: 4.6461\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.8610 - val_loss: 2.6946\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6801 - val_loss: 5.0602\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4922 - val_loss: 4.0644\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.9758 - val_loss: 3.5107\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6520 - val_loss: 4.2287\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.4953 - val_loss: 3.3958\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.1566 - val_loss: 3.9355\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.6682 - val_loss: 4.5369\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.6660 - val_loss: 3.7068\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.8241 - val_loss: 2.3198\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3727 - val_loss: 5.6627\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0325 - val_loss: 2.2623\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.2992 - val_loss: 2.9501\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8963 - val_loss: 3.0324\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.6882 - val_loss: 3.0284\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.6221 - val_loss: 2.9294\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.6011 - val_loss: 2.0395\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.2182 - val_loss: 3.2364\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3613 - val_loss: 2.0285\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.1858 - val_loss: 2.0472\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.4307 - val_loss: 3.6309\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6644 - val_loss: 2.0181\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0840 - val_loss: 2.4500\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0341 - val_loss: 2.1042\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.7871 - val_loss: 2.0670\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.8110 - val_loss: 2.8845\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9106 - val_loss: 1.9970\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.8173 - val_loss: 3.0543\n",
      "Iteration number 33 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 91.5987 - val_loss: 76.3170\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.1025 - val_loss: 36.4421\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.6294 - val_loss: 18.9644\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30.7655 - val_loss: 32.9740\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26.1620 - val_loss: 36.8378\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24.4185 - val_loss: 26.5283\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.8847 - val_loss: 15.1945\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.3388 - val_loss: 15.9888\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.8606 - val_loss: 14.1683\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.9379 - val_loss: 7.8624\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.3767 - val_loss: 2.9888\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4451 - val_loss: 3.3030\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8799 - val_loss: 3.3359\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.0675 - val_loss: 2.4722\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5927 - val_loss: 2.7105\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.8920 - val_loss: 3.1424\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1058 - val_loss: 2.4709\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2391 - val_loss: 4.4923\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.0000 - val_loss: 3.1236\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9257 - val_loss: 3.0538\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9217 - val_loss: 2.6159\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.5265 - val_loss: 2.4739\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3806 - val_loss: 3.9081\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3200 - val_loss: 2.4403\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5825 - val_loss: 3.5587\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0035 - val_loss: 2.1870\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1138 - val_loss: 2.1452\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0290 - val_loss: 3.6953\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.0958 - val_loss: 2.5004\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.7510 - val_loss: 2.2155\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.4935 - val_loss: 2.0574\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5107 - val_loss: 2.1095\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.8314 - val_loss: 1.9686\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.4394 - val_loss: 2.7668\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3242 - val_loss: 2.1572\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5395 - val_loss: 4.2198\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8314 - val_loss: 1.7859\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0946 - val_loss: 2.3619\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9918 - val_loss: 1.9669\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0350 - val_loss: 2.0347\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.2666 - val_loss: 3.6357\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6697 - val_loss: 2.1798\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.8622 - val_loss: 3.0637\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.1465 - val_loss: 1.6850\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.8267 - val_loss: 2.4959\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8446 - val_loss: 2.2763\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5845 - val_loss: 1.7491\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.5886 - val_loss: 3.1149\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5861 - val_loss: 1.7160\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.4150 - val_loss: 2.1369\n",
      "Iteration number 34 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 178968.1250 - val_loss: 99.0497\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 222254.1094 - val_loss: 104.7032\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 64782.2383 - val_loss: 109.9773\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 160038.3750 - val_loss: 109.7538\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28761.1484 - val_loss: 105.2459\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61133.3008 - val_loss: 102.4961\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 101469.1484 - val_loss: 102.8183\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62922.6758 - val_loss: 105.8454\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 97671.7969 - val_loss: 106.8731\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 87914.4375 - val_loss: 103.5748\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 75495.3047 - val_loss: 102.4830\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34832.8594 - val_loss: 104.1493\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37081.9297 - val_loss: 104.8867\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45023.6406 - val_loss: 104.0251\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11856.6885 - val_loss: 103.9416\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15008.8818 - val_loss: 105.3963\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48748.6094 - val_loss: 104.9926\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26238.0137 - val_loss: 103.3743\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49558.4727 - val_loss: 103.3294\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5117.8208 - val_loss: 103.3775\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7470.8789 - val_loss: 103.8174\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56567.1758 - val_loss: 104.0369\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25623.6973 - val_loss: 101.9053\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16603.3594 - val_loss: 102.4069\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36213.7734 - val_loss: 102.1516\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2247.4009 - val_loss: 101.2126\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40703.5586 - val_loss: 101.5656\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33711.2578 - val_loss: 102.9544\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 44217.8633 - val_loss: 101.3850\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12177.4844 - val_loss: 101.5485\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18932.5527 - val_loss: 100.7630\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18861.0371 - val_loss: 101.2274\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19506.6816 - val_loss: 101.0258\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24919.7090 - val_loss: 100.9010\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22361.4414 - val_loss: 102.4318\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43851.3516 - val_loss: 102.2968\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1196.0781 - val_loss: 102.6762\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22300.9531 - val_loss: 102.7137\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6617.2231 - val_loss: 101.4467\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25975.8340 - val_loss: 101.7292\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21021.9434 - val_loss: 101.6493\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15061.5098 - val_loss: 101.1553\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10406.0391 - val_loss: 100.7875\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8494.5908 - val_loss: 101.0258\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13194.4219 - val_loss: 100.5781\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7256.2905 - val_loss: 101.0971\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24822.3047 - val_loss: 100.7698\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17842.2109 - val_loss: 100.6830\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17720.2578 - val_loss: 102.3726\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 46937.9180 - val_loss: 102.6897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 35 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 74.9444 - val_loss: 53.6921\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31.5734 - val_loss: 10.4871\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30.9982 - val_loss: 20.0084\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21.9976 - val_loss: 34.2115\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 21.4110 - val_loss: 27.9614\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.9837 - val_loss: 16.3684\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.6667 - val_loss: 14.4351\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.0501 - val_loss: 16.3184\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2252 - val_loss: 7.0235\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9505 - val_loss: 9.2453\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4741 - val_loss: 5.3459\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9097 - val_loss: 5.7170\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1227 - val_loss: 4.8284\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9600 - val_loss: 4.5993\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.7666 - val_loss: 4.7869\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6757 - val_loss: 4.8528\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4114 - val_loss: 4.0864\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2893 - val_loss: 4.1699\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2648 - val_loss: 4.2604\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.9998 - val_loss: 4.4672\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2380 - val_loss: 3.6722\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1108 - val_loss: 4.0018\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3901 - val_loss: 4.1960\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3072 - val_loss: 3.2959\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9212 - val_loss: 3.2202\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9865 - val_loss: 3.6646\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4089 - val_loss: 3.5330\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1400 - val_loss: 3.6998\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0330 - val_loss: 2.4489\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0211 - val_loss: 3.6888\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9741 - val_loss: 2.6324\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.7382 - val_loss: 3.3255\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6576 - val_loss: 2.5176\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6221 - val_loss: 3.2144\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4119 - val_loss: 2.0628\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5121 - val_loss: 4.7613\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5309 - val_loss: 1.8276\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3621 - val_loss: 2.0701\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2154 - val_loss: 2.7635\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1542 - val_loss: 2.9928\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2161 - val_loss: 2.2652\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0996 - val_loss: 3.0997\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8992 - val_loss: 2.0231\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1920 - val_loss: 2.1205\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4067 - val_loss: 3.3383\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.4753 - val_loss: 3.4257\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.2698 - val_loss: 4.2030\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1457 - val_loss: 2.2164\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.2709 - val_loss: 2.1041\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0577 - val_loss: 2.7756\n",
      "Iteration number 36 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 31226.0586 - val_loss: 77.0460\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 160349.6094 - val_loss: 84.1261\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 131973.1250 - val_loss: 79.3340\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2153.9724 - val_loss: 74.0621\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 149862.3125 - val_loss: 71.7507\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 139039.8906 - val_loss: 77.3150\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52267.5938 - val_loss: 82.5420\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50345.1211 - val_loss: 83.6876\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47376.1641 - val_loss: 83.1009\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3428.3191 - val_loss: 80.8603\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 64040.2500 - val_loss: 79.6540\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 56709.4922 - val_loss: 81.0134\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10841.7939 - val_loss: 84.4205\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 66610.7734 - val_loss: 86.6829\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 56692.4414 - val_loss: 86.2578\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22376.9629 - val_loss: 84.6159\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16625.0312 - val_loss: 84.5531\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26575.1504 - val_loss: 85.8321\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9632.6641 - val_loss: 86.0106\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10394.4033 - val_loss: 86.0349\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11709.7715 - val_loss: 86.3289\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8557.2344 - val_loss: 86.0941\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3180.1714 - val_loss: 87.5660\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37951.8320 - val_loss: 87.4710\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 26941.2480 - val_loss: 86.2720\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23499.9746 - val_loss: 85.7695\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12523.2480 - val_loss: 87.6570\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27756.0156 - val_loss: 87.8680\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31320.9746 - val_loss: 87.6465\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 501.1097 - val_loss: 85.9459\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23619.2012 - val_loss: 85.5258\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39418.6250 - val_loss: 86.2784\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19210.5391 - val_loss: 87.8478\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13529.6963 - val_loss: 87.9099\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12020.8623 - val_loss: 86.9227\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 26299.2969 - val_loss: 86.8482\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11522.6289 - val_loss: 87.8852\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4870.4097 - val_loss: 88.0392\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6886.7905 - val_loss: 87.1211\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18125.6602 - val_loss: 87.6400\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5128.8784 - val_loss: 88.8056\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35774.0859 - val_loss: 89.2223\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24959.9941 - val_loss: 88.5213\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7289.3496 - val_loss: 88.0694\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1711.7935 - val_loss: 89.0001\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36241.2695 - val_loss: 89.5883\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27124.4434 - val_loss: 88.2618\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29306.3125 - val_loss: 87.6705\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16424.5117 - val_loss: 88.7931\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6147.3101 - val_loss: 89.1985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 37 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 80.3972 - val_loss: 60.5375\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.7020 - val_loss: 12.3397\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24.5539 - val_loss: 8.3108\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.1635 - val_loss: 25.2467\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.2891 - val_loss: 24.4149\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.6934 - val_loss: 12.3801\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.4342 - val_loss: 9.5630\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.7376 - val_loss: 14.3259\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4690 - val_loss: 13.5191\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5815 - val_loss: 9.8831\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4002 - val_loss: 9.2381\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.5308 - val_loss: 6.3597\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6012 - val_loss: 4.9876\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7080 - val_loss: 2.6063\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.7866 - val_loss: 2.6666\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3506 - val_loss: 2.5663\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4300 - val_loss: 2.6197\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2140 - val_loss: 2.8424\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.1752 - val_loss: 2.3691\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1832 - val_loss: 2.4274\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7547 - val_loss: 3.1635\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.7608 - val_loss: 2.4503\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5550 - val_loss: 2.9508\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6564 - val_loss: 2.6697\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4693 - val_loss: 2.1131\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.4791 - val_loss: 2.5576\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.3992 - val_loss: 3.0617\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.6082 - val_loss: 2.2284\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.2435 - val_loss: 2.1534\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.1592 - val_loss: 2.0177\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.1775 - val_loss: 4.3697\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7998 - val_loss: 2.0554\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7718 - val_loss: 2.1647\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1271 - val_loss: 2.9205\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.9823 - val_loss: 2.7216\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9520 - val_loss: 1.8788\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8841 - val_loss: 1.8413\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9038 - val_loss: 2.2185\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6043 - val_loss: 2.2756\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5472 - val_loss: 2.2122\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.4243 - val_loss: 2.3164\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.2905 - val_loss: 1.9618\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.5748 - val_loss: 2.6381\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.5195 - val_loss: 2.4042\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.4682 - val_loss: 1.8999\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.4463 - val_loss: 2.2432\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.2546 - val_loss: 2.4132\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.2975 - val_loss: 1.7592\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.3676 - val_loss: 1.8284\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.3945 - val_loss: 2.9115\n",
      "Iteration number 38 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 76.0872 - val_loss: 56.9167\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40.1973 - val_loss: 21.7992\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.9952 - val_loss: 29.7696\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 29.7145 - val_loss: 39.1182\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.7213 - val_loss: 31.5591\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23.3968 - val_loss: 17.0834\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21.4083 - val_loss: 18.6352\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.0689 - val_loss: 20.9886\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.8328 - val_loss: 11.5602\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.3213 - val_loss: 8.4658\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.8658 - val_loss: 5.2513\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.8777 - val_loss: 2.2829\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4416 - val_loss: 4.4344\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.0589 - val_loss: 2.1135\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.2565 - val_loss: 3.5645\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.7940 - val_loss: 4.8473\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5070 - val_loss: 2.1030\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7308 - val_loss: 5.7631\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3637 - val_loss: 2.6759\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.6766 - val_loss: 3.5038\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2587 - val_loss: 4.2535\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.8676 - val_loss: 3.8965\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.6244 - val_loss: 3.2353\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3413 - val_loss: 4.4890\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3588 - val_loss: 3.7612\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9726 - val_loss: 3.4253\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2324 - val_loss: 4.5698\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3238 - val_loss: 3.6497\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2494 - val_loss: 4.1397\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3668 - val_loss: 3.7146\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8381 - val_loss: 3.6421\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2044 - val_loss: 3.2373\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3742 - val_loss: 4.3176\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0969 - val_loss: 2.5961\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2269 - val_loss: 4.7091\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0474 - val_loss: 3.1392\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9151 - val_loss: 3.0476\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3628 - val_loss: 5.9801\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6927 - val_loss: 2.5449\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6336 - val_loss: 3.9844\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1977 - val_loss: 3.2977\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0933 - val_loss: 4.1880\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0200 - val_loss: 3.0613\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9850 - val_loss: 3.9372\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9641 - val_loss: 2.9597\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8822 - val_loss: 4.4123\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7521 - val_loss: 3.1831\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7904 - val_loss: 3.9599\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7355 - val_loss: 3.1755\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6088 - val_loss: 3.2164\n",
      "Iteration number 39 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 47091.0820 - val_loss: 109.1131\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 368349.8125 - val_loss: 111.5030\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 214011.1719 - val_loss: 104.6370\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21812.4805 - val_loss: 95.3637\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 306832.6875 - val_loss: 92.4755\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 263203.8125 - val_loss: 96.4674\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 104166.2812 - val_loss: 102.1443\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38844.0508 - val_loss: 103.3928\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 80132.9922 - val_loss: 101.7690\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37209.3242 - val_loss: 98.9944\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65642.5391 - val_loss: 99.1756\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7010.6392 - val_loss: 99.1527\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9436.0703 - val_loss: 99.7298\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16897.8770 - val_loss: 98.6225\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33460.0898 - val_loss: 99.5731\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16849.0664 - val_loss: 99.0763\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44562.4258 - val_loss: 98.7085\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5359.7749 - val_loss: 99.4426\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7820.0889 - val_loss: 100.0435\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25638.4922 - val_loss: 98.5713\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 51792.8047 - val_loss: 98.7738\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18914.5020 - val_loss: 99.8143\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27057.5234 - val_loss: 97.7956\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35376.6367 - val_loss: 96.7445\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34159.4766 - val_loss: 99.6355\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 131884.3750 - val_loss: 100.6445\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 90910.3594 - val_loss: 98.6557\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13613.6279 - val_loss: 97.7320\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5717.2041 - val_loss: 99.4735\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 75030.8125 - val_loss: 99.1965\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59544.1133 - val_loss: 97.0931\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31270.0684 - val_loss: 97.1142\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13914.1875 - val_loss: 98.3491\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 48037.7422 - val_loss: 99.0233\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30809.1406 - val_loss: 97.4504\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31689.7969 - val_loss: 97.4827\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12776.5469 - val_loss: 98.5544\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4466.3560 - val_loss: 97.8405\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 76641.5156 - val_loss: 97.6548\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27812.7129 - val_loss: 99.6231\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 57813.5391 - val_loss: 100.9938\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51134.2422 - val_loss: 100.2399\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16338.4502 - val_loss: 99.7341\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6702.9487 - val_loss: 100.0568\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35313.5547 - val_loss: 99.5427\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19316.4551 - val_loss: 100.1636\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15019.0068 - val_loss: 98.5167\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37215.1133 - val_loss: 98.7608\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14570.8994 - val_loss: 97.9556\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11501.2617 - val_loss: 98.5303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 40 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 89.2396 - val_loss: 79.9889\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.4865 - val_loss: 59.9108\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 54.9297 - val_loss: 39.2189\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44.1042 - val_loss: 30.0093\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41.2326 - val_loss: 27.2603\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36.3825 - val_loss: 27.0408\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.3034 - val_loss: 18.6167\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 30.3946 - val_loss: 16.6792\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29.2299 - val_loss: 13.9191\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25.7257 - val_loss: 6.0844\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22.5930 - val_loss: 12.5037\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.7502 - val_loss: 7.0831\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.6566 - val_loss: 4.1241\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.8920 - val_loss: 6.7969\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.0944 - val_loss: 5.6891\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.9065 - val_loss: 5.2268\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.9080 - val_loss: 4.4171\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.4004 - val_loss: 4.3178\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.6755 - val_loss: 8.8245\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.8357 - val_loss: 4.5937\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.0122 - val_loss: 9.0582\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.8332 - val_loss: 5.5112\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.9415 - val_loss: 3.9394\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.7217 - val_loss: 3.2471\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.7177 - val_loss: 5.8883\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8089 - val_loss: 3.4642\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3998 - val_loss: 4.5766\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3772 - val_loss: 4.4629\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0192 - val_loss: 3.7519\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3211 - val_loss: 4.4325\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3186 - val_loss: 4.3187\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.4019 - val_loss: 4.4748\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8436 - val_loss: 4.0243\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0778 - val_loss: 3.6603\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5455 - val_loss: 4.3422\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.5031 - val_loss: 5.7105\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8396 - val_loss: 2.5360\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7833 - val_loss: 5.0142\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.9985 - val_loss: 4.4699\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4731 - val_loss: 3.3860\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4130 - val_loss: 5.1859\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.5895 - val_loss: 3.3771\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3195 - val_loss: 5.0919\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2750 - val_loss: 2.9315\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1466 - val_loss: 4.0958\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1823 - val_loss: 4.5172\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4011 - val_loss: 2.7439\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5102 - val_loss: 5.0346\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.9651 - val_loss: 3.7774\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2834 - val_loss: 3.0410\n",
      "Iteration number 41 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 160304.8750 - val_loss: 102.2317\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 67399.7109 - val_loss: 113.5374\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 151629.7969 - val_loss: 111.8665\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 127550.1953 - val_loss: 108.6011\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50341.8633 - val_loss: 103.9577\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31039.2461 - val_loss: 102.6149\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34401.3008 - val_loss: 104.0151\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25226.0410 - val_loss: 104.2103\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8795.7051 - val_loss: 101.6241\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 62094.5117 - val_loss: 100.9566\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50632.3867 - val_loss: 102.3046\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11786.9434 - val_loss: 103.1132\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3095.9121 - val_loss: 103.2325\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15524.9141 - val_loss: 102.7831\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 292.3264 - val_loss: 99.9559\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 64747.4414 - val_loss: 99.8420\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 64087.2773 - val_loss: 101.2766\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15668.1660 - val_loss: 103.1339\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20879.8887 - val_loss: 103.1489\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24694.4473 - val_loss: 102.4283\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10909.2275 - val_loss: 101.8525\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6680.4521 - val_loss: 101.8300\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 26431.6406 - val_loss: 100.9738\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17028.3613 - val_loss: 101.8977\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16966.1699 - val_loss: 102.2347\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8483.9531 - val_loss: 100.9838\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41677.3281 - val_loss: 100.1946\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15394.5742 - val_loss: 101.5167\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1040.1788 - val_loss: 104.9740\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84557.0859 - val_loss: 105.4891\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 104894.1719 - val_loss: 104.8049\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 75378.7344 - val_loss: 103.3057\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38469.8008 - val_loss: 100.9748\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26303.3262 - val_loss: 99.7351\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27221.7168 - val_loss: 100.4467\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5239.9985 - val_loss: 102.0467\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55884.9883 - val_loss: 102.4874\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48810.4492 - val_loss: 101.4770\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8205.9785 - val_loss: 100.2279\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3940.0884 - val_loss: 99.4841\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22274.9844 - val_loss: 99.9478\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4068.0806 - val_loss: 100.8173\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22784.3594 - val_loss: 100.8608\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18586.5840 - val_loss: 99.9750\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16285.5918 - val_loss: 99.7100\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8610.1133 - val_loss: 100.7546\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19185.6406 - val_loss: 100.6115\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 15803.1689 - val_loss: 99.7811\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10237.0127 - val_loss: 99.8708\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2757.4753 - val_loss: 100.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 42 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 256592.0781 - val_loss: 88.8412\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 160702.6719 - val_loss: 102.2349\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 91952.8438 - val_loss: 107.7032\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 70800.0078 - val_loss: 104.4489\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23071.0020 - val_loss: 99.1375\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 84339.9922 - val_loss: 98.3456\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 82554.7891 - val_loss: 100.2561\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45888.0117 - val_loss: 103.7374\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52056.9453 - val_loss: 104.9923\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34591.8242 - val_loss: 102.0916\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19161.9688 - val_loss: 100.9556\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15514.3633 - val_loss: 101.7643\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14293.2998 - val_loss: 102.0118\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1044.5667 - val_loss: 100.9560\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40201.4414 - val_loss: 99.3428\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39711.4727 - val_loss: 101.0821\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2934.2749 - val_loss: 100.9522\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13663.0820 - val_loss: 101.4311\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5469.1230 - val_loss: 100.8328\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16988.7910 - val_loss: 101.0056\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5901.9644 - val_loss: 103.8079\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45770.8320 - val_loss: 103.6640\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42457.8516 - val_loss: 103.0024\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6043.5283 - val_loss: 100.0548\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43711.1797 - val_loss: 98.5385\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49900.9688 - val_loss: 99.6149\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 20743.5469 - val_loss: 101.5820\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15418.1611 - val_loss: 101.9079\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14222.5889 - val_loss: 100.2346\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30510.5918 - val_loss: 99.7466\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12928.8516 - val_loss: 102.0249\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26962.1250 - val_loss: 102.5841\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30108.8750 - val_loss: 101.6662\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12759.3105 - val_loss: 99.1534\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51420.3828 - val_loss: 98.3422\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46434.2227 - val_loss: 99.8205\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5739.2661 - val_loss: 101.5443\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13481.7559 - val_loss: 101.9123\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22589.3555 - val_loss: 101.2318\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7901.6035 - val_loss: 99.0461\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54097.1992 - val_loss: 98.1821\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 39106.9766 - val_loss: 99.5914\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3019.9556 - val_loss: 101.6757\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 42279.9102 - val_loss: 102.9755\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 44157.7852 - val_loss: 102.2272\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25445.4629 - val_loss: 100.3693\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6222.4468 - val_loss: 100.2601\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8197.9180 - val_loss: 100.9507\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19751.7754 - val_loss: 101.3746\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 241.1625 - val_loss: 100.1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 43 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 99.0915 - val_loss: 79.4526\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.7472 - val_loss: 42.4144\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.1770 - val_loss: 38.6349\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.6801 - val_loss: 38.7392\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30.3373 - val_loss: 31.3958\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25.3594 - val_loss: 20.4785\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20.5827 - val_loss: 15.9866\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16.8204 - val_loss: 7.6393\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.5307 - val_loss: 5.0218\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.0348 - val_loss: 7.7734\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.3613 - val_loss: 4.4840\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.0502 - val_loss: 8.8806\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9155 - val_loss: 2.9888\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.7215 - val_loss: 5.8668\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.1790 - val_loss: 2.7845\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.2929 - val_loss: 4.0284\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.7324 - val_loss: 3.3229\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6203 - val_loss: 3.6606\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5051 - val_loss: 2.9550\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9105 - val_loss: 3.9829\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6062 - val_loss: 2.5620\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2450 - val_loss: 3.2575\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9111 - val_loss: 3.1508\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.6789 - val_loss: 2.2400\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5015 - val_loss: 2.2693\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3056 - val_loss: 2.8755\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2382 - val_loss: 1.9304\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8855 - val_loss: 3.6169\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.8837 - val_loss: 2.2056\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5643 - val_loss: 2.7066\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6613 - val_loss: 1.7655\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4619 - val_loss: 4.8799\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.9220 - val_loss: 1.6745\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7591 - val_loss: 4.6322\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1220 - val_loss: 1.6543\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2944 - val_loss: 4.5640\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0810 - val_loss: 1.6477\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3922 - val_loss: 2.8973\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.4108 - val_loss: 1.5461\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4541 - val_loss: 1.9445\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1048 - val_loss: 1.6462\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5718 - val_loss: 4.0300\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0808 - val_loss: 3.3723\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9586 - val_loss: 4.1592\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0533 - val_loss: 2.1021\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.7614 - val_loss: 1.7894\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9171 - val_loss: 1.9166\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6482 - val_loss: 1.5818\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.6713 - val_loss: 1.8836\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.6850 - val_loss: 1.7286\n",
      "Iteration number 44 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 78.5528 - val_loss: 62.7186\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 62.9445 - val_loss: 40.4890\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 51.0645 - val_loss: 44.0326\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40.0468 - val_loss: 35.9731\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.8151 - val_loss: 18.7321\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27.9383 - val_loss: 17.3860\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22.8282 - val_loss: 6.2233\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.3869 - val_loss: 7.6080\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.6770 - val_loss: 5.6140\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.6989 - val_loss: 6.9225\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.2305 - val_loss: 5.6687\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.0791 - val_loss: 7.4601\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.3964 - val_loss: 4.8894\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.0048 - val_loss: 4.9811\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.1342 - val_loss: 7.9296\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.2677 - val_loss: 4.5467\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.1913 - val_loss: 8.9122\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.8681 - val_loss: 4.4604\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.5051 - val_loss: 7.2864\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.3201 - val_loss: 4.3534\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5149 - val_loss: 6.0416\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4928 - val_loss: 4.8911\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6269 - val_loss: 6.1174\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7373 - val_loss: 4.4025\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8988 - val_loss: 7.3654\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3576 - val_loss: 3.8426\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.3244 - val_loss: 7.8076\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7782 - val_loss: 3.8115\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4384 - val_loss: 7.9394\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8691 - val_loss: 3.5530\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.5912 - val_loss: 5.8506\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4502 - val_loss: 5.6969\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2198 - val_loss: 3.4750\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1909 - val_loss: 7.5371\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6906 - val_loss: 3.4438\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.5172 - val_loss: 5.9915\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8213 - val_loss: 4.4528\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5338 - val_loss: 3.9532\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.2189 - val_loss: 5.1413\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6792 - val_loss: 4.7217\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4564 - val_loss: 4.6499\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6840 - val_loss: 5.7281\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4340 - val_loss: 3.6325\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3022 - val_loss: 5.9315\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.3057 - val_loss: 4.0610\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.0967 - val_loss: 4.4482\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.6047 - val_loss: 4.4603\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2113 - val_loss: 4.5305\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8537 - val_loss: 5.5651\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6671 - val_loss: 3.5560\n",
      "Iteration number 45 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 12163.9287 - val_loss: 119.8618\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 228634.5312 - val_loss: 117.1720\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 136947.3438 - val_loss: 114.5623\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31408.5918 - val_loss: 108.6054\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 590.6096 - val_loss: 99.2175\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 232872.4688 - val_loss: 95.3660\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 221355.7969 - val_loss: 96.6407\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 147222.1094 - val_loss: 100.6483\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70685.9062 - val_loss: 105.5363\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34302.9961 - val_loss: 108.6186\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29752.5195 - val_loss: 107.6302\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12125.9102 - val_loss: 104.7244\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78895.2969 - val_loss: 103.5841\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58520.5977 - val_loss: 104.9300\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34727.4766 - val_loss: 108.1983\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44091.5312 - val_loss: 109.4071\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51338.7852 - val_loss: 108.7745\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21017.0410 - val_loss: 107.5526\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18807.5430 - val_loss: 106.1527\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22023.0703 - val_loss: 106.7623\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5916.9883 - val_loss: 106.9657\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 649.9797 - val_loss: 107.6360\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19200.5195 - val_loss: 107.2203\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6439.9961 - val_loss: 105.3382\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 45743.3281 - val_loss: 105.0099\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40805.7617 - val_loss: 106.4106\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 379.9350 - val_loss: 106.4339\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11018.5264 - val_loss: 106.8316\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5916.5728 - val_loss: 106.4504\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13082.9844 - val_loss: 106.4175\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11998.4160 - val_loss: 107.0519\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8691.9766 - val_loss: 105.5473\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28331.2500 - val_loss: 105.6647\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16363.2266 - val_loss: 106.4872\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19320.9883 - val_loss: 107.2231\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10639.6445 - val_loss: 105.4065\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24102.3008 - val_loss: 105.3301\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25204.8867 - val_loss: 106.0648\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8349.7520 - val_loss: 108.0732\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53355.8945 - val_loss: 108.6889\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46387.0781 - val_loss: 107.8277\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21495.7598 - val_loss: 105.9032\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22993.0918 - val_loss: 105.1329\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24203.0312 - val_loss: 105.5864\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3992.0049 - val_loss: 107.1987\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36322.9961 - val_loss: 107.7637\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35593.4570 - val_loss: 106.7470\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7311.1479 - val_loss: 105.2326\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23865.5898 - val_loss: 104.8807\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24167.7441 - val_loss: 105.7518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 46 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 200494.7500 - val_loss: 86.8451\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3865.9946 - val_loss: 92.5481\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10625.1797 - val_loss: 94.1222\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14306.5293 - val_loss: 92.3947\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32358.6914 - val_loss: 93.3411\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1169.6337 - val_loss: 96.0558\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 62278.9414 - val_loss: 96.8926\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 51797.3164 - val_loss: 94.6548\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6918.2720 - val_loss: 90.8581\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 70756.3125 - val_loss: 90.9279\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 70959.6328 - val_loss: 91.6209\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25056.7734 - val_loss: 94.7789\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22998.1973 - val_loss: 96.1580\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38913.8008 - val_loss: 95.7569\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19952.7559 - val_loss: 93.6365\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35366.0117 - val_loss: 93.8549\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32532.2129 - val_loss: 95.3624\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7970.8511 - val_loss: 95.1909\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8882.1211 - val_loss: 95.7116\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23205.9102 - val_loss: 96.0580\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8316.2705 - val_loss: 95.4454\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7683.1240 - val_loss: 95.5270\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6353.7192 - val_loss: 95.9542\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13004.8896 - val_loss: 95.6410\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 521.4092 - val_loss: 96.4240\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 27930.6973 - val_loss: 96.3660\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17666.5566 - val_loss: 94.6066\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 54787.4883 - val_loss: 93.9554\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39962.4023 - val_loss: 95.5358\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11981.3340 - val_loss: 96.3617\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8692.8418 - val_loss: 95.4661\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31611.5723 - val_loss: 95.2547\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23052.5977 - val_loss: 96.5087\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13705.8486 - val_loss: 96.6064\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5919.8101 - val_loss: 96.2124\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19152.3711 - val_loss: 95.6738\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20172.1543 - val_loss: 96.0949\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3223.5432 - val_loss: 97.5717\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47702.2031 - val_loss: 98.0328\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44607.7188 - val_loss: 97.6419\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32102.9375 - val_loss: 96.1738\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14483.7891 - val_loss: 96.1714\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16517.6289 - val_loss: 97.0031\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15626.8389 - val_loss: 97.0890\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5820.2490 - val_loss: 96.0041\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41964.2773 - val_loss: 95.5155\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23592.5234 - val_loss: 96.3181\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3768.6838 - val_loss: 98.3106\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48010.7773 - val_loss: 98.6694\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 60677.7031 - val_loss: 98.5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 47 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 48 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 112121.9453 - val_loss: 115.9916\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 62823.2188 - val_loss: 115.0217\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5932.9595 - val_loss: 110.4111\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37400.7383 - val_loss: 110.0231\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34892.8867 - val_loss: 112.2965\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35556.7344 - val_loss: 113.1559\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17361.1797 - val_loss: 108.8143\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 83129.5859 - val_loss: 106.7023\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 65746.9453 - val_loss: 110.7621\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9685.8311 - val_loss: 111.0889\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6827.1445 - val_loss: 109.0407\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 43756.4492 - val_loss: 108.0728\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22176.6250 - val_loss: 109.5979\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6800.5610 - val_loss: 115.2619\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 104066.7656 - val_loss: 116.2699\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 112970.8125 - val_loss: 115.2268\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 75394.5391 - val_loss: 112.3375\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17294.3164 - val_loss: 108.7349\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61853.8242 - val_loss: 106.2103\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55456.5859 - val_loss: 107.6870\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2719.3333 - val_loss: 109.3406\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29590.1309 - val_loss: 109.7593\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 32929.9297 - val_loss: 108.4175\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9522.0547 - val_loss: 107.8619\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5023.8921 - val_loss: 107.8308\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4083.5378 - val_loss: 108.2661\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19331.6055 - val_loss: 108.3299\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11298.3047 - val_loss: 106.3798\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42857.2266 - val_loss: 105.8976\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28584.4473 - val_loss: 107.0316\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11255.4121 - val_loss: 109.7169\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54206.8906 - val_loss: 110.0444\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55139.8242 - val_loss: 109.0364\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22697.9688 - val_loss: 107.2840\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2327.0654 - val_loss: 103.9622\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 91389.1562 - val_loss: 102.7469\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 85951.2734 - val_loss: 104.1420\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50719.4219 - val_loss: 105.9413\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14778.7793 - val_loss: 108.1088\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41846.2188 - val_loss: 108.3478\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42079.1992 - val_loss: 107.7160\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15893.8828 - val_loss: 106.0877\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28433.0059 - val_loss: 105.0193\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23088.4043 - val_loss: 105.5128\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13440.4082 - val_loss: 107.9204\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51498.9336 - val_loss: 108.2781\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55895.1914 - val_loss: 107.5912\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38249.4883 - val_loss: 105.9537\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8415.7236 - val_loss: 105.3053\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5705.9385 - val_loss: 106.5028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 49 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 68.6432 - val_loss: 49.1721\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43.8220 - val_loss: 25.8666\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37.8151 - val_loss: 30.8987\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28.8314 - val_loss: 33.6151\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25.1011 - val_loss: 18.5252\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22.8744 - val_loss: 11.7562\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.7063 - val_loss: 17.1232\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.5748 - val_loss: 3.2887\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.1424 - val_loss: 5.6289\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.4538 - val_loss: 2.1991\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.5963 - val_loss: 5.8719\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.9948 - val_loss: 2.0551\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.4865 - val_loss: 4.7734\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.1722 - val_loss: 2.3205\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5323 - val_loss: 3.7774\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.2426 - val_loss: 2.2092\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5513 - val_loss: 5.0969\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2539 - val_loss: 2.4858\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.8885 - val_loss: 2.7338\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8338 - val_loss: 3.6400\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6144 - val_loss: 2.4610\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2458 - val_loss: 3.3091\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0906 - val_loss: 2.8943\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.7063 - val_loss: 2.9194\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5299 - val_loss: 3.0370\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1512 - val_loss: 2.8388\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0496 - val_loss: 3.6378\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6494 - val_loss: 2.5055\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4380 - val_loss: 4.3442\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9269 - val_loss: 2.8360\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4126 - val_loss: 3.0809\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5052 - val_loss: 3.0304\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4369 - val_loss: 4.2834\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2754 - val_loss: 2.7377\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.2951 - val_loss: 2.8428\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4690 - val_loss: 3.2110\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2076 - val_loss: 2.6404\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.1302 - val_loss: 4.0828\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2762 - val_loss: 3.0998\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1103 - val_loss: 3.6843\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1737 - val_loss: 3.7005\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0491 - val_loss: 4.5215\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7520 - val_loss: 3.7094\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9197 - val_loss: 2.3896\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0773 - val_loss: 2.5557\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7917 - val_loss: 2.8027\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0735 - val_loss: 3.5980\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7320 - val_loss: 2.7402\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.2543 - val_loss: 4.4926\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6762 - val_loss: 2.5541\n",
      "Iteration number 50 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 65.2903 - val_loss: 48.0871\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41.1006 - val_loss: 17.1814\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34.9801 - val_loss: 29.0946\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27.6066 - val_loss: 34.0166\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24.8494 - val_loss: 26.0068\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.9910 - val_loss: 18.4688\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.4752 - val_loss: 18.2001\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.8372 - val_loss: 17.1843\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.9496 - val_loss: 6.0434\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.5115 - val_loss: 11.3177\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4762 - val_loss: 3.3023\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6979 - val_loss: 6.0274\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3715 - val_loss: 3.5639\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0802 - val_loss: 4.5462\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2331 - val_loss: 4.7660\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8552 - val_loss: 5.8866\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4620 - val_loss: 3.2289\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8667 - val_loss: 5.9517\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0400 - val_loss: 3.4571\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1884 - val_loss: 4.4170\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0127 - val_loss: 3.5888\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8515 - val_loss: 3.5489\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6876 - val_loss: 3.5888\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5672 - val_loss: 5.1392\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5160 - val_loss: 4.6502\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5575 - val_loss: 3.8406\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4707 - val_loss: 3.2633\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8991 - val_loss: 5.5058\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5778 - val_loss: 3.2614\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7070 - val_loss: 5.6727\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8276 - val_loss: 3.2862\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8657 - val_loss: 4.4027\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6509 - val_loss: 3.5704\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5112 - val_loss: 3.4406\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1547 - val_loss: 3.6172\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1120 - val_loss: 3.1829\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5366 - val_loss: 5.4240\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3732 - val_loss: 3.1808\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2184 - val_loss: 3.5394\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5101 - val_loss: 3.9359\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0186 - val_loss: 3.0832\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0149 - val_loss: 3.5782\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7573 - val_loss: 3.2401\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6704 - val_loss: 4.0996\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7627 - val_loss: 3.0986\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7931 - val_loss: 3.0157\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7866 - val_loss: 4.7405\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1034 - val_loss: 3.0280\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2950 - val_loss: 3.3768\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7892 - val_loss: 3.7991\n",
      "Iteration number 51 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 379673.6875 - val_loss: 95.0587\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14934.9688 - val_loss: 97.1087\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 61707.0664 - val_loss: 100.1751\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71168.6562 - val_loss: 99.3613\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16849.4160 - val_loss: 100.2089\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 83906.9219 - val_loss: 100.9599\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28344.8613 - val_loss: 93.8935\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 137760.7500 - val_loss: 93.1577\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 163414.9375 - val_loss: 95.1306\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 104760.9766 - val_loss: 100.8193\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70431.6484 - val_loss: 101.3707\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61445.0391 - val_loss: 98.0835\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54721.3555 - val_loss: 98.1358\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28906.8887 - val_loss: 102.0773\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 94458.9844 - val_loss: 101.9750\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 61798.3359 - val_loss: 100.5500\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11983.1348 - val_loss: 98.7618\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18158.4258 - val_loss: 99.8594\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62927.5078 - val_loss: 101.0932\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23421.3125 - val_loss: 97.5039\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 90140.2109 - val_loss: 96.2339\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 84831.5000 - val_loss: 97.1547\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7502.7021 - val_loss: 101.2497\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50779.4062 - val_loss: 102.5415\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 98856.1641 - val_loss: 102.2365\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 75623.1016 - val_loss: 98.6262\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 66496.3906 - val_loss: 97.5292\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48487.1992 - val_loss: 99.0400\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10742.2012 - val_loss: 99.6835\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4837.9360 - val_loss: 100.3110\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38646.0078 - val_loss: 100.4329\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6947.6118 - val_loss: 99.1502\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 67801.0000 - val_loss: 97.3029\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 67942.3047 - val_loss: 98.9952\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3040.9836 - val_loss: 101.6112\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 69352.9062 - val_loss: 102.1740\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 69240.7969 - val_loss: 100.2765\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6016.2368 - val_loss: 97.5907\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63954.4727 - val_loss: 97.5973\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64160.7695 - val_loss: 99.4491\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9678.0078 - val_loss: 99.7040\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24718.4922 - val_loss: 99.4666\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20455.7773 - val_loss: 100.3117\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12678.0098 - val_loss: 98.0980\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 70114.4531 - val_loss: 97.9636\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44066.3711 - val_loss: 99.0498\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33041.5703 - val_loss: 100.8813\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18755.6465 - val_loss: 99.1300\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24316.0098 - val_loss: 99.2086\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21651.4629 - val_loss: 100.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 52 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 10622.6953 - val_loss: 109.2208\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 169230.2344 - val_loss: 105.7361\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 132609.6250 - val_loss: 112.8179\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14521.8984 - val_loss: 121.0970\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 114422.7500 - val_loss: 120.5193\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 106797.3047 - val_loss: 118.8924\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26359.1113 - val_loss: 113.1940\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 895.5901 - val_loss: 110.0983\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46424.9688 - val_loss: 111.0575\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16435.9258 - val_loss: 112.7993\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8884.4150 - val_loss: 112.5716\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6938.3848 - val_loss: 111.2549\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44789.8594 - val_loss: 109.8666\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36421.1836 - val_loss: 113.7508\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 64254.1758 - val_loss: 114.8460\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52378.5508 - val_loss: 113.0092\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30073.0723 - val_loss: 108.4004\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77545.0547 - val_loss: 106.6618\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70738.3516 - val_loss: 107.6891\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51375.7617 - val_loss: 111.2313\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44834.8438 - val_loss: 112.3501\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38649.0430 - val_loss: 110.6155\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2057.4302 - val_loss: 110.1690\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8105.0430 - val_loss: 108.9975\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14708.0381 - val_loss: 109.8050\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7049.3496 - val_loss: 109.0956\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19064.1191 - val_loss: 109.2230\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6780.0664 - val_loss: 111.6101\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46959.6250 - val_loss: 111.4763\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36632.5938 - val_loss: 109.9221\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6909.0640 - val_loss: 109.1931\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1070.6350 - val_loss: 111.3647\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47690.6875 - val_loss: 111.1717\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36137.8789 - val_loss: 109.6543\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11515.5234 - val_loss: 106.5733\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75331.4062 - val_loss: 105.2482\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62431.5273 - val_loss: 106.9621\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12274.8330 - val_loss: 109.1076\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11977.7598 - val_loss: 109.6567\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28123.6875 - val_loss: 109.0170\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9299.7861 - val_loss: 106.9724\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33441.4609 - val_loss: 106.6826\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30925.6016 - val_loss: 108.0537\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6612.0488 - val_loss: 107.9673\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4696.8433 - val_loss: 108.5663\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16417.0547 - val_loss: 108.2431\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3577.5813 - val_loss: 108.2031\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16885.1934 - val_loss: 108.4500\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5442.7134 - val_loss: 107.8540\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4134.3696 - val_loss: 107.5928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 53 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 82.5169 - val_loss: 58.7989\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33.1647 - val_loss: 9.1541\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30.8248 - val_loss: 19.5209\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21.8246 - val_loss: 33.5588\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.6361 - val_loss: 31.4300\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20.3354 - val_loss: 17.4711\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.7770 - val_loss: 13.0562\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.5652 - val_loss: 17.6803\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.4720 - val_loss: 19.4386\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.0119 - val_loss: 10.1643\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.0275 - val_loss: 11.6100\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.9138 - val_loss: 11.4931\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.1071 - val_loss: 6.8345\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5810 - val_loss: 7.2806\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0883 - val_loss: 3.1267\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8031 - val_loss: 3.8124\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.3912 - val_loss: 3.2983\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7252 - val_loss: 2.7826\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3895 - val_loss: 3.9947\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5127 - val_loss: 2.6558\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.1723 - val_loss: 2.9031\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.9053 - val_loss: 2.9540\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6352 - val_loss: 3.0579\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4060 - val_loss: 2.9869\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2788 - val_loss: 2.7893\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9710 - val_loss: 3.0438\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6112 - val_loss: 3.6192\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7895 - val_loss: 4.3915\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2533 - val_loss: 4.3756\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4464 - val_loss: 3.9701\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9676 - val_loss: 4.2162\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1879 - val_loss: 3.6693\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5774 - val_loss: 3.1101\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8823 - val_loss: 3.9089\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5799 - val_loss: 2.7609\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7772 - val_loss: 3.0044\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7034 - val_loss: 4.3414\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4187 - val_loss: 4.7965\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9816 - val_loss: 4.2923\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4458 - val_loss: 3.9308\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6030 - val_loss: 4.3801\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9970 - val_loss: 3.7098\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4504 - val_loss: 4.7805\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7290 - val_loss: 3.2651\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8312 - val_loss: 4.1917\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6399 - val_loss: 2.9163\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2599 - val_loss: 3.7520\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1734 - val_loss: 3.2021\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4360 - val_loss: 4.3493\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2148 - val_loss: 3.0252\n",
      "Iteration number 54 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 15129.8896 - val_loss: 86.2581\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 459534.4062 - val_loss: 83.8477\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 301444.2500 - val_loss: 90.7137\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 124642.4453 - val_loss: 97.5361\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 120428.7500 - val_loss: 99.7461\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 123609.3125 - val_loss: 98.2472\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34219.5938 - val_loss: 96.7479\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19759.9941 - val_loss: 98.0418\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27567.9316 - val_loss: 97.9086\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20944.2832 - val_loss: 97.2583\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32571.9043 - val_loss: 98.7351\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41712.2461 - val_loss: 98.1869\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12662.2891 - val_loss: 97.7111\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15957.5146 - val_loss: 98.5652\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25451.8262 - val_loss: 98.5232\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12911.8779 - val_loss: 97.8107\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10251.5713 - val_loss: 98.6295\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37660.5742 - val_loss: 98.1073\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18604.0332 - val_loss: 97.4727\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14516.7881 - val_loss: 98.2992\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48128.3477 - val_loss: 98.7725\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22034.8594 - val_loss: 97.4795\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31119.5820 - val_loss: 97.2904\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25212.3281 - val_loss: 98.1441\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46849.6953 - val_loss: 98.5214\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36783.4062 - val_loss: 96.5510\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 94763.8672 - val_loss: 96.1931\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78082.9922 - val_loss: 97.4629\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7782.1802 - val_loss: 97.4978\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19598.6074 - val_loss: 97.6504\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4705.0547 - val_loss: 97.5565\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14201.4180 - val_loss: 97.6097\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15313.3750 - val_loss: 97.7659\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5388.8511 - val_loss: 97.4063\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10486.8467 - val_loss: 98.0423\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28487.2695 - val_loss: 98.2716\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6506.6768 - val_loss: 97.6446\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8027.7959 - val_loss: 98.7287\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37100.4805 - val_loss: 98.6237\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12514.4736 - val_loss: 97.7934\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8257.5215 - val_loss: 98.2501\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37013.0078 - val_loss: 98.4107\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14368.2812 - val_loss: 96.8520\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63551.7773 - val_loss: 96.4291\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 64866.4492 - val_loss: 97.6032\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19454.5918 - val_loss: 97.8630\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4157.3628 - val_loss: 97.8168\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6672.1279 - val_loss: 97.5458\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 7722.0742 - val_loss: 97.6925\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3507.4778 - val_loss: 97.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 55 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 49851.9531 - val_loss: 126.5642\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 128560.6953 - val_loss: 122.3995\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58325.7422 - val_loss: 119.0095\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14064.6689 - val_loss: 110.6261\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 140257.8281 - val_loss: 106.9037\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 135895.6719 - val_loss: 107.6487\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 87954.9609 - val_loss: 110.2445\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33434.3633 - val_loss: 114.0679\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31030.8613 - val_loss: 115.1070\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47069.5742 - val_loss: 114.6906\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 28024.3750 - val_loss: 110.8772\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26734.9180 - val_loss: 110.1632\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39459.2852 - val_loss: 110.2816\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30079.7070 - val_loss: 113.4514\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56676.3633 - val_loss: 114.4234\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54880.1875 - val_loss: 112.3731\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13841.4922 - val_loss: 110.1127\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43131.4648 - val_loss: 108.7267\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34132.3242 - val_loss: 110.6634\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14022.7617 - val_loss: 111.0210\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8123.6431 - val_loss: 110.1257\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20717.5293 - val_loss: 109.4667\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10604.8555 - val_loss: 110.1777\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7348.6382 - val_loss: 110.7812\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12144.7080 - val_loss: 109.6448\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17481.8926 - val_loss: 109.5420\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7032.9185 - val_loss: 111.1874\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39334.3203 - val_loss: 111.7402\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30498.6191 - val_loss: 110.9242\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6289.4844 - val_loss: 108.3443\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36119.0156 - val_loss: 107.3982\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43447.6094 - val_loss: 108.1528\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20783.8613 - val_loss: 109.3325\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19216.7520 - val_loss: 110.0222\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6337.0977 - val_loss: 108.7256\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15200.1973 - val_loss: 108.2721\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16889.0664 - val_loss: 108.5235\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9911.1445 - val_loss: 110.7916\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 60935.9922 - val_loss: 111.7395\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49744.8242 - val_loss: 110.7211\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20742.3086 - val_loss: 108.5151\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7680.4810 - val_loss: 107.5238\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16434.4629 - val_loss: 108.0704\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3427.7402 - val_loss: 109.3314\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27575.7656 - val_loss: 109.2442\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22341.8379 - val_loss: 108.2230\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8955.9033 - val_loss: 107.7592\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4613.0483 - val_loss: 107.9772\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5388.5928 - val_loss: 107.9014\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12051.1230 - val_loss: 108.3347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 56 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 150637.0469 - val_loss: 60.4213\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7843.4517 - val_loss: 78.2517\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 279397.3125 - val_loss: 86.6454\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 261473.6094 - val_loss: 81.3868\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 122426.0781 - val_loss: 76.5772\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9731.7227 - val_loss: 74.9318\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3858.7952 - val_loss: 77.3545\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55303.1719 - val_loss: 78.6021\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36227.7422 - val_loss: 77.0980\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10772.2002 - val_loss: 72.8374\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 99749.6250 - val_loss: 72.0944\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 94798.7734 - val_loss: 73.4121\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37484.5898 - val_loss: 77.3111\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 896.1779 - val_loss: 79.9520\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40042.3867 - val_loss: 80.6342\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16345.6084 - val_loss: 78.1476\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44849.6875 - val_loss: 77.3968\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45159.8164 - val_loss: 79.5829\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1411.3341 - val_loss: 82.0379\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 49043.3320 - val_loss: 83.0145\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46105.3945 - val_loss: 81.4497\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5124.9077 - val_loss: 81.3142\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9759.5859 - val_loss: 81.0556\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12114.8457 - val_loss: 81.4756\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11398.0293 - val_loss: 81.5437\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3551.6985 - val_loss: 82.1167\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13466.7002 - val_loss: 81.3448\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19051.2168 - val_loss: 81.1822\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15372.1396 - val_loss: 82.3213\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4442.9321 - val_loss: 79.9762\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38880.6172 - val_loss: 80.1066\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40205.1953 - val_loss: 81.3452\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13516.3535 - val_loss: 84.0391\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30569.6875 - val_loss: 84.3756\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33835.2070 - val_loss: 83.6012\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 606.9387 - val_loss: 83.3613\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16812.3496 - val_loss: 83.5672\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1555.7280 - val_loss: 80.9259\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 46403.3008 - val_loss: 80.7822\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54772.1758 - val_loss: 81.7888\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23700.8887 - val_loss: 83.6363\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20207.5781 - val_loss: 84.8879\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17181.7012 - val_loss: 83.9814\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9220.3271 - val_loss: 84.1778\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 902.1580 - val_loss: 85.6823\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37535.0898 - val_loss: 85.9400\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25089.7129 - val_loss: 85.0505\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9156.7344 - val_loss: 84.4651\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2349.0254 - val_loss: 85.7480\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40231.5195 - val_loss: 86.5591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 57 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 85.0218 - val_loss: 63.3569\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.9170 - val_loss: 15.1152\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31.5831 - val_loss: 16.9278\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24.0383 - val_loss: 29.0915\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20.3073 - val_loss: 24.1956\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.1224 - val_loss: 15.7648\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.0179 - val_loss: 14.7492\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.7749 - val_loss: 14.3257\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.2451 - val_loss: 10.6457\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2244 - val_loss: 4.3161\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3614 - val_loss: 3.5672\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0933 - val_loss: 3.2143\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5843 - val_loss: 3.1966\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2331 - val_loss: 6.7468\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5219 - val_loss: 3.0794\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7918 - val_loss: 5.6883\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7836 - val_loss: 2.8403\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4805 - val_loss: 3.0726\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6094 - val_loss: 6.0282\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9408 - val_loss: 3.2625\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6654 - val_loss: 5.4262\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1656 - val_loss: 2.7712\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8662 - val_loss: 3.9748\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7084 - val_loss: 3.1332\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5641 - val_loss: 3.4557\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6107 - val_loss: 2.8203\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4242 - val_loss: 3.5777\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.2218 - val_loss: 3.2884\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.2461 - val_loss: 2.8288\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7653 - val_loss: 2.9338\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7206 - val_loss: 4.4351\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2465 - val_loss: 2.8308\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5544 - val_loss: 2.8125\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8539 - val_loss: 2.8077\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.8028 - val_loss: 3.1894\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7935 - val_loss: 3.4576\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6481 - val_loss: 2.6617\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6370 - val_loss: 2.8169\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6418 - val_loss: 2.8818\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9092 - val_loss: 4.2116\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9149 - val_loss: 2.9937\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5846 - val_loss: 2.7351\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5819 - val_loss: 2.9644\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4363 - val_loss: 3.1686\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.4516 - val_loss: 2.9046\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8090 - val_loss: 2.7443\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0102 - val_loss: 2.9616\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4755 - val_loss: 3.0443\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4010 - val_loss: 3.0160\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5008 - val_loss: 3.5227\n",
      "Iteration number 58 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 5182665.5000 - val_loss: 98.9624\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4310527.5000 - val_loss: 97.6350\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3778872.7500 - val_loss: 96.9113\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2219867.2500 - val_loss: 96.1115\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2254320.0000 - val_loss: 95.3471\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1819722.1250 - val_loss: 94.7150\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1227185.2500 - val_loss: 93.9089\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 890387.0625 - val_loss: 93.2578\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 369219.8125 - val_loss: 92.5693\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 167549.5625 - val_loss: 91.9929\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 473681.8438 - val_loss: 91.2386\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 803382.9375 - val_loss: 90.6090\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 325013.2812 - val_loss: 89.9545\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 488839.4062 - val_loss: 89.2880\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 105165.7656 - val_loss: 88.6478\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 315888.8438 - val_loss: 88.0013\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 697024.0000 - val_loss: 87.4450\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 902603.1875 - val_loss: 86.8623\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 950543.3750 - val_loss: 86.3107\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 559213.6250 - val_loss: 85.8506\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 528475.3125 - val_loss: 85.2501\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 559538.4375 - val_loss: 84.7649\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 586367.1875 - val_loss: 84.1492\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 561560.1250 - val_loss: 83.6226\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 492095.5938 - val_loss: 83.1017\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 531332.8125 - val_loss: 82.6128\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 548104.2500 - val_loss: 82.0400\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 596379.3750 - val_loss: 81.4950\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 296038.3750 - val_loss: 81.0405\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 193117.8750 - val_loss: 80.4946\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 487160.9062 - val_loss: 80.0507\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 521842.9375 - val_loss: 79.5582\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 488242.2500 - val_loss: 79.1295\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 471454.0938 - val_loss: 78.6893\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 128557.6484 - val_loss: 78.2627\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 147597.7344 - val_loss: 77.8882\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 180810.3594 - val_loss: 77.3445\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 160890.3281 - val_loss: 76.8560\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 157260.8750 - val_loss: 76.3386\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 154657.0312 - val_loss: 75.7984\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 158970.4688 - val_loss: 75.3355\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 186016.2031 - val_loss: 74.9352\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 378076.7812 - val_loss: 74.4649\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 636270.7500 - val_loss: 74.0925\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1053379.5000 - val_loss: 73.8329\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 312172.8438 - val_loss: 73.5620\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 232736.7344 - val_loss: 73.3324\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 320172.2500 - val_loss: 73.0423\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 113331.8438 - val_loss: 72.7192\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 321028.8750 - val_loss: 72.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 59 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 74.1189 - val_loss: 49.7629\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35.4840 - val_loss: 12.2132\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31.3260 - val_loss: 25.1044\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24.8393 - val_loss: 31.8078\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22.9921 - val_loss: 23.3178\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.4667 - val_loss: 15.9892\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.0315 - val_loss: 15.1514\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.8656 - val_loss: 16.9423\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.4340 - val_loss: 7.1974\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9612 - val_loss: 8.8777\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.7232 - val_loss: 5.8664\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.9344 - val_loss: 6.3418\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3343 - val_loss: 7.2424\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.0015 - val_loss: 4.2320\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9464 - val_loss: 9.2884\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.2345 - val_loss: 4.1377\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4060 - val_loss: 6.0775\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.3460 - val_loss: 5.1988\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8963 - val_loss: 5.8933\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7824 - val_loss: 5.6149\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.5402 - val_loss: 4.5231\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4788 - val_loss: 6.4024\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3276 - val_loss: 3.8917\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1897 - val_loss: 7.4156\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4301 - val_loss: 5.0036\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2507 - val_loss: 3.8193\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0021 - val_loss: 5.0760\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7368 - val_loss: 6.5533\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6227 - val_loss: 5.1774\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4511 - val_loss: 3.6320\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4642 - val_loss: 4.6649\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.1632 - val_loss: 4.0956\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.0628 - val_loss: 5.4356\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9295 - val_loss: 3.7741\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0417 - val_loss: 3.9363\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.7744 - val_loss: 5.2919\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7468 - val_loss: 4.1608\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.6619 - val_loss: 4.1833\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5306 - val_loss: 5.2604\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.7437 - val_loss: 4.3419\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5998 - val_loss: 2.0275\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9283 - val_loss: 7.1915\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0657 - val_loss: 3.1087\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8711 - val_loss: 2.4687\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.2990 - val_loss: 2.9290\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1874 - val_loss: 6.9642\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8325 - val_loss: 1.7760\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4253 - val_loss: 3.7392\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7002 - val_loss: 4.6808\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4302 - val_loss: 1.6556\n",
      "Iteration number 60 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 87.0844 - val_loss: 67.5338\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.6300 - val_loss: 25.6634\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5949 - val_loss: 28.3616\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29.2408 - val_loss: 36.5468\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 26.1975 - val_loss: 32.6163\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22.8520 - val_loss: 20.4799\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18.7532 - val_loss: 16.4838\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.6064 - val_loss: 15.1548\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.5198 - val_loss: 10.8874\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2873 - val_loss: 6.5435\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1668 - val_loss: 6.9689\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3860 - val_loss: 5.3489\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1472 - val_loss: 6.6335\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.7979 - val_loss: 4.4526\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7834 - val_loss: 8.3306\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5606 - val_loss: 3.0243\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.3104 - val_loss: 4.3769\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7586 - val_loss: 4.2940\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2481 - val_loss: 5.9793\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5459 - val_loss: 2.6282\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6160 - val_loss: 5.4666\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1211 - val_loss: 3.6254\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7345 - val_loss: 3.4733\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.0936 - val_loss: 4.6085\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7329 - val_loss: 2.8992\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2989 - val_loss: 3.4340\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2901 - val_loss: 4.0304\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0593 - val_loss: 3.1035\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8662 - val_loss: 3.5396\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9716 - val_loss: 2.9890\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9960 - val_loss: 2.6744\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0902 - val_loss: 5.1479\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1766 - val_loss: 2.6212\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4715 - val_loss: 2.8430\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6952 - val_loss: 3.1395\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3645 - val_loss: 2.6489\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2556 - val_loss: 3.3071\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7569 - val_loss: 2.6064\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6530 - val_loss: 2.9350\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6942 - val_loss: 2.8062\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4776 - val_loss: 2.6322\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9374 - val_loss: 3.1128\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.4807 - val_loss: 2.4079\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4810 - val_loss: 2.4915\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7238 - val_loss: 2.3454\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7193 - val_loss: 3.1346\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.3972 - val_loss: 3.6738\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.3065 - val_loss: 3.2768\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.1786 - val_loss: 2.9999\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7636 - val_loss: 2.2113\n",
      "Iteration number 61 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 18550.9297 - val_loss: 115.0797\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 291241.6250 - val_loss: 110.4249\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 191128.0156 - val_loss: 104.4535\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53932.0703 - val_loss: 97.2562\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 100454.6797 - val_loss: 92.1032\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90953.4453 - val_loss: 97.2977\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36575.2734 - val_loss: 98.6470\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23638.5254 - val_loss: 95.2406\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52285.0664 - val_loss: 94.7360\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32695.4180 - val_loss: 96.8013\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5373.5356 - val_loss: 102.2580\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 127341.1875 - val_loss: 104.2369\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 121188.4844 - val_loss: 101.7760\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52564.8008 - val_loss: 98.8208\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5945.4829 - val_loss: 97.4039\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6877.3843 - val_loss: 99.3461\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35281.8242 - val_loss: 98.9468\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20387.0254 - val_loss: 96.0910\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40850.7188 - val_loss: 96.3149\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29387.7109 - val_loss: 99.0348\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27968.3379 - val_loss: 98.8209\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7991.4990 - val_loss: 97.6504\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6702.3457 - val_loss: 96.9551\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26743.4473 - val_loss: 97.2268\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4659.2642 - val_loss: 101.2492\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 103027.2812 - val_loss: 103.2967\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 86364.5859 - val_loss: 101.5231\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36095.6250 - val_loss: 98.6174\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7023.9805 - val_loss: 97.4880\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19738.4395 - val_loss: 98.2896\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 648.3627 - val_loss: 101.0815\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69620.7266 - val_loss: 101.6010\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62680.8555 - val_loss: 99.9389\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13123.4160 - val_loss: 97.9490\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38237.3906 - val_loss: 96.6710\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36381.5312 - val_loss: 98.1433\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2180.2368 - val_loss: 100.5560\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 49526.0391 - val_loss: 100.9419\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47572.2734 - val_loss: 100.4410\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28126.3164 - val_loss: 97.4477\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25840.2441 - val_loss: 96.9269\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42527.0391 - val_loss: 97.0825\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33881.4258 - val_loss: 99.9673\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 49855.8867 - val_loss: 101.0236\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 48259.3477 - val_loss: 99.5892\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4516.0166 - val_loss: 98.0956\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45164.0938 - val_loss: 96.9332\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40538.0547 - val_loss: 99.0456\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19320.4082 - val_loss: 99.5716\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7243.9761 - val_loss: 98.7417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 62 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 74.7477 - val_loss: 54.1404\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.1222 - val_loss: 6.6230\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27.6610 - val_loss: 21.1870\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.1457 - val_loss: 28.9997\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.6697 - val_loss: 20.1265\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.3615 - val_loss: 13.1896\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.6025 - val_loss: 18.6230\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.8314 - val_loss: 12.7490\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.8602 - val_loss: 13.0877\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6708 - val_loss: 10.8477\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.9171 - val_loss: 8.2262\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3891 - val_loss: 7.0969\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.7216 - val_loss: 5.5804\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1698 - val_loss: 6.2455\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5802 - val_loss: 3.4137\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2383 - val_loss: 5.1367\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.0000 - val_loss: 3.2247\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4075 - val_loss: 4.3950\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1826 - val_loss: 3.0780\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8568 - val_loss: 3.6857\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9061 - val_loss: 2.9836\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5566 - val_loss: 3.0750\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5486 - val_loss: 3.9166\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8508 - val_loss: 4.4430\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9957 - val_loss: 5.3815\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.2164 - val_loss: 3.6175\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4371 - val_loss: 4.8654\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9701 - val_loss: 2.7723\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5089 - val_loss: 2.7907\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3258 - val_loss: 2.8887\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2211 - val_loss: 2.9026\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3526 - val_loss: 3.2074\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8319 - val_loss: 2.8186\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1587 - val_loss: 2.9346\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0207 - val_loss: 3.0008\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8402 - val_loss: 2.5719\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6631 - val_loss: 2.6479\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6265 - val_loss: 2.7270\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9074 - val_loss: 3.0359\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7621 - val_loss: 2.6433\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6381 - val_loss: 2.9109\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8057 - val_loss: 2.4617\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6020 - val_loss: 2.6504\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4650 - val_loss: 2.6929\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7181 - val_loss: 2.5202\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.0852 - val_loss: 2.9840\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3007 - val_loss: 3.9188\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5017 - val_loss: 3.3517\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9671 - val_loss: 2.7832\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5385 - val_loss: 2.5672\n",
      "Iteration number 63 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 2494805.5000 - val_loss: 100.2677\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4343650.0000 - val_loss: 99.2557\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4516037.5000 - val_loss: 98.5782\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 997127.5000 - val_loss: 97.7368\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 919595.0625 - val_loss: 96.8748\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 320067.4375 - val_loss: 96.1270\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 661921.5625 - val_loss: 95.3337\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 928741.5000 - val_loss: 94.5655\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1085453.6250 - val_loss: 93.9167\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 550441.6875 - val_loss: 93.2631\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 292260.6875 - val_loss: 92.5108\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 628908.5000 - val_loss: 91.8852\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 839545.6875 - val_loss: 91.3718\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 820962.1250 - val_loss: 90.6534\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 448170.5938 - val_loss: 90.0867\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 700980.5625 - val_loss: 89.4969\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1008954.9375 - val_loss: 88.9878\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 996091.6875 - val_loss: 88.4793\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 944104.1875 - val_loss: 88.1783\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 659326.5000 - val_loss: 87.7224\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 427523.9375 - val_loss: 87.2688\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 485016.8438 - val_loss: 86.9076\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 227976.1875 - val_loss: 86.4750\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 120343.0938 - val_loss: 85.9716\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 321602.2500 - val_loss: 85.4712\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 94944.2109 - val_loss: 85.0116\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 127257.6172 - val_loss: 84.5593\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 164036.4531 - val_loss: 84.0691\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 121901.4844 - val_loss: 83.5673\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 164157.6250 - val_loss: 83.0989\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 165100.3906 - val_loss: 82.6745\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 311278.2500 - val_loss: 82.2619\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 562399.1875 - val_loss: 81.8706\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 167890.8281 - val_loss: 81.4662\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 198516.8594 - val_loss: 81.0577\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 460130.2500 - val_loss: 80.6638\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 361037.3750 - val_loss: 80.3332\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 102867.0781 - val_loss: 79.9903\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 143012.2344 - val_loss: 79.6618\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 119470.0625 - val_loss: 79.3624\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 132646.6094 - val_loss: 79.0244\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 125859.2500 - val_loss: 78.6800\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 129262.8984 - val_loss: 78.3831\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 130376.3828 - val_loss: 78.0842\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 120355.1719 - val_loss: 77.7788\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 137197.7969 - val_loss: 77.4458\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 122266.8281 - val_loss: 77.1776\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 137449.9688 - val_loss: 76.8867\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 122923.8672 - val_loss: 76.5977\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 132120.5312 - val_loss: 76.2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 64 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 28120.7637 - val_loss: 107.1560\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 100352.4844 - val_loss: 104.6785\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55939.1172 - val_loss: 100.2706\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52043.3477 - val_loss: 98.8414\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39130.8008 - val_loss: 102.3630\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34011.8164 - val_loss: 101.8847\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20719.4844 - val_loss: 100.1943\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30149.3555 - val_loss: 99.8512\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14238.3105 - val_loss: 101.5371\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19596.9395 - val_loss: 101.4087\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13989.4639 - val_loss: 99.9766\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40485.0273 - val_loss: 99.6211\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20667.9316 - val_loss: 101.0194\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29266.3555 - val_loss: 101.9505\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25039.8438 - val_loss: 100.1676\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40604.0781 - val_loss: 99.5727\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32977.2227 - val_loss: 101.9697\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51228.9062 - val_loss: 102.6894\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47079.8828 - val_loss: 101.0056\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13818.7734 - val_loss: 100.4663\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6309.0664 - val_loss: 102.6871\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63024.8828 - val_loss: 103.0306\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 51468.1602 - val_loss: 102.3185\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8776.9424 - val_loss: 99.5160\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73808.1328 - val_loss: 97.7976\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 63340.6133 - val_loss: 99.6379\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24089.8105 - val_loss: 101.2219\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41320.2188 - val_loss: 101.4504\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35136.7773 - val_loss: 100.3716\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3316.5659 - val_loss: 100.1767\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8296.7266 - val_loss: 100.0913\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5886.5796 - val_loss: 99.9122\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3661.7224 - val_loss: 100.3449\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8675.7158 - val_loss: 100.2262\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3769.1958 - val_loss: 99.6156\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23237.9590 - val_loss: 99.5373\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12072.5088 - val_loss: 100.1392\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12859.1113 - val_loss: 100.4015\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7440.3643 - val_loss: 99.9689\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22653.6133 - val_loss: 99.5597\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18301.7812 - val_loss: 100.7371\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35527.6875 - val_loss: 101.0935\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31380.3594 - val_loss: 100.3895\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2704.1489 - val_loss: 100.1683\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6606.3657 - val_loss: 100.0855\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12207.9912 - val_loss: 99.8981\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1231.1805 - val_loss: 100.0062\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5762.1426 - val_loss: 100.2662\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11696.0732 - val_loss: 100.2175\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2639.8323 - val_loss: 100.1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 65 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 90.4844 - val_loss: 70.1912\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42.0088 - val_loss: 19.8513\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32.1752 - val_loss: 22.0390\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24.9721 - val_loss: 30.4013\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21.9063 - val_loss: 21.6125\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.3314 - val_loss: 13.9611\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.5246 - val_loss: 16.5372\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.4696 - val_loss: 14.4114\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.2927 - val_loss: 12.0946\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.3110 - val_loss: 6.9040\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.1257 - val_loss: 7.5069\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.6952 - val_loss: 4.7975\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.9748 - val_loss: 6.1435\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4903 - val_loss: 3.7766\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.1847 - val_loss: 5.6721\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.7878 - val_loss: 3.6447\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.4754 - val_loss: 5.7676\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3352 - val_loss: 3.5204\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.8757 - val_loss: 4.5245\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8822 - val_loss: 4.0085\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9305 - val_loss: 3.0018\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9029 - val_loss: 5.3860\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5073 - val_loss: 2.3488\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6933 - val_loss: 3.9033\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6736 - val_loss: 3.5966\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.0386 - val_loss: 2.6832\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5370 - val_loss: 5.3838\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6437 - val_loss: 2.1674\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6166 - val_loss: 3.7986\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6985 - val_loss: 3.5376\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2599 - val_loss: 3.1274\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0601 - val_loss: 4.3154\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.9580 - val_loss: 3.1271\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0283 - val_loss: 3.5048\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8339 - val_loss: 3.2457\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8476 - val_loss: 4.6269\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6161 - val_loss: 3.2877\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4278 - val_loss: 3.1724\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3422 - val_loss: 3.2268\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2234 - val_loss: 2.7579\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3110 - val_loss: 2.9243\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8853 - val_loss: 4.5202\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6575 - val_loss: 2.6778\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9261 - val_loss: 3.6849\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9371 - val_loss: 2.3239\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7467 - val_loss: 4.1665\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9038 - val_loss: 3.1305\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.1414 - val_loss: 2.5803\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.5195 - val_loss: 3.6122\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.4421 - val_loss: 2.5364\n",
      "Iteration number 66 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 102.4346 - val_loss: 79.8718\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45.0232 - val_loss: 28.6956\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.5888 - val_loss: 22.0568\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30.8140 - val_loss: 36.6549\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26.0747 - val_loss: 38.0231\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23.8256 - val_loss: 28.8384\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.5573 - val_loss: 17.2658\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18.9035 - val_loss: 17.3362\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.6513 - val_loss: 18.4627\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.9111 - val_loss: 13.4784\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.9892 - val_loss: 10.7233\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5548 - val_loss: 7.5988\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.3234 - val_loss: 9.9259\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.8921 - val_loss: 5.2651\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.1198 - val_loss: 9.6606\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6436 - val_loss: 6.4769\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3454 - val_loss: 9.5707\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4000 - val_loss: 6.8349\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9418 - val_loss: 7.1255\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7939 - val_loss: 7.3666\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6412 - val_loss: 7.0787\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4888 - val_loss: 7.3597\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2715 - val_loss: 6.8246\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2824 - val_loss: 6.0751\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2168 - val_loss: 5.5779\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8614 - val_loss: 7.0656\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8086 - val_loss: 4.1761\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7313 - val_loss: 6.5307\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.7705 - val_loss: 6.0937\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.5180 - val_loss: 3.3958\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3644 - val_loss: 7.1385\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2115 - val_loss: 4.1883\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.9513 - val_loss: 6.2767\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1457 - val_loss: 5.1302\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7880 - val_loss: 5.0118\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5672 - val_loss: 5.0468\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4422 - val_loss: 4.3307\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3859 - val_loss: 4.9918\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1749 - val_loss: 3.7264\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0207 - val_loss: 5.4882\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2868 - val_loss: 2.2898\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0949 - val_loss: 3.6267\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7519 - val_loss: 4.0671\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8807 - val_loss: 3.8992\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6948 - val_loss: 4.7998\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6159 - val_loss: 1.6711\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8988 - val_loss: 5.8361\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5554 - val_loss: 1.8993\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7485 - val_loss: 4.6558\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7909 - val_loss: 4.0008\n",
      "Iteration number 67 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 92.1184 - val_loss: 67.9599\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40.1310 - val_loss: 15.9844\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25.7555 - val_loss: 9.4668\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.9788 - val_loss: 22.5387\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19.2733 - val_loss: 25.7717\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.7102 - val_loss: 13.0762\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.7309 - val_loss: 7.6051\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.8808 - val_loss: 11.4479\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.7136 - val_loss: 10.0224\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0623 - val_loss: 7.0558\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9304 - val_loss: 6.5452\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1242 - val_loss: 6.9776\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0611 - val_loss: 6.1749\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.9591 - val_loss: 6.8024\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.6363 - val_loss: 6.2451\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6412 - val_loss: 6.7174\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9434 - val_loss: 6.0463\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4517 - val_loss: 6.6795\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8296 - val_loss: 6.0145\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0382 - val_loss: 6.4608\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.5895 - val_loss: 6.0178\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.5141 - val_loss: 7.2971\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.7531 - val_loss: 6.1374\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.2194 - val_loss: 6.3648\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.0423 - val_loss: 6.0361\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.1489 - val_loss: 7.1730\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.7937 - val_loss: 5.9263\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.0448 - val_loss: 6.4023\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.0440 - val_loss: 6.0823\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7003 - val_loss: 5.7870\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.6545 - val_loss: 6.1929\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4.6482 - val_loss: 5.6795\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.5630 - val_loss: 7.0444\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9496 - val_loss: 5.7375\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6474 - val_loss: 5.8206\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8509 - val_loss: 6.2280\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5297 - val_loss: 5.5566\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.4343 - val_loss: 7.0969\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.1148 - val_loss: 5.4159\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5223 - val_loss: 6.2647\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.3552 - val_loss: 5.3554\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.4531 - val_loss: 6.6720\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.4216 - val_loss: 5.3091\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.2568 - val_loss: 5.8999\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.2316 - val_loss: 5.2244\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.1329 - val_loss: 5.4869\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.0446 - val_loss: 5.3420\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.9434 - val_loss: 5.1479\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.8742 - val_loss: 5.5328\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.7599 - val_loss: 5.0084\n",
      "Iteration number 68 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 80.5226 - val_loss: 58.5061\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33.1927 - val_loss: 6.8662\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25.3859 - val_loss: 2.8707\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.1645 - val_loss: 19.6879\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.6167 - val_loss: 24.4745\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.5911 - val_loss: 15.0432\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.0117 - val_loss: 7.6428\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.8662 - val_loss: 10.4895\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.8517 - val_loss: 13.0362\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.8504 - val_loss: 9.3732\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.4600 - val_loss: 8.0352\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.8242 - val_loss: 3.4342\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5032 - val_loss: 3.0636\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.7423 - val_loss: 4.8145\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.9528 - val_loss: 3.3638\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.2141 - val_loss: 4.5582\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3340 - val_loss: 4.7088\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.0067 - val_loss: 3.0299\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.6479 - val_loss: 3.1219\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5568 - val_loss: 4.1990\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.9717 - val_loss: 4.4653\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.9974 - val_loss: 3.4998\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.8279 - val_loss: 3.1763\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.8770 - val_loss: 3.2102\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.9043 - val_loss: 3.7227\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.1119 - val_loss: 3.1688\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.7131 - val_loss: 3.3083\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.7490 - val_loss: 3.4497\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.7185 - val_loss: 3.2111\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5640 - val_loss: 3.1429\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5826 - val_loss: 3.1342\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.5998 - val_loss: 3.7129\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.0819 - val_loss: 3.0739\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.5017 - val_loss: 3.0806\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.5664 - val_loss: 3.1618\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4973 - val_loss: 3.1528\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3829 - val_loss: 3.1238\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4436 - val_loss: 3.2737\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5294 - val_loss: 3.1133\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3371 - val_loss: 3.1062\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3763 - val_loss: 3.5107\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5494 - val_loss: 3.0179\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.3802 - val_loss: 3.2734\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.6652 - val_loss: 4.6346\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0971 - val_loss: 3.4426\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.7203 - val_loss: 3.1480\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5971 - val_loss: 3.7207\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9734 - val_loss: 3.8126\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0369 - val_loss: 4.4965\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8029 - val_loss: 3.1678\n",
      "Iteration number 69 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 51.4310 - val_loss: 24.8838\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.4341 - val_loss: 5.6661\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.0572 - val_loss: 22.9343\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.6873 - val_loss: 27.0747\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.7659 - val_loss: 15.0447\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.0575 - val_loss: 8.1889\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.3201 - val_loss: 14.0643\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.5941 - val_loss: 14.6826\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.1396 - val_loss: 8.9053\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6946 - val_loss: 12.5081\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6926 - val_loss: 4.5469\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5528 - val_loss: 6.6140\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6660 - val_loss: 4.3637\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9358 - val_loss: 4.1482\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3085 - val_loss: 4.0189\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1816 - val_loss: 3.8816\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2197 - val_loss: 4.0084\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3040 - val_loss: 4.4599\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0613 - val_loss: 5.6295\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6823 - val_loss: 4.6639\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0218 - val_loss: 4.1386\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6354 - val_loss: 4.1282\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5628 - val_loss: 4.4816\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8880 - val_loss: 4.0876\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4138 - val_loss: 4.2406\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.3893 - val_loss: 4.1573\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1661 - val_loss: 4.1335\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.1358 - val_loss: 4.1447\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0917 - val_loss: 4.0645\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1760 - val_loss: 4.0886\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.2060 - val_loss: 4.4011\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4041 - val_loss: 4.0307\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9195 - val_loss: 3.9130\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8462 - val_loss: 3.9394\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1611 - val_loss: 4.4107\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4505 - val_loss: 4.1144\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8611 - val_loss: 4.2429\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0910 - val_loss: 4.0709\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8581 - val_loss: 3.9247\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9590 - val_loss: 4.0309\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7479 - val_loss: 4.1180\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7852 - val_loss: 4.1729\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8658 - val_loss: 3.8604\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5357 - val_loss: 3.9821\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8020 - val_loss: 3.7244\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3884 - val_loss: 3.7749\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4680 - val_loss: 3.8346\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.5499 - val_loss: 4.0115\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.8749 - val_loss: 3.9289\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4540 - val_loss: 3.9462\n",
      "Iteration number 70 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1868641.8750 - val_loss: 73.7066\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 878342.1875 - val_loss: 89.9292\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 337272.8125 - val_loss: 104.3337\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 392228.4375 - val_loss: 102.8928\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 212276.5781 - val_loss: 99.2928\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 204276.8906 - val_loss: 93.1998\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 341083.7812 - val_loss: 95.3240\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 105049.5469 - val_loss: 100.1793\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 127542.7109 - val_loss: 100.7042\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 136728.5938 - val_loss: 98.0197\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 120972.4062 - val_loss: 97.3055\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58636.4609 - val_loss: 101.7288\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 269186.4062 - val_loss: 102.4869\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 169753.3906 - val_loss: 99.0593\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33123.6680 - val_loss: 98.1159\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 52541.4258 - val_loss: 99.2952\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 64196.0117 - val_loss: 97.9120\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 45283.9258 - val_loss: 100.8908\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 193159.3281 - val_loss: 101.7060\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 73791.9531 - val_loss: 97.4417\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 134579.8750 - val_loss: 96.9028\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 105965.8672 - val_loss: 99.1550\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62788.3281 - val_loss: 100.2807\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27195.5742 - val_loss: 98.9517\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28323.1113 - val_loss: 101.8159\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 131301.4219 - val_loss: 101.0836\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42710.6758 - val_loss: 99.3532\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33771.5352 - val_loss: 102.0983\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 125837.8984 - val_loss: 101.6522\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62502.9258 - val_loss: 97.8698\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 179487.5156 - val_loss: 97.7502\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 100670.0938 - val_loss: 100.3092\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 134104.3438 - val_loss: 102.5903\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 105375.3438 - val_loss: 99.3046\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 113746.8672 - val_loss: 98.9851\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 69875.0859 - val_loss: 102.2085\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 121057.8672 - val_loss: 101.2012\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19113.3750 - val_loss: 99.4071\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 101672.1875 - val_loss: 98.0434\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 124598.5625 - val_loss: 101.3656\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75754.6094 - val_loss: 100.5564\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9829.9570 - val_loss: 98.7070\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 226562.3125 - val_loss: 96.9788\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 116207.6328 - val_loss: 100.6909\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 114134.4609 - val_loss: 101.9989\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 105678.4922 - val_loss: 99.5667\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 64674.2617 - val_loss: 99.3001\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41442.8203 - val_loss: 101.3276\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 59174.0664 - val_loss: 100.0319\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 54060.5625 - val_loss: 100.4075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 71 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 144143.2656 - val_loss: 93.9451\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69968.9062 - val_loss: 100.1026\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26892.1719 - val_loss: 90.8044\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38868.5898 - val_loss: 91.0355\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35463.1367 - val_loss: 97.3786\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46888.4648 - val_loss: 98.4309\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16361.8682 - val_loss: 93.4078\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28180.8184 - val_loss: 92.2023\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26305.8691 - val_loss: 95.7460\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21777.1621 - val_loss: 96.2706\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1544.0306 - val_loss: 96.4164\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10898.2002 - val_loss: 96.5786\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12504.8750 - val_loss: 93.5796\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15783.9971 - val_loss: 94.9046\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1993.1581 - val_loss: 99.5482\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39088.5312 - val_loss: 98.4598\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23361.2031 - val_loss: 96.3783\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26110.9590 - val_loss: 92.7757\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24338.9531 - val_loss: 96.6128\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28625.0781 - val_loss: 97.6461\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9377.6221 - val_loss: 94.1825\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23363.0566 - val_loss: 93.4016\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20764.8887 - val_loss: 96.1899\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28020.8887 - val_loss: 97.9306\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2334.8843 - val_loss: 96.3382\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22392.9062 - val_loss: 97.4518\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6775.8569 - val_loss: 94.5120\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22057.4941 - val_loss: 93.8894\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19784.5859 - val_loss: 97.5962\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25145.8633 - val_loss: 97.5214\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14335.1416 - val_loss: 92.9834\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30047.3223 - val_loss: 93.6944\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21060.8359 - val_loss: 95.6289\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18445.2480 - val_loss: 97.4842\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7631.6890 - val_loss: 92.7810\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55255.9883 - val_loss: 90.9996\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46615.2031 - val_loss: 92.6657\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17936.2656 - val_loss: 98.5785\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21535.8496 - val_loss: 100.1125\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35872.1211 - val_loss: 98.2778\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16906.7754 - val_loss: 94.5882\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20757.1465 - val_loss: 95.0521\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15675.4131 - val_loss: 97.4714\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12860.2939 - val_loss: 97.1990\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2228.4941 - val_loss: 95.0008\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28275.5957 - val_loss: 94.5447\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21791.8301 - val_loss: 97.2370\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20533.9434 - val_loss: 98.4144\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6928.2886 - val_loss: 95.0206\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37889.7266 - val_loss: 93.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 72 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1720354.8750 - val_loss: 82.2321\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 685483.5000 - val_loss: 91.2005\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 212590.4219 - val_loss: 96.3483\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 178496.6094 - val_loss: 92.4116\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 319647.3750 - val_loss: 91.6452\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 186630.5000 - val_loss: 94.6161\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 230631.7344 - val_loss: 96.3033\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 125621.9453 - val_loss: 92.5802\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 309478.0312 - val_loss: 91.6552\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 227604.5312 - val_loss: 92.9609\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67291.3516 - val_loss: 95.8031\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 171788.8906 - val_loss: 94.7599\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59760.6641 - val_loss: 92.0868\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 218164.5156 - val_loss: 91.7697\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 146840.2812 - val_loss: 93.4452\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 92502.5391 - val_loss: 94.8660\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 81657.3281 - val_loss: 93.0720\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 96937.7266 - val_loss: 92.9846\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28991.3457 - val_loss: 94.2676\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 195529.6875 - val_loss: 95.9141\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 215436.7031 - val_loss: 94.3430\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50423.1094 - val_loss: 92.3448\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 181716.8750 - val_loss: 92.5073\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38870.0391 - val_loss: 93.9519\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46725.1406 - val_loss: 92.1386\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 133975.2188 - val_loss: 92.2704\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 75108.9844 - val_loss: 94.6685\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 215529.5312 - val_loss: 94.7309\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 150930.2812 - val_loss: 92.9686\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25396.3281 - val_loss: 92.9535\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 84614.9297 - val_loss: 94.1256\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 71748.7969 - val_loss: 92.5311\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 183476.0469 - val_loss: 92.1421\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 96018.9453 - val_loss: 94.0214\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34109.2812 - val_loss: 94.6577\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28535.6719 - val_loss: 94.2442\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 116510.0000 - val_loss: 94.2330\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 83249.4844 - val_loss: 96.0307\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 81638.7656 - val_loss: 95.8325\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 71091.2812 - val_loss: 95.1299\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12672.4043 - val_loss: 97.1710\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 239626.1094 - val_loss: 98.0642\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 199991.9531 - val_loss: 96.1049\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73287.1250 - val_loss: 94.0567\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 168224.5156 - val_loss: 94.5765\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67623.6953 - val_loss: 96.3850\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 144469.9219 - val_loss: 96.7609\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 130692.8516 - val_loss: 95.7430\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16471.1660 - val_loss: 94.9712\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 71571.8516 - val_loss: 95.3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 73 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 225389.8750 - val_loss: 71.9609\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22902.4336 - val_loss: 83.0532\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 101306.1016 - val_loss: 89.0479\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 129553.8281 - val_loss: 87.4517\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 76447.8594 - val_loss: 84.2368\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12305.0674 - val_loss: 82.7449\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5423.2817 - val_loss: 82.5881\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 52382.4336 - val_loss: 80.9033\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26259.2676 - val_loss: 83.2964\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37905.2188 - val_loss: 84.8955\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31251.0332 - val_loss: 83.8548\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7747.8042 - val_loss: 83.5227\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7320.5278 - val_loss: 83.3795\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4788.9482 - val_loss: 83.3001\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9635.0811 - val_loss: 83.8930\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43523.2695 - val_loss: 85.6475\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28450.9961 - val_loss: 83.5835\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35522.3086 - val_loss: 82.6516\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24285.4746 - val_loss: 83.7733\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22699.0703 - val_loss: 85.5020\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22087.0098 - val_loss: 83.8515\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21429.4492 - val_loss: 84.3831\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4848.1318 - val_loss: 86.4326\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41177.4258 - val_loss: 86.5489\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33468.7617 - val_loss: 84.7442\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19531.4668 - val_loss: 84.8055\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 419.8939 - val_loss: 84.8894\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17773.4434 - val_loss: 84.6943\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14561.2549 - val_loss: 86.2230\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36021.3242 - val_loss: 86.8975\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16205.2783 - val_loss: 84.7611\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39101.1250 - val_loss: 84.0773\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37485.5078 - val_loss: 84.7514\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6667.8618 - val_loss: 86.2662\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1234.2894 - val_loss: 86.9072\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16808.5352 - val_loss: 86.3587\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6890.1733 - val_loss: 86.7474\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13307.6572 - val_loss: 86.5537\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2833.0579 - val_loss: 87.1435\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12667.1172 - val_loss: 86.3620\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15501.6943 - val_loss: 86.3541\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 242.2429 - val_loss: 86.6201\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4172.6948 - val_loss: 87.1913\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9356.1377 - val_loss: 86.9233\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 620.5816 - val_loss: 87.3921\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22516.5176 - val_loss: 87.5324\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14272.9160 - val_loss: 85.8555\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25097.5996 - val_loss: 86.2684\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14474.0068 - val_loss: 86.9487\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21176.4805 - val_loss: 88.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 74 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 62.9749 - val_loss: 46.3094\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29.8969 - val_loss: 10.8919\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33.4016 - val_loss: 16.0011\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.6175 - val_loss: 26.9077\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.3578 - val_loss: 19.9647\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.5587 - val_loss: 7.5501\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.7214 - val_loss: 12.0906\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.5421 - val_loss: 4.5994\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7304 - val_loss: 6.7494\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9400 - val_loss: 3.3746\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9519 - val_loss: 5.2557\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4854 - val_loss: 4.8707\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2783 - val_loss: 4.7741\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2874 - val_loss: 5.6457\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7516 - val_loss: 4.0552\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0833 - val_loss: 5.8486\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3416 - val_loss: 5.8283\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6453 - val_loss: 3.2463\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9901 - val_loss: 4.1991\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3951 - val_loss: 5.4770\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4004 - val_loss: 4.1241\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0549 - val_loss: 4.6276\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0116 - val_loss: 4.9378\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0029 - val_loss: 3.3259\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1213 - val_loss: 5.5749\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0202 - val_loss: 3.6735\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6828 - val_loss: 3.9963\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9708 - val_loss: 4.3622\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0765 - val_loss: 3.7781\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.6656 - val_loss: 4.1268\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4841 - val_loss: 3.1181\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6896 - val_loss: 3.1970\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4512 - val_loss: 3.1497\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4625 - val_loss: 3.1796\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4208 - val_loss: 3.7215\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7246 - val_loss: 4.7964\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0479 - val_loss: 2.8766\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1710 - val_loss: 4.0910\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4949 - val_loss: 3.7911\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.5995 - val_loss: 2.7878\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1077 - val_loss: 4.7739\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2591 - val_loss: 3.1516\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8321 - val_loss: 2.6697\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5509 - val_loss: 3.7323\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.3596 - val_loss: 2.9727\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2713 - val_loss: 2.7200\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1774 - val_loss: 2.8439\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2063 - val_loss: 3.5657\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.1723 - val_loss: 2.5913\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9769 - val_loss: 3.5815\n",
      "Iteration number 75 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 69.1234 - val_loss: 52.0821\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31.7689 - val_loss: 18.2995\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30.2779 - val_loss: 27.5433\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22.4042 - val_loss: 33.0661\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.4018 - val_loss: 24.5635\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.5233 - val_loss: 13.6635\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.3337 - val_loss: 19.3233\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.7570 - val_loss: 16.4115\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.0178 - val_loss: 9.0129\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.6868 - val_loss: 13.0355\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.4026 - val_loss: 7.1636\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2177 - val_loss: 4.1762\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5070 - val_loss: 4.3867\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1436 - val_loss: 3.5100\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.2073 - val_loss: 3.1897\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.8439 - val_loss: 3.7460\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5736 - val_loss: 3.2507\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6864 - val_loss: 4.2190\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6809 - val_loss: 3.1454\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4846 - val_loss: 4.6113\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4896 - val_loss: 3.7284\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0593 - val_loss: 3.7727\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7696 - val_loss: 3.3869\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8085 - val_loss: 3.4045\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4624 - val_loss: 3.6217\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2366 - val_loss: 3.3792\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0502 - val_loss: 3.6386\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9924 - val_loss: 3.3065\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6793 - val_loss: 3.6001\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.5397 - val_loss: 3.3286\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2878 - val_loss: 3.1128\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1764 - val_loss: 3.3657\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9855 - val_loss: 3.7169\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1253 - val_loss: 2.9642\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7496 - val_loss: 3.3172\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5664 - val_loss: 2.8768\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3647 - val_loss: 3.8506\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6250 - val_loss: 3.3573\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5271 - val_loss: 3.2359\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0049 - val_loss: 2.7551\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9263 - val_loss: 3.4534\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2313 - val_loss: 2.6152\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.2533 - val_loss: 2.7479\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3053 - val_loss: 3.6536\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1028 - val_loss: 3.0216\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2162 - val_loss: 2.5659\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8630 - val_loss: 2.2911\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5728 - val_loss: 2.4670\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7341 - val_loss: 3.2723\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8701 - val_loss: 2.6105\n",
      "Iteration number 76 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 90937.9453 - val_loss: 93.0035\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 116423.0625 - val_loss: 94.4752\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 60356.2305 - val_loss: 90.9733\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 21121.0312 - val_loss: 83.9647\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 121680.4609 - val_loss: 82.4673\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 114777.5625 - val_loss: 85.2298\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 55661.0312 - val_loss: 88.7617\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12380.9326 - val_loss: 90.0636\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6967.3242 - val_loss: 89.3485\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6135.1724 - val_loss: 88.9501\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19788.2500 - val_loss: 89.3504\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25021.7891 - val_loss: 90.9770\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7488.6289 - val_loss: 89.2677\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14432.4570 - val_loss: 89.1346\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19958.6094 - val_loss: 90.2223\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19352.8086 - val_loss: 90.9280\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12440.3516 - val_loss: 88.0528\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66362.6641 - val_loss: 87.1876\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 62703.2812 - val_loss: 89.3739\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20308.1270 - val_loss: 91.9421\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28321.0234 - val_loss: 92.4600\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27635.0762 - val_loss: 91.1098\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12717.0410 - val_loss: 90.9800\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5445.4990 - val_loss: 93.0844\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50772.1680 - val_loss: 93.7051\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43711.7383 - val_loss: 92.2428\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 911.7878 - val_loss: 91.7947\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7801.8340 - val_loss: 91.3801\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15067.5166 - val_loss: 91.3088\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7708.5659 - val_loss: 93.2991\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50707.7266 - val_loss: 94.0761\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30756.3066 - val_loss: 92.8987\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9805.2686 - val_loss: 89.9990\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 74724.3125 - val_loss: 88.5347\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69510.8828 - val_loss: 89.8602\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32099.8613 - val_loss: 91.4060\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21497.4727 - val_loss: 94.4761\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47355.2109 - val_loss: 95.4273\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 60405.7422 - val_loss: 95.5230\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40371.7109 - val_loss: 94.2416\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16927.4570 - val_loss: 92.2522\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21099.0059 - val_loss: 91.9107\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35225.9688 - val_loss: 92.0230\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24890.2559 - val_loss: 93.8333\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17824.8281 - val_loss: 94.4306\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17476.5059 - val_loss: 93.7479\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1846.2224 - val_loss: 93.9343\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7105.3921 - val_loss: 93.6417\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9410.5879 - val_loss: 93.5797\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 175.5434 - val_loss: 94.5385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 77 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 81.7749 - val_loss: 64.6692\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 60.8235 - val_loss: 46.4818\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42.4123 - val_loss: 44.0478\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34.6311 - val_loss: 25.6920\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30.5420 - val_loss: 19.9497\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25.0290 - val_loss: 23.4957\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24.2845 - val_loss: 13.0644\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.8940 - val_loss: 6.8494\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21.0301 - val_loss: 8.1277\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.9025 - val_loss: 3.4627\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.5495 - val_loss: 7.0260\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.8420 - val_loss: 3.1460\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.9814 - val_loss: 4.5043\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.3297 - val_loss: 3.1327\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.7704 - val_loss: 3.3371\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.3141 - val_loss: 3.6064\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.7809 - val_loss: 2.8183\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.0262 - val_loss: 5.1596\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.9042 - val_loss: 3.5552\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.1075 - val_loss: 3.4383\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.4308 - val_loss: 4.1783\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.9352 - val_loss: 3.3452\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4814 - val_loss: 3.2241\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.8626 - val_loss: 3.1417\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3458 - val_loss: 3.7250\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0593 - val_loss: 3.2198\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7971 - val_loss: 3.7740\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.2525 - val_loss: 3.4198\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6405 - val_loss: 3.3217\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7294 - val_loss: 3.8359\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4262 - val_loss: 3.1672\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.7343 - val_loss: 4.0161\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.0549 - val_loss: 3.4535\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.1631 - val_loss: 4.3895\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.0739 - val_loss: 4.1697\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5666 - val_loss: 3.6550\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4846 - val_loss: 4.6417\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5192 - val_loss: 3.9512\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8177 - val_loss: 4.1328\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6080 - val_loss: 3.3466\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9880 - val_loss: 3.8618\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8678 - val_loss: 3.2746\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7616 - val_loss: 3.5745\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6517 - val_loss: 3.4919\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7437 - val_loss: 3.3261\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7970 - val_loss: 3.5770\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7057 - val_loss: 3.8175\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3114 - val_loss: 2.9630\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.3150 - val_loss: 3.6697\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5758 - val_loss: 5.4237\n",
      "Iteration number 78 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 69.5878 - val_loss: 47.2780\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27.0954 - val_loss: 5.1176\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29.0914 - val_loss: 16.2686\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.4455 - val_loss: 27.9557\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.1063 - val_loss: 25.9970\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.9938 - val_loss: 13.9917\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.8877 - val_loss: 6.9331\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.5491 - val_loss: 13.6878\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.8247 - val_loss: 9.4619\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.7976 - val_loss: 4.9681\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5791 - val_loss: 6.4286\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.1256 - val_loss: 2.5090\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3984 - val_loss: 3.6753\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.2590 - val_loss: 3.1660\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8183 - val_loss: 3.5243\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2530 - val_loss: 2.8211\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2064 - val_loss: 3.4768\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.5286 - val_loss: 2.9753\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6208 - val_loss: 4.3902\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1779 - val_loss: 2.9483\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.7623 - val_loss: 4.0531\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5211 - val_loss: 2.9751\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4010 - val_loss: 3.8396\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2679 - val_loss: 3.2723\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1217 - val_loss: 4.1503\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9655 - val_loss: 3.9056\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1786 - val_loss: 4.3838\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0344 - val_loss: 3.3153\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6877 - val_loss: 4.5579\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1946 - val_loss: 3.4712\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7228 - val_loss: 3.2887\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7496 - val_loss: 3.3257\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6738 - val_loss: 3.5504\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8079 - val_loss: 3.1893\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7133 - val_loss: 4.4532\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6998 - val_loss: 2.9799\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5955 - val_loss: 3.6313\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7699 - val_loss: 3.0928\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7491 - val_loss: 3.2348\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6511 - val_loss: 4.0420\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5424 - val_loss: 3.0760\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2696 - val_loss: 3.1751\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1666 - val_loss: 3.0776\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.1413 - val_loss: 2.9576\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0967 - val_loss: 3.3277\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1412 - val_loss: 2.9639\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9943 - val_loss: 2.9249\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.0354 - val_loss: 3.2509\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2023 - val_loss: 2.9475\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2988 - val_loss: 3.6745\n",
      "Iteration number 79 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 4749770.0000 - val_loss: 100.4075\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3814828.2500 - val_loss: 98.7893\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3732720.0000 - val_loss: 97.6544\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1310775.6250 - val_loss: 96.1586\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 862910.0000 - val_loss: 95.2983\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 748211.9375 - val_loss: 93.9874\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 778496.0625 - val_loss: 93.0150\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 463411.1562 - val_loss: 92.0694\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 779023.2500 - val_loss: 91.1079\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 218704.2031 - val_loss: 90.0809\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 177394.6250 - val_loss: 89.1606\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 309665.6875 - val_loss: 88.2918\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 692825.8750 - val_loss: 87.3733\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 598825.0625 - val_loss: 86.4821\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 681008.6875 - val_loss: 85.7058\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 279140.5000 - val_loss: 84.8133\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 236293.2969 - val_loss: 84.0805\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 577102.4375 - val_loss: 83.3548\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 665346.3750 - val_loss: 82.5534\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 173797.5625 - val_loss: 81.7675\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 426869.8125 - val_loss: 80.9306\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 673947.9375 - val_loss: 80.3454\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 309868.7500 - val_loss: 79.7085\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 131625.8750 - val_loss: 78.9557\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 398123.6562 - val_loss: 78.2243\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 648727.6875 - val_loss: 77.5977\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 277679.2812 - val_loss: 77.0629\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 143906.6250 - val_loss: 76.4312\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 155327.2812 - val_loss: 75.6702\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 152744.2969 - val_loss: 75.0401\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 195360.7188 - val_loss: 74.2771\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 243140.6562 - val_loss: 73.5394\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 577597.4375 - val_loss: 72.9697\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 460485.2500 - val_loss: 72.4992\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 598356.1875 - val_loss: 72.0453\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 206248.4062 - val_loss: 71.5997\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 124738.6016 - val_loss: 71.0163\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 411713.8438 - val_loss: 70.5126\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 537300.2500 - val_loss: 70.0211\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 198059.9844 - val_loss: 69.4682\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 168706.6562 - val_loss: 68.9978\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 133566.9219 - val_loss: 68.4815\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 170653.3906 - val_loss: 67.9851\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 153477.9688 - val_loss: 67.4754\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 142119.7031 - val_loss: 66.9045\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 131852.4219 - val_loss: 66.3303\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 166262.1875 - val_loss: 65.9289\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 155959.9531 - val_loss: 65.4773\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 137302.1250 - val_loss: 65.0282\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 141847.7969 - val_loss: 64.6346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 80 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 75.0589 - val_loss: 55.3152\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30.9972 - val_loss: 10.3572\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.3190 - val_loss: 20.5226\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22.6841 - val_loss: 32.5392\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.5679 - val_loss: 24.0125\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.7880 - val_loss: 11.3158\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.4920 - val_loss: 14.5916\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.1295 - val_loss: 9.7697\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3779 - val_loss: 5.9077\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.4164 - val_loss: 3.2144\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.9229 - val_loss: 4.7429\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.0152 - val_loss: 3.2495\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.5866 - val_loss: 4.0534\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2568 - val_loss: 2.5664\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.9485 - val_loss: 3.0507\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6396 - val_loss: 3.1705\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.6228 - val_loss: 2.7682\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0038 - val_loss: 3.3829\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0764 - val_loss: 3.0489\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8438 - val_loss: 3.7034\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0619 - val_loss: 3.0578\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7756 - val_loss: 3.7645\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.5599 - val_loss: 3.5719\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3259 - val_loss: 2.6469\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0923 - val_loss: 3.0063\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.1199 - val_loss: 3.4195\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0819 - val_loss: 2.5848\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0038 - val_loss: 2.7470\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9167 - val_loss: 3.9424\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0941 - val_loss: 2.8219\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5304 - val_loss: 3.6867\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9444 - val_loss: 4.2666\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8937 - val_loss: 3.5189\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.6680 - val_loss: 2.9731\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5084 - val_loss: 2.4369\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.4872 - val_loss: 2.7355\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1052 - val_loss: 2.3651\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9211 - val_loss: 2.9452\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.9891 - val_loss: 2.3101\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.3147 - val_loss: 2.7945\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.2574 - val_loss: 3.4266\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7118 - val_loss: 2.3393\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.6071 - val_loss: 2.7416\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6650 - val_loss: 2.9631\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.8566 - val_loss: 2.1251\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9889 - val_loss: 2.4344\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9489 - val_loss: 3.4026\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8441 - val_loss: 1.8416\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5425 - val_loss: 2.1233\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.3290 - val_loss: 3.3179\n",
      "Iteration number 81 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 4802774.5000 - val_loss: 91.6412\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3961739.2500 - val_loss: 90.5651\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3853653.0000 - val_loss: 90.3854\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1737857.8750 - val_loss: 89.7312\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 740637.8125 - val_loss: 89.0482\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1011321.5625 - val_loss: 88.4389\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1269717.8750 - val_loss: 87.6789\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 878352.5000 - val_loss: 86.9829\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 492528.5312 - val_loss: 86.2636\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 915144.1875 - val_loss: 85.6245\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 269590.2500 - val_loss: 84.8551\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 223298.2969 - val_loss: 83.9992\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 206139.4531 - val_loss: 83.2452\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 599784.0625 - val_loss: 82.6404\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 585976.1875 - val_loss: 81.9202\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 590975.4375 - val_loss: 81.2016\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 661494.9375 - val_loss: 80.6036\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 650042.8125 - val_loss: 79.9782\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 573503.6250 - val_loss: 79.4692\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 534679.5625 - val_loss: 79.0328\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 653349.5000 - val_loss: 78.5498\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 582864.6250 - val_loss: 78.1100\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 523466.2188 - val_loss: 77.6048\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 547401.8750 - val_loss: 77.1510\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 588875.2500 - val_loss: 76.7682\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 465210.0000 - val_loss: 76.2798\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 141994.3125 - val_loss: 75.7686\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 255660.3125 - val_loss: 75.1973\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 629917.6875 - val_loss: 74.7537\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 384446.6562 - val_loss: 74.2201\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 388629.5312 - val_loss: 73.7555\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 235272.1562 - val_loss: 73.2534\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 290646.2812 - val_loss: 72.8323\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89480.6562 - val_loss: 72.3694\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 402401.9375 - val_loss: 71.8511\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 614796.6250 - val_loss: 71.3657\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 268480.3125 - val_loss: 70.9565\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 137544.2500 - val_loss: 70.5042\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 164960.8438 - val_loss: 70.0196\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 465755.4062 - val_loss: 69.5604\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 520929.1562 - val_loss: 69.2713\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 230864.8438 - val_loss: 68.9168\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 184688.5781 - val_loss: 68.5507\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 474652.2188 - val_loss: 68.1473\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 531336.1875 - val_loss: 67.8791\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 149264.0469 - val_loss: 67.5053\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 150405.3750 - val_loss: 67.1296\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 135729.2969 - val_loss: 66.7118\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 354100.4062 - val_loss: 66.3600\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 528948.8125 - val_loss: 66.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 82 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 87753.6719 - val_loss: 98.9431\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 77573.6484 - val_loss: 97.6518\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31701.7344 - val_loss: 94.5834\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 61044.6133 - val_loss: 93.2153\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44093.6406 - val_loss: 96.5359\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24641.9961 - val_loss: 96.8194\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15495.9229 - val_loss: 94.4543\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35958.4688 - val_loss: 95.3067\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22070.8477 - val_loss: 97.8862\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52157.7852 - val_loss: 98.8112\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43614.6133 - val_loss: 95.6966\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 51159.6367 - val_loss: 94.7465\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42240.4883 - val_loss: 96.0132\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23334.8730 - val_loss: 99.3082\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 68500.4688 - val_loss: 100.5378\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 65383.0000 - val_loss: 99.0397\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27977.8594 - val_loss: 96.8765\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37248.8867 - val_loss: 96.5602\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31940.5684 - val_loss: 98.0055\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1865.8008 - val_loss: 97.9214\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9481.3242 - val_loss: 98.5181\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14257.6973 - val_loss: 98.4464\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1688.7246 - val_loss: 96.9073\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41317.6953 - val_loss: 96.6362\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31866.3359 - val_loss: 97.4682\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5301.8789 - val_loss: 99.3693\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42222.7266 - val_loss: 100.1512\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42860.3750 - val_loss: 99.5238\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25749.2363 - val_loss: 97.7701\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18035.1309 - val_loss: 97.8546\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18314.1934 - val_loss: 98.9935\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13101.0605 - val_loss: 98.9428\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2205.1914 - val_loss: 97.6589\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30414.4863 - val_loss: 97.6225\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25413.1367 - val_loss: 98.6272\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1231.1666 - val_loss: 98.5593\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5436.0137 - val_loss: 99.3365\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21770.1816 - val_loss: 99.4890\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2144.4111 - val_loss: 98.9360\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2021.1123 - val_loss: 98.6284\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9930.8848 - val_loss: 98.7534\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3429.7271 - val_loss: 100.7132\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49334.6094 - val_loss: 101.1069\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51709.8477 - val_loss: 100.7818\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27694.6309 - val_loss: 99.8449\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5047.1582 - val_loss: 98.8487\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8046.3257 - val_loss: 99.4440\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9077.2939 - val_loss: 99.2337\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 592.9227 - val_loss: 98.1539\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36389.2031 - val_loss: 97.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 83 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 68.6353 - val_loss: 45.8238\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25.2564 - val_loss: 8.6104\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.4770 - val_loss: 4.8480\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.8903 - val_loss: 18.4724\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.1217 - val_loss: 10.3940\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5581 - val_loss: 4.4626\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3042 - val_loss: 10.4599\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5346 - val_loss: 10.6774\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.1863 - val_loss: 5.5791\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.6161 - val_loss: 6.8564\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2780 - val_loss: 9.9278\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.5572 - val_loss: 4.7021\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1281 - val_loss: 7.8114\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.5008 - val_loss: 4.6192\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8937 - val_loss: 5.0588\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.6964 - val_loss: 3.3453\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4298 - val_loss: 3.1010\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.4348 - val_loss: 3.7847\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.1941 - val_loss: 3.1850\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.1685 - val_loss: 3.3429\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.1322 - val_loss: 3.3884\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.0083 - val_loss: 3.4828\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.9769 - val_loss: 4.1125\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.2053 - val_loss: 3.1890\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.9675 - val_loss: 3.5024\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.9562 - val_loss: 3.1915\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.8391 - val_loss: 4.0655\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.0971 - val_loss: 3.0875\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.9468 - val_loss: 3.0213\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.0769 - val_loss: 4.4960\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.3245 - val_loss: 3.0493\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.9957 - val_loss: 3.0480\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.9434 - val_loss: 3.7029\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.7643 - val_loss: 3.1907\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.7049 - val_loss: 3.8088\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.1683 - val_loss: 3.1477\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.9195 - val_loss: 3.0018\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.7985 - val_loss: 4.2572\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.0962 - val_loss: 3.0466\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.6969 - val_loss: 3.1888\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.5470 - val_loss: 3.0591\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.6201 - val_loss: 3.1580\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.5709 - val_loss: 3.7264\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.6177 - val_loss: 3.0466\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.6609 - val_loss: 5.6293\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.1564 - val_loss: 3.4365\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.5747 - val_loss: 4.3238\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.7488 - val_loss: 2.9518\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.7450 - val_loss: 3.4742\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.5486 - val_loss: 3.1288\n",
      "Iteration number 84 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 72.2573 - val_loss: 47.9791\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.2689 - val_loss: 28.2932\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.9743 - val_loss: 32.4904\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28.5371 - val_loss: 25.0535\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23.3835 - val_loss: 13.5004\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.2446 - val_loss: 17.2707\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.8536 - val_loss: 8.9605\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.9693 - val_loss: 11.0826\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.0679 - val_loss: 8.7516\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.6718 - val_loss: 9.5742\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.0408 - val_loss: 9.0219\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.9152 - val_loss: 9.7535\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.9992 - val_loss: 8.5984\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.0424 - val_loss: 10.0482\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.1986 - val_loss: 8.9013\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.2010 - val_loss: 8.7935\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.5062 - val_loss: 9.8404\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.9900 - val_loss: 8.7452\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9179 - val_loss: 10.1217\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9109 - val_loss: 8.9038\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.6690 - val_loss: 9.0936\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.4765 - val_loss: 9.4930\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.3850 - val_loss: 9.1027\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.4109 - val_loss: 9.2408\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.1419 - val_loss: 9.2243\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.1381 - val_loss: 9.2796\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.0157 - val_loss: 9.4440\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.8825 - val_loss: 9.0080\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.8589 - val_loss: 9.7187\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.8447 - val_loss: 8.9284\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.6473 - val_loss: 8.5715\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6121 - val_loss: 8.7940\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.6197 - val_loss: 9.0275\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6298 - val_loss: 9.0065\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3306 - val_loss: 8.9658\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.2317 - val_loss: 8.6054\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.0661 - val_loss: 8.6609\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.0805 - val_loss: 8.5856\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1432 - val_loss: 8.9185\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9008 - val_loss: 8.6358\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.8736 - val_loss: 8.6521\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.7463 - val_loss: 8.3223\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.8434 - val_loss: 8.7882\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5864 - val_loss: 8.4669\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.8603 - val_loss: 8.7017\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9144 - val_loss: 8.7638\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4398 - val_loss: 8.5130\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.3389 - val_loss: 8.7472\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.5456 - val_loss: 8.3214\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5009 - val_loss: 8.4343\n",
      "Iteration number 85 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 92.0944 - val_loss: 72.3022\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.8374 - val_loss: 30.5180\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23.9352 - val_loss: 8.7195\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21.6231 - val_loss: 20.6585\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.8485 - val_loss: 23.9333\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.9680 - val_loss: 15.9437\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.3348 - val_loss: 11.0229\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.3256 - val_loss: 13.8207\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.5030 - val_loss: 11.8582\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.9126 - val_loss: 7.4279\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.2655 - val_loss: 10.7824\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4361 - val_loss: 6.5505\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6955 - val_loss: 6.7571\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9932 - val_loss: 6.6504\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6305 - val_loss: 6.3735\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9382 - val_loss: 6.0918\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3767 - val_loss: 6.0723\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1834 - val_loss: 6.2480\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1387 - val_loss: 7.0018\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3420 - val_loss: 6.7994\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2832 - val_loss: 6.1947\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7556 - val_loss: 6.3873\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.5736 - val_loss: 6.6333\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3445 - val_loss: 6.1958\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.1350 - val_loss: 6.1740\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4657 - val_loss: 6.6766\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.4687 - val_loss: 6.0520\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1527 - val_loss: 6.2365\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9852 - val_loss: 6.1237\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7229 - val_loss: 6.1676\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7349 - val_loss: 6.3040\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6847 - val_loss: 6.1393\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6273 - val_loss: 6.1189\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7747 - val_loss: 6.0657\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5970 - val_loss: 6.5079\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.3141 - val_loss: 6.2534\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1932 - val_loss: 6.1815\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8546 - val_loss: 6.3549\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7936 - val_loss: 6.1376\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8416 - val_loss: 6.2947\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0029 - val_loss: 6.3220\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.5016 - val_loss: 6.2028\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3610 - val_loss: 6.1161\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.2234 - val_loss: 6.1912\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1754 - val_loss: 5.9965\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2458 - val_loss: 6.1134\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4866 - val_loss: 5.9142\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2759 - val_loss: 6.0368\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0615 - val_loss: 6.1611\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0961 - val_loss: 5.7699\n",
      "Iteration number 86 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 87.9591 - val_loss: 68.5423\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40.8277 - val_loss: 23.7929\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.2103 - val_loss: 14.1403\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22.0472 - val_loss: 26.4425\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19.8618 - val_loss: 24.0904\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.6446 - val_loss: 14.7270\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.1573 - val_loss: 13.5759\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.9743 - val_loss: 14.4066\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3766 - val_loss: 6.5209\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.1045 - val_loss: 10.4619\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.8227 - val_loss: 6.9801\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3640 - val_loss: 8.2968\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9786 - val_loss: 6.8198\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4794 - val_loss: 7.0296\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3827 - val_loss: 7.1655\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0980 - val_loss: 7.3106\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.9084 - val_loss: 7.4039\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8470 - val_loss: 7.1938\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7936 - val_loss: 7.0690\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.7475 - val_loss: 7.0290\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6463 - val_loss: 7.1701\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3910 - val_loss: 7.1285\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2389 - val_loss: 7.1225\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2039 - val_loss: 6.9388\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3255 - val_loss: 7.4845\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3039 - val_loss: 7.2449\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 8.1708 - val_loss: 7.5180\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.4135 - val_loss: 6.9348\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9756 - val_loss: 6.8656\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7930 - val_loss: 6.7934\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7592 - val_loss: 6.7821\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8751 - val_loss: 6.7483\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3769 - val_loss: 7.1943\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2512 - val_loss: 6.2240\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5956 - val_loss: 6.3671\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6354 - val_loss: 6.5472\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4300 - val_loss: 6.3674\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3047 - val_loss: 6.6485\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4981 - val_loss: 6.4722\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3105 - val_loss: 6.4560\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1801 - val_loss: 6.0332\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6666 - val_loss: 6.0258\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2087 - val_loss: 6.5399\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9771 - val_loss: 5.8511\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4324 - val_loss: 5.8613\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1905 - val_loss: 8.1786\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7048 - val_loss: 5.8204\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2820 - val_loss: 6.7009\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8989 - val_loss: 5.4698\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8863 - val_loss: 5.5369\n",
      "Iteration number 87 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 54294.4844 - val_loss: 126.8910\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 206543.9531 - val_loss: 132.3884\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 138083.7969 - val_loss: 122.0973\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33064.0117 - val_loss: 112.4515\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 105382.3828 - val_loss: 108.7240\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 105406.1172 - val_loss: 108.5867\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 77459.6250 - val_loss: 112.6749\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5518.9492 - val_loss: 117.5034\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 112518.9453 - val_loss: 118.5027\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 111122.6562 - val_loss: 115.7361\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 56131.7031 - val_loss: 113.2323\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15025.4277 - val_loss: 109.4034\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38020.9844 - val_loss: 108.2427\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48171.8672 - val_loss: 108.8130\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20412.7734 - val_loss: 111.0328\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10202.6689 - val_loss: 111.7896\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13708.2842 - val_loss: 110.4905\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17494.7090 - val_loss: 110.5554\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2856.1897 - val_loss: 112.2797\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22152.0566 - val_loss: 112.1598\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19644.1094 - val_loss: 111.5410\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13211.6846 - val_loss: 110.2348\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11201.3311 - val_loss: 111.6815\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19376.6094 - val_loss: 111.4137\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6236.7568 - val_loss: 110.2398\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15803.2109 - val_loss: 110.0036\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10720.8262 - val_loss: 110.8475\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14577.6973 - val_loss: 111.1239\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7530.4014 - val_loss: 109.4036\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25890.2578 - val_loss: 109.4181\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19076.8965 - val_loss: 111.1928\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22794.4434 - val_loss: 111.1910\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9252.0000 - val_loss: 109.9353\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13043.2686 - val_loss: 109.6244\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9549.1162 - val_loss: 110.3698\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14319.0771 - val_loss: 110.5961\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8758.5869 - val_loss: 108.7106\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33054.7148 - val_loss: 108.5374\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20491.9199 - val_loss: 109.5761\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11743.3623 - val_loss: 110.2663\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4459.8052 - val_loss: 109.2175\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30241.5586 - val_loss: 108.2703\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11936.1123 - val_loss: 109.5291\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1183.7706 - val_loss: 112.9857\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 88576.2578 - val_loss: 114.2869\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 90017.8750 - val_loss: 113.4870\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73866.7266 - val_loss: 111.0481\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27172.3203 - val_loss: 108.6318\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9100.8066 - val_loss: 107.7799\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16741.6562 - val_loss: 107.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 88 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 107001.8594 - val_loss: 90.6555\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 105387.3906 - val_loss: 90.9240\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50552.3906 - val_loss: 87.2553\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40859.9570 - val_loss: 86.2518\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16587.6484 - val_loss: 87.6554\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33927.6797 - val_loss: 89.3097\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37852.3164 - val_loss: 88.4736\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 507.6433 - val_loss: 85.4062\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 72444.0859 - val_loss: 84.4380\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 69299.8438 - val_loss: 86.1490\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18689.3984 - val_loss: 88.7096\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10439.2842 - val_loss: 89.4301\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23455.9043 - val_loss: 88.8128\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15060.8867 - val_loss: 88.6442\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5217.5171 - val_loss: 88.6891\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6728.9570 - val_loss: 89.4197\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12147.9756 - val_loss: 88.6049\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15950.3682 - val_loss: 89.1563\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4226.2446 - val_loss: 88.4822\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 27152.7441 - val_loss: 88.5498\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2490.4839 - val_loss: 90.0955\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20980.1270 - val_loss: 90.3530\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26336.5762 - val_loss: 89.3314\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19303.7715 - val_loss: 88.9700\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12793.9961 - val_loss: 89.7784\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6416.4839 - val_loss: 87.5821\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57809.1562 - val_loss: 87.5092\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53548.9570 - val_loss: 88.6002\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15086.6729 - val_loss: 90.2456\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7258.2739 - val_loss: 90.6886\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17691.6816 - val_loss: 90.2258\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11727.6670 - val_loss: 90.0962\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4069.5007 - val_loss: 90.1157\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18681.3066 - val_loss: 89.9041\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4770.8315 - val_loss: 90.3928\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3994.0476 - val_loss: 90.8102\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14153.4902 - val_loss: 90.5576\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5522.7095 - val_loss: 90.5771\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8991.0859 - val_loss: 90.7812\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5630.2671 - val_loss: 90.2745\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7859.8882 - val_loss: 90.4560\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2071.4548 - val_loss: 91.0255\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27249.3066 - val_loss: 91.4542\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20460.3418 - val_loss: 90.3932\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27548.4844 - val_loss: 89.9436\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10037.6260 - val_loss: 91.1344\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16307.8486 - val_loss: 91.5771\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19736.0156 - val_loss: 91.2837\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4593.2856 - val_loss: 91.0573\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4793.6001 - val_loss: 90.8243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 89 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 103.0272 - val_loss: 85.9301\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 55.6932 - val_loss: 47.9190\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41.8082 - val_loss: 18.4834\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35.4281 - val_loss: 33.7702\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29.9395 - val_loss: 38.0934\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27.2474 - val_loss: 29.8430\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.5658 - val_loss: 16.0237\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18.9269 - val_loss: 19.1280\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.0386 - val_loss: 16.4915\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.0223 - val_loss: 9.1820\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.8197 - val_loss: 8.0391\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.9050 - val_loss: 6.9575\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.4310 - val_loss: 7.3388\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.1103 - val_loss: 6.5842\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.7515 - val_loss: 6.8750\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2686 - val_loss: 6.1494\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3506 - val_loss: 8.4272\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.1798 - val_loss: 7.6118\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.0041 - val_loss: 5.9088\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.6783 - val_loss: 8.9296\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.5105 - val_loss: 6.1185\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.1234 - val_loss: 9.9301\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3192 - val_loss: 5.5984\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0876 - val_loss: 8.7986\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5390 - val_loss: 5.4715\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5538 - val_loss: 7.0291\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.0157 - val_loss: 6.0813\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1607 - val_loss: 6.4220\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.0429 - val_loss: 5.6839\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9068 - val_loss: 5.9950\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5414 - val_loss: 5.6804\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8276 - val_loss: 7.2859\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4781 - val_loss: 5.3656\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5417 - val_loss: 6.6708\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4241 - val_loss: 5.3468\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8991 - val_loss: 6.1566\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8544 - val_loss: 5.4292\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4036 - val_loss: 5.5112\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2075 - val_loss: 5.4037\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1460 - val_loss: 5.3502\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0224 - val_loss: 5.7879\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3994 - val_loss: 5.5340\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8748 - val_loss: 6.3030\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.8556 - val_loss: 5.1299\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0561 - val_loss: 5.2591\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7143 - val_loss: 6.5778\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4265 - val_loss: 5.5179\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7555 - val_loss: 4.7588\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5765 - val_loss: 6.3983\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0276 - val_loss: 4.9659\n",
      "Iteration number 90 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 233667.8438 - val_loss: 86.4621\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60440.4258 - val_loss: 94.3506\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20806.5059 - val_loss: 84.4627\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 115181.3047 - val_loss: 83.0247\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 110077.0938 - val_loss: 87.6391\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11124.3467 - val_loss: 91.5178\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33761.2266 - val_loss: 94.2757\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62467.9727 - val_loss: 94.1315\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12171.1064 - val_loss: 89.1174\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 59731.2031 - val_loss: 86.6934\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 63946.3359 - val_loss: 89.4368\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2148.6748 - val_loss: 91.9646\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15734.5645 - val_loss: 93.4351\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37586.8594 - val_loss: 91.5396\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 162.9455 - val_loss: 92.2126\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35558.1055 - val_loss: 92.6731\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25259.2129 - val_loss: 87.5965\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 83458.7031 - val_loss: 85.8639\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73641.3516 - val_loss: 87.1984\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59596.5391 - val_loss: 92.9876\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52161.0000 - val_loss: 94.8001\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54233.3438 - val_loss: 92.9144\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12036.4766 - val_loss: 90.4052\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 45831.3750 - val_loss: 89.2592\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34714.8398 - val_loss: 90.5140\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7327.6211 - val_loss: 92.3892\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6824.4150 - val_loss: 90.3966\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35664.7070 - val_loss: 90.5277\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22042.2480 - val_loss: 92.8887\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13410.2422 - val_loss: 92.7045\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9603.5020 - val_loss: 90.7290\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32945.7617 - val_loss: 90.8171\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20118.5840 - val_loss: 93.0787\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36693.6250 - val_loss: 94.1290\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17154.1738 - val_loss: 92.1226\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3973.9382 - val_loss: 91.7787\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12262.5469 - val_loss: 92.7445\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21807.3242 - val_loss: 93.3547\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4189.5425 - val_loss: 90.8419\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 57950.9727 - val_loss: 89.3503\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47200.8477 - val_loss: 91.4251\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20477.1621 - val_loss: 94.8449\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51874.8047 - val_loss: 95.8110\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51052.1055 - val_loss: 94.5850\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15887.5508 - val_loss: 92.9353\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17345.2207 - val_loss: 92.1696\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16763.2559 - val_loss: 93.2140\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9628.6904 - val_loss: 93.3712\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 851.5771 - val_loss: 93.9292\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18839.1309 - val_loss: 93.8039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 91 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 81.4377 - val_loss: 64.9638\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63.2220 - val_loss: 45.1406\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47.2901 - val_loss: 40.4612\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.5635 - val_loss: 29.3958\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26.5900 - val_loss: 23.9730\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19.5805 - val_loss: 15.8311\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.8111 - val_loss: 6.1716\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.7136 - val_loss: 8.0698\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.2877 - val_loss: 6.0867\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.0285 - val_loss: 7.4214\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.7933 - val_loss: 5.4612\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.6407 - val_loss: 5.9310\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.3808 - val_loss: 6.0161\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1859 - val_loss: 5.4810\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.2203 - val_loss: 5.9448\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9204 - val_loss: 5.3295\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.6823 - val_loss: 6.1221\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.7337 - val_loss: 5.1315\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.0601 - val_loss: 6.0994\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.1460 - val_loss: 5.1559\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3087 - val_loss: 5.8298\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.4474 - val_loss: 4.9130\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9969 - val_loss: 6.2739\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5531 - val_loss: 5.0146\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0262 - val_loss: 4.9214\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0030 - val_loss: 4.8747\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0617 - val_loss: 5.1850\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.8992 - val_loss: 4.4948\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0353 - val_loss: 5.5373\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6407 - val_loss: 4.5279\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3114 - val_loss: 5.2289\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7120 - val_loss: 4.3911\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4832 - val_loss: 6.1034\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1993 - val_loss: 4.4048\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.3346 - val_loss: 5.7801\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7057 - val_loss: 4.2492\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.2827 - val_loss: 6.1318\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5472 - val_loss: 4.2199\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6360 - val_loss: 4.2161\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8134 - val_loss: 4.7357\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.0686 - val_loss: 4.2676\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5387 - val_loss: 5.5323\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5183 - val_loss: 4.0751\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2446 - val_loss: 4.8095\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0910 - val_loss: 4.1401\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9037 - val_loss: 4.2596\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7130 - val_loss: 4.1805\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1119 - val_loss: 4.0677\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.9320 - val_loss: 4.0820\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6598 - val_loss: 4.4690\n",
      "Iteration number 92 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 82.4664 - val_loss: 57.1688\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33.2848 - val_loss: 4.7387\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29.1305 - val_loss: 3.4930\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.5363 - val_loss: 18.7431\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.3185 - val_loss: 21.7279\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 16.4887 - val_loss: 10.2618\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.7273 - val_loss: 6.2584\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.3712 - val_loss: 9.1731\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.7935 - val_loss: 7.7996\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.8171 - val_loss: 4.2385\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.5737 - val_loss: 4.2670\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.1691 - val_loss: 5.9568\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.9517 - val_loss: 6.4570\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.7611 - val_loss: 5.6193\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.1360 - val_loss: 4.2447\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5096 - val_loss: 4.2501\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.1343 - val_loss: 5.1395\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5790 - val_loss: 4.7539\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.5603 - val_loss: 4.5607\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.2367 - val_loss: 4.2935\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8510 - val_loss: 4.2941\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6979 - val_loss: 4.3011\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5282 - val_loss: 4.2077\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3620 - val_loss: 4.1864\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3097 - val_loss: 4.2314\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0426 - val_loss: 4.0278\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6142 - val_loss: 3.9643\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6464 - val_loss: 3.9816\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8216 - val_loss: 4.0863\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.3784 - val_loss: 4.2102\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.7581 - val_loss: 4.0027\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.1105 - val_loss: 3.8028\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9511 - val_loss: 3.7374\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9950 - val_loss: 3.6624\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.1315 - val_loss: 3.9771\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1088 - val_loss: 3.5810\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5145 - val_loss: 3.6239\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.1756 - val_loss: 3.4279\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9635 - val_loss: 4.4386\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.0433 - val_loss: 3.6442\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5155 - val_loss: 3.9089\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1019 - val_loss: 3.5955\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.9412 - val_loss: 3.5155\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0565 - val_loss: 5.0671\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2137 - val_loss: 4.3043\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.3991 - val_loss: 5.0891\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.7799 - val_loss: 3.6689\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0621 - val_loss: 5.1317\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0588 - val_loss: 4.3059\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.0020 - val_loss: 3.8410\n",
      "Iteration number 93 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 78.9525 - val_loss: 62.2533\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57.1200 - val_loss: 38.8629\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46.5969 - val_loss: 47.5958\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39.3895 - val_loss: 48.1978\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35.3070 - val_loss: 33.3600\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29.7946 - val_loss: 15.7031\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25.6277 - val_loss: 19.2102\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23.5679 - val_loss: 11.3379\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21.6519 - val_loss: 8.5921\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.8893 - val_loss: 13.9124\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.7425 - val_loss: 8.3624\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.6947 - val_loss: 10.3321\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.0103 - val_loss: 4.7386\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.4264 - val_loss: 5.6733\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.7802 - val_loss: 3.8450\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.3932 - val_loss: 4.4864\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.0562 - val_loss: 4.8085\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.6229 - val_loss: 3.4949\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.1290 - val_loss: 5.0367\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.4317 - val_loss: 3.5442\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.2945 - val_loss: 5.2021\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.1655 - val_loss: 2.9038\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.6431 - val_loss: 3.1979\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.3919 - val_loss: 3.5680\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.1859 - val_loss: 3.7111\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.9237 - val_loss: 3.1290\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3399 - val_loss: 2.7616\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.2216 - val_loss: 2.9074\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9798 - val_loss: 3.4936\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0190 - val_loss: 2.7368\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.0638 - val_loss: 2.5153\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6022 - val_loss: 2.7798\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4292 - val_loss: 2.8378\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5586 - val_loss: 4.4120\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8801 - val_loss: 2.3101\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.4338 - val_loss: 2.9518\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6258 - val_loss: 2.4030\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4520 - val_loss: 2.3613\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1508 - val_loss: 2.3759\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8572 - val_loss: 2.4627\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6929 - val_loss: 2.3397\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6538 - val_loss: 2.2509\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2912 - val_loss: 1.9816\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4342 - val_loss: 2.0840\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.9189 - val_loss: 2.7172\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2589 - val_loss: 2.0964\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5102 - val_loss: 3.5603\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.3698 - val_loss: 3.4185\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.4998 - val_loss: 2.3979\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.1525 - val_loss: 2.5755\n",
      "Iteration number 94 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 82.3479 - val_loss: 52.9908\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37.3874 - val_loss: 8.1901\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.8584 - val_loss: 16.5900\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25.7291 - val_loss: 27.4907\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.4550 - val_loss: 21.9418\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20.6308 - val_loss: 10.2910\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.9991 - val_loss: 6.2277\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.3309 - val_loss: 7.1255\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.3081 - val_loss: 10.1241\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9089 - val_loss: 6.7238\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.3216 - val_loss: 6.3240\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0580 - val_loss: 6.7395\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.1517 - val_loss: 6.4106\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.2936 - val_loss: 6.3964\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9018 - val_loss: 6.1554\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5539 - val_loss: 5.9371\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3637 - val_loss: 5.6108\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3903 - val_loss: 5.6784\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.7198 - val_loss: 5.2401\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2424 - val_loss: 5.4937\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3111 - val_loss: 5.2811\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3574 - val_loss: 5.0810\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.9682 - val_loss: 5.3560\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.8024 - val_loss: 4.9551\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8842 - val_loss: 4.8891\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7902 - val_loss: 4.8795\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6236 - val_loss: 4.6960\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9495 - val_loss: 4.6127\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.7602 - val_loss: 5.6121\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.6133 - val_loss: 4.4571\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7587 - val_loss: 4.4773\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.6080 - val_loss: 4.5615\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.6432 - val_loss: 5.4872\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1419 - val_loss: 4.7445\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0705 - val_loss: 4.9941\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.3235 - val_loss: 4.2989\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.2311 - val_loss: 4.3943\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0758 - val_loss: 4.3613\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9062 - val_loss: 4.9169\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.3532 - val_loss: 4.0584\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9922 - val_loss: 4.2947\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.8027 - val_loss: 3.9285\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.0395 - val_loss: 4.1605\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.8353 - val_loss: 3.8723\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0792 - val_loss: 4.2578\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.4768 - val_loss: 3.6939\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.1887 - val_loss: 3.6784\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8043 - val_loss: 3.9899\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5550 - val_loss: 3.8862\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5953 - val_loss: 3.5889\n",
      "Iteration number 95 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 86.8824 - val_loss: 61.9417\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 44.8840 - val_loss: 18.7138\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 44.3336 - val_loss: 25.9627\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.6207 - val_loss: 38.7644\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30.7286 - val_loss: 31.7202\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24.9110 - val_loss: 17.8881\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24.3166 - val_loss: 17.6463\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.9173 - val_loss: 22.0028\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.9467 - val_loss: 13.5388\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.6908 - val_loss: 10.1817\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.6795 - val_loss: 7.9450\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.7790 - val_loss: 6.8340\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.0132 - val_loss: 6.4923\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.0823 - val_loss: 6.2234\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.7118 - val_loss: 5.7957\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.8278 - val_loss: 6.5898\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.5070 - val_loss: 5.4230\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.9729 - val_loss: 6.3854\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.8397 - val_loss: 5.0101\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.7849 - val_loss: 5.2779\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.4977 - val_loss: 5.1465\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.6840 - val_loss: 5.0716\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.3718 - val_loss: 5.8916\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.4902 - val_loss: 4.7699\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.1894 - val_loss: 5.3780\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6113 - val_loss: 4.4317\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9999 - val_loss: 5.1006\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.6387 - val_loss: 4.4913\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5329 - val_loss: 4.8454\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3872 - val_loss: 5.2775\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0697 - val_loss: 4.4358\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.0761 - val_loss: 5.0371\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9135 - val_loss: 5.0642\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8213 - val_loss: 4.7186\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7575 - val_loss: 4.3265\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9207 - val_loss: 6.0083\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.3754 - val_loss: 4.0952\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9881 - val_loss: 6.7345\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.1150 - val_loss: 4.0414\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0178 - val_loss: 5.0876\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5267 - val_loss: 4.1850\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.2316 - val_loss: 6.8488\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1326 - val_loss: 3.9192\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.1410 - val_loss: 6.2194\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.3013 - val_loss: 3.9264\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9158 - val_loss: 5.1355\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1528 - val_loss: 3.9820\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8006 - val_loss: 4.5535\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.8464 - val_loss: 4.2904\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5568 - val_loss: 4.2012\n",
      "Iteration number 96 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 64.6233 - val_loss: 43.3798\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.3654 - val_loss: 2.0146\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.6903 - val_loss: 16.2864\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.2499 - val_loss: 26.1644\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.4067 - val_loss: 16.6097\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.2644 - val_loss: 13.1373\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.6262 - val_loss: 19.0049\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.4855 - val_loss: 15.0002\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2710 - val_loss: 11.0452\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7778 - val_loss: 11.7262\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5571 - val_loss: 9.7140\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3952 - val_loss: 5.1319\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2014 - val_loss: 5.9110\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8353 - val_loss: 7.0777\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6239 - val_loss: 6.6326\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4695 - val_loss: 5.2626\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5883 - val_loss: 6.4337\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3748 - val_loss: 6.8880\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3384 - val_loss: 4.2751\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1411 - val_loss: 4.6652\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9537 - val_loss: 5.5878\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9213 - val_loss: 3.1868\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.3811 - val_loss: 6.9770\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.3641 - val_loss: 2.5631\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8975 - val_loss: 3.3780\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.6990 - val_loss: 3.0315\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7022 - val_loss: 2.3486\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5093 - val_loss: 2.4673\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.3698 - val_loss: 3.2326\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.3181 - val_loss: 2.4925\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2269 - val_loss: 2.3187\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1124 - val_loss: 2.6052\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1175 - val_loss: 2.5027\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0730 - val_loss: 2.5038\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0373 - val_loss: 2.3769\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9374 - val_loss: 2.5268\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0658 - val_loss: 2.7526\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0122 - val_loss: 2.7151\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0452 - val_loss: 2.4792\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3613 - val_loss: 2.6543\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0041 - val_loss: 2.5166\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7412 - val_loss: 2.8258\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7472 - val_loss: 2.5389\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2131 - val_loss: 2.2657\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2935 - val_loss: 3.9414\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3495 - val_loss: 2.8861\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4801 - val_loss: 2.1896\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9015 - val_loss: 2.4268\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.6016 - val_loss: 2.0931\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7201 - val_loss: 2.7753\n",
      "Iteration number 97 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 59.0739 - val_loss: 27.2121\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23.6459 - val_loss: 9.5762\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18.5173 - val_loss: 14.6649\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16.3942 - val_loss: 21.1252\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.7080 - val_loss: 12.8821\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.1847 - val_loss: 4.9206\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.7194 - val_loss: 3.2108\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.4724 - val_loss: 8.3614\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5505 - val_loss: 10.0552\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6913 - val_loss: 4.7475\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1325 - val_loss: 4.3882\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4429 - val_loss: 4.9653\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2386 - val_loss: 2.3698\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7171 - val_loss: 3.3754\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3161 - val_loss: 2.2035\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4063 - val_loss: 2.1469\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.1561 - val_loss: 3.2369\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7817 - val_loss: 4.2338\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1499 - val_loss: 5.9175\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9584 - val_loss: 2.9851\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.1599 - val_loss: 2.3788\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8522 - val_loss: 2.7602\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.6063 - val_loss: 2.4603\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8341 - val_loss: 4.8271\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8854 - val_loss: 2.2561\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7997 - val_loss: 2.6954\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5971 - val_loss: 3.6565\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4877 - val_loss: 2.3242\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5472 - val_loss: 2.8424\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.3378 - val_loss: 3.1067\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4130 - val_loss: 2.2050\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6684 - val_loss: 2.3028\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5235 - val_loss: 4.5974\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8309 - val_loss: 2.7007\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9785 - val_loss: 3.7585\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5642 - val_loss: 3.0377\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.3361 - val_loss: 2.7500\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2624 - val_loss: 3.3117\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4070 - val_loss: 3.4228\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.2059 - val_loss: 2.5356\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.0159 - val_loss: 3.0341\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0649 - val_loss: 3.7579\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.1627 - val_loss: 2.2471\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5340 - val_loss: 2.2354\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4245 - val_loss: 4.0707\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.2680 - val_loss: 2.2003\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.2660 - val_loss: 2.4562\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.1194 - val_loss: 4.3516\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.1105 - val_loss: 2.2590\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.9791 - val_loss: 2.8203\n",
      "Iteration number 98 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 79.5139 - val_loss: 55.2971\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39.2077 - val_loss: 19.0878\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.6320 - val_loss: 17.5495\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25.5340 - val_loss: 28.0909\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25.8569 - val_loss: 26.9918\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.7686 - val_loss: 13.5672\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18.0734 - val_loss: 13.3827\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15.4513 - val_loss: 17.3891\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.8438 - val_loss: 10.7091\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.1505 - val_loss: 11.2756\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.7297 - val_loss: 11.8902\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.0438 - val_loss: 10.3246\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.2701 - val_loss: 11.8762\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.1814 - val_loss: 10.4301\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.7875 - val_loss: 11.1597\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.5616 - val_loss: 10.6484\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.9038 - val_loss: 10.1119\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.7668 - val_loss: 10.4197\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.9851 - val_loss: 10.0430\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.5324 - val_loss: 10.1196\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.1598 - val_loss: 9.7204\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.2242 - val_loss: 9.9828\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2540 - val_loss: 9.8166\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.9587 - val_loss: 9.5290\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6398 - val_loss: 10.6183\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.5483 - val_loss: 9.4942\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.1938 - val_loss: 9.7581\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.0511 - val_loss: 9.4673\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.2365 - val_loss: 9.4282\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.0667 - val_loss: 9.3084\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9667 - val_loss: 9.0660\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.8745 - val_loss: 9.0305\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7831 - val_loss: 9.2511\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.7860 - val_loss: 9.0786\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7565 - val_loss: 9.2736\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.8877 - val_loss: 8.8870\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6229 - val_loss: 8.8313\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1782 - val_loss: 9.2000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3260 - val_loss: 9.4376\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.6522 - val_loss: 8.6333\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.4337 - val_loss: 8.7246\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9800 - val_loss: 8.8223\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5078 - val_loss: 8.6251\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.8349 - val_loss: 8.3485\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.6514 - val_loss: 9.0915\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2723 - val_loss: 8.2840\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5270 - val_loss: 8.5837\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.1592 - val_loss: 8.7810\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.9326 - val_loss: 8.3951\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.5432 - val_loss: 8.2402\n",
      "Iteration number 99 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 44859.2617 - val_loss: 113.9239\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 314769.7500 - val_loss: 116.8645\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 249520.4688 - val_loss: 108.9129\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70469.5234 - val_loss: 102.3528\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35531.4180 - val_loss: 99.4528\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38686.9414 - val_loss: 101.3177\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34457.6992 - val_loss: 102.5341\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23761.2051 - val_loss: 98.1340\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76219.9062 - val_loss: 97.7250\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70435.4453 - val_loss: 99.0373\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37668.1445 - val_loss: 102.9211\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52693.7773 - val_loss: 104.1043\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50164.6211 - val_loss: 102.7090\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21420.1133 - val_loss: 99.1738\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 70804.8359 - val_loss: 98.4852\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62360.5469 - val_loss: 99.7643\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11826.9619 - val_loss: 102.2336\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37030.4609 - val_loss: 104.3241\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52028.9570 - val_loss: 103.6686\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23566.0762 - val_loss: 101.4544\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37373.3867 - val_loss: 100.3754\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31840.9238 - val_loss: 102.2055\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3307.2693 - val_loss: 101.8148\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8996.4785 - val_loss: 102.1404\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1735.3657 - val_loss: 102.3479\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6983.9185 - val_loss: 101.3363\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20590.3555 - val_loss: 101.5992\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5481.2202 - val_loss: 103.1621\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47749.3555 - val_loss: 104.1167\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30387.3613 - val_loss: 101.8611\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14004.6562 - val_loss: 101.3700\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14834.4033 - val_loss: 102.7139\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26710.1094 - val_loss: 103.0195\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9334.7959 - val_loss: 101.5930\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33568.5156 - val_loss: 100.6376\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25136.8105 - val_loss: 101.4437\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13841.5186 - val_loss: 105.0096\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 58892.1523 - val_loss: 105.5613\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69715.9297 - val_loss: 104.3959\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38552.4609 - val_loss: 102.7778\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8535.7070 - val_loss: 101.9984\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 183.9397 - val_loss: 101.8403\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15843.3057 - val_loss: 101.5157\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15098.3008 - val_loss: 102.8868\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21766.0254 - val_loss: 102.8086\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5222.4556 - val_loss: 101.6904\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18562.8711 - val_loss: 101.4339\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16877.5527 - val_loss: 102.8091\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20300.9531 - val_loss: 102.7542\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6465.9365 - val_loss: 101.4202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 100 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 86.4527 - val_loss: 67.0498\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45.4784 - val_loss: 23.7865\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.5106 - val_loss: 7.8649\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.4102 - val_loss: 16.0520\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.0854 - val_loss: 22.6734\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.7417 - val_loss: 13.8068\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.6747 - val_loss: 7.2156\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3905 - val_loss: 11.0047\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6034 - val_loss: 14.7960\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4803 - val_loss: 10.4247\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8139 - val_loss: 6.7953\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3675 - val_loss: 9.7121\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9576 - val_loss: 8.6552\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3563 - val_loss: 6.1750\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9325 - val_loss: 6.8447\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1806 - val_loss: 5.9310\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6551 - val_loss: 5.5650\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.1572 - val_loss: 4.2235\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.8090 - val_loss: 4.4521\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.4730 - val_loss: 3.8965\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.8834 - val_loss: 3.9559\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8282 - val_loss: 3.9052\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9265 - val_loss: 4.1695\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8264 - val_loss: 4.0853\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5955 - val_loss: 4.0645\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5756 - val_loss: 3.7852\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.3730 - val_loss: 3.7204\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.3207 - val_loss: 3.7427\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.2212 - val_loss: 3.7776\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2724 - val_loss: 3.7766\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1526 - val_loss: 3.7514\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0783 - val_loss: 3.7073\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.9954 - val_loss: 3.6980\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0401 - val_loss: 3.8431\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.2575 - val_loss: 3.6968\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6264 - val_loss: 4.1329\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4099 - val_loss: 3.7682\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0481 - val_loss: 3.8796\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0290 - val_loss: 3.5132\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.9226 - val_loss: 3.5365\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0793 - val_loss: 3.5065\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.9908 - val_loss: 3.8154\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.8978 - val_loss: 3.6004\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1036 - val_loss: 3.5368\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0329 - val_loss: 3.6844\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.8839 - val_loss: 3.5585\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.9748 - val_loss: 4.1149\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.3842 - val_loss: 4.0823\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.2786 - val_loss: 3.4580\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7837 - val_loss: 4.4859\n",
      "Iteration number 101 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 90.4131 - val_loss: 68.8780\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.0040 - val_loss: 29.1619\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33.4500 - val_loss: 20.4554\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26.9286 - val_loss: 28.8773\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23.2213 - val_loss: 32.3073\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.5498 - val_loss: 23.9477\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.6141 - val_loss: 12.1975\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.0971 - val_loss: 14.7351\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.7221 - val_loss: 18.3641\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.8034 - val_loss: 6.1022\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.1468 - val_loss: 10.7718\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.9880 - val_loss: 4.5187\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1527 - val_loss: 7.2414\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5016 - val_loss: 1.9201\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2688 - val_loss: 6.8725\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9382 - val_loss: 3.4113\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3975 - val_loss: 4.5560\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5116 - val_loss: 3.1534\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2735 - val_loss: 2.9224\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8877 - val_loss: 2.7121\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7817 - val_loss: 2.5203\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4659 - val_loss: 3.5087\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2032 - val_loss: 1.8663\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0252 - val_loss: 3.0787\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8226 - val_loss: 1.7536\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6476 - val_loss: 2.0165\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5844 - val_loss: 2.9946\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4741 - val_loss: 1.4640\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4581 - val_loss: 1.9852\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0710 - val_loss: 2.4100\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3366 - val_loss: 1.9831\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3148 - val_loss: 2.2243\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7656 - val_loss: 1.4418\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6915 - val_loss: 1.4956\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6640 - val_loss: 1.7443\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5834 - val_loss: 1.6929\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4359 - val_loss: 1.5012\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2332 - val_loss: 1.9013\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2658 - val_loss: 1.4804\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0114 - val_loss: 1.3983\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1077 - val_loss: 1.8820\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1390 - val_loss: 2.1386\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0227 - val_loss: 1.7584\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7834 - val_loss: 2.9629\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0326 - val_loss: 1.5694\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6020 - val_loss: 1.4432\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9551 - val_loss: 3.0125\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9656 - val_loss: 2.4750\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5766 - val_loss: 2.1038\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8908 - val_loss: 2.0640\n",
      "Iteration number 102 finished\n"
     ]
    }
   ],
   "source": [
    "zipcodes = df_time_series.columns\n",
    "dict_mape_skylar = {}\n",
    "dict_pred_skylar = {}\n",
    "\n",
    "for zipcode in range(len(zipcodes)):\n",
    "\n",
    "    # init a RMM model\n",
    "    rnn_model = Sequential()\n",
    "    # add 4 layers of RNN and a last layer\n",
    "\n",
    "    # we define shape on first layer, (60,1) because we use 60 inputs per prediction\n",
    "    rnn_model.add(LSTM(units= 60, return_sequences = False, input_shape=((60,1))))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # 3 other layers\n",
    "    #rnn_model.add(LSTM(units= 30, return_sequences = True))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # return_sequence is False because we want only 1 output after this layer\n",
    "    #rnn_model.add(LSTM(units= 60, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # last layer \n",
    "\n",
    "    rnn_model.add(Dense(units=1))\n",
    "\n",
    "    # compile - because this is a regression model we want to minimize MSE\n",
    "\n",
    "    rnn_model.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "\n",
    "    # We get only the specific column(Zipcode from our train and test datas)\n",
    "    train_data = train.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    test_data = test.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # We are using normalizaion rather than standascaler. \n",
    "    # In a upward trending timeseries it is better to not start from negative\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Because we are using 60 previous values to model and predict the next value, \n",
    "    # We set X_train from arrays of 60 for each y_train value\n",
    "    # Same idea for test data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(train_data_scaled)):\n",
    "        X_train.append(train_data_scaled[i-60:i])\n",
    "        y_train.append(train_data_scaled[i])\n",
    "\n",
    "    data_total = pd.concat((train.iloc[:,zipcode:zipcode+1], test.iloc[:,zipcode:zipcode+1]),axis=0)\n",
    "    inputs = data_total[len(train)-60:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(60,len(inputs)):\n",
    "        X_test.append(inputs[i-60:i])\n",
    "        y_test.append(inputs[i])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(test_data)\n",
    "\n",
    "    # We need numpy arrays for our model\n",
    "    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # We fit our data to our zipcode specific data\n",
    "    rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, scaler.transform(y_test)))\n",
    "\n",
    "    # Make predictions on the data\n",
    "\n",
    "    y_hat_raw = rnn_model.predict(X_train)\n",
    "    y_hat = scaler.inverse_transform(y_hat_raw)\n",
    "\n",
    "    # Use the score on unseen test data to calculate the MAPE\n",
    "\n",
    "    dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))      \n",
    "\n",
    "    # We get the last 60 values from our test data which is basically last 60 values in the data set\n",
    "    last_60 = df_time_series.iloc[-60:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # Before we use our data we scale it\n",
    "    last_60 = scaler.transform(last_60)\n",
    "    \n",
    "    # Our input should be in (x,60,1) format\n",
    "    x_new_pred = last_60[-60:].reshape(1,60,1)\n",
    "\n",
    "    # make a prediction, add to the last_60 for the next prediction and \n",
    "    y_pred = rnn_model.predict(x_new_pred)\n",
    "\n",
    "    # We add our predition to our list of predictions for zipcode specific predictions list\n",
    "    dict_pred_skylar[zipcodes[zipcode]]=scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(f'Iteration number {zipcode} finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89108: array([[89125.06]], dtype=float32),\n",
       " 89121: array([[75994.12]], dtype=float32),\n",
       " 89117: array([[342993.94]], dtype=float32),\n",
       " 89052: array([[421245.44]], dtype=float32),\n",
       " 89123: array([[302137.3]], dtype=float32),\n",
       " 89031: array([[120645.31]], dtype=float32),\n",
       " 89110: array([[86367.11]], dtype=float32),\n",
       " 89074: array([[313313.8]], dtype=float32),\n",
       " 89103: array([[105097.86]], dtype=float32),\n",
       " 89148: array([[304354.1]], dtype=float32),\n",
       " 89147: array([[127211.54]], dtype=float32),\n",
       " 89119: array([[95203.36]], dtype=float32),\n",
       " 89129: array([[136210.56]], dtype=float32),\n",
       " 89122: array([[99995.11]], dtype=float32),\n",
       " 89115: array([[49483.06]], dtype=float32),\n",
       " 89502: array([[103521.21]], dtype=float32),\n",
       " 89014: array([[144321.5]], dtype=float32),\n",
       " 89131: array([[340571.3]], dtype=float32),\n",
       " 89509: array([[442702.12]], dtype=float32),\n",
       " 89436: array([[174319.03]], dtype=float32),\n",
       " 89015: array([[98834.02]], dtype=float32),\n",
       " 89128: array([[138708.28]], dtype=float32),\n",
       " 89523: array([[389421.16]], dtype=float32),\n",
       " 89104: array([[76258.59]], dtype=float32),\n",
       " 89012: array([[345105.72]], dtype=float32),\n",
       " 89030: array([[86262.86]], dtype=float32),\n",
       " 89431: array([[85330.53]], dtype=float32),\n",
       " 89032: array([[86667.86]], dtype=float32),\n",
       " 89506: array([[118694.53]], dtype=float32),\n",
       " 89102: array([[76455.164]], dtype=float32),\n",
       " 89139: array([[142436.7]], dtype=float32),\n",
       " 89149: array([[151599.61]], dtype=float32),\n",
       " 89178: array([[300754.56]], dtype=float32),\n",
       " 89113: array([[304622.88]], dtype=float32),\n",
       " 89521: array([[414650.53]], dtype=float32),\n",
       " 89183: array([[124785.68]], dtype=float32),\n",
       " 89135: array([[421180.38]], dtype=float32),\n",
       " 89107: array([[81638.05]], dtype=float32),\n",
       " 89511: array([[646172.7]], dtype=float32),\n",
       " 89002: array([[308202.84]], dtype=float32),\n",
       " 89130: array([[129408.92]], dtype=float32),\n",
       " 89134: array([[320814.12]], dtype=float32),\n",
       " 89503: array([[119717.45]], dtype=float32),\n",
       " 89081: array([[114632.67]], dtype=float32),\n",
       " 89141: array([[321766.6]], dtype=float32),\n",
       " 89011: array([[272069.34]], dtype=float32),\n",
       " 89142: array([[72033.64]], dtype=float32),\n",
       " 89434: array([[129602.984]], dtype=float32),\n",
       " 89512: array([[115600.35]], dtype=float32),\n",
       " 89145: array([[92809.625]], dtype=float32),\n",
       " 89084: array([[299766.88]], dtype=float32),\n",
       " 89701: array([[265423.44]], dtype=float32),\n",
       " 89801: array([[208460.4]], dtype=float32),\n",
       " 89120: array([[100827.47]], dtype=float32),\n",
       " 89044: array([[350935.9]], dtype=float32),\n",
       " 89156: array([[82416.85]], dtype=float32),\n",
       " 89048: array([[101105.82]], dtype=float32),\n",
       " 89118: array([[148262.86]], dtype=float32),\n",
       " 89706: array([[263521.75]], dtype=float32),\n",
       " 89408: array([[144694.62]], dtype=float32),\n",
       " 89166: array([[292753.38]], dtype=float32),\n",
       " 89144: array([[355562.78]], dtype=float32),\n",
       " 89146: array([[154365.]], dtype=float32),\n",
       " 89027: array([[242222.94]], dtype=float32),\n",
       " 89403: array([[171603.86]], dtype=float32),\n",
       " 89433: array([[102987.836]], dtype=float32),\n",
       " 89005: array([[320821.78]], dtype=float32),\n",
       " 89138: array([[436478.25]], dtype=float32),\n",
       " 89460: array([[326733.5]], dtype=float32),\n",
       " 89423: array([[395983.56]], dtype=float32),\n",
       " 89410: array([[366729.84]], dtype=float32),\n",
       " 89815: array([[215286.89]], dtype=float32),\n",
       " 89029: array([[131214.25]], dtype=float32),\n",
       " 89109: array([[165541.64]], dtype=float32),\n",
       " 89508: array([[150758.38]], dtype=float32),\n",
       " 89703: array([[397177.84]], dtype=float32),\n",
       " 89441: array([[428157.22]], dtype=float32),\n",
       " 89060: array([[78774.56]], dtype=float32),\n",
       " 89143: array([[280067.12]], dtype=float32),\n",
       " 89519: array([[550517.]], dtype=float32),\n",
       " 89447: array([[116557.16]], dtype=float32),\n",
       " 89179: array([[311430.2]], dtype=float32),\n",
       " 89429: array([[109313.07]], dtype=float32),\n",
       " 89061: array([[105543.38]], dtype=float32),\n",
       " 89451: array([[931118.7]], dtype=float32),\n",
       " 89501: array([[343421.28]], dtype=float32),\n",
       " 89705: array([[321901.6]], dtype=float32),\n",
       " 89510: array([[424555.62]], dtype=float32),\n",
       " 89086: array([[120434.48]], dtype=float32),\n",
       " 89448: array([[415196.28]], dtype=float32),\n",
       " 89704: array([[425430.1]], dtype=float32),\n",
       " 89449: array([[256005.6]], dtype=float32),\n",
       " 89040: array([[209113.64]], dtype=float32),\n",
       " 89444: array([[289542.3]], dtype=float32),\n",
       " 89085: array([[331103.47]], dtype=float32),\n",
       " 89034: array([[255054.42]], dtype=float32),\n",
       " 89021: array([[230877.84]], dtype=float32),\n",
       " 89439: array([[458706.2]], dtype=float32),\n",
       " 89411: array([[515886.7]], dtype=float32),\n",
       " 89124: array([[337681.62]], dtype=float32),\n",
       " 89440: array([[99456.234]], dtype=float32),\n",
       " 89413: array([[2040080.5]], dtype=float32),\n",
       " 89155: array([[357517.4]], dtype=float32)}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pred_skylar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89108: inf,\n",
       " 89121: inf,\n",
       " 89117: 1230066.2112004093,\n",
       " 89052: 849023.4076489556,\n",
       " 89123: 1245902.8314519874,\n",
       " 89031: inf,\n",
       " 89110: inf,\n",
       " 89074: 1235234.9873707858,\n",
       " 89103: inf,\n",
       " 89148: 1564602.609267752,\n",
       " 89147: inf,\n",
       " 89119: inf,\n",
       " 89129: inf,\n",
       " 89122: inf,\n",
       " 89115: inf,\n",
       " 89502: inf,\n",
       " 89014: inf,\n",
       " 89131: 1267790.6867763042,\n",
       " 89509: 861158.6664328449,\n",
       " 89436: inf,\n",
       " 89015: inf,\n",
       " 89128: inf,\n",
       " 89523: 1116613.6573751096,\n",
       " 89104: inf,\n",
       " 89012: 803228.1592199908,\n",
       " 89030: inf,\n",
       " 89431: inf,\n",
       " 89032: inf,\n",
       " 89506: inf,\n",
       " 89102: inf,\n",
       " 89139: inf,\n",
       " 89149: inf,\n",
       " 89178: 1263958.5142729054,\n",
       " 89113: 1231231.4229128067,\n",
       " 89521: 900697.026561388,\n",
       " 89183: inf,\n",
       " 89135: 1030794.2057844118,\n",
       " 89107: inf,\n",
       " 89511: 1099164.863237715,\n",
       " 89002: 874431.9452965424,\n",
       " 89130: inf,\n",
       " 89134: 2055561.3968449957,\n",
       " 89503: inf,\n",
       " 89081: inf,\n",
       " 89141: 1109612.7007757071,\n",
       " 89011: 1274199.9438122606,\n",
       " 89142: inf,\n",
       " 89434: inf,\n",
       " 89512: inf,\n",
       " 89145: inf,\n",
       " 89084: 1126084.1104500473,\n",
       " 89701: 717319.0582727147,\n",
       " 89801: inf,\n",
       " 89120: inf,\n",
       " 89044: 681496.2415705951,\n",
       " 89156: inf,\n",
       " 89048: inf,\n",
       " 89118: inf,\n",
       " 89706: 550594.133251606,\n",
       " 89408: inf,\n",
       " 89166: 853139.2038593336,\n",
       " 89144: 935709.0020983517,\n",
       " 89146: inf,\n",
       " 89027: 626998.6678725225,\n",
       " 89403: inf,\n",
       " 89433: inf,\n",
       " 89005: 737327.2088295636,\n",
       " 89138: 1161405.077756935,\n",
       " 89460: 576897.2225772525,\n",
       " 89423: 704213.0442148822,\n",
       " 89410: 653551.9546868667,\n",
       " 89815: inf,\n",
       " 89029: inf,\n",
       " 89109: inf,\n",
       " 89508: inf,\n",
       " 89703: 990975.8898129726,\n",
       " 89441: 1029440.0940955299,\n",
       " 89060: inf,\n",
       " 89143: 1531513.2771627223,\n",
       " 89519: 1287210.3579656263,\n",
       " 89447: inf,\n",
       " 89179: 812589.4835636253,\n",
       " 89429: inf,\n",
       " 89061: inf,\n",
       " 89451: 1162558.7394056001,\n",
       " 89501: 694543.6927779577,\n",
       " 89705: 666047.7668984331,\n",
       " 89510: 902305.1468193594,\n",
       " 89086: inf,\n",
       " 89448: inf,\n",
       " 89704: 805071.7431239514,\n",
       " 89449: inf,\n",
       " 89040: 1094984.957853918,\n",
       " 89444: 637412.1169201456,\n",
       " 89085: 1484817.5105409324,\n",
       " 89034: 959847.0209837235,\n",
       " 89021: 1018985.4868376467,\n",
       " 89439: 829505.0863944809,\n",
       " 89411: 1195062.9838804866,\n",
       " 89124: 923523.0060611685,\n",
       " 89440: inf,\n",
       " 89413: 2654001.6272303164,\n",
       " 89155: 1066815.2493125491}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_mape_skylar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95804: [0.5159191513365095, 75412.6796875, 'RNN'],\n",
       " 95817: [0.4806917270953116, 82854.0859375, 'RNN'],\n",
       " 95813: [0.013083894437494591, 341304.875, 'RNN'],\n",
       " 95785: [0.01378739311178748, 422513.25, 'RNN'],\n",
       " 95819: [0.015094171486925623, 301021.0625, 'RNN'],\n",
       " 95770: [0.44194695282497615, 105605.78125, 'RNN'],\n",
       " 95806: [0.5182788597996814, 70026.3359375, 'RNN'],\n",
       " 95790: [0.007388430655138559, 312865.75, 'RNN'],\n",
       " 95799: [0.41473107013635707, 110862.84375, 'RNN'],\n",
       " 95844: [0.014626261526478987, 297665.53125, 'RNN'],\n",
       " 95843: [0.40972854999398295, 126288.140625, 'RNN'],\n",
       " 95815: [0.4957810488444431, 84689.921875, 'RNN'],\n",
       " 95825: [0.38387902090114595, 142043.46875, 'RNN'],\n",
       " 95818: [0.4386295986242681, 94474.0703125, 'RNN'],\n",
       " 95811: [0.46491245082909255, 74676.609375, 'RNN'],\n",
       " 95931: [0.44696939316482326, 114605.4375, 'RNN'],\n",
       " 95753: [0.3965936438523714, 141604.265625, 'RNN'],\n",
       " 95827: [0.007951250432951461, 335392.75, 'RNN'],\n",
       " 95937: [0.010482319800557482, 444971.84375, 'RNN'],\n",
       " 95914: [0.4358761083009109, 168000.984375, 'RNN'],\n",
       " 95754: [0.43916482062443524, 106289.3515625, 'RNN'],\n",
       " 95824: [0.3774964689018774, 143480.625, 'RNN'],\n",
       " 95945: [0.009420181348985288, 393342.9375, 'RNN'],\n",
       " 95800: [0.4718195009651555, 84472.21875, 'RNN'],\n",
       " 95751: [0.011770262489814314, 343317.875, 'RNN'],\n",
       " 95769: [0.2418764663897689, 81770.640625, 'RNN'],\n",
       " 95909: [0.541548922420154, 80201.6171875, 'RNN'],\n",
       " 95771: [0.4449168818684283, 96661.84375, 'RNN'],\n",
       " 95935: [0.468579774527048, 115184.875, 'RNN'],\n",
       " 95798: [0.49470465844168654, 83719.421875, 'RNN'],\n",
       " 95835: [0.3906188879587259, 140822.90625, 'RNN'],\n",
       " 95845: [0.3527866797556514, 166657.90625, 'RNN'],\n",
       " 95865: [0.0060464769748770665, 294301.125, 'RNN'],\n",
       " 95809: [0.009771453341725073, 304432.59375, 'RNN'],\n",
       " 95944: [0.010799909267872594, 409787.03125, 'RNN'],\n",
       " 399671: [0.4116425192150598, 124373.84375, 'RNN'],\n",
       " 95831: [0.013558921555743184, 427525.21875, 'RNN'],\n",
       " 95803: [0.517279830987193, 71889.5390625, 'RNN'],\n",
       " 95939: [0.017354669112205005, 643723.25, 'RNN'],\n",
       " 399665: [0.014149467428044914, 302807.65625, 'RNN'],\n",
       " 95826: [0.3977985782396422, 129545.7578125, 'RNN'],\n",
       " 95830: [0.01499383163019032, 316861.25, 'RNN'],\n",
       " 95932: [0.41069818420484944, 147422.921875, 'RNN'],\n",
       " 95792: [0.41483758989555536, 114382.765625, 'RNN'],\n",
       " 95837: [0.02081529672912315, 327126.6875, 'RNN'],\n",
       " 95750: [0.015961433084506354, 267443.625, 'RNN'],\n",
       " 95838: [0.4022623108188854, 102916.2578125, 'RNN'],\n",
       " 95912: [0.4455681412177846, 132910.53125, 'RNN'],\n",
       " 95940: [0.28050054567188604, 115600.046875, 'RNN'],\n",
       " 95841: [0.3897281475301448, 120660.484375, 'RNN'],\n",
       " 95793: [0.009597087395329643, 296469.84375, 'RNN'],\n",
       " 95952: [0.009495231708585497, 266254.875, 'RNN'],\n",
       " 95963: [0.10176629964979514, 209590.125, 'RNN'],\n",
       " 95816: [0.4315038321521024, 116423.96875, 'RNN'],\n",
       " 95779: [0.011447647262227374, 356830.5, 'RNN'],\n",
       " 95852: [0.46973642009308786, 84205.7265625, 'RNN'],\n",
       " 95783: [0.3317365500787004, 106907.9921875, 'RNN'],\n",
       " 95814: [0.38382792279041755, 134058.5, 'RNN'],\n",
       " 95957: [0.012981924290519522, 267417.28125, 'RNN'],\n",
       " 95888: [0.19147234315544517, 143140.03125, 'RNN'],\n",
       " 95861: [0.014256302542522825, 286464.03125, 'RNN'],\n",
       " 95840: [0.01030218372133625, 347827.71875, 'RNN'],\n",
       " 95842: [0.36788399256165016, 167712.90625, 'RNN'],\n",
       " 95766: [0.00854011861571219, 239586.078125, 'RNN'],\n",
       " 95883: [0.1520333966450159, 175152.21875, 'RNN'],\n",
       " 95911: [0.46489085262274765, 113575.8046875, 'RNN'],\n",
       " 95744: [0.00984138429584488, 318896.78125, 'RNN'],\n",
       " 95834: [0.011436811817719347, 434530.78125, 'RNN'],\n",
       " 95928: [0.021741427708519265, 318965.125, 'RNN'],\n",
       " 95901: [0.015790881595813135, 398780.40625, 'RNN'],\n",
       " 95890: [0.01847956218986767, 367463.875, 'RNN'],\n",
       " 95966: [0.07944586290889326, 216266.828125, 'RNN'],\n",
       " 95768: [0.16659501239545244, 133545.65625, 'RNN'],\n",
       " 95805: [0.3309421671862406, 162035.734375, 'RNN'],\n",
       " 399673: [0.43961954063396863, 131789.515625, 'RNN'],\n",
       " 95954: [0.010090192830097204, 399326.6875, 'RNN'],\n",
       " 399672: [0.02068608427753164, 418189.25, 'RNN'],\n",
       " 95787: [0.32292317749437116, 81608.4609375, 'RNN'],\n",
       " 95839: [0.018493146927664354, 276744.0, 'RNN'],\n",
       " 399674: [0.013792924062759431, 540005.875, 'RNN'],\n",
       " 95922: [0.12094748056449896, 114301.2109375, 'RNN'],\n",
       " 95866: [0.008060034743548408, 306858.6875, 'RNN'],\n",
       " 95907: [0.16924311825053417, 108803.5859375, 'RNN'],\n",
       " 95788: [0.41459605477245626, 98749.265625, 'RNN'],\n",
       " 95926: [0.022131163635094733, 916679.0625, 'RNN'],\n",
       " 95930: [0.03876847845117795, 338159.3125, 'RNN'],\n",
       " 95956: [0.02446487880320502, 315065.6875, 'RNN'],\n",
       " 95938: [0.02889695214142176, 428775.71875, 'RNN'],\n",
       " 95795: [0.3838596467150377, 137223.53125, 'RNN'],\n",
       " 95923: [0.32736431115352693, 409056.8125, 'RNN'],\n",
       " 95955: [0.02124960986573491, 423724.21875, 'RNN'],\n",
       " 95924: [0.23029241142242796, 260255.78125, 'RNN'],\n",
       " 95775: [0.013657195455473416, 207778.890625, 'RNN'],\n",
       " 95919: [0.01986937571165866, 285412.59375, 'RNN'],\n",
       " 95794: [0.009203299905793253, 330588.71875, 'RNN'],\n",
       " 399666: [0.013165532119944867, 323501.25, 'RNN'],\n",
       " 95760: [0.012689090960715351, 309324.90625, 'RNN'],\n",
       " 95916: [0.013263515868673158, 456363.8125, 'RNN'],\n",
       " 95891: [0.01297970825903085, 651686.3125, 'RNN'],\n",
       " 95820: [0.026793016022013318, 333740.6875, 'RNN'],\n",
       " 95917: [0.4154968076834546, 102394.203125, 'RNN'],\n",
       " 95893: [0.026021759253071913, 2057796.75, 'RNN'],\n",
       " 95851: [0.010471334813466493, 355289.84375, 'RNN']}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89005: [0.022498635550434295, 315770.5862729762, 'FBP_scale=0.5'],\n",
       " 89011: [0.04278110779000683, 268191.1951533978, 'FBP_scale=0.5'],\n",
       " 89012: [0.03408125028112888, 346791.0020159719, 'FBP_scale=0.5'],\n",
       " 89014: [0.02982231867033438, 290775.76827606466, 'FBP_scale=0.5'],\n",
       " 89015: [0.020673062452361255, 255266.9013634051, 'FBP_scale=0.5'],\n",
       " 89021: [0.021685927237354685, 310127.47890419036, 'FBP_scale=0.5'],\n",
       " 89027: [0.023356007127800827, 240189.23249319484, 'FBP_scale=0.5'],\n",
       " 89029: [0.0280397544224704, 182509.39476487262, 'FBP_scale=0.5'],\n",
       " 89030: [0.03602921269009029, 153247.78988254067, 'FBP_scale=0.5'],\n",
       " 89031: [0.03434730300348244, 246300.94475486007, 'FBP_scale=0.5'],\n",
       " 89032: [0.045912141431496335, 234114.60925612983, 'FBP_scale=0.5'],\n",
       " 89040: [0.052278179111354565, 208033.3162393082, 'FBP_scale=0.5'],\n",
       " 89044: [0.026860553573338542, 357295.44824271597, 'FBP_scale=0.5'],\n",
       " 89048: [0.04679328785772354, 200705.8126463924, 'FBP_scale=0.5'],\n",
       " 89052: [0.025238772814148578, 421068.9254136304, 'FBP_scale=0.5'],\n",
       " 89060: [0.05044588420751083, 154590.7171150974, 'FBP_scale=0.5'],\n",
       " 89061: [0.05167060208025199, 219499.46418643033, 'FBP_scale=0.5'],\n",
       " 89074: [0.031614012629685995, 316779.48254232004, 'FBP_scale=0.5'],\n",
       " 89081: [0.04179429582249042, 255788.3319140967, 'FBP_scale=0.5'],\n",
       " 89084: [0.02960237024440737, 299204.5957428111, 'FBP_scale=0.5'],\n",
       " 89085: [0.03774310893184554, 328288.87104909273, 'FBP_scale=0.5'],\n",
       " 89086: [0.022623376705750278, 279634.99856473086, 'FBP_scale=0.5'],\n",
       " 89102: [0.040796909553926605, 220765.39635029866, 'FBP_scale=0.5'],\n",
       " 89103: [0.023349681918025767, 254729.35021436046, 'FBP_scale=0.5'],\n",
       " 89104: [0.03320603155912621, 212632.1144190938, 'FBP_scale=0.5'],\n",
       " 89107: [0.05935506051263894, 198917.1941191062, 'FBP_scale=0.5'],\n",
       " 89108: [0.053552150532358844, 212876.99612153973, 'FBP_scale=0.5'],\n",
       " 89109: [0.07727488712982523, 337940.7916967204, 'FBP_scale=0.5'],\n",
       " 89110: [0.04725188507969076, 200482.01372467002, 'FBP_scale=0.5'],\n",
       " 89113: [0.043625364435827534, 309582.4499731394, 'FBP_scale=0.5'],\n",
       " 89115: [0.04808106594745356, 180066.93932910392, 'FBP_scale=0.5'],\n",
       " 89117: [0.029426083389244503, 344299.1564222108, 'FBP_scale=0.5'],\n",
       " 89118: [0.030271458421119, 271179.49889021384, 'FBP_scale=0.5'],\n",
       " 89119: [0.026782273794856256, 241955.26361875163, 'FBP_scale=0.5'],\n",
       " 89120: [0.04554779842216769, 267252.62681162066, 'FBP_scale=0.5'],\n",
       " 89121: [0.03251929889460807, 212357.25585671476, 'FBP_scale=0.5'],\n",
       " 89122: [0.061933752527614086, 214762.9394826224, 'FBP_scale=0.5'],\n",
       " 89123: [0.04825771073766382, 306773.87555588817, 'FBP_scale=0.5'],\n",
       " 89124: [0.0937953210600353, 334290.0833986482, 'FBP_scale=0.5'],\n",
       " 89128: [0.029905361981916723, 280846.724090128, 'FBP_scale=0.5'],\n",
       " 89129: [0.026517157639345555, 286423.08475005795, 'FBP_scale=0.5'],\n",
       " 89130: [0.025429646834373133, 276657.8056960072, 'FBP_scale=0.5'],\n",
       " 89131: [0.02483231367385673, 339574.2471591072, 'FBP_scale=0.5'],\n",
       " 89134: [0.038341795950534115, 321577.72028144787, 'FBP_scale=0.5'],\n",
       " 89135: [0.024515869611043625, 425834.5057004451, 'FBP_scale=0.5'],\n",
       " 89138: [0.032858074757566254, 442950.4158662549, 'FBP_scale=0.5'],\n",
       " 89139: [0.029566433244114444, 289032.9615452033, 'FBP_scale=0.5'],\n",
       " 89141: [0.034115387972923454, 321001.58057856036, 'FBP_scale=0.5'],\n",
       " 89142: [0.04194677994191061, 213715.51190621968, 'FBP_scale=0.5'],\n",
       " 89143: [0.057232444162401676, 283231.0973787324, 'FBP_scale=0.5'],\n",
       " 89144: [0.024782252424292387, 351505.7533436969, 'FBP_scale=0.5'],\n",
       " 89145: [0.024787502553774866, 246658.82776447045, 'FBP_scale=0.5'],\n",
       " 89146: [0.042324631114278415, 320103.6004428028, 'FBP_scale=0.5'],\n",
       " 89147: [0.014973894613094363, 272818.3010017803, 'FBP_scale=0.5'],\n",
       " 89148: [0.046392384187789994, 305625.52330460254, 'FBP_scale=0.5'],\n",
       " 89149: [0.03378183762916275, 308219.1848478401, 'FBP_scale=0.5'],\n",
       " 89155: [0.01926188734707299, 362032.9962344175, 'FBP_scale=0.5'],\n",
       " 89156: [0.045454014922245524, 207605.68758203776, 'FBP_scale=0.5'],\n",
       " 89166: [0.031835900515247546, 291128.0588082098, 'FBP_scale=0.5'],\n",
       " 89178: [0.03695304263395325, 295479.7674959657, 'FBP_scale=0.5'],\n",
       " 89179: [0.017686717512439786, 305660.96584050445, 'FBP_scale=0.5'],\n",
       " 89403: [0.022850621255721595, 275411.9877160178, 'FBP_scale=0.5'],\n",
       " 89408: [0.0364164969395669, 244086.15490036257, 'FBP_scale=0.5'],\n",
       " 89410: [0.054124594959493774, 373451.8138814837, 'FBP_scale=0.5'],\n",
       " 89411: [0.03320864612697135, 659160.513359919, 'FBP_scale=0.5'],\n",
       " 89413: [0.06451534890433677, 2132853.3588797115, 'FBP_scale=0.5'],\n",
       " 89423: [0.039261552321618015, 403664.2838719558, 'FBP_scale=0.5'],\n",
       " 89429: [0.03392726123407389, 191969.94510094702, 'FBP_scale=0.5'],\n",
       " 89431: [0.040307572198368696, 251931.37670638357, 'FBP_scale=0.5'],\n",
       " 89433: [0.023971527220539444, 274932.279549524, 'FBP_scale=0.5'],\n",
       " 89434: [0.042867507086386175, 303049.82422532566, 'FBP_scale=0.5'],\n",
       " 89436: [0.03748659863446806, 373725.1710211443, 'FBP_scale=0.5'],\n",
       " 89439: [0.05640902283540983, 454322.1839203852, 'FBP_scale=0.5'],\n",
       " 89440: [0.045543683310369336, 218486.83054223805, 'FBP_scale=0.5'],\n",
       " 89444: [0.051584223018417606, 276026.96248109627, 'FBP_scale=0.5'],\n",
       " 89447: [0.03528869275268434, 168143.63871695238, 'FBP_scale=0.5'],\n",
       " 89448: [0.05224819563754419, 736841.7751282966, 'FBP_scale=0.5'],\n",
       " 89449: [0.06992530950915793, 381426.39967530925, 'FBP_scale=0.5'],\n",
       " 89451: [0.04582917758575527, 946704.3623023875, 'FBP_scale=0.5'],\n",
       " 89460: [0.058460290765724114, 324424.9757866733, 'FBP_scale=0.5'],\n",
       " 89501: [0.053482173681949546, 351052.4832722586, 'FBP_scale=0.5'],\n",
       " 89502: [0.020103747985949223, 284076.71654429485, 'FBP_scale=0.5'],\n",
       " 89503: [0.04092247748861434, 314054.913904733, 'FBP_scale=0.5'],\n",
       " 89506: [0.030989881767913532, 280461.8992750567, 'FBP_scale=0.5'],\n",
       " 89509: [0.028004390547727243, 452250.1469241155, 'FBP_scale=0.5'],\n",
       " 89510: [0.03678098305692088, 431762.4565774328, 'FBP_scale=0.5'],\n",
       " 89511: [0.027204512517963773, 666469.6560600224, 'FBP_scale=0.5'],\n",
       " 89512: [0.031919613786859626, 233341.54418264233, 'FBP_scale=0.5'],\n",
       " 89521: [0.02429083202181481, 417320.8573649556, 'FBP_scale=0.5'],\n",
       " 89523: [0.021539231083709576, 397864.98620824347, 'FBP_scale=0.5'],\n",
       " 89701: [0.02731434444478958, 270163.8202057961, 'FBP_scale=0.5'],\n",
       " 89703: [0.024193958362711956, 404803.0094934392, 'FBP_scale=0.5'],\n",
       " 89704: [0.08357990835093837, 423194.0997806724, 'FBP_scale=0.5'],\n",
       " 89705: [0.046550476695143735, 319915.2612081292, 'FBP_scale=0.5'],\n",
       " 89706: [0.027981614194214768, 268942.85774527164, 'FBP_scale=0.5'],\n",
       " 89801: [0.033157206621436924, 241310.69109952607, 'FBP_scale=0.5'],\n",
       " 89815: [0.03217108263103794, 238194.8008724951, 'FBP_scale=0.5'],\n",
       " 89002: [0.03444270744775924, 307046.4987918806, 'FBP_scale=0.5'],\n",
       " 89034: [0.036062482078580683, 332575.9172435973, 'FBP_scale=0.5'],\n",
       " 89183: [0.04578603188943014, 277916.42593488516, 'FBP_scale=0.5'],\n",
       " 89441: [0.0254675908325991, 422765.85601377813, 'FBP_scale=0.5'],\n",
       " 89508: [0.017187629795996175, 301861.70888802106, 'FBP_scale=0.5'],\n",
       " 89519: [0.02247708340155557, 540689.2117415073, 'FBP_scale=0.5']}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e81d9768a2937af9514d7fa33aa30feb69a40df5b58c34cfa60b871c6c10885"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
