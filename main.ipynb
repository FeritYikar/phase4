{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from fbprophet.diagnostics import performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>334200.0</td>\n",
       "      <td>335400.0</td>\n",
       "      <td>336500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1005500</td>\n",
       "      <td>1007500</td>\n",
       "      <td>1007800</td>\n",
       "      <td>1009600</td>\n",
       "      <td>1013300</td>\n",
       "      <td>1018700</td>\n",
       "      <td>1024400</td>\n",
       "      <td>1030700</td>\n",
       "      <td>1033800</td>\n",
       "      <td>1030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90668</td>\n",
       "      <td>75070</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>Collin</td>\n",
       "      <td>2</td>\n",
       "      <td>235700.0</td>\n",
       "      <td>236900.0</td>\n",
       "      <td>236700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>308000</td>\n",
       "      <td>310000</td>\n",
       "      <td>312500</td>\n",
       "      <td>314100</td>\n",
       "      <td>315000</td>\n",
       "      <td>316600</td>\n",
       "      <td>318100</td>\n",
       "      <td>319600</td>\n",
       "      <td>321100</td>\n",
       "      <td>321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris</td>\n",
       "      <td>3</td>\n",
       "      <td>210400.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321000</td>\n",
       "      <td>320600</td>\n",
       "      <td>320200</td>\n",
       "      <td>320400</td>\n",
       "      <td>320800</td>\n",
       "      <td>321200</td>\n",
       "      <td>321200</td>\n",
       "      <td>323000</td>\n",
       "      <td>326900</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>4</td>\n",
       "      <td>498100.0</td>\n",
       "      <td>500900.0</td>\n",
       "      <td>503100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1289800</td>\n",
       "      <td>1287700</td>\n",
       "      <td>1287400</td>\n",
       "      <td>1291500</td>\n",
       "      <td>1296600</td>\n",
       "      <td>1299000</td>\n",
       "      <td>1302700</td>\n",
       "      <td>1306400</td>\n",
       "      <td>1308500</td>\n",
       "      <td>1307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93144</td>\n",
       "      <td>79936</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>5</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119100</td>\n",
       "      <td>119400</td>\n",
       "      <td>120000</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120500</td>\n",
       "      <td>121000</td>\n",
       "      <td>121500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14718</th>\n",
       "      <td>58333</td>\n",
       "      <td>1338</td>\n",
       "      <td>Ashfield</td>\n",
       "      <td>MA</td>\n",
       "      <td>Greenfield Town</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>14719</td>\n",
       "      <td>94600.0</td>\n",
       "      <td>94300.0</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>216800</td>\n",
       "      <td>217700</td>\n",
       "      <td>218600</td>\n",
       "      <td>218500</td>\n",
       "      <td>218100</td>\n",
       "      <td>216400</td>\n",
       "      <td>213100</td>\n",
       "      <td>209800</td>\n",
       "      <td>209200</td>\n",
       "      <td>209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14719</th>\n",
       "      <td>59107</td>\n",
       "      <td>3293</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>NH</td>\n",
       "      <td>Claremont</td>\n",
       "      <td>Grafton</td>\n",
       "      <td>14720</td>\n",
       "      <td>92700.0</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>92400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>202100</td>\n",
       "      <td>208400</td>\n",
       "      <td>212200</td>\n",
       "      <td>215200</td>\n",
       "      <td>214300</td>\n",
       "      <td>213100</td>\n",
       "      <td>213700</td>\n",
       "      <td>218300</td>\n",
       "      <td>222700</td>\n",
       "      <td>225800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14720</th>\n",
       "      <td>75672</td>\n",
       "      <td>40404</td>\n",
       "      <td>Berea</td>\n",
       "      <td>KY</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Madison</td>\n",
       "      <td>14721</td>\n",
       "      <td>57100.0</td>\n",
       "      <td>57300.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121800</td>\n",
       "      <td>122800</td>\n",
       "      <td>124600</td>\n",
       "      <td>126700</td>\n",
       "      <td>128800</td>\n",
       "      <td>130600</td>\n",
       "      <td>131700</td>\n",
       "      <td>132500</td>\n",
       "      <td>133000</td>\n",
       "      <td>133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14721</th>\n",
       "      <td>93733</td>\n",
       "      <td>81225</td>\n",
       "      <td>Mount Crested Butte</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunnison</td>\n",
       "      <td>14722</td>\n",
       "      <td>191100.0</td>\n",
       "      <td>192400.0</td>\n",
       "      <td>193700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>662800</td>\n",
       "      <td>671200</td>\n",
       "      <td>682400</td>\n",
       "      <td>695600</td>\n",
       "      <td>695500</td>\n",
       "      <td>694700</td>\n",
       "      <td>706400</td>\n",
       "      <td>705300</td>\n",
       "      <td>681500</td>\n",
       "      <td>664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14722</th>\n",
       "      <td>95851</td>\n",
       "      <td>89155</td>\n",
       "      <td>Mesquite</td>\n",
       "      <td>NV</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Clark</td>\n",
       "      <td>14723</td>\n",
       "      <td>176400.0</td>\n",
       "      <td>176300.0</td>\n",
       "      <td>176100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>333800</td>\n",
       "      <td>336400</td>\n",
       "      <td>339700</td>\n",
       "      <td>343800</td>\n",
       "      <td>346800</td>\n",
       "      <td>348900</td>\n",
       "      <td>350400</td>\n",
       "      <td>353000</td>\n",
       "      <td>356000</td>\n",
       "      <td>357200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14723 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RegionID  RegionName                 City State              Metro  \\\n",
       "0         84654       60657              Chicago    IL            Chicago   \n",
       "1         90668       75070             McKinney    TX  Dallas-Fort Worth   \n",
       "2         91982       77494                 Katy    TX            Houston   \n",
       "3         84616       60614              Chicago    IL            Chicago   \n",
       "4         93144       79936              El Paso    TX            El Paso   \n",
       "...         ...         ...                  ...   ...                ...   \n",
       "14718     58333        1338             Ashfield    MA    Greenfield Town   \n",
       "14719     59107        3293            Woodstock    NH          Claremont   \n",
       "14720     75672       40404                Berea    KY           Richmond   \n",
       "14721     93733       81225  Mount Crested Butte    CO                NaN   \n",
       "14722     95851       89155             Mesquite    NV          Las Vegas   \n",
       "\n",
       "      CountyName  SizeRank   1996-04   1996-05   1996-06  ...  2017-07  \\\n",
       "0           Cook         1  334200.0  335400.0  336500.0  ...  1005500   \n",
       "1         Collin         2  235700.0  236900.0  236700.0  ...   308000   \n",
       "2         Harris         3  210400.0  212200.0  212200.0  ...   321000   \n",
       "3           Cook         4  498100.0  500900.0  503100.0  ...  1289800   \n",
       "4        El Paso         5   77300.0   77300.0   77300.0  ...   119100   \n",
       "...          ...       ...       ...       ...       ...  ...      ...   \n",
       "14718   Franklin     14719   94600.0   94300.0   94000.0  ...   216800   \n",
       "14719    Grafton     14720   92700.0   92500.0   92400.0  ...   202100   \n",
       "14720    Madison     14721   57100.0   57300.0   57500.0  ...   121800   \n",
       "14721   Gunnison     14722  191100.0  192400.0  193700.0  ...   662800   \n",
       "14722      Clark     14723  176400.0  176300.0  176100.0  ...   333800   \n",
       "\n",
       "       2017-08  2017-09  2017-10  2017-11  2017-12  2018-01  2018-02  2018-03  \\\n",
       "0      1007500  1007800  1009600  1013300  1018700  1024400  1030700  1033800   \n",
       "1       310000   312500   314100   315000   316600   318100   319600   321100   \n",
       "2       320600   320200   320400   320800   321200   321200   323000   326900   \n",
       "3      1287700  1287400  1291500  1296600  1299000  1302700  1306400  1308500   \n",
       "4       119400   120000   120300   120300   120300   120300   120500   121000   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "14718   217700   218600   218500   218100   216400   213100   209800   209200   \n",
       "14719   208400   212200   215200   214300   213100   213700   218300   222700   \n",
       "14720   122800   124600   126700   128800   130600   131700   132500   133000   \n",
       "14721   671200   682400   695600   695500   694700   706400   705300   681500   \n",
       "14722   336400   339700   343800   346800   348900   350400   353000   356000   \n",
       "\n",
       "       2018-04  \n",
       "0      1030600  \n",
       "1       321800  \n",
       "2       329900  \n",
       "3      1307000  \n",
       "4       121500  \n",
       "...        ...  \n",
       "14718   209300  \n",
       "14719   225800  \n",
       "14720   133400  \n",
       "14721   664400  \n",
       "14722   357200  \n",
       "\n",
       "[14723 rows x 272 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/zillow_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>60657</th>\n",
       "      <th>75070</th>\n",
       "      <th>77494</th>\n",
       "      <th>60614</th>\n",
       "      <th>79936</th>\n",
       "      <th>77084</th>\n",
       "      <th>10467</th>\n",
       "      <th>60640</th>\n",
       "      <th>77449</th>\n",
       "      <th>94109</th>\n",
       "      <th>...</th>\n",
       "      <th>3765</th>\n",
       "      <th>84781</th>\n",
       "      <th>12429</th>\n",
       "      <th>97028</th>\n",
       "      <th>12720</th>\n",
       "      <th>1338</th>\n",
       "      <th>3293</th>\n",
       "      <th>40404</th>\n",
       "      <th>81225</th>\n",
       "      <th>89155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01</th>\n",
       "      <td>334200</td>\n",
       "      <td>235700</td>\n",
       "      <td>210400</td>\n",
       "      <td>498100</td>\n",
       "      <td>77300</td>\n",
       "      <td>95000</td>\n",
       "      <td>152900</td>\n",
       "      <td>216500</td>\n",
       "      <td>95400</td>\n",
       "      <td>766000</td>\n",
       "      <td>...</td>\n",
       "      <td>80800</td>\n",
       "      <td>135900</td>\n",
       "      <td>78300</td>\n",
       "      <td>136200</td>\n",
       "      <td>62500</td>\n",
       "      <td>94600</td>\n",
       "      <td>92700</td>\n",
       "      <td>57100</td>\n",
       "      <td>191100</td>\n",
       "      <td>176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01</th>\n",
       "      <td>335400</td>\n",
       "      <td>236900</td>\n",
       "      <td>212200</td>\n",
       "      <td>500900</td>\n",
       "      <td>77300</td>\n",
       "      <td>95200</td>\n",
       "      <td>152700</td>\n",
       "      <td>216700</td>\n",
       "      <td>95600</td>\n",
       "      <td>771100</td>\n",
       "      <td>...</td>\n",
       "      <td>80100</td>\n",
       "      <td>136300</td>\n",
       "      <td>78300</td>\n",
       "      <td>136600</td>\n",
       "      <td>62600</td>\n",
       "      <td>94300</td>\n",
       "      <td>92500</td>\n",
       "      <td>57300</td>\n",
       "      <td>192400</td>\n",
       "      <td>176300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01</th>\n",
       "      <td>336500</td>\n",
       "      <td>236700</td>\n",
       "      <td>212200</td>\n",
       "      <td>503100</td>\n",
       "      <td>77300</td>\n",
       "      <td>95400</td>\n",
       "      <td>152600</td>\n",
       "      <td>216900</td>\n",
       "      <td>95800</td>\n",
       "      <td>776500</td>\n",
       "      <td>...</td>\n",
       "      <td>79400</td>\n",
       "      <td>136600</td>\n",
       "      <td>78200</td>\n",
       "      <td>136800</td>\n",
       "      <td>62700</td>\n",
       "      <td>94000</td>\n",
       "      <td>92400</td>\n",
       "      <td>57500</td>\n",
       "      <td>193700</td>\n",
       "      <td>176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01</th>\n",
       "      <td>337600</td>\n",
       "      <td>235400</td>\n",
       "      <td>210700</td>\n",
       "      <td>504600</td>\n",
       "      <td>77300</td>\n",
       "      <td>95700</td>\n",
       "      <td>152400</td>\n",
       "      <td>217000</td>\n",
       "      <td>96100</td>\n",
       "      <td>781900</td>\n",
       "      <td>...</td>\n",
       "      <td>78600</td>\n",
       "      <td>136900</td>\n",
       "      <td>78200</td>\n",
       "      <td>136800</td>\n",
       "      <td>62700</td>\n",
       "      <td>93700</td>\n",
       "      <td>92200</td>\n",
       "      <td>57700</td>\n",
       "      <td>195000</td>\n",
       "      <td>176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01</th>\n",
       "      <td>338500</td>\n",
       "      <td>233300</td>\n",
       "      <td>208300</td>\n",
       "      <td>505500</td>\n",
       "      <td>77400</td>\n",
       "      <td>95900</td>\n",
       "      <td>152300</td>\n",
       "      <td>217100</td>\n",
       "      <td>96400</td>\n",
       "      <td>787300</td>\n",
       "      <td>...</td>\n",
       "      <td>77900</td>\n",
       "      <td>137100</td>\n",
       "      <td>78100</td>\n",
       "      <td>136700</td>\n",
       "      <td>62700</td>\n",
       "      <td>93400</td>\n",
       "      <td>92100</td>\n",
       "      <td>58000</td>\n",
       "      <td>196300</td>\n",
       "      <td>175900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>1018700</td>\n",
       "      <td>316600</td>\n",
       "      <td>321200</td>\n",
       "      <td>1299000</td>\n",
       "      <td>120300</td>\n",
       "      <td>162800</td>\n",
       "      <td>414300</td>\n",
       "      <td>777900</td>\n",
       "      <td>172300</td>\n",
       "      <td>3778700</td>\n",
       "      <td>...</td>\n",
       "      <td>123400</td>\n",
       "      <td>257600</td>\n",
       "      <td>171300</td>\n",
       "      <td>341000</td>\n",
       "      <td>122800</td>\n",
       "      <td>216400</td>\n",
       "      <td>213100</td>\n",
       "      <td>130600</td>\n",
       "      <td>694700</td>\n",
       "      <td>348900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>1024400</td>\n",
       "      <td>318100</td>\n",
       "      <td>321200</td>\n",
       "      <td>1302700</td>\n",
       "      <td>120300</td>\n",
       "      <td>162800</td>\n",
       "      <td>413900</td>\n",
       "      <td>778500</td>\n",
       "      <td>173300</td>\n",
       "      <td>3770800</td>\n",
       "      <td>...</td>\n",
       "      <td>124400</td>\n",
       "      <td>258000</td>\n",
       "      <td>172400</td>\n",
       "      <td>342300</td>\n",
       "      <td>123200</td>\n",
       "      <td>213100</td>\n",
       "      <td>213700</td>\n",
       "      <td>131700</td>\n",
       "      <td>706400</td>\n",
       "      <td>350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>1030700</td>\n",
       "      <td>319600</td>\n",
       "      <td>323000</td>\n",
       "      <td>1306400</td>\n",
       "      <td>120500</td>\n",
       "      <td>162900</td>\n",
       "      <td>411400</td>\n",
       "      <td>780500</td>\n",
       "      <td>174200</td>\n",
       "      <td>3763100</td>\n",
       "      <td>...</td>\n",
       "      <td>125500</td>\n",
       "      <td>260600</td>\n",
       "      <td>173600</td>\n",
       "      <td>345000</td>\n",
       "      <td>123200</td>\n",
       "      <td>209800</td>\n",
       "      <td>218300</td>\n",
       "      <td>132500</td>\n",
       "      <td>705300</td>\n",
       "      <td>353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>1033800</td>\n",
       "      <td>321100</td>\n",
       "      <td>326900</td>\n",
       "      <td>1308500</td>\n",
       "      <td>121000</td>\n",
       "      <td>163500</td>\n",
       "      <td>413200</td>\n",
       "      <td>782800</td>\n",
       "      <td>175400</td>\n",
       "      <td>3779800</td>\n",
       "      <td>...</td>\n",
       "      <td>126600</td>\n",
       "      <td>264700</td>\n",
       "      <td>175800</td>\n",
       "      <td>348000</td>\n",
       "      <td>120700</td>\n",
       "      <td>209200</td>\n",
       "      <td>222700</td>\n",
       "      <td>133000</td>\n",
       "      <td>681500</td>\n",
       "      <td>356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>1030600</td>\n",
       "      <td>321800</td>\n",
       "      <td>329900</td>\n",
       "      <td>1307000</td>\n",
       "      <td>121500</td>\n",
       "      <td>164300</td>\n",
       "      <td>417900</td>\n",
       "      <td>782800</td>\n",
       "      <td>176200</td>\n",
       "      <td>3813500</td>\n",
       "      <td>...</td>\n",
       "      <td>127500</td>\n",
       "      <td>266800</td>\n",
       "      <td>177500</td>\n",
       "      <td>349300</td>\n",
       "      <td>117700</td>\n",
       "      <td>209300</td>\n",
       "      <td>225800</td>\n",
       "      <td>133400</td>\n",
       "      <td>664400</td>\n",
       "      <td>357200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 14723 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              60657   75070   77494    60614   79936   77084   10467   60640  \\\n",
       "1996-04-01   334200  235700  210400   498100   77300   95000  152900  216500   \n",
       "1996-05-01   335400  236900  212200   500900   77300   95200  152700  216700   \n",
       "1996-06-01   336500  236700  212200   503100   77300   95400  152600  216900   \n",
       "1996-07-01   337600  235400  210700   504600   77300   95700  152400  217000   \n",
       "1996-08-01   338500  233300  208300   505500   77400   95900  152300  217100   \n",
       "...             ...     ...     ...      ...     ...     ...     ...     ...   \n",
       "2017-12-01  1018700  316600  321200  1299000  120300  162800  414300  777900   \n",
       "2018-01-01  1024400  318100  321200  1302700  120300  162800  413900  778500   \n",
       "2018-02-01  1030700  319600  323000  1306400  120500  162900  411400  780500   \n",
       "2018-03-01  1033800  321100  326900  1308500  121000  163500  413200  782800   \n",
       "2018-04-01  1030600  321800  329900  1307000  121500  164300  417900  782800   \n",
       "\n",
       "             77449    94109  ...   3765    84781   12429   97028   12720  \\\n",
       "1996-04-01   95400   766000  ...   80800  135900   78300  136200   62500   \n",
       "1996-05-01   95600   771100  ...   80100  136300   78300  136600   62600   \n",
       "1996-06-01   95800   776500  ...   79400  136600   78200  136800   62700   \n",
       "1996-07-01   96100   781900  ...   78600  136900   78200  136800   62700   \n",
       "1996-08-01   96400   787300  ...   77900  137100   78100  136700   62700   \n",
       "...            ...      ...  ...     ...     ...     ...     ...     ...   \n",
       "2017-12-01  172300  3778700  ...  123400  257600  171300  341000  122800   \n",
       "2018-01-01  173300  3770800  ...  124400  258000  172400  342300  123200   \n",
       "2018-02-01  174200  3763100  ...  125500  260600  173600  345000  123200   \n",
       "2018-03-01  175400  3779800  ...  126600  264700  175800  348000  120700   \n",
       "2018-04-01  176200  3813500  ...  127500  266800  177500  349300  117700   \n",
       "\n",
       "             1338    3293    40404   81225   89155  \n",
       "1996-04-01   94600   92700   57100  191100  176400  \n",
       "1996-05-01   94300   92500   57300  192400  176300  \n",
       "1996-06-01   94000   92400   57500  193700  176100  \n",
       "1996-07-01   93700   92200   57700  195000  176000  \n",
       "1996-08-01   93400   92100   58000  196300  175900  \n",
       "...            ...     ...     ...     ...     ...  \n",
       "2017-12-01  216400  213100  130600  694700  348900  \n",
       "2018-01-01  213100  213700  131700  706400  350400  \n",
       "2018-02-01  209800  218300  132500  705300  353000  \n",
       "2018-03-01  209200  222700  133000  681500  356000  \n",
       "2018-04-01  209300  225800  133400  664400  357200  \n",
       "\n",
       "[265 rows x 14723 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series = pd.DataFrame(index=pd.to_datetime(df.columns[7:]), data=np.ones(len(df.columns)-7))\n",
    "for i in range(df.shape[0]):\n",
    "    df_time_series[df['RegionName'][i]] = df.iloc[i,7:]\n",
    "df_time_series.drop(df_time_series.columns[0],axis=1, inplace=True)\n",
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156891"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89108"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nv = df[df['State'] == 'NV']\n",
    "nv_zipcodes = df_nv.RegionName.tolist()\n",
    "nv_zipcodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = df_time_series[nv_zipcodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ferityikar/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/frame.py:4317: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "df_time_series.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_time_series.iloc[:,0].plot(figsize=(16,9))\n",
    "df_time_series.iloc[:,7].plot()\n",
    "df_time_series.iloc[:,4].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(df_time_series)*.85)\n",
    "train_pre = df_time_series.iloc[:size]\n",
    "test = df_time_series.iloc[size:]\n",
    "size2 = int(len(train_pre)*.85)\n",
    "train = train_pre.iloc[:size2]\n",
    "validation = train_pre.iloc[size2:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying a RNN model to see how it does on our fourth(random) zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "train_data = train.iloc[:,x:x+1].values.astype(int)\n",
    "val_data = validation.iloc[:,x:x+1].values.astype(int)\n",
    "test_data = test.iloc[:,x:x+1].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "train_data_scaled = scaler.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset with 60 timesteps (5 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60,len(train_data_scaled)):\n",
    "    X_train.append(train_data_scaled[i-60:i])\n",
    "    y_train.append(train_data_scaled[i])\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Validation Data \n",
    "data_total_val = pd.concat((train.iloc[:,x:x+1], validation.iloc[:,x:x+1]),axis=0)\n",
    "val_input = data_total_val[len(train)-60:].values\n",
    "val_input = scaler.transform(val_input)\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "for i in range(60,len(val_input)):\n",
    "    X_val.append(val_input[i-60:i])\n",
    "    y_val.append(val_input[i])\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "\n",
    "# Test Data \n",
    "data_total = pd.concat((train_pre.iloc[:,x:x+1], test.iloc[:,x:x+1]),axis=0)\n",
    "test_input = data_total[len(train_pre)-60:].values\n",
    "test_input = scaler.transform(test_input)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(60,len(test_input)):\n",
    "    X_test.append(test_input[i-60:i])\n",
    "    y_test.append(test_input[i])\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60)                14880     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 14,941\n",
      "Trainable params: 14,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(units= 60, return_sequences = False, input_shape=((60,1))))\n",
    "rnn_model.add(Dense(units=1))\n",
    "rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.5973 - val_loss: 0.0367\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3454 - val_loss: 0.0065\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1537 - val_loss: 0.0069\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0401 - val_loss: 0.1045\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0923 - val_loss: 0.0546\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0362 - val_loss: 0.0155\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0291 - val_loss: 0.0067\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0342 - val_loss: 0.0063\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0307 - val_loss: 0.0101\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0234 - val_loss: 0.0172\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0195 - val_loss: 0.0239\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0205 - val_loss: 0.0257\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0198 - val_loss: 0.0207\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0170 - val_loss: 0.0149\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0154 - val_loss: 0.0101\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0144 - val_loss: 0.0111\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0131 - val_loss: 0.0125\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0123 - val_loss: 0.0121\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0103 - val_loss: 0.0082\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0085 - val_loss: 0.0067\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0074 - val_loss: 0.0066\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0022 - val_loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb2bc3a5100>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_raw_val = rnn_model.predict(X_val)\n",
    "y_hat_val = scaler.inverse_transform(y_hat_raw_val)\n",
    "y_val_unscaled = scaler.inverse_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_val_unscaled, color='red', label='Real Prices')\n",
    "plt.plot(y_hat_val, color='blue', label='Predicted Prices')\n",
    "plt.title('Unseen Data Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although our model was successful on the first zipcode, when we check its success on other zipcodes we see that the results are not always good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import our dictionaries with all model scores from our dictionaries folder. To see how the model was run for all our zipcodes and how validation, test errors were calculated you can check ferit_yikar.ipynb file\n",
    "We have 4 different RNN models for each zip-code. Later we willcompare all our models to choose best model for all zip-codes seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_in = open('jupyter_files/dictionaries/rnn_dict.pickle','rb')\n",
    "rnn_dict = pickle.load(print_in)\n",
    "print_in.close()\n",
    "\n",
    "print_in = open('jupyter_files/dictionaries/rnn_w_dropout_dict.pickle','rb')\n",
    "rnn_w_dropout_dict = pickle.load(print_in)\n",
    "print_in.close()\n",
    "\n",
    "print_in = open('jupyter_files/dictionaries/rnn_2_layer_dict.pickle','rb')\n",
    "rnn_2_layer_dict = pickle.load(print_in)\n",
    "print_in.close()\n",
    "\n",
    "print_in = open('jupyter_files/dictionaries/rnn_2_layer_w_dropout_dict.pickle','rb')\n",
    "rnn_2_layer_w_dropout_dict = pickle.load(print_in)\n",
    "print_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average our first RNN model has validation MAPE of 4% and test MAPE of 11%. We can use this model for some zipcodes but not all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03722894621219502,\n",
       " [0.03918008339347867,\n",
       "  0.04249053080533641,\n",
       "  0.029745497713399783,\n",
       "  0.09271575816653368,\n",
       "  0.025213764982227663,\n",
       "  0.02240274911956474,\n",
       "  0.03712706337289838,\n",
       "  0.02701220876632889,\n",
       "  0.020230009987194573,\n",
       "  0.034230203529890084,\n",
       "  0.02492848783461322,\n",
       "  0.04708653721453273,\n",
       "  0.023377066907098898,\n",
       "  0.024444143664827393,\n",
       "  0.022997988758695295,\n",
       "  0.019394399597616983,\n",
       "  0.020675465817814556,\n",
       "  0.025721969928557634,\n",
       "  0.03509833206152496,\n",
       "  0.02772421229075083,\n",
       "  0.0285866787275961,\n",
       "  0.027227066318064624,\n",
       "  0.03659789732867641,\n",
       "  0.028885540695157433,\n",
       "  0.02602384220677365,\n",
       "  0.06540218060850479,\n",
       "  0.041628030820886834,\n",
       "  0.21366220664719376,\n",
       "  0.03839161593042156,\n",
       "  0.030151874467689202,\n",
       "  0.03915371801929651,\n",
       "  0.03020102233697849,\n",
       "  0.030180608369524756,\n",
       "  0.02825407942549682,\n",
       "  0.04170786682014605,\n",
       "  0.017644404319569283,\n",
       "  0.08021144972081255,\n",
       "  0.051198742969434684,\n",
       "  0.015128621016044138,\n",
       "  0.023340184704304105,\n",
       "  0.024898875109147105,\n",
       "  0.03272100689120338,\n",
       "  0.0501980508980156,\n",
       "  0.03583285480933528,\n",
       "  0.022761032010995132,\n",
       "  0.032033417164021964,\n",
       "  0.03459980596585793,\n",
       "  0.0386242288083223,\n",
       "  0.026252396067882607,\n",
       "  0.02131109046032544,\n",
       "  0.024468790217601864,\n",
       "  0.026525679964151852,\n",
       "  0.03172318503270931,\n",
       "  0.035821297882089,\n",
       "  0.03421493295922262,\n",
       "  0.032590240958653205,\n",
       "  0.08213367706087349,\n",
       "  0.023137440949657265,\n",
       "  0.03361073403234413,\n",
       "  0.027513533116478722,\n",
       "  0.017328889458865456,\n",
       "  0.022278700444537582,\n",
       "  0.027806433178535796,\n",
       "  0.020740086093070157,\n",
       "  0.02379246564783574,\n",
       "  0.025982609278387397,\n",
       "  0.02579207246055772,\n",
       "  0.024203707878021945,\n",
       "  0.02155220634351883,\n",
       "  0.028048549521733353,\n",
       "  0.02266121148259634,\n",
       "  0.031509502192160366,\n",
       "  0.023324108614095812,\n",
       "  0.08028098482096918,\n",
       "  0.02404940841422752,\n",
       "  0.026605819705325644,\n",
       "  0.04616578523780177,\n",
       "  0.06798047342771384,\n",
       "  0.029578799592597304,\n",
       "  0.02622597364713289,\n",
       "  0.026490788757334474,\n",
       "  0.11929721868273381,\n",
       "  0.02090957545307403,\n",
       "  0.059984461781161715,\n",
       "  0.01173909825263278,\n",
       "  0.05548136741264739,\n",
       "  0.019394135992787033,\n",
       "  0.04755960050638048,\n",
       "  0.020292264045174827,\n",
       "  0.020017315596736633,\n",
       "  0.04837276766000851,\n",
       "  0.01973184372284484,\n",
       "  0.023716009639220156,\n",
       "  0.08204397669047553,\n",
       "  0.027126537536874933,\n",
       "  0.01614472350821041,\n",
       "  0.028065194461827373,\n",
       "  0.029258715033300308,\n",
       "  0.02399191267321002,\n",
       "  0.10305996288117628,\n",
       "  0.11196375284668916,\n",
       "  0.07732808038654718,\n",
       "  0.020357993171009073])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_val_mape = []\n",
    "for z in rnn_dict.values():\n",
    "    rnn_val_mape.append(z[0])\n",
    "np.mean(rnn_val_mape), rnn_val_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facebook Prophet Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models below iterates over every zipcode in Nevada and predecits the prices in May 2018. It cross validates the model fitted with 17 years of training data, one year of validation set (horizon) and the model makes predictions per zipcode for the test data, each year between 2012 and 2018. It returns average Mean Absolute Percentage Error (MAPE) for each zipcode for both cross validation and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import our dictionaries with all model scores from our dictionaries folder. To see how the model was run for all our zipcodes and how validation, test errors were calculated you can check ferit_yikar.ipynb file\n",
    "We have 2 different Facebook Prophet models for each zip-code. Later we willcompare all our models to choose best model for all zip-codes seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_in = open('jupyter_files/dictionaries/fbp_50_scale_dict.pickle','rb')\n",
    "fbp_50_scale_dict = pickle.load(print_in)\n",
    "print_in.close()\n",
    "\n",
    "#print_in = open('jupyter_files/dictionaries/fbp_25_scale_dict.pickle','rb')\n",
    "#fbp_25_scale_dict = pickle.load(print_in)\n",
    "#print_in.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average our first Facebook Prophet model has validation MAPE of 7% and test MAPE of 39%. We can use this model for some zipcodes but not all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07158379949631066,\n",
       " [0.11213088616593422,\n",
       "  0.09895751084578441,\n",
       "  0.07790285644506334,\n",
       "  0.07413099525999427,\n",
       "  0.07738283848497714,\n",
       "  0.09013601281862955,\n",
       "  0.14359359106381303,\n",
       "  0.07372217203870735,\n",
       "  0.09521674817587714,\n",
       "  0.08154645561744807,\n",
       "  0.08276006451072541,\n",
       "  0.08402794853394402,\n",
       "  0.08224852252540327,\n",
       "  0.09916832545899193,\n",
       "  0.16216558981306284,\n",
       "  0.07987983519365985,\n",
       "  0.07523523222946585,\n",
       "  0.08683328609631094,\n",
       "  0.04778910236780197,\n",
       "  0.05596774984350215,\n",
       "  0.07600944424035325,\n",
       "  0.08358539371626506,\n",
       "  0.05272474183280769,\n",
       "  0.13491385551588003,\n",
       "  0.07216264509525928,\n",
       "  0.0,\n",
       "  0.08640293306341709,\n",
       "  0.10514582662492034,\n",
       "  0.08105150488073284,\n",
       "  0.11773064111880047,\n",
       "  0.08032253435421008,\n",
       "  0.07782807386418283,\n",
       "  0.07333093634278602,\n",
       "  0.08046923664288104,\n",
       "  0.05263742492445968,\n",
       "  0.08052637511049648,\n",
       "  0.08054927039131825,\n",
       "  0.12483256960133497,\n",
       "  0.05353174398557985,\n",
       "  0.07206007763296045,\n",
       "  0.07958637957344829,\n",
       "  0.06834734671222979,\n",
       "  0.05660006207530183,\n",
       "  0.08978932200682956,\n",
       "  0.0743499904889898,\n",
       "  0.06527197766049661,\n",
       "  0.10961200111511915,\n",
       "  0.06349515462591604,\n",
       "  0.0,\n",
       "  0.08478147557322531,\n",
       "  0.07940408969138511,\n",
       "  0.05159250338227841,\n",
       "  0.003197895622070568,\n",
       "  0.08036663369333359,\n",
       "  0.07410072301993442,\n",
       "  0.11850707482986304,\n",
       "  0.04699048327043555,\n",
       "  0.08741568130890866,\n",
       "  0.05315395500367852,\n",
       "  0.0,\n",
       "  0.08691367627372049,\n",
       "  0.08034894955692652,\n",
       "  0.0802325494711454,\n",
       "  0.053526662047582385,\n",
       "  0.0,\n",
       "  0.08500706935181293,\n",
       "  0.0626017652594819,\n",
       "  0.08410771833873387,\n",
       "  0.050850644674261036,\n",
       "  0.04511454997653495,\n",
       "  0.048050075007278946,\n",
       "  0.0040705597099636535,\n",
       "  0.07959021484440681,\n",
       "  0.001085619317763456,\n",
       "  0.06673970182258344,\n",
       "  0.050602714592988804,\n",
       "  0.06946779683673589,\n",
       "  0.051374730839320246,\n",
       "  0.07901530400752091,\n",
       "  0.06510903299169507,\n",
       "  0.0,\n",
       "  0.06700891256565723,\n",
       "  0.0,\n",
       "  0.0462120730553399,\n",
       "  0.04263399417932605,\n",
       "  0.07871488254334189,\n",
       "  0.07362495751087235,\n",
       "  0.07065750337235518,\n",
       "  0.09825855219123744,\n",
       "  0.04246781068962296,\n",
       "  0.09863019587161617,\n",
       "  0.06833337357231233,\n",
       "  0.0772825552149453,\n",
       "  0.13586682555087495,\n",
       "  0.09289975448950726,\n",
       "  0.07273528739895475,\n",
       "  0.05975496026493341,\n",
       "  0.0670876542419639,\n",
       "  0.05898275474138115,\n",
       "  0.1285898902038855,\n",
       "  0.06752511405742875,\n",
       "  0.05233261188003482,\n",
       "  0.07654864752276494])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_val_mape = []\n",
    "for z in fbp_50_scale_dict.values():\n",
    "    fb_val_mape.append(z[0])\n",
    "np.mean(fb_val_mape), fb_val_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.037575237987934114, 0.056519773001086626)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(fbp_mape), np.mean(fbp_mape2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMA - SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_in = open('jupyter_files/SARIMAX_summary.pickl','rb')\n",
    "sarimax_dict = pickle.load(print_in)\n",
    "print_in.close()\n",
    "print_in = open('jupyter_files/SARIMA_summary.pickl','rb')\n",
    "sarima_dict = pickle.load(print_in)\n",
    "print_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14147840001613393"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sarima_dict.values())[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rnn_dict, rnn_2_layer_dict, rnn_2_layer_w_dropout_dict, rnn_w_dropout_dict, fbp_50_scale_dict]\n",
    "best_model_dict = {}\n",
    "for zipcode in rnn_dict.keys():\n",
    "    best_model = [1]\n",
    "    for model in models:\n",
    "        if model[zipcode][0]<best_model[0]:\n",
    "            best_model = model[zipcode]\n",
    "    best_model_dict[zipcode] = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89108: [0.03918008339347867,\n",
       "  0.02324273698072249,\n",
       "  array([[206739.39]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89121: [0.04249053080533641,\n",
       "  0.09075772556037923,\n",
       "  array([[204989.14]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89117: [0.028123232541239714,\n",
       "  0.045895206093298516,\n",
       "  array([[332322.88]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89052: [0.07413099525999427,\n",
       "  0.30864445191825685,\n",
       "  229682.2443676644,\n",
       "  'Facebook Prophet 0.5 Scale'],\n",
       " 89123: [0.02305602132279191,\n",
       "  0.011121031869867733,\n",
       "  array([[305719.94]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89031: [0.02240274911956474,\n",
       "  0.022868370211432492,\n",
       "  array([[240816.86]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89110: [0.03143365884024171,\n",
       "  0.07795946815163626,\n",
       "  array([[192151.]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89074: [0.02461964466857517,\n",
       "  0.016955612960913333,\n",
       "  array([[312295.03]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89103: [0.020230009987194573,\n",
       "  0.03665875360957248,\n",
       "  array([[250961.8]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89148: [0.03206962109933308,\n",
       "  0.027555278884971675,\n",
       "  array([[302781.97]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89147: [0.02492848783461322,\n",
       "  0.04887042762494738,\n",
       "  array([[265378.44]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89119: [0.04708653721453273,\n",
       "  0.06338780087602505,\n",
       "  array([[236049.47]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89129: [0.023377066907098898,\n",
       "  0.04776643009723585,\n",
       "  array([[276296.78]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89122: [0.024444143664827393,\n",
       "  0.008295738576931755,\n",
       "  array([[211914.44]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89115: [0.020478888982663934,\n",
       "  0.03813845307477733,\n",
       "  array([[173611.97]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89502: [0.019394399597616983,\n",
       "  0.044532981580081746,\n",
       "  array([[280435.62]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89014: [0.02051603703483403,\n",
       "  0.04637591348038984,\n",
       "  array([[280800.]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89131: [0.02234317176379308,\n",
       "  0.0352344442531203,\n",
       "  array([[331004.06]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89509: [0.028534813351679976,\n",
       "  0.029498854400012174,\n",
       "  array([[432338.9]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89436: [0.02772421229075083,\n",
       "  0.0111600487900889,\n",
       "  array([[378837.12]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89015: [0.0285866787275961,\n",
       "  0.03850802042367164,\n",
       "  array([[251806.58]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89128: [0.027227066318064624,\n",
       "  0.04358463164315352,\n",
       "  array([[271911.2]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89523: [0.024815995826525057,\n",
       "  0.022116312702984548,\n",
       "  array([[391011.22]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89104: [0.02787402702206847,\n",
       "  0.0471366220025526,\n",
       "  array([[208524.]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89012: [0.025782151700148987,\n",
       "  0.0382602477437557,\n",
       "  array([[335998.1]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89030: [0.0, 0.2767431208024321, 62100.0, 'Facebook Prophet 0.5 Scale'],\n",
       " 89431: [0.03982397137602468,\n",
       "  0.03815724733471657,\n",
       "  array([[243782.95]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89032: [0.02435210625527166,\n",
       "  0.014453127312831045,\n",
       "  array([[227407.]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89506: [0.032410059608340605,\n",
       "  0.07719998737821851,\n",
       "  array([[270413.03]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89102: [0.030151874467689202,\n",
       "  0.010681586413580206,\n",
       "  array([[218885.69]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89139: [0.03416216647779677,\n",
       "  0.03369473401855004,\n",
       "  array([[287437.78]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89149: [0.03020102233697849,\n",
       "  0.042711533335936094,\n",
       "  array([[301354.53]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89178: [0.030180608369524756,\n",
       "  0.03584006405155033,\n",
       "  array([[292375.47]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89113: [0.02825407942549682,\n",
       "  0.03518618644495326,\n",
       "  array([[304314.97]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89521: [0.03428616594461293,\n",
       "  0.02326395652104087,\n",
       "  array([[402596.84]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89183: [0.017644404319569283,\n",
       "  0.037681999804238045,\n",
       "  array([[270984.16]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89135: [0.025592319667568624,\n",
       "  0.026726473701510843,\n",
       "  array([[412659.8]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89107: [0.04806053831933459,\n",
       "  0.007211643273714699,\n",
       "  array([[197391.03]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89511: [0.015128621016044138,\n",
       "  0.009379827076333499,\n",
       "  array([[650157.6]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89002: [0.023340184704304105,\n",
       "  0.04218185547614392,\n",
       "  array([[300737.56]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89130: [0.024898875109147105,\n",
       "  0.035127576936861804,\n",
       "  array([[270581.6]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89134: [0.028247919650316575,\n",
       "  0.035763989615938095,\n",
       "  array([[313139.97]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89503: [0.04393609920874447,\n",
       "  0.017877839527142926,\n",
       "  array([[316642.3]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89081: [0.035024718934313165,\n",
       "  0.042674718935269765,\n",
       "  array([[252159.83]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89141: [0.022761032010995132,\n",
       "  0.024706139939923093,\n",
       "  array([[316948.5]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89011: [0.028554922138012973,\n",
       "  0.05612697934015769,\n",
       "  array([[262186.8]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89142: [0.02871841435337775,\n",
       "  0.05803488985532168,\n",
       "  array([[205930.2]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89434: [0.0386242288083223,\n",
       "  0.024865866507304758,\n",
       "  array([[296423.4]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89512: [0.0, 0.22188868550263507, 115600.0, 'Facebook Prophet 0.5 Scale'],\n",
       " 89145: [0.02131109046032544,\n",
       "  0.036145271299921046,\n",
       "  array([[240277.45]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89084: [0.024468790217601864,\n",
       "  0.02975210816859166,\n",
       "  array([[296102.3]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89701: [0.026525679964151852,\n",
       "  0.07068000594279708,\n",
       "  array([[265169.]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89801: [0.003197895622070568,\n",
       "  0.18605038006532307,\n",
       "  165674.9113653253,\n",
       "  'Facebook Prophet 0.5 Scale'],\n",
       " 89120: [0.035821297882089,\n",
       "  0.05270237553979061,\n",
       "  array([[262426.88]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89044: [0.01614564672361334,\n",
       "  0.03151480104371876,\n",
       "  array([[349552.47]], dtype=float32),\n",
       "  'RNN 2 Layer Model'],\n",
       " 89156: [0.032590240958653205,\n",
       "  0.05058152350984232,\n",
       "  array([[200560.62]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89048: [0.04699048327043555,\n",
       "  0.3906516592920465,\n",
       "  74636.93072923394,\n",
       "  'Facebook Prophet 0.5 Scale'],\n",
       " 89118: [0.023137440949657265,\n",
       "  0.03295044042064042,\n",
       "  array([[264572.38]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89706: [0.03282951964714845,\n",
       "  0.08425611364301155,\n",
       "  array([[261385.22]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89408: [0.0, 0.18866819120027137, 130900.0, 'Facebook Prophet 0.5 Scale'],\n",
       " 89166: [0.017171340465638812,\n",
       "  0.05284322112895361,\n",
       "  array([[278315.5]], dtype=float32),\n",
       "  'RNN 2 Layer Model'],\n",
       " 89144: [0.022278700444537582,\n",
       "  0.038498163636300625,\n",
       "  array([[339739.22]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89146: [0.027806433178535796,\n",
       "  0.017631641134536035,\n",
       "  array([[316637.25]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89027: [0.020740086093070157,\n",
       "  0.09979547902540706,\n",
       "  array([[236619.5]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89403: [0.0, 0.16488227735459848, 158700.0, 'Facebook Prophet 0.5 Scale'],\n",
       " 89433: [0.025982609278387397,\n",
       "  0.03664509277208583,\n",
       "  array([[269685.12]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89005: [0.02579207246055772,\n",
       "  0.04167824493094232,\n",
       "  array([[310641.6]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89138: [0.024203707878021945,\n",
       "  0.0260358132326577,\n",
       "  array([[429147.1]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89460: [0.02155220634351883,\n",
       "  0.04526378372748169,\n",
       "  array([[316541.72]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89423: [0.025744513303702633,\n",
       "  0.02797251913627973,\n",
       "  array([[390167.53]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89410: [0.02266121148259634,\n",
       "  0.02989309216526772,\n",
       "  array([[364308.94]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89815: [0.0040705597099636535,\n",
       "  0.1972316236046547,\n",
       "  157628.88032379237,\n",
       "  'Facebook Prophet 0.5 Scale'],\n",
       " 89029: [0.01887977325164621,\n",
       "  0.07952504371731113,\n",
       "  array([[179293.98]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89109: [0.001085619317763456,\n",
       "  0.29487591640079563,\n",
       "  147029.74307195845,\n",
       "  'Facebook Prophet 0.5 Scale'],\n",
       " 89508: [0.02404940841422752,\n",
       "  0.03885765360221083,\n",
       "  array([[295647.6]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89703: [0.026605819705325644,\n",
       "  0.016845209189167005,\n",
       "  array([[395978.06]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89441: [0.04616578523780177,\n",
       "  0.02622971110060917,\n",
       "  array([[404043.8]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89060: [0.051374730839320246,\n",
       "  0.4481145912083443,\n",
       "  43268.07774765215,\n",
       "  'Facebook Prophet 0.5 Scale'],\n",
       " 89143: [0.029578799592597304,\n",
       "  0.03921069609550251,\n",
       "  array([[278578.9]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89519: [0.02622597364713289,\n",
       "  0.00837922805262121,\n",
       "  array([[530255.]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89447: [0.0, 0.1263294007067059, 105800.0, 'Facebook Prophet 0.5 Scale'],\n",
       " 89179: [0.0605525696581128,\n",
       "  0.08430970827822995,\n",
       "  array([[274424.34]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89429: [0.0, 0.17126642848040285, 100000.0, 'Facebook Prophet 0.5 Scale'],\n",
       " 89061: [0.0462120730553399,\n",
       "  0.37363904163418543,\n",
       "  91747.13796971427,\n",
       "  'Facebook Prophet 0.5 Scale'],\n",
       " 89451: [0.01146325738703841,\n",
       "  0.11453240842348449,\n",
       "  array([[887312.9]], dtype=float32),\n",
       "  'RNN 2 Layer Model'],\n",
       " 89501: [0.053523688064274745,\n",
       "  0.05064160048424097,\n",
       "  array([[336516.84]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89705: [0.01937345629182956,\n",
       "  0.06401691101955152,\n",
       "  array([[311722.75]], dtype=float32),\n",
       "  'RNN 2 Layer Model'],\n",
       " 89510: [0.04755960050638048,\n",
       "  0.016534748311037507,\n",
       "  array([[419795.16]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89086: [0.01673016945521541,\n",
       "  0.03195043797599434,\n",
       "  array([[276370.8]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89448: [0.020017315596736633,\n",
       "  0.048648592266616456,\n",
       "  array([[711522.44]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89704: [0.04805456593353047,\n",
       "  0.060358284469924486,\n",
       "  array([[384078.25]], dtype=float32),\n",
       "  'RNN 2 Layer Model'],\n",
       " 89449: [0.01973184372284484,\n",
       "  0.013429929386041619,\n",
       "  array([[375250.25]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89040: [0.023108450067453077,\n",
       "  0.09858743608405558,\n",
       "  array([[203617.3]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89444: [0.026226758084559564,\n",
       "  0.06654471331692842,\n",
       "  array([[265535.44]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89085: [0.026943162246036954,\n",
       "  0.02956933611526067,\n",
       "  array([[324097.06]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89034: [0.01614472350821041,\n",
       "  0.06342068882946472,\n",
       "  array([[320045.7]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89021: [0.0261632453865171,\n",
       "  0.01956434431718388,\n",
       "  array([[308233.66]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89439: [0.024921618023112452,\n",
       "  0.029563771898699343,\n",
       "  array([[434206.47]], dtype=float32),\n",
       "  'RNN w/ Dropout Model'],\n",
       " 89411: [0.02399191267321002,\n",
       "  0.022258930811882134,\n",
       "  array([[643628.1]], dtype=float32),\n",
       "  'RNN Model'],\n",
       " 89124: [0.05740765026870919,\n",
       "  0.051293241221755936,\n",
       "  array([[320317.47]], dtype=float32),\n",
       "  'RNN 2 Layer w/ Dropout Model'],\n",
       " 89440: [0.06752511405742875,\n",
       "  0.5613130532458728,\n",
       "  36897.156711760465,\n",
       "  'Facebook Prophet 0.5 Scale'],\n",
       " 89413: [0.027003445982966806,\n",
       "  0.16854946154128886,\n",
       "  array([[2011938.9]], dtype=float32),\n",
       "  'RNN 2 Layer Model'],\n",
       " 89155: [0.020357993171009073,\n",
       "  0.018942563381857885,\n",
       "  array([[356689.66]], dtype=float32),\n",
       "  'RNN Model']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07400322811805274,\n",
       " [0.02324273698072249,\n",
       "  0.09075772556037923,\n",
       "  0.045895206093298516,\n",
       "  0.30864445191825685,\n",
       "  0.011121031869867733,\n",
       "  0.022868370211432492,\n",
       "  0.07795946815163626,\n",
       "  0.016955612960913333,\n",
       "  0.03665875360957248,\n",
       "  0.027555278884971675,\n",
       "  0.04887042762494738,\n",
       "  0.06338780087602505,\n",
       "  0.04776643009723585,\n",
       "  0.008295738576931755,\n",
       "  0.03813845307477733,\n",
       "  0.044532981580081746,\n",
       "  0.04637591348038984,\n",
       "  0.0352344442531203,\n",
       "  0.029498854400012174,\n",
       "  0.0111600487900889,\n",
       "  0.03850802042367164,\n",
       "  0.04358463164315352,\n",
       "  0.022116312702984548,\n",
       "  0.0471366220025526,\n",
       "  0.0382602477437557,\n",
       "  0.2767431208024321,\n",
       "  0.03815724733471657,\n",
       "  0.014453127312831045,\n",
       "  0.07719998737821851,\n",
       "  0.010681586413580206,\n",
       "  0.03369473401855004,\n",
       "  0.042711533335936094,\n",
       "  0.03584006405155033,\n",
       "  0.03518618644495326,\n",
       "  0.02326395652104087,\n",
       "  0.037681999804238045,\n",
       "  0.026726473701510843,\n",
       "  0.007211643273714699,\n",
       "  0.009379827076333499,\n",
       "  0.04218185547614392,\n",
       "  0.035127576936861804,\n",
       "  0.035763989615938095,\n",
       "  0.017877839527142926,\n",
       "  0.042674718935269765,\n",
       "  0.024706139939923093,\n",
       "  0.05612697934015769,\n",
       "  0.05803488985532168,\n",
       "  0.024865866507304758,\n",
       "  0.22188868550263507,\n",
       "  0.036145271299921046,\n",
       "  0.02975210816859166,\n",
       "  0.07068000594279708,\n",
       "  0.18605038006532307,\n",
       "  0.05270237553979061,\n",
       "  0.03151480104371876,\n",
       "  0.05058152350984232,\n",
       "  0.3906516592920465,\n",
       "  0.03295044042064042,\n",
       "  0.08425611364301155,\n",
       "  0.18866819120027137,\n",
       "  0.05284322112895361,\n",
       "  0.038498163636300625,\n",
       "  0.017631641134536035,\n",
       "  0.09979547902540706,\n",
       "  0.16488227735459848,\n",
       "  0.03664509277208583,\n",
       "  0.04167824493094232,\n",
       "  0.0260358132326577,\n",
       "  0.04526378372748169,\n",
       "  0.02797251913627973,\n",
       "  0.02989309216526772,\n",
       "  0.1972316236046547,\n",
       "  0.07952504371731113,\n",
       "  0.29487591640079563,\n",
       "  0.03885765360221083,\n",
       "  0.016845209189167005,\n",
       "  0.02622971110060917,\n",
       "  0.4481145912083443,\n",
       "  0.03921069609550251,\n",
       "  0.00837922805262121,\n",
       "  0.1263294007067059,\n",
       "  0.08430970827822995,\n",
       "  0.17126642848040285,\n",
       "  0.37363904163418543,\n",
       "  0.11453240842348449,\n",
       "  0.05064160048424097,\n",
       "  0.06401691101955152,\n",
       "  0.016534748311037507,\n",
       "  0.03195043797599434,\n",
       "  0.048648592266616456,\n",
       "  0.060358284469924486,\n",
       "  0.013429929386041619,\n",
       "  0.09858743608405558,\n",
       "  0.06654471331692842,\n",
       "  0.02956933611526067,\n",
       "  0.06342068882946472,\n",
       "  0.01956434431718388,\n",
       "  0.029563771898699343,\n",
       "  0.022258930811882134,\n",
       "  0.051293241221755936,\n",
       "  0.5613130532458728,\n",
       "  0.16854946154128886,\n",
       "  0.018942563381857885])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_val_mape = []\n",
    "for z in best_model_dict.values():\n",
    "    bm_val_mape.append(z[1])\n",
    "np.mean(bm_val_mape), bm_val_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'FBP_scale=0.5',\n",
       "  'RNN',\n",
       "  'RNN_2_Layers',\n",
       "  'RNN_2_layer_w/_D.o.',\n",
       "  'RNN_w/_D.o.',\n",
       "  'SARIMA',\n",
       "  'Sarimax'},\n",
       " [27, 14, 12, 14, 12, 1, 18])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_types = []\n",
    "for item in best_model_dict.values():\n",
    "    model_types.append([item[2]])\n",
    "list = []\n",
    "for item in model_types:\n",
    "    list.append(item[0])\n",
    "labels = set(list)\n",
    "sizes = []\n",
    "#list.count(labels[0])\n",
    "for i in labels:\n",
    "    sizes.append(list.count(i))\n",
    "labels, sizes\n",
    "labels2 = x = ['FB Prophet 50% Scaler', 'SARIMA','RNN w/ Dropout', 'SARIMAX','RNN 2 Layers','RNN 2 Layers w/ Dropout','RNN']\n",
    "labels, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1584x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explode = (0.1, 0.1, 0, 0.1, 0, 0, 0.1) \n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(22,10))\n",
    "ax1.pie(sizes, explode=explode, labels=labels2, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.xticks(fontsize= 50)\n",
    "plt.show()\n",
    "fig1.savefig('pie.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_mape_list = []\n",
    "for item in best_model_dict.values():\n",
    "    best_model_mape_list.append(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_1_mape = np.mean(rnn_mape)\n",
    "rnn_2_mape = np.mean(rnn_mape2)\n",
    "rnn_3_mape = np.mean(rnn_mape3)\n",
    "rnn_4_mape = np.mean(rnn_mape4)\n",
    "fbp_1_mape = np.mean(fbp_mape)\n",
    "fbp_2_mape = np.mean(fbp_mape2)\n",
    "sarima_mape = np.mean(sarima_mape_list)\n",
    "sarimax_mape = np.mean(sarimax_mape_list)\n",
    "best_model_mape = np.mean(best_model_mape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-223-de4837f53625>:7: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels(['0%','2.5%','5%','7.5%','10%','12.5%','15%','17.5%','20%'])\n",
      "<ipython-input-223-de4837f53625>:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(labels = x, rotation=40)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1872x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(26,10))\n",
    "\n",
    "\n",
    "y = [rnn_1_mape,rnn_2_mape,rnn_3_mape,rnn_4_mape, fbp_1_mape, fbp_2_mape, sarima_mape, sarimax_mape, best_model_mape]\n",
    "x = ['RNN','RNN 2 Layers','RNN w/ Dropout','RNN 2 Layer w/ Dropout', 'FB Prophet 50% Scaler', 'FB Prophet 25% Scaler', 'SARIMA', 'SARIMAX', 'Fusion Model']\n",
    "ax.set_title('Model MAPE Improvement Chart')\n",
    "ax.set_yticklabels(['0%','2.5%','5%','7.5%','10%','12.5%','15%','17.5%','20%'])\n",
    "ax.set_xticklabels(labels = x, rotation=40)\n",
    "ax.set_ylabel('MAPE')\n",
    "ax.set_xlabel('Models')\n",
    "sns.barplot(x=x, y=y, palette=\"coolwarm\")\n",
    "sns.set_style('ticks')\n",
    "sns.set_context(\"talk\");\n",
    "fig.savefig('model_improvement.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding our Best Models predictions to our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_columns = []\n",
    "for column in df_time_series.columns:\n",
    "    zipcode_columns.append(zipcode_converter[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.columns = zipcode_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>89108</th>\n",
       "      <th>89121</th>\n",
       "      <th>89117</th>\n",
       "      <th>89052</th>\n",
       "      <th>89123</th>\n",
       "      <th>89031</th>\n",
       "      <th>89110</th>\n",
       "      <th>89074</th>\n",
       "      <th>89103</th>\n",
       "      <th>89148</th>\n",
       "      <th>...</th>\n",
       "      <th>89444</th>\n",
       "      <th>89085</th>\n",
       "      <th>89034</th>\n",
       "      <th>89021</th>\n",
       "      <th>89439</th>\n",
       "      <th>89411</th>\n",
       "      <th>89124</th>\n",
       "      <th>89440</th>\n",
       "      <th>89413</th>\n",
       "      <th>89155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01</th>\n",
       "      <td>102500.0</td>\n",
       "      <td>106800.0</td>\n",
       "      <td>165100.0</td>\n",
       "      <td>185700.0</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>122800.0</td>\n",
       "      <td>95800.0</td>\n",
       "      <td>148000.0</td>\n",
       "      <td>118900.0</td>\n",
       "      <td>157300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>116800.0</td>\n",
       "      <td>170900.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153200.0</td>\n",
       "      <td>184200.0</td>\n",
       "      <td>299200.0</td>\n",
       "      <td>166100.0</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.0</td>\n",
       "      <td>176400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01</th>\n",
       "      <td>102500.0</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>164500.0</td>\n",
       "      <td>186300.0</td>\n",
       "      <td>143500.0</td>\n",
       "      <td>122800.0</td>\n",
       "      <td>95800.0</td>\n",
       "      <td>147800.0</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>156000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>170800.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153700.0</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>299600.0</td>\n",
       "      <td>166600.0</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562800.0</td>\n",
       "      <td>176300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01</th>\n",
       "      <td>102500.0</td>\n",
       "      <td>107200.0</td>\n",
       "      <td>164000.0</td>\n",
       "      <td>186900.0</td>\n",
       "      <td>143100.0</td>\n",
       "      <td>122700.0</td>\n",
       "      <td>95800.0</td>\n",
       "      <td>147600.0</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>154700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117200.0</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195900.0</td>\n",
       "      <td>154100.0</td>\n",
       "      <td>185800.0</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>167300.0</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562700.0</td>\n",
       "      <td>176100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01</th>\n",
       "      <td>102600.0</td>\n",
       "      <td>107400.0</td>\n",
       "      <td>163500.0</td>\n",
       "      <td>187400.0</td>\n",
       "      <td>142700.0</td>\n",
       "      <td>122700.0</td>\n",
       "      <td>95900.0</td>\n",
       "      <td>147300.0</td>\n",
       "      <td>119100.0</td>\n",
       "      <td>153500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117400.0</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195700.0</td>\n",
       "      <td>154400.0</td>\n",
       "      <td>186400.0</td>\n",
       "      <td>300200.0</td>\n",
       "      <td>167900.0</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.0</td>\n",
       "      <td>176000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01</th>\n",
       "      <td>102700.0</td>\n",
       "      <td>107600.0</td>\n",
       "      <td>163200.0</td>\n",
       "      <td>187700.0</td>\n",
       "      <td>142400.0</td>\n",
       "      <td>122700.0</td>\n",
       "      <td>96100.0</td>\n",
       "      <td>147100.0</td>\n",
       "      <td>119200.0</td>\n",
       "      <td>152600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>117600.0</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195400.0</td>\n",
       "      <td>154700.0</td>\n",
       "      <td>186900.0</td>\n",
       "      <td>300500.0</td>\n",
       "      <td>168600.0</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562300.0</td>\n",
       "      <td>175900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>197300.0</td>\n",
       "      <td>198700.0</td>\n",
       "      <td>327100.0</td>\n",
       "      <td>403800.0</td>\n",
       "      <td>290400.0</td>\n",
       "      <td>231600.0</td>\n",
       "      <td>186600.0</td>\n",
       "      <td>300100.0</td>\n",
       "      <td>240400.0</td>\n",
       "      <td>291400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>266200.0</td>\n",
       "      <td>313100.0</td>\n",
       "      <td>311700.0</td>\n",
       "      <td>298300.0</td>\n",
       "      <td>444500.0</td>\n",
       "      <td>639300.0</td>\n",
       "      <td>316800.0</td>\n",
       "      <td>199800.0</td>\n",
       "      <td>2098400.0</td>\n",
       "      <td>348900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>200700.0</td>\n",
       "      <td>201500.0</td>\n",
       "      <td>330700.0</td>\n",
       "      <td>407300.0</td>\n",
       "      <td>294300.0</td>\n",
       "      <td>234600.0</td>\n",
       "      <td>189200.0</td>\n",
       "      <td>303500.0</td>\n",
       "      <td>243700.0</td>\n",
       "      <td>294100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>316500.0</td>\n",
       "      <td>315500.0</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>449500.0</td>\n",
       "      <td>642500.0</td>\n",
       "      <td>317600.0</td>\n",
       "      <td>201600.0</td>\n",
       "      <td>2121300.0</td>\n",
       "      <td>350400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>203500.0</td>\n",
       "      <td>204000.0</td>\n",
       "      <td>334600.0</td>\n",
       "      <td>410400.0</td>\n",
       "      <td>297400.0</td>\n",
       "      <td>237200.0</td>\n",
       "      <td>191700.0</td>\n",
       "      <td>306700.0</td>\n",
       "      <td>246300.0</td>\n",
       "      <td>296900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>275600.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>302500.0</td>\n",
       "      <td>450100.0</td>\n",
       "      <td>653800.0</td>\n",
       "      <td>323400.0</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>2153600.0</td>\n",
       "      <td>353000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>206600.0</td>\n",
       "      <td>206700.0</td>\n",
       "      <td>338800.0</td>\n",
       "      <td>413700.0</td>\n",
       "      <td>300200.0</td>\n",
       "      <td>239800.0</td>\n",
       "      <td>194500.0</td>\n",
       "      <td>309800.0</td>\n",
       "      <td>249500.0</td>\n",
       "      <td>299400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>282100.0</td>\n",
       "      <td>322400.0</td>\n",
       "      <td>323600.0</td>\n",
       "      <td>305700.0</td>\n",
       "      <td>451100.0</td>\n",
       "      <td>666000.0</td>\n",
       "      <td>334700.0</td>\n",
       "      <td>216500.0</td>\n",
       "      <td>2167100.0</td>\n",
       "      <td>356000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>209300.0</td>\n",
       "      <td>208600.0</td>\n",
       "      <td>342000.0</td>\n",
       "      <td>416100.0</td>\n",
       "      <td>302400.0</td>\n",
       "      <td>241900.0</td>\n",
       "      <td>196600.0</td>\n",
       "      <td>312200.0</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>300800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>286000.0</td>\n",
       "      <td>324700.0</td>\n",
       "      <td>326600.0</td>\n",
       "      <td>307800.0</td>\n",
       "      <td>455300.0</td>\n",
       "      <td>672600.0</td>\n",
       "      <td>344300.0</td>\n",
       "      <td>222800.0</td>\n",
       "      <td>2161900.0</td>\n",
       "      <td>357200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               89108     89121     89117     89052     89123     89031  \\\n",
       "1996-04-01  102500.0  106800.0  165100.0  185700.0  144000.0  122800.0   \n",
       "1996-05-01  102500.0  107000.0  164500.0  186300.0  143500.0  122800.0   \n",
       "1996-06-01  102500.0  107200.0  164000.0  186900.0  143100.0  122700.0   \n",
       "1996-07-01  102600.0  107400.0  163500.0  187400.0  142700.0  122700.0   \n",
       "1996-08-01  102700.0  107600.0  163200.0  187700.0  142400.0  122700.0   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2017-12-01  197300.0  198700.0  327100.0  403800.0  290400.0  231600.0   \n",
       "2018-01-01  200700.0  201500.0  330700.0  407300.0  294300.0  234600.0   \n",
       "2018-02-01  203500.0  204000.0  334600.0  410400.0  297400.0  237200.0   \n",
       "2018-03-01  206600.0  206700.0  338800.0  413700.0  300200.0  239800.0   \n",
       "2018-04-01  209300.0  208600.0  342000.0  416100.0  302400.0  241900.0   \n",
       "\n",
       "               89110     89074     89103     89148  ...     89444     89085  \\\n",
       "1996-04-01   95800.0  148000.0  118900.0  157300.0  ...  116800.0  170900.0   \n",
       "1996-05-01   95800.0  147800.0  119000.0  156000.0  ...  117000.0  170800.0   \n",
       "1996-06-01   95800.0  147600.0  119000.0  154700.0  ...  117200.0  170700.0   \n",
       "1996-07-01   95900.0  147300.0  119100.0  153500.0  ...  117400.0  170700.0   \n",
       "1996-08-01   96100.0  147100.0  119200.0  152600.0  ...  117600.0  170700.0   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2017-12-01  186600.0  300100.0  240400.0  291400.0  ...  266200.0  313100.0   \n",
       "2018-01-01  189200.0  303500.0  243700.0  294100.0  ...  270000.0  316500.0   \n",
       "2018-02-01  191700.0  306700.0  246300.0  296900.0  ...  275600.0  319500.0   \n",
       "2018-03-01  194500.0  309800.0  249500.0  299400.0  ...  282100.0  322400.0   \n",
       "2018-04-01  196600.0  312200.0  252000.0  300800.0  ...  286000.0  324700.0   \n",
       "\n",
       "               89034     89021     89439     89411     89124     89440  \\\n",
       "1996-04-01  196000.0  153200.0  184200.0  299200.0  166100.0  293200.0   \n",
       "1996-05-01  196000.0  153700.0  185000.0  299600.0  166600.0  293200.0   \n",
       "1996-06-01  195900.0  154100.0  185800.0  299900.0  167300.0  293200.0   \n",
       "1996-07-01  195700.0  154400.0  186400.0  300200.0  167900.0  293200.0   \n",
       "1996-08-01  195400.0  154700.0  186900.0  300500.0  168600.0  293200.0   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2017-12-01  311700.0  298300.0  444500.0  639300.0  316800.0  199800.0   \n",
       "2018-01-01  315500.0  299900.0  449500.0  642500.0  317600.0  201600.0   \n",
       "2018-02-01  319500.0  302500.0  450100.0  653800.0  323400.0  207000.0   \n",
       "2018-03-01  323600.0  305700.0  451100.0  666000.0  334700.0  216500.0   \n",
       "2018-04-01  326600.0  307800.0  455300.0  672600.0  344300.0  222800.0   \n",
       "\n",
       "                89413     89155  \n",
       "1996-04-01   562400.0  176400.0  \n",
       "1996-05-01   562800.0  176300.0  \n",
       "1996-06-01   562700.0  176100.0  \n",
       "1996-07-01   562400.0  176000.0  \n",
       "1996-08-01   562300.0  175900.0  \n",
       "...               ...       ...  \n",
       "2017-12-01  2098400.0  348900.0  \n",
       "2018-01-01  2121300.0  350400.0  \n",
       "2018-02-01  2153600.0  353000.0  \n",
       "2018-03-01  2167100.0  356000.0  \n",
       "2018-04-01  2161900.0  357200.0  \n",
       "\n",
       "[265 rows x 103 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_05_18 = []\n",
    "for zipcode in df_time_series.columns:\n",
    "    if zipcode in best_model_dict.keys():\n",
    "        predictions_05_18.append(best_model_dict[zipcode][1])\n",
    "    else:\n",
    "        predictions_05_18.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_05_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ferityikar/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df_time_series.loc['2018-05-01_pred'] = predictions_05_18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>89108</th>\n",
       "      <th>89121</th>\n",
       "      <th>89117</th>\n",
       "      <th>89052</th>\n",
       "      <th>89123</th>\n",
       "      <th>89031</th>\n",
       "      <th>89110</th>\n",
       "      <th>89074</th>\n",
       "      <th>89103</th>\n",
       "      <th>89148</th>\n",
       "      <th>...</th>\n",
       "      <th>89444</th>\n",
       "      <th>89085</th>\n",
       "      <th>89034</th>\n",
       "      <th>89021</th>\n",
       "      <th>89439</th>\n",
       "      <th>89411</th>\n",
       "      <th>89124</th>\n",
       "      <th>89440</th>\n",
       "      <th>89413</th>\n",
       "      <th>89155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>106800.000000</td>\n",
       "      <td>165100.00000</td>\n",
       "      <td>185700.000</td>\n",
       "      <td>144000.00000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>148000.00</td>\n",
       "      <td>118900.000000</td>\n",
       "      <td>157300.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>116800.0000</td>\n",
       "      <td>170900.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153200.0</td>\n",
       "      <td>184200.00000</td>\n",
       "      <td>299200.0</td>\n",
       "      <td>166100.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.000</td>\n",
       "      <td>176400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107000.000000</td>\n",
       "      <td>164500.00000</td>\n",
       "      <td>186300.000</td>\n",
       "      <td>143500.00000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147800.00</td>\n",
       "      <td>119000.000000</td>\n",
       "      <td>156000.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117000.0000</td>\n",
       "      <td>170800.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153700.0</td>\n",
       "      <td>185000.00000</td>\n",
       "      <td>299600.0</td>\n",
       "      <td>166600.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562800.000</td>\n",
       "      <td>176300.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107200.000000</td>\n",
       "      <td>164000.00000</td>\n",
       "      <td>186900.000</td>\n",
       "      <td>143100.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147600.00</td>\n",
       "      <td>119000.000000</td>\n",
       "      <td>154700.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117200.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195900.0</td>\n",
       "      <td>154100.0</td>\n",
       "      <td>185800.00000</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>167300.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562700.000</td>\n",
       "      <td>176100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01 00:00:00</th>\n",
       "      <td>102600.000000</td>\n",
       "      <td>107400.000000</td>\n",
       "      <td>163500.00000</td>\n",
       "      <td>187400.000</td>\n",
       "      <td>142700.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95900.000000</td>\n",
       "      <td>147300.00</td>\n",
       "      <td>119100.000000</td>\n",
       "      <td>153500.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117400.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195700.0</td>\n",
       "      <td>154400.0</td>\n",
       "      <td>186400.00000</td>\n",
       "      <td>300200.0</td>\n",
       "      <td>167900.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.000</td>\n",
       "      <td>176000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01 00:00:00</th>\n",
       "      <td>102700.000000</td>\n",
       "      <td>107600.000000</td>\n",
       "      <td>163200.00000</td>\n",
       "      <td>187700.000</td>\n",
       "      <td>142400.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>96100.000000</td>\n",
       "      <td>147100.00</td>\n",
       "      <td>119200.000000</td>\n",
       "      <td>152600.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117600.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195400.0</td>\n",
       "      <td>154700.0</td>\n",
       "      <td>186900.00000</td>\n",
       "      <td>300500.0</td>\n",
       "      <td>168600.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562300.000</td>\n",
       "      <td>175900.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>200700.000000</td>\n",
       "      <td>201500.000000</td>\n",
       "      <td>330700.00000</td>\n",
       "      <td>407300.000</td>\n",
       "      <td>294300.00000</td>\n",
       "      <td>234600.000000</td>\n",
       "      <td>189200.000000</td>\n",
       "      <td>303500.00</td>\n",
       "      <td>243700.000000</td>\n",
       "      <td>294100.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>270000.0000</td>\n",
       "      <td>316500.0</td>\n",
       "      <td>315500.0</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>449500.00000</td>\n",
       "      <td>642500.0</td>\n",
       "      <td>317600.0000</td>\n",
       "      <td>201600.0</td>\n",
       "      <td>2121300.000</td>\n",
       "      <td>350400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>203500.000000</td>\n",
       "      <td>204000.000000</td>\n",
       "      <td>334600.00000</td>\n",
       "      <td>410400.000</td>\n",
       "      <td>297400.00000</td>\n",
       "      <td>237200.000000</td>\n",
       "      <td>191700.000000</td>\n",
       "      <td>306700.00</td>\n",
       "      <td>246300.000000</td>\n",
       "      <td>296900.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>275600.0000</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>302500.0</td>\n",
       "      <td>450100.00000</td>\n",
       "      <td>653800.0</td>\n",
       "      <td>323400.0000</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>2153600.000</td>\n",
       "      <td>353000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>206600.000000</td>\n",
       "      <td>206700.000000</td>\n",
       "      <td>338800.00000</td>\n",
       "      <td>413700.000</td>\n",
       "      <td>300200.00000</td>\n",
       "      <td>239800.000000</td>\n",
       "      <td>194500.000000</td>\n",
       "      <td>309800.00</td>\n",
       "      <td>249500.000000</td>\n",
       "      <td>299400.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>282100.0000</td>\n",
       "      <td>322400.0</td>\n",
       "      <td>323600.0</td>\n",
       "      <td>305700.0</td>\n",
       "      <td>451100.00000</td>\n",
       "      <td>666000.0</td>\n",
       "      <td>334700.0000</td>\n",
       "      <td>216500.0</td>\n",
       "      <td>2167100.000</td>\n",
       "      <td>356000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>209300.000000</td>\n",
       "      <td>208600.000000</td>\n",
       "      <td>342000.00000</td>\n",
       "      <td>416100.000</td>\n",
       "      <td>302400.00000</td>\n",
       "      <td>241900.000000</td>\n",
       "      <td>196600.000000</td>\n",
       "      <td>312200.00</td>\n",
       "      <td>252000.000000</td>\n",
       "      <td>300800.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>286000.0000</td>\n",
       "      <td>324700.0</td>\n",
       "      <td>326600.0</td>\n",
       "      <td>307800.0</td>\n",
       "      <td>455300.00000</td>\n",
       "      <td>672600.0</td>\n",
       "      <td>344300.0000</td>\n",
       "      <td>222800.0</td>\n",
       "      <td>2161900.000</td>\n",
       "      <td>357200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01_pred</th>\n",
       "      <td>212876.996122</td>\n",
       "      <td>212357.255857</td>\n",
       "      <td>343835.59375</td>\n",
       "      <td>421466.875</td>\n",
       "      <td>303811.84375</td>\n",
       "      <td>246300.944755</td>\n",
       "      <td>200482.013725</td>\n",
       "      <td>312865.75</td>\n",
       "      <td>251018.223795</td>\n",
       "      <td>305326.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>279638.8125</td>\n",
       "      <td>330100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>453697.84375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333740.6875</td>\n",
       "      <td>190700.0</td>\n",
       "      <td>2082682.875</td>\n",
       "      <td>361679.90625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             89108          89121         89117       89052  \\\n",
       "1996-04-01 00:00:00  102500.000000  106800.000000  165100.00000  185700.000   \n",
       "1996-05-01 00:00:00  102500.000000  107000.000000  164500.00000  186300.000   \n",
       "1996-06-01 00:00:00  102500.000000  107200.000000  164000.00000  186900.000   \n",
       "1996-07-01 00:00:00  102600.000000  107400.000000  163500.00000  187400.000   \n",
       "1996-08-01 00:00:00  102700.000000  107600.000000  163200.00000  187700.000   \n",
       "...                            ...            ...           ...         ...   \n",
       "2018-01-01 00:00:00  200700.000000  201500.000000  330700.00000  407300.000   \n",
       "2018-02-01 00:00:00  203500.000000  204000.000000  334600.00000  410400.000   \n",
       "2018-03-01 00:00:00  206600.000000  206700.000000  338800.00000  413700.000   \n",
       "2018-04-01 00:00:00  209300.000000  208600.000000  342000.00000  416100.000   \n",
       "2018-05-01_pred      212876.996122  212357.255857  343835.59375  421466.875   \n",
       "\n",
       "                            89123          89031          89110      89074  \\\n",
       "1996-04-01 00:00:00  144000.00000  122800.000000   95800.000000  148000.00   \n",
       "1996-05-01 00:00:00  143500.00000  122800.000000   95800.000000  147800.00   \n",
       "1996-06-01 00:00:00  143100.00000  122700.000000   95800.000000  147600.00   \n",
       "1996-07-01 00:00:00  142700.00000  122700.000000   95900.000000  147300.00   \n",
       "1996-08-01 00:00:00  142400.00000  122700.000000   96100.000000  147100.00   \n",
       "...                           ...            ...            ...        ...   \n",
       "2018-01-01 00:00:00  294300.00000  234600.000000  189200.000000  303500.00   \n",
       "2018-02-01 00:00:00  297400.00000  237200.000000  191700.000000  306700.00   \n",
       "2018-03-01 00:00:00  300200.00000  239800.000000  194500.000000  309800.00   \n",
       "2018-04-01 00:00:00  302400.00000  241900.000000  196600.000000  312200.00   \n",
       "2018-05-01_pred      303811.84375  246300.944755  200482.013725  312865.75   \n",
       "\n",
       "                             89103        89148  ...        89444     89085  \\\n",
       "1996-04-01 00:00:00  118900.000000  157300.0000  ...  116800.0000  170900.0   \n",
       "1996-05-01 00:00:00  119000.000000  156000.0000  ...  117000.0000  170800.0   \n",
       "1996-06-01 00:00:00  119000.000000  154700.0000  ...  117200.0000  170700.0   \n",
       "1996-07-01 00:00:00  119100.000000  153500.0000  ...  117400.0000  170700.0   \n",
       "1996-08-01 00:00:00  119200.000000  152600.0000  ...  117600.0000  170700.0   \n",
       "...                            ...          ...  ...          ...       ...   \n",
       "2018-01-01 00:00:00  243700.000000  294100.0000  ...  270000.0000  316500.0   \n",
       "2018-02-01 00:00:00  246300.000000  296900.0000  ...  275600.0000  319500.0   \n",
       "2018-03-01 00:00:00  249500.000000  299400.0000  ...  282100.0000  322400.0   \n",
       "2018-04-01 00:00:00  252000.000000  300800.0000  ...  286000.0000  324700.0   \n",
       "2018-05-01_pred      251018.223795  305326.5625  ...  279638.8125  330100.0   \n",
       "\n",
       "                        89034     89021         89439     89411        89124  \\\n",
       "1996-04-01 00:00:00  196000.0  153200.0  184200.00000  299200.0  166100.0000   \n",
       "1996-05-01 00:00:00  196000.0  153700.0  185000.00000  299600.0  166600.0000   \n",
       "1996-06-01 00:00:00  195900.0  154100.0  185800.00000  299900.0  167300.0000   \n",
       "1996-07-01 00:00:00  195700.0  154400.0  186400.00000  300200.0  167900.0000   \n",
       "1996-08-01 00:00:00  195400.0  154700.0  186900.00000  300500.0  168600.0000   \n",
       "...                       ...       ...           ...       ...          ...   \n",
       "2018-01-01 00:00:00  315500.0  299900.0  449500.00000  642500.0  317600.0000   \n",
       "2018-02-01 00:00:00  319500.0  302500.0  450100.00000  653800.0  323400.0000   \n",
       "2018-03-01 00:00:00  323600.0  305700.0  451100.00000  666000.0  334700.0000   \n",
       "2018-04-01 00:00:00  326600.0  307800.0  455300.00000  672600.0  344300.0000   \n",
       "2018-05-01_pred           0.0       0.0  453697.84375       0.0  333740.6875   \n",
       "\n",
       "                        89440        89413         89155  \n",
       "1996-04-01 00:00:00  293200.0   562400.000  176400.00000  \n",
       "1996-05-01 00:00:00  293200.0   562800.000  176300.00000  \n",
       "1996-06-01 00:00:00  293200.0   562700.000  176100.00000  \n",
       "1996-07-01 00:00:00  293200.0   562400.000  176000.00000  \n",
       "1996-08-01 00:00:00  293200.0   562300.000  175900.00000  \n",
       "...                       ...          ...           ...  \n",
       "2018-01-01 00:00:00  201600.0  2121300.000  350400.00000  \n",
       "2018-02-01 00:00:00  207000.0  2153600.000  353000.00000  \n",
       "2018-03-01 00:00:00  216500.0  2167100.000  356000.00000  \n",
       "2018-04-01 00:00:00  222800.0  2161900.000  357200.00000  \n",
       "2018-05-01_pred      190700.0  2082682.875  361679.90625  \n",
       "\n",
       "[266 rows x 103 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_return = {}\n",
    "for i in df_time_series.columns:\n",
    "    investment_return[i] = (df_time_series[i][-1]-df_time_series[i][-2])/df_time_series[i][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89448: -1.0,\n",
       " 89449: -1.0,\n",
       " 89034: -1.0,\n",
       " 89021: -1.0,\n",
       " 89411: -1.0,\n",
       " 89440: -0.1440754039497307,\n",
       " 89109: -0.06368849984907939,\n",
       " 89403: -0.05772005772005772,\n",
       " 89436: -0.05225015001536002,\n",
       " 89512: -0.047372954349698536,\n",
       " 89413: -0.03664236319903788,\n",
       " 89429: -0.03379828326180258,\n",
       " 89124: -0.030668929712460064,\n",
       " 89511: -0.02986241620023129,\n",
       " 89156: -0.028897632102470983,\n",
       " 89451: -0.02755555701662108,\n",
       " 89122: -0.02687998117247378,\n",
       " 89410: -0.024777401804670914,\n",
       " 89433: -0.023406785042469288,\n",
       " 89444: -0.022241914335664335,\n",
       " 89423: -0.01899039052890529,\n",
       " 89703: -0.016678927604038413,\n",
       " 89701: -0.016057372505543236,\n",
       " 89519: -0.013868014974433893,\n",
       " 89705: -0.013570170632435817,\n",
       " 89801: -0.011791737329410124,\n",
       " 89521: -0.010857668067226892,\n",
       " 89144: -0.009602167568337129,\n",
       " 89434: -0.008952254641909815,\n",
       " 89509: -0.008843687817820032,\n",
       " 89815: -0.00859215226680593,\n",
       " 89706: -0.0077280844155844155,\n",
       " 89503: -0.00548033526756931,\n",
       " 89523: -0.0052024848254931715,\n",
       " 89103: -0.0038959373226174474,\n",
       " 89704: -0.0037051052198448153,\n",
       " 89439: -0.0035189023720623765,\n",
       " 89447: -0.0021149037569591664,\n",
       " 89134: 0.0002814465408805031,\n",
       " 89135: 0.0007228047766159696,\n",
       " 89501: 0.0007674237940218999,\n",
       " 89118: 0.0014013991514543684,\n",
       " 89074: 0.0021324471492632927,\n",
       " 89460: 0.002898670333367592,\n",
       " 89138: 0.0033907070303583657,\n",
       " 89506: 0.0038006416430090436,\n",
       " 89040: 0.003864246500965251,\n",
       " 89431: 0.004110708275741608,\n",
       " 89123: 0.004668795469576719,\n",
       " 89128: 0.004818333059491853,\n",
       " 89084: 0.004982521186440678,\n",
       " 89117: 0.005367233187134503,\n",
       " 89002: 0.006339834662678631,\n",
       " 89508: 0.0068769475917980815,\n",
       " 89115: 0.00689631270757408,\n",
       " 89029: 0.007226240424241816,\n",
       " 89441: 0.007586334997622444,\n",
       " 89044: 0.007659311985231469,\n",
       " 89131: 0.007676996112440191,\n",
       " 89102: 0.008061170549308945,\n",
       " 89146: 0.008200316355284487,\n",
       " 89178: 0.00960934819897084,\n",
       " 89502: 0.010230144183125343,\n",
       " 89014: 0.011042309722060698,\n",
       " 89142: 0.011910567737782554,\n",
       " 89113: 0.011957274590163934,\n",
       " 89129: 0.01209570583059348,\n",
       " 89048: 0.012444001991040319,\n",
       " 89155: 0.012541730823068309,\n",
       " 89030: 0.012873693870063938,\n",
       " 89052: 0.012898041336217256,\n",
       " 89107: 0.013849103563232377,\n",
       " 89120: 0.014241467975789993,\n",
       " 89141: 0.014408379556259905,\n",
       " 89179: 0.014536210317460318,\n",
       " 89027: 0.014765261012282932,\n",
       " 89148: 0.015048412566489361,\n",
       " 89145: 0.015232606010703994,\n",
       " 89012: 0.015464465431738622,\n",
       " 89149: 0.015549208724349615,\n",
       " 89130: 0.016206261510128914,\n",
       " 89085: 0.016630736064059133,\n",
       " 89108: 0.017090282472717315,\n",
       " 89015: 0.01740494764210884,\n",
       " 89121: 0.018011773042736167,\n",
       " 89031: 0.01819323999528761,\n",
       " 89183: 0.01949963208241354,\n",
       " 89110: 0.019745746310630814,\n",
       " 89104: 0.01981829457598941,\n",
       " 89086: 0.020193354851261818,\n",
       " 89408: 0.020610057708161583,\n",
       " 89147: 0.021103901235491745,\n",
       " 89119: 0.021339230134029687,\n",
       " 89032: 0.021442448761473946,\n",
       " 89061: 0.02262443438914027,\n",
       " 89005: 0.022760683932007697,\n",
       " 89011: 0.022894300075872533,\n",
       " 89081: 0.02315332765638677,\n",
       " 89143: 0.023676292949176808,\n",
       " 89166: 0.02389814733707078,\n",
       " 89510: 0.025691410950661853,\n",
       " 89139: 0.027802706405703665,\n",
       " 89060: 0.05800064931281908}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_return = dict(sorted(investment_return.items(), key=lambda item: item[1]))\n",
    "investment_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in investment_return.keys():\n",
    "    list.append(i)\n",
    "best_5_investments = list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89143, 89166, 89510, 89139, 89060]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_5_investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>89143</th>\n",
       "      <th>89166</th>\n",
       "      <th>89510</th>\n",
       "      <th>89139</th>\n",
       "      <th>89060</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-01 00:00:00</th>\n",
       "      <td>244600.00000</td>\n",
       "      <td>255300.00000</td>\n",
       "      <td>400200.00000</td>\n",
       "      <td>254200.000000</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01 00:00:00</th>\n",
       "      <td>247300.00000</td>\n",
       "      <td>258600.00000</td>\n",
       "      <td>408000.00000</td>\n",
       "      <td>256600.000000</td>\n",
       "      <td>121800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01 00:00:00</th>\n",
       "      <td>250700.00000</td>\n",
       "      <td>262000.00000</td>\n",
       "      <td>412500.00000</td>\n",
       "      <td>258900.000000</td>\n",
       "      <td>125100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01 00:00:00</th>\n",
       "      <td>255000.00000</td>\n",
       "      <td>265800.00000</td>\n",
       "      <td>415700.00000</td>\n",
       "      <td>261900.000000</td>\n",
       "      <td>127600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 00:00:00</th>\n",
       "      <td>259500.00000</td>\n",
       "      <td>270100.00000</td>\n",
       "      <td>415100.00000</td>\n",
       "      <td>265800.000000</td>\n",
       "      <td>130000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 00:00:00</th>\n",
       "      <td>262500.00000</td>\n",
       "      <td>273500.00000</td>\n",
       "      <td>416500.00000</td>\n",
       "      <td>269300.000000</td>\n",
       "      <td>134600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:00:00</th>\n",
       "      <td>265500.00000</td>\n",
       "      <td>276500.00000</td>\n",
       "      <td>419500.00000</td>\n",
       "      <td>273100.000000</td>\n",
       "      <td>140100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>268500.00000</td>\n",
       "      <td>279200.00000</td>\n",
       "      <td>421800.00000</td>\n",
       "      <td>276700.000000</td>\n",
       "      <td>143500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>271700.00000</td>\n",
       "      <td>281700.00000</td>\n",
       "      <td>420600.00000</td>\n",
       "      <td>280100.000000</td>\n",
       "      <td>146700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>275800.00000</td>\n",
       "      <td>283900.00000</td>\n",
       "      <td>418300.00000</td>\n",
       "      <td>283100.000000</td>\n",
       "      <td>149700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>279400.00000</td>\n",
       "      <td>285400.00000</td>\n",
       "      <td>415500.00000</td>\n",
       "      <td>284900.000000</td>\n",
       "      <td>151400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01_pred</th>\n",
       "      <td>286015.15625</td>\n",
       "      <td>292220.53125</td>\n",
       "      <td>426174.78125</td>\n",
       "      <td>292820.991055</td>\n",
       "      <td>160181.298306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            89143         89166         89510          89139  \\\n",
       "2017-06-01 00:00:00  244600.00000  255300.00000  400200.00000  254200.000000   \n",
       "2017-07-01 00:00:00  247300.00000  258600.00000  408000.00000  256600.000000   \n",
       "2017-08-01 00:00:00  250700.00000  262000.00000  412500.00000  258900.000000   \n",
       "2017-09-01 00:00:00  255000.00000  265800.00000  415700.00000  261900.000000   \n",
       "2017-10-01 00:00:00  259500.00000  270100.00000  415100.00000  265800.000000   \n",
       "2017-11-01 00:00:00  262500.00000  273500.00000  416500.00000  269300.000000   \n",
       "2017-12-01 00:00:00  265500.00000  276500.00000  419500.00000  273100.000000   \n",
       "2018-01-01 00:00:00  268500.00000  279200.00000  421800.00000  276700.000000   \n",
       "2018-02-01 00:00:00  271700.00000  281700.00000  420600.00000  280100.000000   \n",
       "2018-03-01 00:00:00  275800.00000  283900.00000  418300.00000  283100.000000   \n",
       "2018-04-01 00:00:00  279400.00000  285400.00000  415500.00000  284900.000000   \n",
       "2018-05-01_pred      286015.15625  292220.53125  426174.78125  292820.991055   \n",
       "\n",
       "                             89060  \n",
       "2017-06-01 00:00:00  119600.000000  \n",
       "2017-07-01 00:00:00  121800.000000  \n",
       "2017-08-01 00:00:00  125100.000000  \n",
       "2017-09-01 00:00:00  127600.000000  \n",
       "2017-10-01 00:00:00  130000.000000  \n",
       "2017-11-01 00:00:00  134600.000000  \n",
       "2017-12-01 00:00:00  140100.000000  \n",
       "2018-01-01 00:00:00  143500.000000  \n",
       "2018-02-01 00:00:00  146700.000000  \n",
       "2018-03-01 00:00:00  149700.000000  \n",
       "2018-04-01 00:00:00  151400.000000  \n",
       "2018-05-01_pred      160181.298306  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_chart_data = df_time_series[best_5_investments][-12:]\n",
    "investment_chart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1584x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "months = [\"June '17\", \"July '17\",\"Aug '17\",\"Sep '17\",\"Oct '17\",\"Nov '17\",\"Dec '18\",\"Jan '18\",\"Feb '18\",\"Mar '18\",\"Apr '18\", \"May '18\"]\n",
    "fig, ax = plt.subplots(figsize=(22,7))\n",
    "fig = plt.figure()\n",
    "\n",
    "ax.plot(months, investment_chart_data[89143])\n",
    "ax.plot(months, investment_chart_data[89166])\n",
    "ax.plot(months, investment_chart_data[89510])\n",
    "ax.plot(months, investment_chart_data[89139])\n",
    "ax.plot(months, investment_chart_data[89060])\n",
    "\n",
    "\n",
    "\n",
    "ax.set_title('Top 5 Profitable Zipcodes')\n",
    "ax.legend(['89143','89166','89510','89139','89060'], loc=('upper left'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>89108</th>\n",
       "      <th>89121</th>\n",
       "      <th>89117</th>\n",
       "      <th>89052</th>\n",
       "      <th>89123</th>\n",
       "      <th>89031</th>\n",
       "      <th>89110</th>\n",
       "      <th>89074</th>\n",
       "      <th>89103</th>\n",
       "      <th>89148</th>\n",
       "      <th>...</th>\n",
       "      <th>89444</th>\n",
       "      <th>89085</th>\n",
       "      <th>89034</th>\n",
       "      <th>89021</th>\n",
       "      <th>89439</th>\n",
       "      <th>89411</th>\n",
       "      <th>89124</th>\n",
       "      <th>89440</th>\n",
       "      <th>89413</th>\n",
       "      <th>89155</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>106800.000000</td>\n",
       "      <td>165100.00000</td>\n",
       "      <td>185700.000</td>\n",
       "      <td>144000.00000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>148000.00</td>\n",
       "      <td>118900.000000</td>\n",
       "      <td>157300.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>116800.0000</td>\n",
       "      <td>170900.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153200.0</td>\n",
       "      <td>184200.00000</td>\n",
       "      <td>299200.0</td>\n",
       "      <td>166100.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.000</td>\n",
       "      <td>176400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107000.000000</td>\n",
       "      <td>164500.00000</td>\n",
       "      <td>186300.000</td>\n",
       "      <td>143500.00000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147800.00</td>\n",
       "      <td>119000.000000</td>\n",
       "      <td>156000.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117000.0000</td>\n",
       "      <td>170800.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>153700.0</td>\n",
       "      <td>185000.00000</td>\n",
       "      <td>299600.0</td>\n",
       "      <td>166600.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562800.000</td>\n",
       "      <td>176300.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107200.000000</td>\n",
       "      <td>164000.00000</td>\n",
       "      <td>186900.000</td>\n",
       "      <td>143100.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147600.00</td>\n",
       "      <td>119000.000000</td>\n",
       "      <td>154700.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117200.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195900.0</td>\n",
       "      <td>154100.0</td>\n",
       "      <td>185800.00000</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>167300.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562700.000</td>\n",
       "      <td>176100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01 00:00:00</th>\n",
       "      <td>102600.000000</td>\n",
       "      <td>107400.000000</td>\n",
       "      <td>163500.00000</td>\n",
       "      <td>187400.000</td>\n",
       "      <td>142700.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95900.000000</td>\n",
       "      <td>147300.00</td>\n",
       "      <td>119100.000000</td>\n",
       "      <td>153500.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117400.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195700.0</td>\n",
       "      <td>154400.0</td>\n",
       "      <td>186400.00000</td>\n",
       "      <td>300200.0</td>\n",
       "      <td>167900.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562400.000</td>\n",
       "      <td>176000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01 00:00:00</th>\n",
       "      <td>102700.000000</td>\n",
       "      <td>107600.000000</td>\n",
       "      <td>163200.00000</td>\n",
       "      <td>187700.000</td>\n",
       "      <td>142400.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>96100.000000</td>\n",
       "      <td>147100.00</td>\n",
       "      <td>119200.000000</td>\n",
       "      <td>152600.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117600.0000</td>\n",
       "      <td>170700.0</td>\n",
       "      <td>195400.0</td>\n",
       "      <td>154700.0</td>\n",
       "      <td>186900.00000</td>\n",
       "      <td>300500.0</td>\n",
       "      <td>168600.0000</td>\n",
       "      <td>293200.0</td>\n",
       "      <td>562300.000</td>\n",
       "      <td>175900.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>200700.000000</td>\n",
       "      <td>201500.000000</td>\n",
       "      <td>330700.00000</td>\n",
       "      <td>407300.000</td>\n",
       "      <td>294300.00000</td>\n",
       "      <td>234600.000000</td>\n",
       "      <td>189200.000000</td>\n",
       "      <td>303500.00</td>\n",
       "      <td>243700.000000</td>\n",
       "      <td>294100.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>270000.0000</td>\n",
       "      <td>316500.0</td>\n",
       "      <td>315500.0</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>449500.00000</td>\n",
       "      <td>642500.0</td>\n",
       "      <td>317600.0000</td>\n",
       "      <td>201600.0</td>\n",
       "      <td>2121300.000</td>\n",
       "      <td>350400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>203500.000000</td>\n",
       "      <td>204000.000000</td>\n",
       "      <td>334600.00000</td>\n",
       "      <td>410400.000</td>\n",
       "      <td>297400.00000</td>\n",
       "      <td>237200.000000</td>\n",
       "      <td>191700.000000</td>\n",
       "      <td>306700.00</td>\n",
       "      <td>246300.000000</td>\n",
       "      <td>296900.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>275600.0000</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>302500.0</td>\n",
       "      <td>450100.00000</td>\n",
       "      <td>653800.0</td>\n",
       "      <td>323400.0000</td>\n",
       "      <td>207000.0</td>\n",
       "      <td>2153600.000</td>\n",
       "      <td>353000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>206600.000000</td>\n",
       "      <td>206700.000000</td>\n",
       "      <td>338800.00000</td>\n",
       "      <td>413700.000</td>\n",
       "      <td>300200.00000</td>\n",
       "      <td>239800.000000</td>\n",
       "      <td>194500.000000</td>\n",
       "      <td>309800.00</td>\n",
       "      <td>249500.000000</td>\n",
       "      <td>299400.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>282100.0000</td>\n",
       "      <td>322400.0</td>\n",
       "      <td>323600.0</td>\n",
       "      <td>305700.0</td>\n",
       "      <td>451100.00000</td>\n",
       "      <td>666000.0</td>\n",
       "      <td>334700.0000</td>\n",
       "      <td>216500.0</td>\n",
       "      <td>2167100.000</td>\n",
       "      <td>356000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>209300.000000</td>\n",
       "      <td>208600.000000</td>\n",
       "      <td>342000.00000</td>\n",
       "      <td>416100.000</td>\n",
       "      <td>302400.00000</td>\n",
       "      <td>241900.000000</td>\n",
       "      <td>196600.000000</td>\n",
       "      <td>312200.00</td>\n",
       "      <td>252000.000000</td>\n",
       "      <td>300800.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>286000.0000</td>\n",
       "      <td>324700.0</td>\n",
       "      <td>326600.0</td>\n",
       "      <td>307800.0</td>\n",
       "      <td>455300.00000</td>\n",
       "      <td>672600.0</td>\n",
       "      <td>344300.0000</td>\n",
       "      <td>222800.0</td>\n",
       "      <td>2161900.000</td>\n",
       "      <td>357200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01_pred</th>\n",
       "      <td>212876.996122</td>\n",
       "      <td>212357.255857</td>\n",
       "      <td>343835.59375</td>\n",
       "      <td>421466.875</td>\n",
       "      <td>303811.84375</td>\n",
       "      <td>246300.944755</td>\n",
       "      <td>200482.013725</td>\n",
       "      <td>312865.75</td>\n",
       "      <td>251018.223795</td>\n",
       "      <td>305326.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>279638.8125</td>\n",
       "      <td>330100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>453697.84375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333740.6875</td>\n",
       "      <td>190700.0</td>\n",
       "      <td>2082682.875</td>\n",
       "      <td>361679.90625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             89108          89121         89117       89052  \\\n",
       "1996-04-01 00:00:00  102500.000000  106800.000000  165100.00000  185700.000   \n",
       "1996-05-01 00:00:00  102500.000000  107000.000000  164500.00000  186300.000   \n",
       "1996-06-01 00:00:00  102500.000000  107200.000000  164000.00000  186900.000   \n",
       "1996-07-01 00:00:00  102600.000000  107400.000000  163500.00000  187400.000   \n",
       "1996-08-01 00:00:00  102700.000000  107600.000000  163200.00000  187700.000   \n",
       "...                            ...            ...           ...         ...   \n",
       "2018-01-01 00:00:00  200700.000000  201500.000000  330700.00000  407300.000   \n",
       "2018-02-01 00:00:00  203500.000000  204000.000000  334600.00000  410400.000   \n",
       "2018-03-01 00:00:00  206600.000000  206700.000000  338800.00000  413700.000   \n",
       "2018-04-01 00:00:00  209300.000000  208600.000000  342000.00000  416100.000   \n",
       "2018-05-01_pred      212876.996122  212357.255857  343835.59375  421466.875   \n",
       "\n",
       "                            89123          89031          89110      89074  \\\n",
       "1996-04-01 00:00:00  144000.00000  122800.000000   95800.000000  148000.00   \n",
       "1996-05-01 00:00:00  143500.00000  122800.000000   95800.000000  147800.00   \n",
       "1996-06-01 00:00:00  143100.00000  122700.000000   95800.000000  147600.00   \n",
       "1996-07-01 00:00:00  142700.00000  122700.000000   95900.000000  147300.00   \n",
       "1996-08-01 00:00:00  142400.00000  122700.000000   96100.000000  147100.00   \n",
       "...                           ...            ...            ...        ...   \n",
       "2018-01-01 00:00:00  294300.00000  234600.000000  189200.000000  303500.00   \n",
       "2018-02-01 00:00:00  297400.00000  237200.000000  191700.000000  306700.00   \n",
       "2018-03-01 00:00:00  300200.00000  239800.000000  194500.000000  309800.00   \n",
       "2018-04-01 00:00:00  302400.00000  241900.000000  196600.000000  312200.00   \n",
       "2018-05-01_pred      303811.84375  246300.944755  200482.013725  312865.75   \n",
       "\n",
       "                             89103        89148  ...        89444     89085  \\\n",
       "1996-04-01 00:00:00  118900.000000  157300.0000  ...  116800.0000  170900.0   \n",
       "1996-05-01 00:00:00  119000.000000  156000.0000  ...  117000.0000  170800.0   \n",
       "1996-06-01 00:00:00  119000.000000  154700.0000  ...  117200.0000  170700.0   \n",
       "1996-07-01 00:00:00  119100.000000  153500.0000  ...  117400.0000  170700.0   \n",
       "1996-08-01 00:00:00  119200.000000  152600.0000  ...  117600.0000  170700.0   \n",
       "...                            ...          ...  ...          ...       ...   \n",
       "2018-01-01 00:00:00  243700.000000  294100.0000  ...  270000.0000  316500.0   \n",
       "2018-02-01 00:00:00  246300.000000  296900.0000  ...  275600.0000  319500.0   \n",
       "2018-03-01 00:00:00  249500.000000  299400.0000  ...  282100.0000  322400.0   \n",
       "2018-04-01 00:00:00  252000.000000  300800.0000  ...  286000.0000  324700.0   \n",
       "2018-05-01_pred      251018.223795  305326.5625  ...  279638.8125  330100.0   \n",
       "\n",
       "                        89034     89021         89439     89411        89124  \\\n",
       "1996-04-01 00:00:00  196000.0  153200.0  184200.00000  299200.0  166100.0000   \n",
       "1996-05-01 00:00:00  196000.0  153700.0  185000.00000  299600.0  166600.0000   \n",
       "1996-06-01 00:00:00  195900.0  154100.0  185800.00000  299900.0  167300.0000   \n",
       "1996-07-01 00:00:00  195700.0  154400.0  186400.00000  300200.0  167900.0000   \n",
       "1996-08-01 00:00:00  195400.0  154700.0  186900.00000  300500.0  168600.0000   \n",
       "...                       ...       ...           ...       ...          ...   \n",
       "2018-01-01 00:00:00  315500.0  299900.0  449500.00000  642500.0  317600.0000   \n",
       "2018-02-01 00:00:00  319500.0  302500.0  450100.00000  653800.0  323400.0000   \n",
       "2018-03-01 00:00:00  323600.0  305700.0  451100.00000  666000.0  334700.0000   \n",
       "2018-04-01 00:00:00  326600.0  307800.0  455300.00000  672600.0  344300.0000   \n",
       "2018-05-01_pred           0.0       0.0  453697.84375       0.0  333740.6875   \n",
       "\n",
       "                        89440        89413         89155  \n",
       "1996-04-01 00:00:00  293200.0   562400.000  176400.00000  \n",
       "1996-05-01 00:00:00  293200.0   562800.000  176300.00000  \n",
       "1996-06-01 00:00:00  293200.0   562700.000  176100.00000  \n",
       "1996-07-01 00:00:00  293200.0   562400.000  176000.00000  \n",
       "1996-08-01 00:00:00  293200.0   562300.000  175900.00000  \n",
       "...                       ...          ...           ...  \n",
       "2018-01-01 00:00:00  201600.0  2121300.000  350400.00000  \n",
       "2018-02-01 00:00:00  207000.0  2153600.000  353000.00000  \n",
       "2018-03-01 00:00:00  216500.0  2167100.000  356000.00000  \n",
       "2018-04-01 00:00:00  222800.0  2161900.000  357200.00000  \n",
       "2018-05-01_pred      190700.0  2082682.875  361679.90625  \n",
       "\n",
       "[266 rows x 103 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 48085.5508 - val_loss: 70.4427\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 132760.1406 - val_loss: 70.2606\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 83623.4375 - val_loss: 77.6148\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16281.0430 - val_loss: 79.2507\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4100.2905 - val_loss: 77.4637\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 70966.1016 - val_loss: 77.3141\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54380.8008 - val_loss: 80.6926\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17259.9961 - val_loss: 81.6933\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7471.9990 - val_loss: 80.0082\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 55874.8086 - val_loss: 79.7206\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33641.9766 - val_loss: 81.3715\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27480.5762 - val_loss: 83.6959\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17681.2930 - val_loss: 82.4140\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21191.7324 - val_loss: 82.5766\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13569.1592 - val_loss: 83.4720\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8530.3281 - val_loss: 84.3346\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13691.3613 - val_loss: 83.6648\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21160.4219 - val_loss: 83.4899\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4673.2422 - val_loss: 84.8462\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30500.9238 - val_loss: 85.5635\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26431.3613 - val_loss: 84.5232\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2644.3977 - val_loss: 85.0466\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7191.6299 - val_loss: 84.2816\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14878.9160 - val_loss: 84.9828\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3943.1587 - val_loss: 84.8064\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16847.7852 - val_loss: 84.9109\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2616.3237 - val_loss: 86.2734\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35914.9219 - val_loss: 86.7591\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27253.4531 - val_loss: 86.1380\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5131.1235 - val_loss: 84.1875\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 62452.5938 - val_loss: 83.5330\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 58700.8750 - val_loss: 84.8473\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23360.2363 - val_loss: 86.5859\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3693.9766 - val_loss: 89.2188\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 85035.7109 - val_loss: 90.5022\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 72314.6719 - val_loss: 90.2431\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33161.1562 - val_loss: 89.1218\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9052.6055 - val_loss: 87.0567\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 62542.1250 - val_loss: 86.4001\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 69204.7500 - val_loss: 87.2910\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51822.3555 - val_loss: 88.3313\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19332.3750 - val_loss: 89.4425\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11744.0225 - val_loss: 90.5121\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14191.7168 - val_loss: 90.1349\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3656.2295 - val_loss: 90.3574\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7948.5322 - val_loss: 90.2888\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 601.0316 - val_loss: 89.3877\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29169.0723 - val_loss: 89.4420\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24290.5371 - val_loss: 90.0256\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1489.8262 - val_loss: 90.8719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 0 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 109346.1250 - val_loss: 110.0506\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 147550.9531 - val_loss: 105.7346\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 66764.4062 - val_loss: 106.5142\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 58314.0117 - val_loss: 110.3191\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 208475.2969 - val_loss: 107.2347\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 74132.5938 - val_loss: 101.7326\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 223629.0000 - val_loss: 100.0141\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 141416.0469 - val_loss: 103.1070\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 92367.4141 - val_loss: 106.2805\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 143432.3906 - val_loss: 104.2293\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45207.4492 - val_loss: 101.9201\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 122365.9844 - val_loss: 102.9886\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 53778.3711 - val_loss: 106.2193\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 196343.1094 - val_loss: 106.8525\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 120794.7500 - val_loss: 104.3534\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39095.1758 - val_loss: 103.3664\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23567.3750 - val_loss: 104.0257\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24152.8008 - val_loss: 103.1609\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11612.9590 - val_loss: 102.8549\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7647.1333 - val_loss: 102.6429\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7336.5732 - val_loss: 102.7357\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21894.1504 - val_loss: 102.2689\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47039.7930 - val_loss: 102.0769\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9010.8369 - val_loss: 102.6413\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18529.8652 - val_loss: 103.1552\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34614.7500 - val_loss: 104.1159\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 58685.3477 - val_loss: 103.1019\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11822.0391 - val_loss: 102.6107\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18632.1543 - val_loss: 103.0826\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24711.2402 - val_loss: 102.3591\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35754.2500 - val_loss: 101.7047\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31786.0781 - val_loss: 102.5519\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19561.6055 - val_loss: 101.7361\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24974.7695 - val_loss: 102.3831\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38869.0234 - val_loss: 102.4058\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19743.2578 - val_loss: 101.4325\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8262.8154 - val_loss: 101.8102\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22733.8867 - val_loss: 101.3125\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28166.1191 - val_loss: 101.3769\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31717.3164 - val_loss: 102.6816\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 73777.2734 - val_loss: 101.8668\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21870.4961 - val_loss: 100.8936\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 77222.9375 - val_loss: 101.6067\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31175.2793 - val_loss: 102.8830\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29081.9629 - val_loss: 102.2317\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11030.8926 - val_loss: 102.8061\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30958.6641 - val_loss: 102.4581\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15530.6846 - val_loss: 102.4660\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16757.1543 - val_loss: 102.3256\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19381.2422 - val_loss: 102.5926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 1 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 57.7800 - val_loss: 38.7170\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47.7402 - val_loss: 29.1224\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.9042 - val_loss: 37.6954\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32.6638 - val_loss: 33.0170\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27.6202 - val_loss: 19.6893\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24.5426 - val_loss: 12.7351\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20.5773 - val_loss: 17.0647\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.2276 - val_loss: 7.6647\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.2309 - val_loss: 7.9649\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.5134 - val_loss: 3.1358\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.7345 - val_loss: 4.1382\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.1945 - val_loss: 3.2758\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.3860 - val_loss: 3.2250\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.2269 - val_loss: 3.3523\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.6959 - val_loss: 4.3220\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.5364 - val_loss: 4.2952\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.3206 - val_loss: 3.6108\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1737 - val_loss: 4.1865\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.9154 - val_loss: 2.8963\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.9555 - val_loss: 2.7851\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1922 - val_loss: 3.3643\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7951 - val_loss: 3.5323\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5698 - val_loss: 3.1342\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.4127 - val_loss: 3.7309\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.0911 - val_loss: 3.9261\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5672 - val_loss: 3.2349\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6393 - val_loss: 3.1375\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2719 - val_loss: 3.6234\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.6874 - val_loss: 5.6890\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9913 - val_loss: 1.3568\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3143 - val_loss: 3.2321\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5163 - val_loss: 3.2041\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6665 - val_loss: 3.2308\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7309 - val_loss: 3.4179\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.3764 - val_loss: 2.8847\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3306 - val_loss: 3.9104\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4901 - val_loss: 1.7017\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4642 - val_loss: 5.4694\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4671 - val_loss: 1.8831\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9132 - val_loss: 3.3267\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9844 - val_loss: 2.7028\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9894 - val_loss: 2.4549\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8054 - val_loss: 5.0506\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2226 - val_loss: 1.5944\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6545 - val_loss: 3.6213\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5004 - val_loss: 2.6501\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4742 - val_loss: 2.5832\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4375 - val_loss: 4.1670\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5028 - val_loss: 1.4440\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3592 - val_loss: 3.5887\n",
      "Iteration number 2 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 121.5051 - val_loss: 98.1408\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 69.8706 - val_loss: 52.8936\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33.6626 - val_loss: 12.6598\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31.6024 - val_loss: 24.3897\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.6426 - val_loss: 35.0597\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23.0239 - val_loss: 31.8119\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.5397 - val_loss: 19.4544\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.0029 - val_loss: 11.9570\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.2919 - val_loss: 15.2965\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.5507 - val_loss: 13.8847\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.7442 - val_loss: 9.7035\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1657 - val_loss: 5.1673\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9794 - val_loss: 4.5045\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.7045 - val_loss: 6.2826\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4863 - val_loss: 4.3956\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7229 - val_loss: 5.3275\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5248 - val_loss: 4.8954\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5808 - val_loss: 6.2427\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4102 - val_loss: 3.2227\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.2143 - val_loss: 6.4173\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9911 - val_loss: 2.5714\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9056 - val_loss: 5.3130\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5369 - val_loss: 2.9524\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2636 - val_loss: 3.8850\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0913 - val_loss: 4.8019\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9966 - val_loss: 3.5707\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8496 - val_loss: 2.8522\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.6344 - val_loss: 3.4213\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5272 - val_loss: 2.3893\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5236 - val_loss: 4.1486\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5960 - val_loss: 2.4846\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0835 - val_loss: 4.1698\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2015 - val_loss: 2.3473\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3006 - val_loss: 3.4400\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0146 - val_loss: 2.6533\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0618 - val_loss: 3.7348\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8336 - val_loss: 2.6351\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0808 - val_loss: 3.8175\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8894 - val_loss: 2.4410\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0216 - val_loss: 2.7733\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4634 - val_loss: 2.4836\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.1897 - val_loss: 2.4220\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2449 - val_loss: 2.9221\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.0298 - val_loss: 2.6046\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2752 - val_loss: 3.3456\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4389 - val_loss: 2.5416\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6579 - val_loss: 2.7945\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0188 - val_loss: 2.1996\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5487 - val_loss: 2.1385\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.4989 - val_loss: 2.1491\n",
      "Iteration number 3 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 77.7590 - val_loss: 62.2216\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52.8757 - val_loss: 32.5403\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.3793 - val_loss: 32.4866\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28.4981 - val_loss: 25.9237\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24.3893 - val_loss: 10.9301\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.3096 - val_loss: 12.3044\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18.8514 - val_loss: 5.8748\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.7729 - val_loss: 8.5945\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.1014 - val_loss: 5.2465\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.6711 - val_loss: 6.9480\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.4464 - val_loss: 6.2344\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.8733 - val_loss: 6.2258\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.0257 - val_loss: 5.4233\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.5675 - val_loss: 5.6769\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0420 - val_loss: 4.7492\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.7571 - val_loss: 6.6264\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.5149 - val_loss: 4.7006\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.3851 - val_loss: 5.2099\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.0838 - val_loss: 6.0328\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7229 - val_loss: 4.7526\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2819 - val_loss: 5.6426\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8099 - val_loss: 4.7364\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5478 - val_loss: 5.5266\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7376 - val_loss: 4.2110\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1953 - val_loss: 4.5155\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0600 - val_loss: 6.6158\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3006 - val_loss: 2.9273\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2837 - val_loss: 7.6977\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7427 - val_loss: 2.9116\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9320 - val_loss: 5.4538\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.2993 - val_loss: 3.6150\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6132 - val_loss: 4.3487\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8866 - val_loss: 3.5119\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6111 - val_loss: 4.7978\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7177 - val_loss: 2.7650\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6389 - val_loss: 6.5308\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0376 - val_loss: 2.7883\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4135 - val_loss: 4.9035\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9966 - val_loss: 2.6206\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1756 - val_loss: 5.0159\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3034 - val_loss: 3.3395\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1236 - val_loss: 3.5082\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2660 - val_loss: 4.1668\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9947 - val_loss: 3.8021\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1060 - val_loss: 2.7649\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8246 - val_loss: 3.4127\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3429 - val_loss: 3.0853\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1831 - val_loss: 4.1254\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4432 - val_loss: 2.3130\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9195 - val_loss: 3.8350\n",
      "Iteration number 4 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 21822.1758 - val_loss: 66.6627\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 278095.0000 - val_loss: 61.0409\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 243388.0469 - val_loss: 73.0938\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19088.5039 - val_loss: 80.1178\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 98212.2812 - val_loss: 84.6682\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85591.3672 - val_loss: 83.2650\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29839.6113 - val_loss: 80.4944\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17158.7500 - val_loss: 80.3800\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32677.5566 - val_loss: 80.9825\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1766.8317 - val_loss: 84.6360\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 68457.9844 - val_loss: 86.2526\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73539.0625 - val_loss: 86.0142\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 52387.8711 - val_loss: 82.7192\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37307.6680 - val_loss: 81.3724\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36557.4258 - val_loss: 83.0757\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2394.5566 - val_loss: 85.7901\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50162.1758 - val_loss: 86.2957\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48637.4141 - val_loss: 84.7273\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10677.4463 - val_loss: 82.4272\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 58390.6992 - val_loss: 81.3686\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 36485.7812 - val_loss: 83.0803\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8574.5234 - val_loss: 85.0163\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13072.9834 - val_loss: 84.6329\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9898.4336 - val_loss: 84.6160\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 272.7167 - val_loss: 83.8581\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30285.3262 - val_loss: 83.6725\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16258.2109 - val_loss: 86.4272\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44953.3242 - val_loss: 87.3630\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 44230.2773 - val_loss: 86.2764\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15095.3945 - val_loss: 84.2313\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30413.2441 - val_loss: 84.0591\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28699.4238 - val_loss: 85.4346\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4390.5928 - val_loss: 87.8748\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60047.9141 - val_loss: 88.7170\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52304.8633 - val_loss: 87.9274\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25767.5781 - val_loss: 85.9350\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28364.9629 - val_loss: 84.9669\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26296.1504 - val_loss: 85.5686\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3798.3250 - val_loss: 86.6740\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1733.9213 - val_loss: 85.8244\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32979.0469 - val_loss: 85.3226\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27823.3789 - val_loss: 87.6184\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28147.6875 - val_loss: 88.1971\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25543.9941 - val_loss: 86.9976\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15363.8799 - val_loss: 86.6796\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5257.8311 - val_loss: 88.6821\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29687.6309 - val_loss: 88.9374\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34145.5352 - val_loss: 88.5834\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19429.6934 - val_loss: 86.8757\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20260.4941 - val_loss: 86.6655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 5 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 49257.1445 - val_loss: 75.1683\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 174727.6406 - val_loss: 84.2641\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 85958.7344 - val_loss: 80.4554\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 55797.0273 - val_loss: 72.5885\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 130791.7500 - val_loss: 71.1461\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 131899.7500 - val_loss: 72.8724\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 88555.0078 - val_loss: 78.7432\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15554.0703 - val_loss: 81.7803\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13656.5234 - val_loss: 80.5230\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15254.9111 - val_loss: 81.3196\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1163.7451 - val_loss: 82.4682\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12201.6885 - val_loss: 83.1782\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26822.4883 - val_loss: 82.6898\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6725.0737 - val_loss: 82.2745\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1490.1140 - val_loss: 81.1490\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27325.3555 - val_loss: 81.8193\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5645.5376 - val_loss: 82.2886\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3249.4192 - val_loss: 82.5550\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1530.6379 - val_loss: 81.4564\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21088.8379 - val_loss: 82.1136\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5914.4551 - val_loss: 83.3900\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40788.2617 - val_loss: 84.5884\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23223.3965 - val_loss: 82.2919\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38253.2383 - val_loss: 81.2315\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33000.8828 - val_loss: 82.8365\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4512.6631 - val_loss: 83.2635\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9473.4541 - val_loss: 83.4883\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15611.6582 - val_loss: 84.2471\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11768.6895 - val_loss: 82.7854\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22944.1113 - val_loss: 83.0757\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7327.7222 - val_loss: 84.0421\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4092.2727 - val_loss: 84.6444\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17391.3359 - val_loss: 83.9798\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4412.9126 - val_loss: 84.3902\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13334.8135 - val_loss: 84.1739\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2182.9956 - val_loss: 81.6623\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55193.2422 - val_loss: 81.6113\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49904.8281 - val_loss: 82.9430\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8279.4443 - val_loss: 84.7449\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37103.9375 - val_loss: 86.6305\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41189.8516 - val_loss: 85.9113\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14032.0547 - val_loss: 84.4070\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12615.0176 - val_loss: 84.4464\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14344.5957 - val_loss: 85.5959\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12077.3799 - val_loss: 85.4175\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 682.0203 - val_loss: 84.0292\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42138.1836 - val_loss: 83.6379\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32827.3164 - val_loss: 85.0254\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10237.7568 - val_loss: 85.8917\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2236.0781 - val_loss: 85.9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 6 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 70.4585 - val_loss: 52.4626\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 59.8631 - val_loss: 31.5861\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 49.1708 - val_loss: 41.0355\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40.6009 - val_loss: 43.9696\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.5320 - val_loss: 34.5629\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29.5127 - val_loss: 18.7960\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27.6072 - val_loss: 16.7483\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24.6715 - val_loss: 20.5479\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21.0080 - val_loss: 10.8983\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19.0879 - val_loss: 9.2620\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.7670 - val_loss: 4.8063\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.5454 - val_loss: 3.8681\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.3197 - val_loss: 3.5730\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.6006 - val_loss: 4.4237\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.3417 - val_loss: 3.2173\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.3563 - val_loss: 5.5764\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.1957 - val_loss: 2.6943\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.7386 - val_loss: 5.2321\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.9650 - val_loss: 2.5592\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.7345 - val_loss: 3.6024\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.3038 - val_loss: 6.9486\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.6672 - val_loss: 2.7378\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.2256 - val_loss: 5.4476\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9362 - val_loss: 2.4694\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1893 - val_loss: 4.4058\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7607 - val_loss: 4.6274\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9782 - val_loss: 3.8548\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9902 - val_loss: 5.3803\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9153 - val_loss: 3.5704\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5732 - val_loss: 4.7788\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5802 - val_loss: 4.3089\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4157 - val_loss: 2.9695\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9720 - val_loss: 6.7014\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.8376 - val_loss: 2.4598\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6624 - val_loss: 6.6105\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8076 - val_loss: 5.0773\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9316 - val_loss: 3.9931\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3465 - val_loss: 3.9850\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9208 - val_loss: 4.8455\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1502 - val_loss: 3.8232\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5770 - val_loss: 3.5053\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4641 - val_loss: 4.4907\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5535 - val_loss: 4.8769\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7550 - val_loss: 2.6664\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7338 - val_loss: 4.9406\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0641 - val_loss: 4.7119\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4256 - val_loss: 2.7555\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2633 - val_loss: 4.7368\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4631 - val_loss: 3.9255\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1849 - val_loss: 3.4388\n",
      "Iteration number 7 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 43704.4375 - val_loss: 99.1301\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 220012.8594 - val_loss: 99.6690\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 133430.6562 - val_loss: 102.6879\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 84371.6484 - val_loss: 110.8555\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46256.4219 - val_loss: 112.6356\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 64769.5273 - val_loss: 111.5170\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37436.0469 - val_loss: 107.0152\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32868.8789 - val_loss: 106.1037\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31703.7637 - val_loss: 107.0353\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1259.1360 - val_loss: 107.2674\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9532.0947 - val_loss: 108.5089\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14963.8486 - val_loss: 107.2787\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8444.9297 - val_loss: 108.0279\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20027.4336 - val_loss: 107.6932\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 737.0588 - val_loss: 108.1886\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27881.3945 - val_loss: 108.1619\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16709.0996 - val_loss: 104.6144\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 60539.0195 - val_loss: 103.4673\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 54766.1133 - val_loss: 105.8723\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10115.4873 - val_loss: 109.2828\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 73259.6875 - val_loss: 110.2494\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 65283.1836 - val_loss: 108.2023\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20526.3184 - val_loss: 105.4549\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30624.6289 - val_loss: 103.6722\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30094.3887 - val_loss: 104.9450\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4468.0742 - val_loss: 104.8408\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12634.7305 - val_loss: 104.7301\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8520.0107 - val_loss: 105.2020\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1680.6644 - val_loss: 104.4063\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38242.4961 - val_loss: 102.8238\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31916.7266 - val_loss: 104.6564\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16577.8574 - val_loss: 105.2571\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12480.1367 - val_loss: 103.3047\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25847.0176 - val_loss: 103.3332\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15101.6064 - val_loss: 104.2155\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4745.9741 - val_loss: 104.2926\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1090.4459 - val_loss: 104.5574\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31230.4570 - val_loss: 105.6407\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18603.3262 - val_loss: 104.1961\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10664.7783 - val_loss: 103.4821\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8962.1270 - val_loss: 104.5885\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12737.6465 - val_loss: 104.1285\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4153.5698 - val_loss: 102.7772\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31693.1719 - val_loss: 102.3420\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24643.5020 - val_loss: 103.7663\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11454.1133 - val_loss: 103.9680\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6854.0239 - val_loss: 102.4371\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21573.7949 - val_loss: 102.7130\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13294.9170 - val_loss: 103.6464\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16605.9375 - val_loss: 104.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 8 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 87.3541 - val_loss: 72.9971\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 66.2597 - val_loss: 51.4525\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 50.9399 - val_loss: 54.0616\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 44.4303 - val_loss: 43.8415\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.9074 - val_loss: 23.3005\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32.1542 - val_loss: 22.6162\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 28.0417 - val_loss: 21.8710\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25.1126 - val_loss: 7.8102\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24.0170 - val_loss: 11.4138\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22.6644 - val_loss: 7.3767\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21.0039 - val_loss: 5.7574\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20.0011 - val_loss: 6.5669\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.6573 - val_loss: 3.9642\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.0647 - val_loss: 5.4969\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.9454 - val_loss: 4.1710\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.7678 - val_loss: 5.0573\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.2534 - val_loss: 4.9751\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.5106 - val_loss: 4.4392\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.2483 - val_loss: 4.5322\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.2924 - val_loss: 5.7460\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.3490 - val_loss: 5.5891\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.6679 - val_loss: 4.1939\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.5113 - val_loss: 3.9765\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.5851 - val_loss: 3.5263\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.6658 - val_loss: 5.0527\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.8604 - val_loss: 4.3459\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.6830 - val_loss: 3.6877\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.3302 - val_loss: 3.0715\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.2126 - val_loss: 3.9627\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9290 - val_loss: 3.3355\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9314 - val_loss: 3.5394\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4699 - val_loss: 2.9690\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.2564 - val_loss: 4.6300\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4297 - val_loss: 2.7556\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7864 - val_loss: 2.9279\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8689 - val_loss: 2.5131\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5521 - val_loss: 2.4654\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7299 - val_loss: 2.7864\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9957 - val_loss: 3.3180\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3431 - val_loss: 2.3160\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1101 - val_loss: 2.5390\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.2042 - val_loss: 2.4922\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8314 - val_loss: 2.6316\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6041 - val_loss: 3.4282\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7687 - val_loss: 3.6547\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9132 - val_loss: 2.6088\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2923 - val_loss: 3.8149\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7974 - val_loss: 2.5594\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4599 - val_loss: 2.4905\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7840 - val_loss: 2.4944\n",
      "Iteration number 9 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 194146.2031 - val_loss: 91.2233\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37392.7891 - val_loss: 105.5105\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 78061.4297 - val_loss: 109.6370\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 99360.8750 - val_loss: 107.0429\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39949.4023 - val_loss: 102.7615\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48901.6094 - val_loss: 100.6551\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37036.6914 - val_loss: 102.3920\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8329.1133 - val_loss: 103.0695\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3161.9983 - val_loss: 104.2536\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34915.9414 - val_loss: 104.0986\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20275.1309 - val_loss: 100.5845\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 54855.2734 - val_loss: 100.1002\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 42309.0391 - val_loss: 102.6091\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 764.4224 - val_loss: 102.1079\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8228.2998 - val_loss: 103.7323\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42674.8477 - val_loss: 104.3194\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24975.6543 - val_loss: 100.4705\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44221.5312 - val_loss: 99.6667\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 46403.6484 - val_loss: 100.4861\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15732.7930 - val_loss: 103.3634\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24073.8359 - val_loss: 103.7193\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34591.6484 - val_loss: 103.3048\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23806.3262 - val_loss: 99.3253\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 77842.7734 - val_loss: 97.8311\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 74366.2266 - val_loss: 98.7125\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44996.5742 - val_loss: 101.1795\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16431.8379 - val_loss: 102.4123\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13777.9795 - val_loss: 101.5985\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 979.8381 - val_loss: 101.7888\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5672.4331 - val_loss: 101.4346\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31771.2207 - val_loss: 100.2361\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27669.8848 - val_loss: 102.3042\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27697.6152 - val_loss: 102.6141\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21277.8848 - val_loss: 101.2202\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20485.4512 - val_loss: 100.7854\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10477.2188 - val_loss: 102.0625\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12798.6953 - val_loss: 101.9669\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10226.9053 - val_loss: 101.5012\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20448.4336 - val_loss: 100.5384\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18521.5430 - val_loss: 101.6593\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10130.0703 - val_loss: 101.4895\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 647.6997 - val_loss: 100.1820\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26081.6992 - val_loss: 100.4125\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19970.2617 - val_loss: 101.5379\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20045.1641 - val_loss: 102.0066\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9888.8154 - val_loss: 100.1273\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49885.9023 - val_loss: 99.2055\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39684.8438 - val_loss: 100.5360\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5745.2241 - val_loss: 101.3284\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4448.2510 - val_loss: 101.4091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 10 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 89954.0078 - val_loss: 91.2521\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 99238.4531 - val_loss: 99.0914\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 201925.3125 - val_loss: 100.8140\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 85286.3672 - val_loss: 96.2172\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 64518.0117 - val_loss: 89.8943\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 223559.5469 - val_loss: 90.6342\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 140403.8281 - val_loss: 94.7843\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57481.1719 - val_loss: 98.8798\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 100805.9766 - val_loss: 97.8058\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37408.0117 - val_loss: 94.1452\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 67701.1641 - val_loss: 94.0391\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 67356.7969 - val_loss: 95.2350\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47401.3438 - val_loss: 98.6151\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 82666.4375 - val_loss: 98.1280\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34458.4883 - val_loss: 95.9142\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56328.3281 - val_loss: 95.6354\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 51091.1289 - val_loss: 97.0188\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37198.7695 - val_loss: 99.0919\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 84553.9531 - val_loss: 97.8873\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37153.9805 - val_loss: 95.1163\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 100535.7891 - val_loss: 94.6236\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 68811.6875 - val_loss: 96.0318\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18022.1211 - val_loss: 96.8512\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25667.2559 - val_loss: 95.7576\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41196.1797 - val_loss: 97.2602\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 48640.0898 - val_loss: 97.7349\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23794.7031 - val_loss: 96.3353\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52417.3633 - val_loss: 96.9998\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15565.4932 - val_loss: 99.2835\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 90627.4219 - val_loss: 99.4782\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 72094.8750 - val_loss: 98.0480\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38005.1328 - val_loss: 96.4539\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 70629.4297 - val_loss: 97.0574\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21435.8301 - val_loss: 99.2424\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 78648.5703 - val_loss: 99.7715\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 73722.3984 - val_loss: 98.6897\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15869.5391 - val_loss: 96.4520\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 89753.6250 - val_loss: 96.1995\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83566.0859 - val_loss: 96.8861\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15400.4375 - val_loss: 99.2814\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 77460.9766 - val_loss: 100.2577\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77339.0234 - val_loss: 98.9139\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20880.8457 - val_loss: 97.0213\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40489.1680 - val_loss: 97.4451\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1371.6830 - val_loss: 97.0177\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21183.4121 - val_loss: 97.3123\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15556.4092 - val_loss: 97.5631\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1886.7164 - val_loss: 97.6034\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30989.3086 - val_loss: 97.9399\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7025.7095 - val_loss: 97.6318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 11 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 69382.6797 - val_loss: 115.0790\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 606383.5625 - val_loss: 114.7181\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 439804.6875 - val_loss: 102.6088\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 111621.2891 - val_loss: 90.8820\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 267555.8750 - val_loss: 88.5235\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 230514.0000 - val_loss: 91.4206\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 82716.3828 - val_loss: 96.3592\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14539.1484 - val_loss: 95.2976\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49433.7656 - val_loss: 96.6296\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4999.0210 - val_loss: 96.0011\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40207.2656 - val_loss: 96.8227\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5155.4731 - val_loss: 97.6214\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14337.0967 - val_loss: 96.3619\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50128.8164 - val_loss: 96.9181\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6374.0264 - val_loss: 97.2677\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23100.2949 - val_loss: 98.2296\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49986.2578 - val_loss: 98.4613\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3094.9084 - val_loss: 98.1470\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13498.7266 - val_loss: 97.5598\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11093.8408 - val_loss: 98.5925\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25429.2793 - val_loss: 96.6683\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61704.2812 - val_loss: 97.5327\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10719.7734 - val_loss: 98.8768\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18933.4844 - val_loss: 97.5069\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 65030.8438 - val_loss: 97.6344\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29782.9961 - val_loss: 99.3203\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36990.1133 - val_loss: 97.9376\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23704.3984 - val_loss: 98.0210\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10543.5967 - val_loss: 101.2127\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 119640.4375 - val_loss: 101.0668\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 95706.9531 - val_loss: 99.5676\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54881.2500 - val_loss: 96.9135\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 76294.5078 - val_loss: 98.1825\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12300.8418 - val_loss: 98.9801\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23939.7070 - val_loss: 99.0696\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12855.0967 - val_loss: 100.0510\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14493.3154 - val_loss: 98.7366\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 75727.9844 - val_loss: 98.2645\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 51535.2617 - val_loss: 101.5468\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 110216.2344 - val_loss: 102.6536\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 76458.8281 - val_loss: 101.0045\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19351.8184 - val_loss: 99.8118\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5967.8481 - val_loss: 100.3505\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13746.6309 - val_loss: 99.7553\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13342.8574 - val_loss: 100.1054\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7535.4312 - val_loss: 97.9607\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 80911.8125 - val_loss: 98.0222\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36020.7930 - val_loss: 99.7872\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26950.5996 - val_loss: 100.5058\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25204.7930 - val_loss: 98.9528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 12 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 92802.8828 - val_loss: 74.1958\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 79310.2578 - val_loss: 70.2526\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 58440.7109 - val_loss: 80.2672\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 231945.5312 - val_loss: 84.1281\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 171110.0156 - val_loss: 78.5308\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35661.2188 - val_loss: 77.9873\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19114.3809 - val_loss: 79.6024\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8762.4482 - val_loss: 80.5365\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16172.6436 - val_loss: 81.2652\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16745.9844 - val_loss: 82.7680\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20170.5469 - val_loss: 81.9175\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15817.8916 - val_loss: 83.4123\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30248.7734 - val_loss: 80.8918\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 52323.8164 - val_loss: 81.3577\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7677.7954 - val_loss: 82.6473\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35935.1875 - val_loss: 85.0846\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40099.7070 - val_loss: 83.6986\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 66056.7734 - val_loss: 82.9283\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35682.3555 - val_loss: 85.2492\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5878.4404 - val_loss: 84.9858\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21627.7324 - val_loss: 86.1649\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17887.1211 - val_loss: 85.1048\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13143.5889 - val_loss: 86.1922\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39629.9531 - val_loss: 83.6556\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45731.8086 - val_loss: 83.8715\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30116.0820 - val_loss: 86.1606\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35117.4102 - val_loss: 84.9647\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29380.2500 - val_loss: 85.8719\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15584.5439 - val_loss: 84.8599\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 70919.7422 - val_loss: 84.7225\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 46809.1875 - val_loss: 89.8191\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 197815.2031 - val_loss: 91.9163\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 170675.6719 - val_loss: 90.6500\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 67999.2734 - val_loss: 88.0335\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 62281.5977 - val_loss: 86.8159\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 71681.0312 - val_loss: 87.8457\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10962.0225 - val_loss: 89.9913\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 52373.9297 - val_loss: 90.8108\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 53263.1133 - val_loss: 90.0997\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30943.3555 - val_loss: 89.0669\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39850.9688 - val_loss: 89.9086\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18836.3496 - val_loss: 92.5290\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 90397.4766 - val_loss: 92.4925\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 84265.0000 - val_loss: 91.0737\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33904.8867 - val_loss: 89.5997\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40763.3984 - val_loss: 91.6551\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24331.0762 - val_loss: 91.7257\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20184.0234 - val_loss: 91.1431\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29601.2344 - val_loss: 92.3118\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22858.5391 - val_loss: 92.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 13 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 57503.3672 - val_loss: 112.4765\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 140512.6875 - val_loss: 118.7352\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 75079.7891 - val_loss: 111.9488\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48358.2812 - val_loss: 107.3479\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18020.6621 - val_loss: 109.9244\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 61944.6914 - val_loss: 113.4867\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57475.7969 - val_loss: 110.0753\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8094.8267 - val_loss: 110.0736\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6239.7852 - val_loss: 109.4091\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 28057.2988 - val_loss: 108.8209\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15113.0918 - val_loss: 111.5793\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45503.3359 - val_loss: 112.0193\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38122.7188 - val_loss: 109.2179\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7562.8066 - val_loss: 109.7677\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8200.1348 - val_loss: 109.4004\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2836.8308 - val_loss: 109.1595\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7920.9434 - val_loss: 110.0022\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32287.6582 - val_loss: 110.9653\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24986.0645 - val_loss: 107.3160\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36978.7891 - val_loss: 107.2400\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37840.6953 - val_loss: 108.8817\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10026.5186 - val_loss: 109.5256\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20847.9590 - val_loss: 108.5125\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3520.1304 - val_loss: 111.0477\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39781.0234 - val_loss: 111.5789\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40927.2852 - val_loss: 110.7424\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14593.7744 - val_loss: 108.1394\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36874.8633 - val_loss: 107.1504\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35710.8398 - val_loss: 107.9029\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21354.9004 - val_loss: 110.8227\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54767.1758 - val_loss: 111.7659\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 47657.0234 - val_loss: 110.6987\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25837.1875 - val_loss: 108.0095\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25404.7031 - val_loss: 107.4397\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27756.7109 - val_loss: 108.0257\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 809.8970 - val_loss: 109.9070\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29026.0918 - val_loss: 110.4357\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31221.4414 - val_loss: 108.9121\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5256.5688 - val_loss: 106.7544\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40512.9805 - val_loss: 106.5961\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34218.7188 - val_loss: 107.5695\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 317.1206 - val_loss: 109.2530\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20405.2637 - val_loss: 109.5175\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29354.2637 - val_loss: 109.0191\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8433.9502 - val_loss: 107.2303\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37155.2812 - val_loss: 106.4088\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33347.9414 - val_loss: 107.4062\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1341.8766 - val_loss: 109.0574\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46505.7734 - val_loss: 110.2940\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38791.7852 - val_loss: 108.3601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 14 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 181269.4062 - val_loss: 93.4778\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38251.5156 - val_loss: 106.1953\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 198152.3906 - val_loss: 108.3581\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 167681.2812 - val_loss: 105.2836\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 92015.1016 - val_loss: 101.0465\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33380.8438 - val_loss: 95.8060\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 101150.6406 - val_loss: 94.3402\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 98898.3438 - val_loss: 95.9631\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47243.5391 - val_loss: 98.2394\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14596.7314 - val_loss: 99.1021\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12108.1680 - val_loss: 97.7024\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 42535.4102 - val_loss: 97.5412\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20937.9844 - val_loss: 98.6468\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15691.8057 - val_loss: 99.7843\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22384.0801 - val_loss: 99.4257\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2316.1912 - val_loss: 97.4796\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60094.0977 - val_loss: 97.0265\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55923.1445 - val_loss: 98.1014\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33130.2383 - val_loss: 100.4285\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37927.3047 - val_loss: 101.0056\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34967.0078 - val_loss: 99.7806\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14906.5029 - val_loss: 99.4324\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7394.0576 - val_loss: 99.8743\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4613.1665 - val_loss: 100.0491\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17461.1562 - val_loss: 100.2434\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6938.7983 - val_loss: 98.8122\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26859.6914 - val_loss: 98.9335\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23641.7656 - val_loss: 99.5317\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5925.1367 - val_loss: 99.9793\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3449.3630 - val_loss: 100.3796\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14296.5908 - val_loss: 100.0711\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2281.6531 - val_loss: 98.6124\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45335.5742 - val_loss: 98.5025\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36699.1250 - val_loss: 99.7607\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11065.6904 - val_loss: 100.3337\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3301.9729 - val_loss: 100.3016\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4274.8398 - val_loss: 99.5992\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21524.6641 - val_loss: 99.6693\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12916.7373 - val_loss: 101.3061\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28429.3555 - val_loss: 101.2613\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26093.1289 - val_loss: 100.4036\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8382.4355 - val_loss: 100.1997\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6404.1729 - val_loss: 100.2953\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11638.8975 - val_loss: 100.0162\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6087.7373 - val_loss: 100.8247\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26468.0176 - val_loss: 101.1883\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16400.5996 - val_loss: 100.4519\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4093.1636 - val_loss: 100.3102\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2131.9023 - val_loss: 101.3180\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34186.7266 - val_loss: 101.4847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 15 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 165662.0312 - val_loss: 89.5539\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22987.8359 - val_loss: 82.0533\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 218758.7031 - val_loss: 81.3942\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 160197.0781 - val_loss: 86.5392\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20985.9648 - val_loss: 90.4471\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 110703.3828 - val_loss: 89.6232\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24847.2344 - val_loss: 85.9972\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 143979.3906 - val_loss: 84.5754\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 103860.0156 - val_loss: 88.2952\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34326.7109 - val_loss: 91.6093\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 107706.2422 - val_loss: 91.0607\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 59671.9336 - val_loss: 88.3576\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 79010.8281 - val_loss: 87.4041\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57116.7773 - val_loss: 89.7572\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28860.3359 - val_loss: 89.9716\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10972.4541 - val_loss: 89.7152\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6050.2070 - val_loss: 90.0402\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6600.6060 - val_loss: 89.7196\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7075.7979 - val_loss: 91.3796\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54415.6094 - val_loss: 90.9605\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12434.9541 - val_loss: 90.2189\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19800.0918 - val_loss: 90.9441\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10186.9355 - val_loss: 91.0482\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14701.0215 - val_loss: 90.1751\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20939.1094 - val_loss: 90.9361\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32271.2012 - val_loss: 91.2210\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12622.9814 - val_loss: 90.3498\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14683.0605 - val_loss: 90.7522\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10520.0010 - val_loss: 89.1666\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 79710.2031 - val_loss: 89.1097\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 63142.1523 - val_loss: 91.4904\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 60691.2773 - val_loss: 92.2406\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19749.7891 - val_loss: 91.2792\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8792.4971 - val_loss: 91.7651\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11254.5576 - val_loss: 90.6971\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23642.8672 - val_loss: 91.5519\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36785.9492 - val_loss: 91.3722\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10445.9102 - val_loss: 90.7818\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15492.1230 - val_loss: 91.6000\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49757.4805 - val_loss: 92.1979\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21861.9883 - val_loss: 91.4414\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18453.2441 - val_loss: 92.6958\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24300.5508 - val_loss: 92.4122\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4360.3535 - val_loss: 92.3767\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25850.8906 - val_loss: 92.7766\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21672.9609 - val_loss: 93.4065\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3130.8105 - val_loss: 92.9912\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12533.4727 - val_loss: 94.1524\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37842.4492 - val_loss: 94.0706\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2017.2957 - val_loss: 93.2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 16 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 56.6403 - val_loss: 38.5349\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47.0222 - val_loss: 29.0525\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36.1224 - val_loss: 39.8124\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31.3014 - val_loss: 37.2615\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26.4646 - val_loss: 21.7475\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24.3540 - val_loss: 16.6117\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19.9016 - val_loss: 17.6374\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.4000 - val_loss: 8.5512\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.3573 - val_loss: 3.8554\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.4430 - val_loss: 2.1764\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.4738 - val_loss: 6.8646\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.5602 - val_loss: 2.2738\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.8602 - val_loss: 4.1685\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.9464 - val_loss: 1.7787\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.9484 - val_loss: 2.0863\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.2016 - val_loss: 2.3784\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.0979 - val_loss: 2.4877\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5704 - val_loss: 2.0369\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.3276 - val_loss: 2.2946\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8293 - val_loss: 4.3706\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.0359 - val_loss: 2.2407\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.5671 - val_loss: 3.7208\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4346 - val_loss: 2.2124\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.0771 - val_loss: 2.3772\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3163 - val_loss: 3.7769\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.0393 - val_loss: 2.4280\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2948 - val_loss: 2.4721\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.8190 - val_loss: 2.2260\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3791 - val_loss: 4.2531\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2290 - val_loss: 2.3133\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3656 - val_loss: 3.5666\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2757 - val_loss: 2.0080\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0940 - val_loss: 2.8312\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6766 - val_loss: 2.4075\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7081 - val_loss: 2.3537\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9647 - val_loss: 2.9894\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9905 - val_loss: 2.3907\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9183 - val_loss: 2.1651\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9344 - val_loss: 2.2981\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2832 - val_loss: 3.2092\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1289 - val_loss: 1.7615\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1213 - val_loss: 3.5796\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9175 - val_loss: 1.8194\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6987 - val_loss: 2.4773\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5538 - val_loss: 2.6456\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4264 - val_loss: 3.1707\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5033 - val_loss: 2.3314\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5923 - val_loss: 2.3442\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0366 - val_loss: 2.3033\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.0193 - val_loss: 1.7270\n",
      "Iteration number 17 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 82.9693 - val_loss: 67.7449\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37.8758 - val_loss: 28.5071\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31.3375 - val_loss: 14.9678\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25.4427 - val_loss: 29.4740\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.6078 - val_loss: 33.2744\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.6038 - val_loss: 23.8983\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.2140 - val_loss: 14.3847\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.6174 - val_loss: 19.2649\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.6607 - val_loss: 15.8071\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.9025 - val_loss: 8.7374\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9471 - val_loss: 10.9226\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.8633 - val_loss: 3.2552\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7188 - val_loss: 6.6629\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.8860 - val_loss: 2.0467\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0069 - val_loss: 3.6591\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.7234 - val_loss: 2.6772\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6325 - val_loss: 2.7850\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1619 - val_loss: 2.9718\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7056 - val_loss: 2.1532\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1294 - val_loss: 4.1967\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1159 - val_loss: 2.1347\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6398 - val_loss: 3.3226\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0681 - val_loss: 2.0680\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.7365 - val_loss: 2.8831\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6002 - val_loss: 2.4211\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0604 - val_loss: 2.4258\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1470 - val_loss: 2.2988\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8722 - val_loss: 2.7458\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2527 - val_loss: 2.4808\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1295 - val_loss: 2.2608\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9340 - val_loss: 2.6272\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8846 - val_loss: 2.7510\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5321 - val_loss: 2.8783\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6769 - val_loss: 2.6133\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4484 - val_loss: 3.4073\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7520 - val_loss: 2.6732\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9297 - val_loss: 2.5074\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5704 - val_loss: 2.6941\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4040 - val_loss: 2.3325\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9185 - val_loss: 2.6529\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.1933 - val_loss: 3.0217\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0493 - val_loss: 3.0031\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2192 - val_loss: 2.1616\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4867 - val_loss: 2.4190\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4442 - val_loss: 2.3656\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4609 - val_loss: 2.2206\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3691 - val_loss: 2.6509\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5911 - val_loss: 2.9378\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5055 - val_loss: 2.5908\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8459 - val_loss: 2.5808\n",
      "Iteration number 18 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 80945.3906 - val_loss: 101.9984\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 173535.4531 - val_loss: 104.8891\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 140482.6719 - val_loss: 98.0541\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21123.2344 - val_loss: 91.5310\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 150528.4531 - val_loss: 88.8923\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 123232.6328 - val_loss: 92.1886\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73168.3672 - val_loss: 96.5290\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19275.8594 - val_loss: 97.2834\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30485.6875 - val_loss: 96.7745\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4416.9946 - val_loss: 96.9043\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15617.7910 - val_loss: 96.8475\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12403.3398 - val_loss: 96.7258\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11298.9805 - val_loss: 96.9636\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26036.1504 - val_loss: 96.2422\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9207.9678 - val_loss: 97.9465\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25606.8203 - val_loss: 98.1694\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29974.0371 - val_loss: 97.3326\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3612.6045 - val_loss: 95.4945\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 76649.2578 - val_loss: 94.8108\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 65443.0859 - val_loss: 96.7023\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7257.9390 - val_loss: 98.6983\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 57851.3555 - val_loss: 99.7375\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56846.9023 - val_loss: 99.3027\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36678.6562 - val_loss: 97.6912\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33720.3242 - val_loss: 96.9171\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29686.8066 - val_loss: 98.4038\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23959.5488 - val_loss: 98.6678\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18994.0918 - val_loss: 97.6361\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13240.1230 - val_loss: 97.9116\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3518.9177 - val_loss: 98.6448\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30817.5156 - val_loss: 98.9754\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22063.9648 - val_loss: 98.1584\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19856.7168 - val_loss: 97.6658\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1232.0435 - val_loss: 98.4970\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36310.3594 - val_loss: 99.4354\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40581.1758 - val_loss: 99.2964\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14368.2686 - val_loss: 98.0654\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30356.4570 - val_loss: 97.2955\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32200.4961 - val_loss: 97.6242\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9472.6025 - val_loss: 98.5715\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27442.0898 - val_loss: 99.1873\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25867.0332 - val_loss: 98.6902\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5370.4956 - val_loss: 98.3867\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3560.1768 - val_loss: 98.3335\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2896.8704 - val_loss: 98.8859\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21885.7637 - val_loss: 98.8931\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6840.7715 - val_loss: 98.2088\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19692.6660 - val_loss: 97.8976\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18404.4453 - val_loss: 98.6400\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8894.8359 - val_loss: 98.5118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 19 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 132811.0469 - val_loss: 104.2077\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12482.8828 - val_loss: 116.7451\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 143918.1250 - val_loss: 116.2581\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 136116.2031 - val_loss: 113.3111\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90635.6094 - val_loss: 107.4156\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34679.5156 - val_loss: 106.0415\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22227.7559 - val_loss: 107.3698\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1941.7555 - val_loss: 107.0395\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3081.8630 - val_loss: 108.6687\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 30979.2012 - val_loss: 107.7766\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14869.6104 - val_loss: 105.1557\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61133.1914 - val_loss: 104.2278\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31660.6484 - val_loss: 106.5773\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8869.8535 - val_loss: 107.3134\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13700.0420 - val_loss: 105.5421\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28692.9082 - val_loss: 105.6943\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14910.1592 - val_loss: 108.1849\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50168.1406 - val_loss: 108.4163\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34953.8242 - val_loss: 107.3354\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22297.9590 - val_loss: 103.2650\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 96161.6016 - val_loss: 101.3935\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 83235.7266 - val_loss: 102.5829\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 55676.1719 - val_loss: 105.1734\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3588.2703 - val_loss: 105.7246\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9916.7656 - val_loss: 105.2208\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11905.5947 - val_loss: 105.0609\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 899.2670 - val_loss: 104.8108\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17577.9844 - val_loss: 104.8017\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6454.1367 - val_loss: 106.2462\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39720.0117 - val_loss: 106.7012\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34892.9414 - val_loss: 105.0170\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14593.6533 - val_loss: 104.5718\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4873.1724 - val_loss: 105.7140\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17840.3379 - val_loss: 105.5898\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15228.1123 - val_loss: 105.1345\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20502.9668 - val_loss: 104.0545\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17173.5605 - val_loss: 105.6466\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20641.8809 - val_loss: 105.4518\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17357.2656 - val_loss: 104.2334\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13647.0098 - val_loss: 104.4060\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1553.8468 - val_loss: 105.3803\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 37334.1367 - val_loss: 105.9586\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21726.3867 - val_loss: 104.6967\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4843.1680 - val_loss: 102.3730\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 56060.7500 - val_loss: 101.8358\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60890.3750 - val_loss: 102.1178\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 46434.4766 - val_loss: 103.5554\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14064.5098 - val_loss: 105.4402\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33137.8516 - val_loss: 105.5942\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39166.3281 - val_loss: 104.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 20 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 153036.5938 - val_loss: 91.0811\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 51344.8867 - val_loss: 94.5889\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11474.7021 - val_loss: 88.9247\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 82364.7734 - val_loss: 87.4663\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 67666.9844 - val_loss: 91.1752\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13824.7666 - val_loss: 96.8132\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 99244.3750 - val_loss: 98.1420\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 82364.0781 - val_loss: 97.0751\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27235.7461 - val_loss: 93.0124\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 43126.6914 - val_loss: 91.0889\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 52095.1719 - val_loss: 91.8878\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27680.6914 - val_loss: 95.1971\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25640.0547 - val_loss: 95.3093\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27548.8945 - val_loss: 93.4797\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11939.5547 - val_loss: 93.9073\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8529.1758 - val_loss: 93.6507\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21257.2461 - val_loss: 93.1275\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9183.7842 - val_loss: 94.0099\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2601.6189 - val_loss: 94.2404\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8991.8965 - val_loss: 93.2996\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15834.4111 - val_loss: 93.8337\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5786.2026 - val_loss: 93.6783\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13946.8389 - val_loss: 93.7883\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4582.2695 - val_loss: 93.6678\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18321.9551 - val_loss: 93.4856\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 501.6021 - val_loss: 94.9518\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27122.6504 - val_loss: 95.3608\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25960.1309 - val_loss: 94.6539\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5346.0771 - val_loss: 94.1289\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 422.6141 - val_loss: 93.1363\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20072.6680 - val_loss: 94.0515\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2995.4751 - val_loss: 93.6216\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24235.1660 - val_loss: 93.3483\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4822.7593 - val_loss: 95.6259\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52947.9102 - val_loss: 96.8026\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51594.9062 - val_loss: 95.3953\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20711.9512 - val_loss: 93.2889\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41898.3945 - val_loss: 92.6731\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36621.5547 - val_loss: 94.0834\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4758.2710 - val_loss: 96.1020\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32284.0918 - val_loss: 96.3121\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35852.3438 - val_loss: 95.4982\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16415.5059 - val_loss: 93.7548\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28512.2930 - val_loss: 93.6651\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23748.3945 - val_loss: 94.1376\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2148.8240 - val_loss: 96.1643\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28889.4609 - val_loss: 96.6882\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43679.6875 - val_loss: 96.5427\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31596.6211 - val_loss: 95.1401\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8989.8730 - val_loss: 94.8020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 21 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 75.9538 - val_loss: 60.6610\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40.7564 - val_loss: 24.6694\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39.0600 - val_loss: 30.1170\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.8222 - val_loss: 37.0989\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27.7230 - val_loss: 26.6163\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22.9384 - val_loss: 14.0634\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21.1100 - val_loss: 21.6008\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.9889 - val_loss: 12.6067\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.4311 - val_loss: 9.6227\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.9490 - val_loss: 6.7772\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.7686 - val_loss: 2.6990\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.6687 - val_loss: 2.8650\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.2264 - val_loss: 3.9233\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.0804 - val_loss: 2.9657\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.5235 - val_loss: 2.6963\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7011 - val_loss: 5.1280\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.6088 - val_loss: 3.0294\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8011 - val_loss: 5.2022\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7435 - val_loss: 2.5318\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1217 - val_loss: 3.7389\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7477 - val_loss: 3.1432\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4798 - val_loss: 2.5673\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2318 - val_loss: 3.3795\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9180 - val_loss: 2.3858\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4996 - val_loss: 3.0501\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4637 - val_loss: 2.2873\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2991 - val_loss: 3.8701\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4176 - val_loss: 2.3273\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0281 - val_loss: 3.0360\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.7423 - val_loss: 2.3380\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8912 - val_loss: 4.8183\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0586 - val_loss: 2.2085\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5351 - val_loss: 4.5080\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7744 - val_loss: 3.0554\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5258 - val_loss: 3.9048\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.7518 - val_loss: 2.2900\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5565 - val_loss: 2.5077\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3140 - val_loss: 2.5011\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1454 - val_loss: 2.4475\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9997 - val_loss: 2.6700\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9923 - val_loss: 2.2124\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2377 - val_loss: 2.9641\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2035 - val_loss: 2.5913\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.1334 - val_loss: 2.2243\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.3441 - val_loss: 2.6879\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.9933 - val_loss: 2.1881\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.0846 - val_loss: 2.1943\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.7495 - val_loss: 2.2020\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.0662 - val_loss: 2.0579\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4184 - val_loss: 2.8046\n",
      "Iteration number 22 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 97703.3984 - val_loss: 90.5917\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 69955.1797 - val_loss: 91.3402\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21140.0059 - val_loss: 87.9083\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 70272.4688 - val_loss: 85.6569\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47313.2227 - val_loss: 88.8724\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 562.6105 - val_loss: 89.6084\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8805.2471 - val_loss: 90.5145\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7208.7993 - val_loss: 91.1042\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16695.1309 - val_loss: 89.3401\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41527.7344 - val_loss: 88.2318\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 963.4958 - val_loss: 89.9162\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22845.2637 - val_loss: 89.8558\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10794.1875 - val_loss: 93.5922\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53410.9922 - val_loss: 93.5703\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 41877.8789 - val_loss: 90.6227\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33042.1367 - val_loss: 89.7141\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10477.8447 - val_loss: 93.2828\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 61056.6367 - val_loss: 95.1065\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54088.7578 - val_loss: 94.2108\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41316.5312 - val_loss: 89.3217\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52419.6406 - val_loss: 88.5771\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 57517.5000 - val_loss: 89.9088\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19497.6797 - val_loss: 91.8789\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6209.1792 - val_loss: 96.5124\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 96286.2734 - val_loss: 98.0424\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 98651.6250 - val_loss: 97.6083\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 73982.9688 - val_loss: 95.6794\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42787.2812 - val_loss: 92.6479\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39201.4805 - val_loss: 92.0541\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33792.8164 - val_loss: 93.5600\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11177.8623 - val_loss: 94.0801\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5484.7769 - val_loss: 93.7719\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1428.1842 - val_loss: 92.9170\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24386.5391 - val_loss: 92.8093\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7314.2148 - val_loss: 93.8518\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26563.5059 - val_loss: 95.1511\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27656.9609 - val_loss: 94.2224\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3884.5281 - val_loss: 93.8752\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6085.3193 - val_loss: 93.8830\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 349.9977 - val_loss: 92.7577\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21629.6465 - val_loss: 93.0600\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15999.8027 - val_loss: 94.3629\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13698.9453 - val_loss: 94.2165\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6369.7007 - val_loss: 92.8673\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32834.5117 - val_loss: 92.5890\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24090.9844 - val_loss: 93.7588\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4907.4702 - val_loss: 95.8762\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44394.1328 - val_loss: 96.2619\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45107.2266 - val_loss: 95.6647\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17918.8066 - val_loss: 94.6573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 23 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 80.4739 - val_loss: 57.8881\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.6353 - val_loss: 11.9251\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.7496 - val_loss: 22.0174\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25.3321 - val_loss: 34.3443\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24.0986 - val_loss: 27.9146\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.1588 - val_loss: 14.7260\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17.9839 - val_loss: 11.8057\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.6866 - val_loss: 14.7944\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.8731 - val_loss: 5.3641\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.5403 - val_loss: 4.8095\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.2412 - val_loss: 3.0450\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.4839 - val_loss: 6.5515\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.6204 - val_loss: 3.9796\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1988 - val_loss: 6.5109\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2192 - val_loss: 5.9679\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6833 - val_loss: 4.3373\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3515 - val_loss: 6.3587\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5797 - val_loss: 2.1597\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6649 - val_loss: 6.7958\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6589 - val_loss: 2.4987\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2238 - val_loss: 4.8147\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5199 - val_loss: 2.9518\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3293 - val_loss: 4.3269\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1513 - val_loss: 2.5175\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2316 - val_loss: 5.3111\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0192 - val_loss: 2.9308\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8134 - val_loss: 3.5135\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6118 - val_loss: 3.1251\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4887 - val_loss: 2.2262\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3452 - val_loss: 5.7725\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7685 - val_loss: 2.1298\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5721 - val_loss: 4.8364\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1460 - val_loss: 2.2188\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4811 - val_loss: 5.1095\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9227 - val_loss: 1.9450\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4253 - val_loss: 4.1645\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6448 - val_loss: 1.8674\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2691 - val_loss: 4.0077\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.3070 - val_loss: 1.9824\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0650 - val_loss: 5.1746\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6745 - val_loss: 1.8749\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9762 - val_loss: 3.2440\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5695 - val_loss: 2.4354\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5530 - val_loss: 2.2184\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4932 - val_loss: 2.0068\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4919 - val_loss: 4.1385\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5007 - val_loss: 2.0069\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4550 - val_loss: 2.5580\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1995 - val_loss: 2.0589\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.4513 - val_loss: 2.7858\n",
      "Iteration number 24 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 2636116.2500 - val_loss: 95.4007\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4853628.0000 - val_loss: 93.7893\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3844320.7500 - val_loss: 92.6838\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2058236.6250 - val_loss: 91.6880\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1898743.3750 - val_loss: 90.8270\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1327176.3750 - val_loss: 90.1421\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1175817.2500 - val_loss: 89.3573\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1512773.3750 - val_loss: 88.5174\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 901658.4375 - val_loss: 87.6250\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 603991.2500 - val_loss: 86.9198\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 176071.0312 - val_loss: 86.1455\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 198488.6562 - val_loss: 85.2728\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 173589.6875 - val_loss: 84.4111\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 199097.9219 - val_loss: 83.5481\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 200652.3906 - val_loss: 82.6773\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 165238.2031 - val_loss: 81.9148\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 158930.8906 - val_loss: 81.2121\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 212487.5781 - val_loss: 80.4408\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 161701.8125 - val_loss: 79.6025\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 210251.0469 - val_loss: 78.8511\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 196460.5312 - val_loss: 77.9091\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 168045.2500 - val_loss: 76.9904\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 171737.7344 - val_loss: 76.2393\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 191277.0000 - val_loss: 75.5300\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 191711.0312 - val_loss: 74.6395\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 174409.3438 - val_loss: 73.9019\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 170968.3438 - val_loss: 73.0158\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 185510.2500 - val_loss: 72.2170\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 175447.1250 - val_loss: 71.4107\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 181165.6250 - val_loss: 70.7857\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 171836.2969 - val_loss: 70.0617\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 183571.7500 - val_loss: 69.3277\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 184945.1406 - val_loss: 68.5633\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 164777.9219 - val_loss: 67.7053\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 155166.4531 - val_loss: 66.9896\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 190561.7969 - val_loss: 66.2642\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 182635.7812 - val_loss: 65.5894\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 164220.9375 - val_loss: 64.8633\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 141276.4844 - val_loss: 64.1770\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 190606.0000 - val_loss: 63.4645\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 142864.0156 - val_loss: 62.8265\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 187450.5781 - val_loss: 62.2553\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 182137.3906 - val_loss: 61.7899\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 391377.4062 - val_loss: 61.1379\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 703898.5000 - val_loss: 60.9345\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 986813.2500 - val_loss: 60.8561\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 382976.6250 - val_loss: 60.7890\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 234275.9688 - val_loss: 60.6519\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 307744.1250 - val_loss: 60.4758\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 70031.6719 - val_loss: 60.1220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 25 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 122910.2266 - val_loss: 106.6814\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 127596.5625 - val_loss: 105.4160\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 62446.4336 - val_loss: 100.5896\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7725.1836 - val_loss: 100.5872\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 860.6899 - val_loss: 103.1105\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 83630.2500 - val_loss: 103.8015\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 47875.1328 - val_loss: 101.9382\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26568.8398 - val_loss: 96.3695\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 98973.7266 - val_loss: 95.5603\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 122627.0781 - val_loss: 96.5474\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 88380.5234 - val_loss: 99.4495\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18501.1797 - val_loss: 102.9756\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76352.1172 - val_loss: 103.9834\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73703.3047 - val_loss: 102.4749\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21435.9492 - val_loss: 100.7890\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14475.0117 - val_loss: 100.2441\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17063.4863 - val_loss: 101.2210\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26398.4668 - val_loss: 101.4495\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10317.4053 - val_loss: 100.1424\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43708.4375 - val_loss: 99.5432\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37304.5508 - val_loss: 100.8390\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14612.9033 - val_loss: 101.2603\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5401.4229 - val_loss: 99.9545\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37523.8828 - val_loss: 99.9638\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28810.0566 - val_loss: 100.8935\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4872.0376 - val_loss: 102.9106\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 75832.5234 - val_loss: 103.5892\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 68244.8750 - val_loss: 102.8975\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38255.5312 - val_loss: 101.2621\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14813.2568 - val_loss: 100.6284\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16251.1436 - val_loss: 101.0381\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12121.0332 - val_loss: 101.3529\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1990.8654 - val_loss: 100.4069\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34418.8320 - val_loss: 100.1533\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28463.8262 - val_loss: 101.0987\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13206.1992 - val_loss: 101.3796\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5141.0410 - val_loss: 100.2991\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36535.4922 - val_loss: 100.1154\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25956.6660 - val_loss: 100.6011\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16241.2109 - val_loss: 102.6349\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 69940.3125 - val_loss: 103.4240\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69522.4375 - val_loss: 102.8604\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36126.2188 - val_loss: 101.9940\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15228.2998 - val_loss: 100.0634\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 67910.2266 - val_loss: 99.0711\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 61023.1172 - val_loss: 99.5137\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44988.1641 - val_loss: 101.0871\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3569.3035 - val_loss: 102.7711\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 63577.1133 - val_loss: 103.3013\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 67400.6484 - val_loss: 103.0770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 26 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 218ms/step - loss: 107363.6328 - val_loss: 100.0468\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 75528.2500 - val_loss: 102.7378\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25727.3027 - val_loss: 100.0184\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 58383.7695 - val_loss: 96.3767\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 55118.4570 - val_loss: 98.9474\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7265.3379 - val_loss: 100.0708\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6989.7461 - val_loss: 101.5237\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18502.2773 - val_loss: 100.0611\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10129.7227 - val_loss: 101.5715\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 20554.9551 - val_loss: 100.6932\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4599.6597 - val_loss: 102.0027\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 23227.5723 - val_loss: 101.0759\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1841.7446 - val_loss: 97.5608\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 64649.8828 - val_loss: 97.8437\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 52760.9141 - val_loss: 100.6006\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13522.6826 - val_loss: 104.8428\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 72047.1875 - val_loss: 105.9622\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 66419.8906 - val_loss: 104.3529\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10638.6465 - val_loss: 102.5615\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42129.4062 - val_loss: 100.5951\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 45938.6953 - val_loss: 101.5193\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12278.3359 - val_loss: 103.2264\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17486.5059 - val_loss: 103.7146\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 18877.8125 - val_loss: 102.2372\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14890.4541 - val_loss: 102.7203\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2613.5786 - val_loss: 102.2574\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25440.2871 - val_loss: 101.9796\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18163.2910 - val_loss: 104.8247\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43467.7773 - val_loss: 105.2958\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 41938.3906 - val_loss: 104.4279\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11712.4941 - val_loss: 102.4018\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46741.3984 - val_loss: 101.4666\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 39508.6055 - val_loss: 103.1196\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5743.7773 - val_loss: 103.5602\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3749.8125 - val_loss: 103.8779\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15998.8506 - val_loss: 103.9100\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8651.8232 - val_loss: 102.2501\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 44022.8711 - val_loss: 101.7902\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 36127.7305 - val_loss: 102.8527\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10518.6846 - val_loss: 104.6735\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 48953.3398 - val_loss: 105.5494\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45653.8242 - val_loss: 104.0257\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7055.4160 - val_loss: 103.4655\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7396.3667 - val_loss: 103.7166\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 2247.3738 - val_loss: 102.3815\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28795.5039 - val_loss: 102.5860\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 23152.5273 - val_loss: 103.1330\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3817.5625 - val_loss: 104.5272\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 37153.1523 - val_loss: 105.2300\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 35253.7773 - val_loss: 104.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 27 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 196378.4219 - val_loss: 92.3783\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84537.9375 - val_loss: 97.5313\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63485.2695 - val_loss: 88.9814\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 111916.2891 - val_loss: 87.3583\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 99307.3594 - val_loss: 90.7091\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33813.1953 - val_loss: 95.3416\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 73675.5547 - val_loss: 97.2720\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66865.6016 - val_loss: 95.0586\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 657.3619 - val_loss: 94.4063\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19031.0391 - val_loss: 94.2279\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17845.2207 - val_loss: 93.6416\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15914.8818 - val_loss: 94.4732\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 307.0338 - val_loss: 92.9196\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33248.5977 - val_loss: 92.6269\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27722.1191 - val_loss: 94.1076\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15719.8848 - val_loss: 94.3579\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3291.5652 - val_loss: 92.1994\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38340.6836 - val_loss: 92.5796\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 27757.2793 - val_loss: 93.7024\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15105.7842 - val_loss: 94.5232\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1045.6958 - val_loss: 94.5910\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42843.5312 - val_loss: 95.9311\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36749.0195 - val_loss: 93.0591\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 51365.0547 - val_loss: 91.9551\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25354.8066 - val_loss: 93.6567\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25733.2012 - val_loss: 95.5717\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29296.2832 - val_loss: 94.5082\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7900.2021 - val_loss: 94.3403\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 946.1033 - val_loss: 93.5532\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21029.8594 - val_loss: 94.0797\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3091.5520 - val_loss: 93.9248\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8856.3877 - val_loss: 94.8075\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19521.1309 - val_loss: 94.8602\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15563.4668 - val_loss: 93.9016\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10367.6494 - val_loss: 96.2335\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46802.3477 - val_loss: 96.4353\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42259.6094 - val_loss: 95.1946\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 556.3193 - val_loss: 93.6367\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51253.9609 - val_loss: 92.4475\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35413.8789 - val_loss: 93.5233\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23864.6621 - val_loss: 96.6537\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45904.0273 - val_loss: 97.2991\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 63447.2812 - val_loss: 97.1562\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49222.1133 - val_loss: 95.5723\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3524.4536 - val_loss: 94.9789\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 598.0298 - val_loss: 94.3254\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 20319.3457 - val_loss: 94.6566\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5742.9575 - val_loss: 95.6900\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 30294.6914 - val_loss: 96.1848\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 23509.7480 - val_loss: 95.3075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 28 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 73398.9375 - val_loss: 117.6777\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 146707.6250 - val_loss: 113.6285\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 91152.2188 - val_loss: 105.7094\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35239.8906 - val_loss: 105.8260\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14744.4736 - val_loss: 111.0109\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63356.9922 - val_loss: 109.8432\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46074.7617 - val_loss: 105.4575\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19472.8750 - val_loss: 106.4617\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5163.8818 - val_loss: 105.9675\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47343.9023 - val_loss: 103.7852\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36639.7109 - val_loss: 105.7857\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27274.5137 - val_loss: 107.6734\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4295.0078 - val_loss: 103.6346\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77102.5391 - val_loss: 101.5934\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69266.9297 - val_loss: 103.8053\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35908.1719 - val_loss: 108.6165\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 72275.0547 - val_loss: 110.2166\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67734.4375 - val_loss: 107.2589\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7140.7681 - val_loss: 104.0432\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52759.2656 - val_loss: 102.8664\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50211.9180 - val_loss: 104.7380\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17686.8418 - val_loss: 108.3225\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44091.0859 - val_loss: 108.1338\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41906.6758 - val_loss: 107.3646\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30405.7656 - val_loss: 102.9991\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54754.6797 - val_loss: 102.0125\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58535.6562 - val_loss: 103.2540\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16316.7090 - val_loss: 105.2300\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20159.9453 - val_loss: 105.6796\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18308.4805 - val_loss: 104.0369\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12838.1953 - val_loss: 104.5359\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2645.2388 - val_loss: 106.4778\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50946.2383 - val_loss: 106.8374\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31798.2109 - val_loss: 105.6212\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1337.4749 - val_loss: 104.3646\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5851.7764 - val_loss: 105.4086\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20514.7051 - val_loss: 105.0084\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2573.5410 - val_loss: 103.8470\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21424.0566 - val_loss: 103.6010\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18867.8594 - val_loss: 105.1418\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12278.4844 - val_loss: 104.5921\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2783.4395 - val_loss: 104.9355\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8655.4053 - val_loss: 104.4641\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4356.4380 - val_loss: 104.8518\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20714.3242 - val_loss: 105.1812\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11297.0234 - val_loss: 103.3843\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38589.6367 - val_loss: 102.7497\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30120.7832 - val_loss: 104.0651\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9959.9307 - val_loss: 104.6629\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5478.3301 - val_loss: 102.8833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 29 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 25973.3496 - val_loss: 105.7352\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 231964.0312 - val_loss: 104.3488\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 169784.6250 - val_loss: 97.8519\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38734.7188 - val_loss: 90.9839\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 100655.0625 - val_loss: 89.3774\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 82152.9844 - val_loss: 92.0611\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8911.4619 - val_loss: 95.5398\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67644.9609 - val_loss: 97.6525\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66125.1797 - val_loss: 95.5910\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14647.7373 - val_loss: 92.8173\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65687.9062 - val_loss: 91.8415\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60698.4258 - val_loss: 94.2792\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13909.7930 - val_loss: 97.4707\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 66956.1875 - val_loss: 98.2083\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 62425.0117 - val_loss: 96.3972\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6704.3140 - val_loss: 94.5658\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27266.2246 - val_loss: 94.0226\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30841.9844 - val_loss: 94.7477\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1686.8558 - val_loss: 95.3202\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5091.3750 - val_loss: 96.3915\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24899.2148 - val_loss: 96.2963\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1113.5056 - val_loss: 94.6536\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38391.6094 - val_loss: 93.9079\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36827.1680 - val_loss: 95.6072\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14206.7842 - val_loss: 96.1215\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14995.2939 - val_loss: 95.3995\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9055.4736 - val_loss: 97.9284\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43173.4023 - val_loss: 98.0023\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43304.8203 - val_loss: 97.1365\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18306.9727 - val_loss: 95.0293\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43607.6250 - val_loss: 94.2254\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40706.7188 - val_loss: 95.8769\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5960.1865 - val_loss: 96.2441\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3217.3464 - val_loss: 96.8435\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21565.0703 - val_loss: 96.9976\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2814.4973 - val_loss: 96.4133\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2826.4932 - val_loss: 95.6992\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21285.9941 - val_loss: 95.9100\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3184.0667 - val_loss: 97.0317\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13273.7402 - val_loss: 97.1338\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15406.5596 - val_loss: 96.3958\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1802.6851 - val_loss: 96.7665\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6089.5591 - val_loss: 95.7818\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24454.3359 - val_loss: 95.7692\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10108.3037 - val_loss: 97.2204\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21433.7480 - val_loss: 97.4940\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19977.6211 - val_loss: 96.3091\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14496.2686 - val_loss: 96.3883\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6023.7432 - val_loss: 97.9835\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45987.6797 - val_loss: 98.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 30 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 34930.6211 - val_loss: 84.6999\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 340086.2500 - val_loss: 79.1136\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 252168.3125 - val_loss: 88.6945\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 126351.1562 - val_loss: 97.7109\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11111.7139 - val_loss: 99.9667\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27546.0234 - val_loss: 98.5993\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9395.9346 - val_loss: 99.1554\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7589.9624 - val_loss: 97.2627\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42934.8008 - val_loss: 96.9396\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21026.2754 - val_loss: 101.3425\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47019.1602 - val_loss: 101.7861\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 57937.8867 - val_loss: 100.4210\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25248.6035 - val_loss: 96.8738\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40837.6562 - val_loss: 96.3050\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38432.3359 - val_loss: 97.3422\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4270.3999 - val_loss: 100.5748\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80623.1953 - val_loss: 102.5213\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58244.9531 - val_loss: 100.6798\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16411.5059 - val_loss: 96.2248\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 76336.1797 - val_loss: 93.8803\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80398.6406 - val_loss: 95.1282\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45509.6758 - val_loss: 97.3301\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11275.8760 - val_loss: 98.4040\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3011.8569 - val_loss: 97.5297\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8681.9316 - val_loss: 97.0028\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18504.3691 - val_loss: 98.3822\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18451.7480 - val_loss: 98.4154\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5771.9473 - val_loss: 98.0644\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2125.1753 - val_loss: 97.8747\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3384.9563 - val_loss: 98.3018\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31360.5371 - val_loss: 99.4612\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29010.3789 - val_loss: 97.5837\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24695.7871 - val_loss: 97.0010\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17888.2852 - val_loss: 99.8993\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46225.6523 - val_loss: 100.2507\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44682.0234 - val_loss: 98.8742\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18265.6582 - val_loss: 96.2926\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32143.1641 - val_loss: 96.2882\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31765.2168 - val_loss: 96.7642\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5995.3345 - val_loss: 99.4814\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42065.9297 - val_loss: 100.3434\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 52581.1328 - val_loss: 99.9524\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41114.3086 - val_loss: 97.5771\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19770.8672 - val_loss: 97.0804\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14825.8154 - val_loss: 98.1205\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15401.5234 - val_loss: 98.3083\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6021.4072 - val_loss: 97.1098\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26550.4473 - val_loss: 96.8201\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18792.6973 - val_loss: 97.9395\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2038.9739 - val_loss: 97.7512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 31 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 76.6168 - val_loss: 57.0204\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49.1868 - val_loss: 32.5022\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.7768 - val_loss: 38.5178\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.7367 - val_loss: 35.2200\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27.7363 - val_loss: 22.5146\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24.3326 - val_loss: 15.1913\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21.3988 - val_loss: 15.5885\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 17.3572 - val_loss: 4.6548\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.0866 - val_loss: 7.5897\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.0613 - val_loss: 3.7297\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.6577 - val_loss: 3.9644\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.5900 - val_loss: 5.9709\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.7653 - val_loss: 4.4164\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.9338 - val_loss: 3.4671\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.7166 - val_loss: 4.1819\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.4539 - val_loss: 3.7730\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.5574 - val_loss: 4.1037\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.1911 - val_loss: 4.3082\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.0074 - val_loss: 3.1025\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.6251 - val_loss: 4.2070\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.8368 - val_loss: 3.0731\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.9241 - val_loss: 4.1180\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.7485 - val_loss: 2.8524\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.2236 - val_loss: 3.6857\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2427 - val_loss: 2.7589\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.8084 - val_loss: 2.5270\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.6054 - val_loss: 3.3580\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.9453 - val_loss: 2.4220\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.4031 - val_loss: 4.1646\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.7603 - val_loss: 3.1531\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.3636 - val_loss: 3.5978\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.9390 - val_loss: 2.8113\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.0146 - val_loss: 3.4249\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.4097 - val_loss: 2.4919\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.0516 - val_loss: 2.7335\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.8205 - val_loss: 1.7402\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4115 - val_loss: 2.7650\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.9397 - val_loss: 3.0964\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.5883 - val_loss: 1.9794\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.2926 - val_loss: 2.2030\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.2489 - val_loss: 1.8769\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.8124 - val_loss: 2.9184\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.8347 - val_loss: 2.3636\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.4615 - val_loss: 2.3959\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.2634 - val_loss: 1.6898\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3233 - val_loss: 2.5650\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0554 - val_loss: 2.3495\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.8661 - val_loss: 2.9872\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.1185 - val_loss: 1.5651\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.8713 - val_loss: 3.2777\n",
      "Iteration number 32 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 81.4237 - val_loss: 68.4334\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 50.5618 - val_loss: 38.6314\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43.4994 - val_loss: 40.0330\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 35.2657 - val_loss: 41.0430\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 31.0584 - val_loss: 28.8019\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25.6536 - val_loss: 18.3314\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21.7105 - val_loss: 18.1929\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18.0834 - val_loss: 9.6156\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.3307 - val_loss: 9.1515\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.1411 - val_loss: 5.5007\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.6479 - val_loss: 5.9282\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.6296 - val_loss: 5.2528\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.0906 - val_loss: 5.9466\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.5698 - val_loss: 6.1855\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.2014 - val_loss: 4.4614\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.6139 - val_loss: 4.9446\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.9319 - val_loss: 5.4537\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.6655 - val_loss: 4.7489\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.6411 - val_loss: 4.0158\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2552 - val_loss: 5.2576\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8862 - val_loss: 4.0702\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4500 - val_loss: 4.6461\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.8610 - val_loss: 2.6946\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6801 - val_loss: 5.0602\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4922 - val_loss: 4.0644\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.9758 - val_loss: 3.5107\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6520 - val_loss: 4.2287\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.4953 - val_loss: 3.3958\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.1566 - val_loss: 3.9355\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.6682 - val_loss: 4.5369\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.6660 - val_loss: 3.7068\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.8241 - val_loss: 2.3198\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3727 - val_loss: 5.6627\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0325 - val_loss: 2.2623\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.2992 - val_loss: 2.9501\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8963 - val_loss: 3.0324\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.6882 - val_loss: 3.0284\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.6221 - val_loss: 2.9294\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.6011 - val_loss: 2.0395\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.2182 - val_loss: 3.2364\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3613 - val_loss: 2.0285\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.1858 - val_loss: 2.0472\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.4307 - val_loss: 3.6309\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6644 - val_loss: 2.0181\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0840 - val_loss: 2.4500\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0341 - val_loss: 2.1042\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.7871 - val_loss: 2.0670\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.8110 - val_loss: 2.8845\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9106 - val_loss: 1.9970\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.8173 - val_loss: 3.0543\n",
      "Iteration number 33 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 91.5987 - val_loss: 76.3170\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.1025 - val_loss: 36.4421\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.6294 - val_loss: 18.9644\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30.7655 - val_loss: 32.9740\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26.1620 - val_loss: 36.8378\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24.4185 - val_loss: 26.5283\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.8847 - val_loss: 15.1945\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.3388 - val_loss: 15.9888\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.8606 - val_loss: 14.1683\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.9379 - val_loss: 7.8624\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.3767 - val_loss: 2.9888\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4451 - val_loss: 3.3030\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8799 - val_loss: 3.3359\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.0675 - val_loss: 2.4722\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5927 - val_loss: 2.7105\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.8920 - val_loss: 3.1424\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1058 - val_loss: 2.4709\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2391 - val_loss: 4.4923\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.0000 - val_loss: 3.1236\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9257 - val_loss: 3.0538\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9217 - val_loss: 2.6159\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.5265 - val_loss: 2.4739\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3806 - val_loss: 3.9081\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3200 - val_loss: 2.4403\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5825 - val_loss: 3.5587\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0035 - val_loss: 2.1870\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1138 - val_loss: 2.1452\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0290 - val_loss: 3.6953\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.0958 - val_loss: 2.5004\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.7510 - val_loss: 2.2155\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.4935 - val_loss: 2.0574\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5107 - val_loss: 2.1095\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.8314 - val_loss: 1.9686\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.4394 - val_loss: 2.7668\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3242 - val_loss: 2.1572\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5395 - val_loss: 4.2198\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8314 - val_loss: 1.7859\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0946 - val_loss: 2.3619\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9918 - val_loss: 1.9669\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0350 - val_loss: 2.0347\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.2666 - val_loss: 3.6357\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6697 - val_loss: 2.1798\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.8622 - val_loss: 3.0637\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.1465 - val_loss: 1.6850\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.8267 - val_loss: 2.4959\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8446 - val_loss: 2.2763\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5845 - val_loss: 1.7491\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.5886 - val_loss: 3.1149\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5861 - val_loss: 1.7160\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.4150 - val_loss: 2.1369\n",
      "Iteration number 34 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 178968.1250 - val_loss: 99.0497\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 222254.1094 - val_loss: 104.7032\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 64782.2383 - val_loss: 109.9773\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 160038.3750 - val_loss: 109.7538\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28761.1484 - val_loss: 105.2459\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 61133.3008 - val_loss: 102.4961\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 101469.1484 - val_loss: 102.8183\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62922.6758 - val_loss: 105.8454\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 97671.7969 - val_loss: 106.8731\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 87914.4375 - val_loss: 103.5748\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 75495.3047 - val_loss: 102.4830\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34832.8594 - val_loss: 104.1493\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37081.9297 - val_loss: 104.8867\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45023.6406 - val_loss: 104.0251\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11856.6885 - val_loss: 103.9416\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15008.8818 - val_loss: 105.3963\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48748.6094 - val_loss: 104.9926\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26238.0137 - val_loss: 103.3743\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 49558.4727 - val_loss: 103.3294\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5117.8208 - val_loss: 103.3775\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7470.8789 - val_loss: 103.8174\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56567.1758 - val_loss: 104.0369\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25623.6973 - val_loss: 101.9053\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16603.3594 - val_loss: 102.4069\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36213.7734 - val_loss: 102.1516\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2247.4009 - val_loss: 101.2126\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40703.5586 - val_loss: 101.5656\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33711.2578 - val_loss: 102.9544\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 44217.8633 - val_loss: 101.3850\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12177.4844 - val_loss: 101.5485\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18932.5527 - val_loss: 100.7630\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18861.0371 - val_loss: 101.2274\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19506.6816 - val_loss: 101.0258\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24919.7090 - val_loss: 100.9010\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22361.4414 - val_loss: 102.4318\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43851.3516 - val_loss: 102.2968\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1196.0781 - val_loss: 102.6762\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22300.9531 - val_loss: 102.7137\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6617.2231 - val_loss: 101.4467\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25975.8340 - val_loss: 101.7292\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21021.9434 - val_loss: 101.6493\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15061.5098 - val_loss: 101.1553\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10406.0391 - val_loss: 100.7875\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8494.5908 - val_loss: 101.0258\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13194.4219 - val_loss: 100.5781\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7256.2905 - val_loss: 101.0971\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24822.3047 - val_loss: 100.7698\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17842.2109 - val_loss: 100.6830\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17720.2578 - val_loss: 102.3726\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 46937.9180 - val_loss: 102.6897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 35 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 74.9444 - val_loss: 53.6921\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31.5734 - val_loss: 10.4871\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30.9982 - val_loss: 20.0084\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21.9976 - val_loss: 34.2115\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 21.4110 - val_loss: 27.9614\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.9837 - val_loss: 16.3684\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.6667 - val_loss: 14.4351\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.0501 - val_loss: 16.3184\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2252 - val_loss: 7.0235\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9505 - val_loss: 9.2453\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4741 - val_loss: 5.3459\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9097 - val_loss: 5.7170\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1227 - val_loss: 4.8284\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9600 - val_loss: 4.5993\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.7666 - val_loss: 4.7869\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6757 - val_loss: 4.8528\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4114 - val_loss: 4.0864\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2893 - val_loss: 4.1699\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2648 - val_loss: 4.2604\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.9998 - val_loss: 4.4672\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2380 - val_loss: 3.6722\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1108 - val_loss: 4.0018\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3901 - val_loss: 4.1960\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3072 - val_loss: 3.2959\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9212 - val_loss: 3.2202\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9865 - val_loss: 3.6646\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4089 - val_loss: 3.5330\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1400 - val_loss: 3.6998\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0330 - val_loss: 2.4489\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0211 - val_loss: 3.6888\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9741 - val_loss: 2.6324\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.7382 - val_loss: 3.3255\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6576 - val_loss: 2.5176\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6221 - val_loss: 3.2144\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4119 - val_loss: 2.0628\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5121 - val_loss: 4.7613\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5309 - val_loss: 1.8276\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3621 - val_loss: 2.0701\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2154 - val_loss: 2.7635\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1542 - val_loss: 2.9928\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2161 - val_loss: 2.2652\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0996 - val_loss: 3.0997\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8992 - val_loss: 2.0231\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1920 - val_loss: 2.1205\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4067 - val_loss: 3.3383\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.4753 - val_loss: 3.4257\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.2698 - val_loss: 4.2030\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1457 - val_loss: 2.2164\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.2709 - val_loss: 2.1041\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0577 - val_loss: 2.7756\n",
      "Iteration number 36 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 31226.0586 - val_loss: 77.0460\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 160349.6094 - val_loss: 84.1261\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 131973.1250 - val_loss: 79.3340\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2153.9724 - val_loss: 74.0621\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 149862.3125 - val_loss: 71.7507\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 139039.8906 - val_loss: 77.3150\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52267.5938 - val_loss: 82.5420\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50345.1211 - val_loss: 83.6876\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47376.1641 - val_loss: 83.1009\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3428.3191 - val_loss: 80.8603\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 64040.2500 - val_loss: 79.6540\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 56709.4922 - val_loss: 81.0134\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10841.7939 - val_loss: 84.4205\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 66610.7734 - val_loss: 86.6829\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 56692.4414 - val_loss: 86.2578\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22376.9629 - val_loss: 84.6159\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16625.0312 - val_loss: 84.5531\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26575.1504 - val_loss: 85.8321\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9632.6641 - val_loss: 86.0106\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10394.4033 - val_loss: 86.0349\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11709.7715 - val_loss: 86.3289\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8557.2344 - val_loss: 86.0941\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3180.1714 - val_loss: 87.5660\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37951.8320 - val_loss: 87.4710\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 26941.2480 - val_loss: 86.2720\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23499.9746 - val_loss: 85.7695\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12523.2480 - val_loss: 87.6570\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27756.0156 - val_loss: 87.8680\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31320.9746 - val_loss: 87.6465\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 501.1097 - val_loss: 85.9459\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23619.2012 - val_loss: 85.5258\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39418.6250 - val_loss: 86.2784\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19210.5391 - val_loss: 87.8478\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13529.6963 - val_loss: 87.9099\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12020.8623 - val_loss: 86.9227\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 26299.2969 - val_loss: 86.8482\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11522.6289 - val_loss: 87.8852\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4870.4097 - val_loss: 88.0392\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6886.7905 - val_loss: 87.1211\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18125.6602 - val_loss: 87.6400\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5128.8784 - val_loss: 88.8056\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35774.0859 - val_loss: 89.2223\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24959.9941 - val_loss: 88.5213\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7289.3496 - val_loss: 88.0694\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1711.7935 - val_loss: 89.0001\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36241.2695 - val_loss: 89.5883\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27124.4434 - val_loss: 88.2618\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29306.3125 - val_loss: 87.6705\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16424.5117 - val_loss: 88.7931\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6147.3101 - val_loss: 89.1985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 37 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 80.3972 - val_loss: 60.5375\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.7020 - val_loss: 12.3397\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24.5539 - val_loss: 8.3108\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.1635 - val_loss: 25.2467\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.2891 - val_loss: 24.4149\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.6934 - val_loss: 12.3801\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.4342 - val_loss: 9.5630\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.7376 - val_loss: 14.3259\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4690 - val_loss: 13.5191\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5815 - val_loss: 9.8831\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4002 - val_loss: 9.2381\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.5308 - val_loss: 6.3597\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6012 - val_loss: 4.9876\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7080 - val_loss: 2.6063\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.7866 - val_loss: 2.6666\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3506 - val_loss: 2.5663\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4300 - val_loss: 2.6197\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2140 - val_loss: 2.8424\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.1752 - val_loss: 2.3691\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1832 - val_loss: 2.4274\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7547 - val_loss: 3.1635\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.7608 - val_loss: 2.4503\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5550 - val_loss: 2.9508\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6564 - val_loss: 2.6697\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4693 - val_loss: 2.1131\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.4791 - val_loss: 2.5576\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.3992 - val_loss: 3.0617\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.6082 - val_loss: 2.2284\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.2435 - val_loss: 2.1534\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.1592 - val_loss: 2.0177\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.1775 - val_loss: 4.3697\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7998 - val_loss: 2.0554\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7718 - val_loss: 2.1647\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1271 - val_loss: 2.9205\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.9823 - val_loss: 2.7216\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9520 - val_loss: 1.8788\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8841 - val_loss: 1.8413\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9038 - val_loss: 2.2185\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6043 - val_loss: 2.2756\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5472 - val_loss: 2.2122\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.4243 - val_loss: 2.3164\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.2905 - val_loss: 1.9618\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.5748 - val_loss: 2.6381\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.5195 - val_loss: 2.4042\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.4682 - val_loss: 1.8999\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.4463 - val_loss: 2.2432\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.2546 - val_loss: 2.4132\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.2975 - val_loss: 1.7592\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.3676 - val_loss: 1.8284\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.3945 - val_loss: 2.9115\n",
      "Iteration number 38 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 76.0872 - val_loss: 56.9167\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40.1973 - val_loss: 21.7992\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.9952 - val_loss: 29.7696\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 29.7145 - val_loss: 39.1182\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.7213 - val_loss: 31.5591\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23.3968 - val_loss: 17.0834\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21.4083 - val_loss: 18.6352\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.0689 - val_loss: 20.9886\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.8328 - val_loss: 11.5602\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.3213 - val_loss: 8.4658\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.8658 - val_loss: 5.2513\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.8777 - val_loss: 2.2829\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4416 - val_loss: 4.4344\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.0589 - val_loss: 2.1135\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.2565 - val_loss: 3.5645\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.7940 - val_loss: 4.8473\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5070 - val_loss: 2.1030\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7308 - val_loss: 5.7631\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3637 - val_loss: 2.6759\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.6766 - val_loss: 3.5038\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2587 - val_loss: 4.2535\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.8676 - val_loss: 3.8965\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.6244 - val_loss: 3.2353\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3413 - val_loss: 4.4890\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3588 - val_loss: 3.7612\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9726 - val_loss: 3.4253\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2324 - val_loss: 4.5698\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3238 - val_loss: 3.6497\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2494 - val_loss: 4.1397\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3668 - val_loss: 3.7146\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8381 - val_loss: 3.6421\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2044 - val_loss: 3.2373\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3742 - val_loss: 4.3176\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0969 - val_loss: 2.5961\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2269 - val_loss: 4.7091\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0474 - val_loss: 3.1392\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9151 - val_loss: 3.0476\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3628 - val_loss: 5.9801\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6927 - val_loss: 2.5449\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6336 - val_loss: 3.9844\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1977 - val_loss: 3.2977\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0933 - val_loss: 4.1880\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0200 - val_loss: 3.0613\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9850 - val_loss: 3.9372\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9641 - val_loss: 2.9597\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8822 - val_loss: 4.4123\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7521 - val_loss: 3.1831\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7904 - val_loss: 3.9599\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7355 - val_loss: 3.1755\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6088 - val_loss: 3.2164\n",
      "Iteration number 39 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 47091.0820 - val_loss: 109.1131\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 368349.8125 - val_loss: 111.5030\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 214011.1719 - val_loss: 104.6370\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21812.4805 - val_loss: 95.3637\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 306832.6875 - val_loss: 92.4755\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 263203.8125 - val_loss: 96.4674\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 104166.2812 - val_loss: 102.1443\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38844.0508 - val_loss: 103.3928\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 80132.9922 - val_loss: 101.7690\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37209.3242 - val_loss: 98.9944\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65642.5391 - val_loss: 99.1756\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7010.6392 - val_loss: 99.1527\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9436.0703 - val_loss: 99.7298\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16897.8770 - val_loss: 98.6225\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33460.0898 - val_loss: 99.5731\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16849.0664 - val_loss: 99.0763\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44562.4258 - val_loss: 98.7085\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5359.7749 - val_loss: 99.4426\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7820.0889 - val_loss: 100.0435\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25638.4922 - val_loss: 98.5713\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 51792.8047 - val_loss: 98.7738\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18914.5020 - val_loss: 99.8143\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27057.5234 - val_loss: 97.7956\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35376.6367 - val_loss: 96.7445\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34159.4766 - val_loss: 99.6355\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 131884.3750 - val_loss: 100.6445\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 90910.3594 - val_loss: 98.6557\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13613.6279 - val_loss: 97.7320\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5717.2041 - val_loss: 99.4735\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 75030.8125 - val_loss: 99.1965\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59544.1133 - val_loss: 97.0931\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31270.0684 - val_loss: 97.1142\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13914.1875 - val_loss: 98.3491\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 48037.7422 - val_loss: 99.0233\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30809.1406 - val_loss: 97.4504\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31689.7969 - val_loss: 97.4827\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12776.5469 - val_loss: 98.5544\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4466.3560 - val_loss: 97.8405\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 76641.5156 - val_loss: 97.6548\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27812.7129 - val_loss: 99.6231\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 57813.5391 - val_loss: 100.9938\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51134.2422 - val_loss: 100.2399\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16338.4502 - val_loss: 99.7341\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6702.9487 - val_loss: 100.0568\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35313.5547 - val_loss: 99.5427\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19316.4551 - val_loss: 100.1636\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15019.0068 - val_loss: 98.5167\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37215.1133 - val_loss: 98.7608\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14570.8994 - val_loss: 97.9556\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11501.2617 - val_loss: 98.5303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 40 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 89.2396 - val_loss: 79.9889\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 71.4865 - val_loss: 59.9108\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 54.9297 - val_loss: 39.2189\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44.1042 - val_loss: 30.0093\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41.2326 - val_loss: 27.2603\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36.3825 - val_loss: 27.0408\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.3034 - val_loss: 18.6167\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 30.3946 - val_loss: 16.6792\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29.2299 - val_loss: 13.9191\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25.7257 - val_loss: 6.0844\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22.5930 - val_loss: 12.5037\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.7502 - val_loss: 7.0831\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.6566 - val_loss: 4.1241\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.8920 - val_loss: 6.7969\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.0944 - val_loss: 5.6891\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.9065 - val_loss: 5.2268\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.9080 - val_loss: 4.4171\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.4004 - val_loss: 4.3178\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.6755 - val_loss: 8.8245\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.8357 - val_loss: 4.5937\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.0122 - val_loss: 9.0582\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.8332 - val_loss: 5.5112\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.9415 - val_loss: 3.9394\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.7217 - val_loss: 3.2471\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.7177 - val_loss: 5.8883\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8089 - val_loss: 3.4642\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3998 - val_loss: 4.5766\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3772 - val_loss: 4.4629\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0192 - val_loss: 3.7519\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3211 - val_loss: 4.4325\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3186 - val_loss: 4.3187\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.4019 - val_loss: 4.4748\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8436 - val_loss: 4.0243\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0778 - val_loss: 3.6603\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5455 - val_loss: 4.3422\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.5031 - val_loss: 5.7105\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8396 - val_loss: 2.5360\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7833 - val_loss: 5.0142\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.9985 - val_loss: 4.4699\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4731 - val_loss: 3.3860\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4130 - val_loss: 5.1859\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.5895 - val_loss: 3.3771\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3195 - val_loss: 5.0919\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2750 - val_loss: 2.9315\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1466 - val_loss: 4.0958\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1823 - val_loss: 4.5172\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4011 - val_loss: 2.7439\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5102 - val_loss: 5.0346\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.9651 - val_loss: 3.7774\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2834 - val_loss: 3.0410\n",
      "Iteration number 41 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 160304.8750 - val_loss: 102.2317\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 67399.7109 - val_loss: 113.5374\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 151629.7969 - val_loss: 111.8665\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 127550.1953 - val_loss: 108.6011\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50341.8633 - val_loss: 103.9577\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31039.2461 - val_loss: 102.6149\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34401.3008 - val_loss: 104.0151\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25226.0410 - val_loss: 104.2103\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8795.7051 - val_loss: 101.6241\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 62094.5117 - val_loss: 100.9566\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50632.3867 - val_loss: 102.3046\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11786.9434 - val_loss: 103.1132\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3095.9121 - val_loss: 103.2325\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15524.9141 - val_loss: 102.7831\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 292.3264 - val_loss: 99.9559\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 64747.4414 - val_loss: 99.8420\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 64087.2773 - val_loss: 101.2766\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15668.1660 - val_loss: 103.1339\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20879.8887 - val_loss: 103.1489\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24694.4473 - val_loss: 102.4283\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10909.2275 - val_loss: 101.8525\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6680.4521 - val_loss: 101.8300\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 26431.6406 - val_loss: 100.9738\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17028.3613 - val_loss: 101.8977\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16966.1699 - val_loss: 102.2347\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8483.9531 - val_loss: 100.9838\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41677.3281 - val_loss: 100.1946\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15394.5742 - val_loss: 101.5167\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1040.1788 - val_loss: 104.9740\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84557.0859 - val_loss: 105.4891\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 104894.1719 - val_loss: 104.8049\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 75378.7344 - val_loss: 103.3057\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38469.8008 - val_loss: 100.9748\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26303.3262 - val_loss: 99.7351\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27221.7168 - val_loss: 100.4467\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5239.9985 - val_loss: 102.0467\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55884.9883 - val_loss: 102.4874\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48810.4492 - val_loss: 101.4770\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8205.9785 - val_loss: 100.2279\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3940.0884 - val_loss: 99.4841\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22274.9844 - val_loss: 99.9478\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4068.0806 - val_loss: 100.8173\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22784.3594 - val_loss: 100.8608\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18586.5840 - val_loss: 99.9750\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16285.5918 - val_loss: 99.7100\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8610.1133 - val_loss: 100.7546\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19185.6406 - val_loss: 100.6115\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 15803.1689 - val_loss: 99.7811\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10237.0127 - val_loss: 99.8708\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2757.4753 - val_loss: 100.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 42 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 256592.0781 - val_loss: 88.8412\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 160702.6719 - val_loss: 102.2349\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 91952.8438 - val_loss: 107.7032\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 70800.0078 - val_loss: 104.4489\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23071.0020 - val_loss: 99.1375\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 84339.9922 - val_loss: 98.3456\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 82554.7891 - val_loss: 100.2561\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45888.0117 - val_loss: 103.7374\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52056.9453 - val_loss: 104.9923\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34591.8242 - val_loss: 102.0916\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19161.9688 - val_loss: 100.9556\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15514.3633 - val_loss: 101.7643\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14293.2998 - val_loss: 102.0118\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1044.5667 - val_loss: 100.9560\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40201.4414 - val_loss: 99.3428\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39711.4727 - val_loss: 101.0821\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2934.2749 - val_loss: 100.9522\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13663.0820 - val_loss: 101.4311\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5469.1230 - val_loss: 100.8328\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16988.7910 - val_loss: 101.0056\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5901.9644 - val_loss: 103.8079\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45770.8320 - val_loss: 103.6640\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42457.8516 - val_loss: 103.0024\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6043.5283 - val_loss: 100.0548\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43711.1797 - val_loss: 98.5385\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49900.9688 - val_loss: 99.6149\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 20743.5469 - val_loss: 101.5820\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15418.1611 - val_loss: 101.9079\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14222.5889 - val_loss: 100.2346\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30510.5918 - val_loss: 99.7466\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12928.8516 - val_loss: 102.0249\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26962.1250 - val_loss: 102.5841\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30108.8750 - val_loss: 101.6662\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12759.3105 - val_loss: 99.1534\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51420.3828 - val_loss: 98.3422\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46434.2227 - val_loss: 99.8205\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5739.2661 - val_loss: 101.5443\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13481.7559 - val_loss: 101.9123\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22589.3555 - val_loss: 101.2318\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7901.6035 - val_loss: 99.0461\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54097.1992 - val_loss: 98.1821\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 39106.9766 - val_loss: 99.5914\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3019.9556 - val_loss: 101.6757\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 42279.9102 - val_loss: 102.9755\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 44157.7852 - val_loss: 102.2272\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25445.4629 - val_loss: 100.3693\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6222.4468 - val_loss: 100.2601\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8197.9180 - val_loss: 100.9507\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19751.7754 - val_loss: 101.3746\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 241.1625 - val_loss: 100.1156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 43 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 99.0915 - val_loss: 79.4526\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51.7472 - val_loss: 42.4144\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45.1770 - val_loss: 38.6349\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.6801 - val_loss: 38.7392\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30.3373 - val_loss: 31.3958\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25.3594 - val_loss: 20.4785\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20.5827 - val_loss: 15.9866\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16.8204 - val_loss: 7.6393\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.5307 - val_loss: 5.0218\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.0348 - val_loss: 7.7734\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.3613 - val_loss: 4.4840\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.0502 - val_loss: 8.8806\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9155 - val_loss: 2.9888\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.7215 - val_loss: 5.8668\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.1790 - val_loss: 2.7845\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.2929 - val_loss: 4.0284\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.7324 - val_loss: 3.3229\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6203 - val_loss: 3.6606\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5051 - val_loss: 2.9550\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9105 - val_loss: 3.9829\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6062 - val_loss: 2.5620\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2450 - val_loss: 3.2575\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9111 - val_loss: 3.1508\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.6789 - val_loss: 2.2400\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5015 - val_loss: 2.2693\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3056 - val_loss: 2.8755\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2382 - val_loss: 1.9304\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8855 - val_loss: 3.6169\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.8837 - val_loss: 2.2056\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5643 - val_loss: 2.7066\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6613 - val_loss: 1.7655\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4619 - val_loss: 4.8799\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.9220 - val_loss: 1.6745\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7591 - val_loss: 4.6322\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1220 - val_loss: 1.6543\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2944 - val_loss: 4.5640\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0810 - val_loss: 1.6477\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3922 - val_loss: 2.8973\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.4108 - val_loss: 1.5461\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4541 - val_loss: 1.9445\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1048 - val_loss: 1.6462\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5718 - val_loss: 4.0300\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0808 - val_loss: 3.3723\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9586 - val_loss: 4.1592\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0533 - val_loss: 2.1021\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.7614 - val_loss: 1.7894\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9171 - val_loss: 1.9166\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6482 - val_loss: 1.5818\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.6713 - val_loss: 1.8836\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.6850 - val_loss: 1.7286\n",
      "Iteration number 44 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 78.5528 - val_loss: 62.7186\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 62.9445 - val_loss: 40.4890\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 51.0645 - val_loss: 44.0326\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40.0468 - val_loss: 35.9731\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.8151 - val_loss: 18.7321\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27.9383 - val_loss: 17.3860\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22.8282 - val_loss: 6.2233\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.3869 - val_loss: 7.6080\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.6770 - val_loss: 5.6140\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.6989 - val_loss: 6.9225\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.2305 - val_loss: 5.6687\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.0791 - val_loss: 7.4601\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.3964 - val_loss: 4.8894\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.0048 - val_loss: 4.9811\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.1342 - val_loss: 7.9296\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.2677 - val_loss: 4.5467\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.1913 - val_loss: 8.9122\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.8681 - val_loss: 4.4604\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.5051 - val_loss: 7.2864\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.3201 - val_loss: 4.3534\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5149 - val_loss: 6.0416\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4928 - val_loss: 4.8911\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6269 - val_loss: 6.1174\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7373 - val_loss: 4.4025\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8988 - val_loss: 7.3654\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3576 - val_loss: 3.8426\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.3244 - val_loss: 7.8076\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7782 - val_loss: 3.8115\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4384 - val_loss: 7.9394\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8691 - val_loss: 3.5530\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.5912 - val_loss: 5.8506\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4502 - val_loss: 5.6969\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2198 - val_loss: 3.4750\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1909 - val_loss: 7.5371\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6906 - val_loss: 3.4438\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.5172 - val_loss: 5.9915\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8213 - val_loss: 4.4528\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5338 - val_loss: 3.9532\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.2189 - val_loss: 5.1413\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6792 - val_loss: 4.7217\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4564 - val_loss: 4.6499\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6840 - val_loss: 5.7281\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4340 - val_loss: 3.6325\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3022 - val_loss: 5.9315\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.3057 - val_loss: 4.0610\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.0967 - val_loss: 4.4482\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.6047 - val_loss: 4.4603\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2113 - val_loss: 4.5305\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8537 - val_loss: 5.5651\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6671 - val_loss: 3.5560\n",
      "Iteration number 45 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 12163.9287 - val_loss: 119.8618\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 228634.5312 - val_loss: 117.1720\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 136947.3438 - val_loss: 114.5623\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31408.5918 - val_loss: 108.6054\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 590.6096 - val_loss: 99.2175\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 232872.4688 - val_loss: 95.3660\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 221355.7969 - val_loss: 96.6407\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 147222.1094 - val_loss: 100.6483\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70685.9062 - val_loss: 105.5363\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34302.9961 - val_loss: 108.6186\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29752.5195 - val_loss: 107.6302\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12125.9102 - val_loss: 104.7244\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 78895.2969 - val_loss: 103.5841\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58520.5977 - val_loss: 104.9300\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34727.4766 - val_loss: 108.1983\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44091.5312 - val_loss: 109.4071\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51338.7852 - val_loss: 108.7745\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21017.0410 - val_loss: 107.5526\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18807.5430 - val_loss: 106.1527\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22023.0703 - val_loss: 106.7623\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5916.9883 - val_loss: 106.9657\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 649.9797 - val_loss: 107.6360\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19200.5195 - val_loss: 107.2203\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6439.9961 - val_loss: 105.3382\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 45743.3281 - val_loss: 105.0099\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40805.7617 - val_loss: 106.4106\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 379.9350 - val_loss: 106.4339\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11018.5264 - val_loss: 106.8316\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5916.5728 - val_loss: 106.4504\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13082.9844 - val_loss: 106.4175\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11998.4160 - val_loss: 107.0519\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8691.9766 - val_loss: 105.5473\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28331.2500 - val_loss: 105.6647\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16363.2266 - val_loss: 106.4872\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19320.9883 - val_loss: 107.2231\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10639.6445 - val_loss: 105.4065\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24102.3008 - val_loss: 105.3301\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25204.8867 - val_loss: 106.0648\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8349.7520 - val_loss: 108.0732\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53355.8945 - val_loss: 108.6889\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46387.0781 - val_loss: 107.8277\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21495.7598 - val_loss: 105.9032\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22993.0918 - val_loss: 105.1329\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24203.0312 - val_loss: 105.5864\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3992.0049 - val_loss: 107.1987\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36322.9961 - val_loss: 107.7637\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35593.4570 - val_loss: 106.7470\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7311.1479 - val_loss: 105.2326\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23865.5898 - val_loss: 104.8807\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24167.7441 - val_loss: 105.7518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 46 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 200494.7500 - val_loss: 86.8451\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3865.9946 - val_loss: 92.5481\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10625.1797 - val_loss: 94.1222\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14306.5293 - val_loss: 92.3947\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32358.6914 - val_loss: 93.3411\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1169.6337 - val_loss: 96.0558\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 62278.9414 - val_loss: 96.8926\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 51797.3164 - val_loss: 94.6548\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6918.2720 - val_loss: 90.8581\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 70756.3125 - val_loss: 90.9279\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 70959.6328 - val_loss: 91.6209\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25056.7734 - val_loss: 94.7789\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22998.1973 - val_loss: 96.1580\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38913.8008 - val_loss: 95.7569\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19952.7559 - val_loss: 93.6365\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35366.0117 - val_loss: 93.8549\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32532.2129 - val_loss: 95.3624\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7970.8511 - val_loss: 95.1909\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8882.1211 - val_loss: 95.7116\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23205.9102 - val_loss: 96.0580\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8316.2705 - val_loss: 95.4454\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7683.1240 - val_loss: 95.5270\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6353.7192 - val_loss: 95.9542\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13004.8896 - val_loss: 95.6410\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 521.4092 - val_loss: 96.4240\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 27930.6973 - val_loss: 96.3660\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17666.5566 - val_loss: 94.6066\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 54787.4883 - val_loss: 93.9554\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39962.4023 - val_loss: 95.5358\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11981.3340 - val_loss: 96.3617\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8692.8418 - val_loss: 95.4661\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31611.5723 - val_loss: 95.2547\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23052.5977 - val_loss: 96.5087\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13705.8486 - val_loss: 96.6064\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5919.8101 - val_loss: 96.2124\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19152.3711 - val_loss: 95.6738\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20172.1543 - val_loss: 96.0949\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3223.5432 - val_loss: 97.5717\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47702.2031 - val_loss: 98.0328\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44607.7188 - val_loss: 97.6419\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32102.9375 - val_loss: 96.1738\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14483.7891 - val_loss: 96.1714\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16517.6289 - val_loss: 97.0031\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15626.8389 - val_loss: 97.0890\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5820.2490 - val_loss: 96.0041\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41964.2773 - val_loss: 95.5155\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23592.5234 - val_loss: 96.3181\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3768.6838 - val_loss: 98.3106\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48010.7773 - val_loss: 98.6694\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 60677.7031 - val_loss: 98.5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 47 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 48 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 112121.9453 - val_loss: 115.9916\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 62823.2188 - val_loss: 115.0217\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5932.9595 - val_loss: 110.4111\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37400.7383 - val_loss: 110.0231\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34892.8867 - val_loss: 112.2965\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35556.7344 - val_loss: 113.1559\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17361.1797 - val_loss: 108.8143\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 83129.5859 - val_loss: 106.7023\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 65746.9453 - val_loss: 110.7621\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9685.8311 - val_loss: 111.0889\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6827.1445 - val_loss: 109.0407\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 43756.4492 - val_loss: 108.0728\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22176.6250 - val_loss: 109.5979\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6800.5610 - val_loss: 115.2619\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 104066.7656 - val_loss: 116.2699\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 112970.8125 - val_loss: 115.2268\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 75394.5391 - val_loss: 112.3375\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17294.3164 - val_loss: 108.7349\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61853.8242 - val_loss: 106.2103\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55456.5859 - val_loss: 107.6870\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2719.3333 - val_loss: 109.3406\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29590.1309 - val_loss: 109.7593\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 32929.9297 - val_loss: 108.4175\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9522.0547 - val_loss: 107.8619\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5023.8921 - val_loss: 107.8308\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4083.5378 - val_loss: 108.2661\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19331.6055 - val_loss: 108.3299\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11298.3047 - val_loss: 106.3798\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42857.2266 - val_loss: 105.8976\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28584.4473 - val_loss: 107.0316\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11255.4121 - val_loss: 109.7169\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54206.8906 - val_loss: 110.0444\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55139.8242 - val_loss: 109.0364\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22697.9688 - val_loss: 107.2840\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2327.0654 - val_loss: 103.9622\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 91389.1562 - val_loss: 102.7469\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 85951.2734 - val_loss: 104.1420\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50719.4219 - val_loss: 105.9413\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14778.7793 - val_loss: 108.1088\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41846.2188 - val_loss: 108.3478\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42079.1992 - val_loss: 107.7160\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15893.8828 - val_loss: 106.0877\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28433.0059 - val_loss: 105.0193\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23088.4043 - val_loss: 105.5128\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13440.4082 - val_loss: 107.9204\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51498.9336 - val_loss: 108.2781\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55895.1914 - val_loss: 107.5912\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38249.4883 - val_loss: 105.9537\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8415.7236 - val_loss: 105.3053\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5705.9385 - val_loss: 106.5028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 49 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 68.6432 - val_loss: 49.1721\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43.8220 - val_loss: 25.8666\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37.8151 - val_loss: 30.8987\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28.8314 - val_loss: 33.6151\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25.1011 - val_loss: 18.5252\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22.8744 - val_loss: 11.7562\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.7063 - val_loss: 17.1232\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.5748 - val_loss: 3.2887\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.1424 - val_loss: 5.6289\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.4538 - val_loss: 2.1991\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.5963 - val_loss: 5.8719\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.9948 - val_loss: 2.0551\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.4865 - val_loss: 4.7734\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.1722 - val_loss: 2.3205\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5323 - val_loss: 3.7774\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.2426 - val_loss: 2.2092\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5513 - val_loss: 5.0969\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2539 - val_loss: 2.4858\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.8885 - val_loss: 2.7338\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8338 - val_loss: 3.6400\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6144 - val_loss: 2.4610\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2458 - val_loss: 3.3091\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0906 - val_loss: 2.8943\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.7063 - val_loss: 2.9194\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5299 - val_loss: 3.0370\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1512 - val_loss: 2.8388\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0496 - val_loss: 3.6378\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6494 - val_loss: 2.5055\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4380 - val_loss: 4.3442\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9269 - val_loss: 2.8360\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4126 - val_loss: 3.0809\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5052 - val_loss: 3.0304\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4369 - val_loss: 4.2834\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2754 - val_loss: 2.7377\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.2951 - val_loss: 2.8428\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4690 - val_loss: 3.2110\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2076 - val_loss: 2.6404\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.1302 - val_loss: 4.0828\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2762 - val_loss: 3.0998\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1103 - val_loss: 3.6843\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1737 - val_loss: 3.7005\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0491 - val_loss: 4.5215\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7520 - val_loss: 3.7094\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9197 - val_loss: 2.3896\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0773 - val_loss: 2.5557\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7917 - val_loss: 2.8027\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0735 - val_loss: 3.5980\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7320 - val_loss: 2.7402\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.2543 - val_loss: 4.4926\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6762 - val_loss: 2.5541\n",
      "Iteration number 50 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 65.2903 - val_loss: 48.0871\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41.1006 - val_loss: 17.1814\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34.9801 - val_loss: 29.0946\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27.6066 - val_loss: 34.0166\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24.8494 - val_loss: 26.0068\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.9910 - val_loss: 18.4688\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.4752 - val_loss: 18.2001\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.8372 - val_loss: 17.1843\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.9496 - val_loss: 6.0434\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.5115 - val_loss: 11.3177\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4762 - val_loss: 3.3023\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6979 - val_loss: 6.0274\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3715 - val_loss: 3.5639\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0802 - val_loss: 4.5462\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2331 - val_loss: 4.7660\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8552 - val_loss: 5.8866\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4620 - val_loss: 3.2289\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8667 - val_loss: 5.9517\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0400 - val_loss: 3.4571\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1884 - val_loss: 4.4170\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0127 - val_loss: 3.5888\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8515 - val_loss: 3.5489\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6876 - val_loss: 3.5888\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5672 - val_loss: 5.1392\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5160 - val_loss: 4.6502\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5575 - val_loss: 3.8406\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4707 - val_loss: 3.2633\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8991 - val_loss: 5.5058\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5778 - val_loss: 3.2614\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7070 - val_loss: 5.6727\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8276 - val_loss: 3.2862\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8657 - val_loss: 4.4027\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6509 - val_loss: 3.5704\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5112 - val_loss: 3.4406\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1547 - val_loss: 3.6172\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1120 - val_loss: 3.1829\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5366 - val_loss: 5.4240\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3732 - val_loss: 3.1808\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2184 - val_loss: 3.5394\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5101 - val_loss: 3.9359\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0186 - val_loss: 3.0832\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0149 - val_loss: 3.5782\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7573 - val_loss: 3.2401\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6704 - val_loss: 4.0996\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7627 - val_loss: 3.0986\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7931 - val_loss: 3.0157\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7866 - val_loss: 4.7405\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1034 - val_loss: 3.0280\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2950 - val_loss: 3.3768\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7892 - val_loss: 3.7991\n",
      "Iteration number 51 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 379673.6875 - val_loss: 95.0587\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14934.9688 - val_loss: 97.1087\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 61707.0664 - val_loss: 100.1751\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71168.6562 - val_loss: 99.3613\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16849.4160 - val_loss: 100.2089\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 83906.9219 - val_loss: 100.9599\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28344.8613 - val_loss: 93.8935\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 137760.7500 - val_loss: 93.1577\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 163414.9375 - val_loss: 95.1306\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 104760.9766 - val_loss: 100.8193\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70431.6484 - val_loss: 101.3707\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61445.0391 - val_loss: 98.0835\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54721.3555 - val_loss: 98.1358\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28906.8887 - val_loss: 102.0773\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 94458.9844 - val_loss: 101.9750\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 61798.3359 - val_loss: 100.5500\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11983.1348 - val_loss: 98.7618\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18158.4258 - val_loss: 99.8594\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62927.5078 - val_loss: 101.0932\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23421.3125 - val_loss: 97.5039\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 90140.2109 - val_loss: 96.2339\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 84831.5000 - val_loss: 97.1547\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7502.7021 - val_loss: 101.2497\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50779.4062 - val_loss: 102.5415\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 98856.1641 - val_loss: 102.2365\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 75623.1016 - val_loss: 98.6262\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 66496.3906 - val_loss: 97.5292\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48487.1992 - val_loss: 99.0400\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10742.2012 - val_loss: 99.6835\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4837.9360 - val_loss: 100.3110\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38646.0078 - val_loss: 100.4329\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6947.6118 - val_loss: 99.1502\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 67801.0000 - val_loss: 97.3029\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 67942.3047 - val_loss: 98.9952\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3040.9836 - val_loss: 101.6112\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 69352.9062 - val_loss: 102.1740\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 69240.7969 - val_loss: 100.2765\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6016.2368 - val_loss: 97.5907\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63954.4727 - val_loss: 97.5973\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64160.7695 - val_loss: 99.4491\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9678.0078 - val_loss: 99.7040\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24718.4922 - val_loss: 99.4666\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20455.7773 - val_loss: 100.3117\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12678.0098 - val_loss: 98.0980\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 70114.4531 - val_loss: 97.9636\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44066.3711 - val_loss: 99.0498\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33041.5703 - val_loss: 100.8813\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18755.6465 - val_loss: 99.1300\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24316.0098 - val_loss: 99.2086\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21651.4629 - val_loss: 100.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 52 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 10622.6953 - val_loss: 109.2208\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 169230.2344 - val_loss: 105.7361\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 132609.6250 - val_loss: 112.8179\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14521.8984 - val_loss: 121.0970\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 114422.7500 - val_loss: 120.5193\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 106797.3047 - val_loss: 118.8924\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26359.1113 - val_loss: 113.1940\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 895.5901 - val_loss: 110.0983\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46424.9688 - val_loss: 111.0575\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16435.9258 - val_loss: 112.7993\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8884.4150 - val_loss: 112.5716\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6938.3848 - val_loss: 111.2549\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44789.8594 - val_loss: 109.8666\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36421.1836 - val_loss: 113.7508\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 64254.1758 - val_loss: 114.8460\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52378.5508 - val_loss: 113.0092\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30073.0723 - val_loss: 108.4004\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 77545.0547 - val_loss: 106.6618\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 70738.3516 - val_loss: 107.6891\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51375.7617 - val_loss: 111.2313\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44834.8438 - val_loss: 112.3501\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38649.0430 - val_loss: 110.6155\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2057.4302 - val_loss: 110.1690\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8105.0430 - val_loss: 108.9975\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14708.0381 - val_loss: 109.8050\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7049.3496 - val_loss: 109.0956\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19064.1191 - val_loss: 109.2230\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6780.0664 - val_loss: 111.6101\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46959.6250 - val_loss: 111.4763\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36632.5938 - val_loss: 109.9221\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6909.0640 - val_loss: 109.1931\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1070.6350 - val_loss: 111.3647\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47690.6875 - val_loss: 111.1717\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36137.8789 - val_loss: 109.6543\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11515.5234 - val_loss: 106.5733\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75331.4062 - val_loss: 105.2482\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 62431.5273 - val_loss: 106.9621\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12274.8330 - val_loss: 109.1076\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11977.7598 - val_loss: 109.6567\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28123.6875 - val_loss: 109.0170\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9299.7861 - val_loss: 106.9724\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33441.4609 - val_loss: 106.6826\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30925.6016 - val_loss: 108.0537\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6612.0488 - val_loss: 107.9673\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4696.8433 - val_loss: 108.5663\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16417.0547 - val_loss: 108.2431\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3577.5813 - val_loss: 108.2031\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16885.1934 - val_loss: 108.4500\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5442.7134 - val_loss: 107.8540\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4134.3696 - val_loss: 107.5928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 53 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 82.5169 - val_loss: 58.7989\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33.1647 - val_loss: 9.1541\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30.8248 - val_loss: 19.5209\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21.8246 - val_loss: 33.5588\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.6361 - val_loss: 31.4300\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20.3354 - val_loss: 17.4711\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.7770 - val_loss: 13.0562\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.5652 - val_loss: 17.6803\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.4720 - val_loss: 19.4386\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.0119 - val_loss: 10.1643\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.0275 - val_loss: 11.6100\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.9138 - val_loss: 11.4931\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.1071 - val_loss: 6.8345\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5810 - val_loss: 7.2806\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0883 - val_loss: 3.1267\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8031 - val_loss: 3.8124\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.3912 - val_loss: 3.2983\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7252 - val_loss: 2.7826\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3895 - val_loss: 3.9947\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5127 - val_loss: 2.6558\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.1723 - val_loss: 2.9031\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.9053 - val_loss: 2.9540\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6352 - val_loss: 3.0579\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4060 - val_loss: 2.9869\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2788 - val_loss: 2.7893\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9710 - val_loss: 3.0438\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6112 - val_loss: 3.6192\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7895 - val_loss: 4.3915\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2533 - val_loss: 4.3756\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4464 - val_loss: 3.9701\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9676 - val_loss: 4.2162\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1879 - val_loss: 3.6693\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5774 - val_loss: 3.1101\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8823 - val_loss: 3.9089\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5799 - val_loss: 2.7609\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7772 - val_loss: 3.0044\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7034 - val_loss: 4.3414\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4187 - val_loss: 4.7965\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9816 - val_loss: 4.2923\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4458 - val_loss: 3.9308\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6030 - val_loss: 4.3801\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9970 - val_loss: 3.7098\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4504 - val_loss: 4.7805\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7290 - val_loss: 3.2651\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8312 - val_loss: 4.1917\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6399 - val_loss: 2.9163\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2599 - val_loss: 3.7520\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1734 - val_loss: 3.2021\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4360 - val_loss: 4.3493\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2148 - val_loss: 3.0252\n",
      "Iteration number 54 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 15129.8896 - val_loss: 86.2581\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 459534.4062 - val_loss: 83.8477\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 301444.2500 - val_loss: 90.7137\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 124642.4453 - val_loss: 97.5361\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 120428.7500 - val_loss: 99.7461\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 123609.3125 - val_loss: 98.2472\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34219.5938 - val_loss: 96.7479\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19759.9941 - val_loss: 98.0418\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27567.9316 - val_loss: 97.9086\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20944.2832 - val_loss: 97.2583\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32571.9043 - val_loss: 98.7351\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41712.2461 - val_loss: 98.1869\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12662.2891 - val_loss: 97.7111\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15957.5146 - val_loss: 98.5652\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25451.8262 - val_loss: 98.5232\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12911.8779 - val_loss: 97.8107\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10251.5713 - val_loss: 98.6295\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37660.5742 - val_loss: 98.1073\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18604.0332 - val_loss: 97.4727\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14516.7881 - val_loss: 98.2992\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48128.3477 - val_loss: 98.7725\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22034.8594 - val_loss: 97.4795\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31119.5820 - val_loss: 97.2904\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25212.3281 - val_loss: 98.1441\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46849.6953 - val_loss: 98.5214\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36783.4062 - val_loss: 96.5510\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 94763.8672 - val_loss: 96.1931\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78082.9922 - val_loss: 97.4629\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7782.1802 - val_loss: 97.4978\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19598.6074 - val_loss: 97.6504\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4705.0547 - val_loss: 97.5565\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14201.4180 - val_loss: 97.6097\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15313.3750 - val_loss: 97.7659\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5388.8511 - val_loss: 97.4063\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10486.8467 - val_loss: 98.0423\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28487.2695 - val_loss: 98.2716\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6506.6768 - val_loss: 97.6446\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8027.7959 - val_loss: 98.7287\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37100.4805 - val_loss: 98.6237\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12514.4736 - val_loss: 97.7934\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8257.5215 - val_loss: 98.2501\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37013.0078 - val_loss: 98.4107\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14368.2812 - val_loss: 96.8520\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63551.7773 - val_loss: 96.4291\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 64866.4492 - val_loss: 97.6032\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19454.5918 - val_loss: 97.8630\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4157.3628 - val_loss: 97.8168\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6672.1279 - val_loss: 97.5458\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 7722.0742 - val_loss: 97.6925\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3507.4778 - val_loss: 97.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 55 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 49851.9531 - val_loss: 126.5642\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 128560.6953 - val_loss: 122.3995\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58325.7422 - val_loss: 119.0095\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14064.6689 - val_loss: 110.6261\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 140257.8281 - val_loss: 106.9037\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 135895.6719 - val_loss: 107.6487\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 87954.9609 - val_loss: 110.2445\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33434.3633 - val_loss: 114.0679\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31030.8613 - val_loss: 115.1070\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47069.5742 - val_loss: 114.6906\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 28024.3750 - val_loss: 110.8772\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26734.9180 - val_loss: 110.1632\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39459.2852 - val_loss: 110.2816\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30079.7070 - val_loss: 113.4514\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56676.3633 - val_loss: 114.4234\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54880.1875 - val_loss: 112.3731\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13841.4922 - val_loss: 110.1127\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43131.4648 - val_loss: 108.7267\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34132.3242 - val_loss: 110.6634\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14022.7617 - val_loss: 111.0210\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8123.6431 - val_loss: 110.1257\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20717.5293 - val_loss: 109.4667\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10604.8555 - val_loss: 110.1777\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7348.6382 - val_loss: 110.7812\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12144.7080 - val_loss: 109.6448\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17481.8926 - val_loss: 109.5420\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7032.9185 - val_loss: 111.1874\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39334.3203 - val_loss: 111.7402\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30498.6191 - val_loss: 110.9242\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6289.4844 - val_loss: 108.3443\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36119.0156 - val_loss: 107.3982\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43447.6094 - val_loss: 108.1528\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20783.8613 - val_loss: 109.3325\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19216.7520 - val_loss: 110.0222\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6337.0977 - val_loss: 108.7256\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15200.1973 - val_loss: 108.2721\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16889.0664 - val_loss: 108.5235\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9911.1445 - val_loss: 110.7916\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 60935.9922 - val_loss: 111.7395\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49744.8242 - val_loss: 110.7211\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20742.3086 - val_loss: 108.5151\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7680.4810 - val_loss: 107.5238\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16434.4629 - val_loss: 108.0704\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3427.7402 - val_loss: 109.3314\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27575.7656 - val_loss: 109.2442\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22341.8379 - val_loss: 108.2230\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8955.9033 - val_loss: 107.7592\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4613.0483 - val_loss: 107.9772\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5388.5928 - val_loss: 107.9014\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12051.1230 - val_loss: 108.3347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 56 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 150637.0469 - val_loss: 60.4213\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7843.4517 - val_loss: 78.2517\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 279397.3125 - val_loss: 86.6454\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 261473.6094 - val_loss: 81.3868\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 122426.0781 - val_loss: 76.5772\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9731.7227 - val_loss: 74.9318\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3858.7952 - val_loss: 77.3545\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55303.1719 - val_loss: 78.6021\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36227.7422 - val_loss: 77.0980\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10772.2002 - val_loss: 72.8374\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 99749.6250 - val_loss: 72.0944\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 94798.7734 - val_loss: 73.4121\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37484.5898 - val_loss: 77.3111\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 896.1779 - val_loss: 79.9520\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40042.3867 - val_loss: 80.6342\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16345.6084 - val_loss: 78.1476\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44849.6875 - val_loss: 77.3968\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45159.8164 - val_loss: 79.5829\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1411.3341 - val_loss: 82.0379\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 49043.3320 - val_loss: 83.0145\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 46105.3945 - val_loss: 81.4497\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5124.9077 - val_loss: 81.3142\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9759.5859 - val_loss: 81.0556\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12114.8457 - val_loss: 81.4756\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11398.0293 - val_loss: 81.5437\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3551.6985 - val_loss: 82.1167\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13466.7002 - val_loss: 81.3448\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19051.2168 - val_loss: 81.1822\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15372.1396 - val_loss: 82.3213\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4442.9321 - val_loss: 79.9762\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38880.6172 - val_loss: 80.1066\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40205.1953 - val_loss: 81.3452\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13516.3535 - val_loss: 84.0391\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30569.6875 - val_loss: 84.3756\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33835.2070 - val_loss: 83.6012\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 606.9387 - val_loss: 83.3613\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16812.3496 - val_loss: 83.5672\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1555.7280 - val_loss: 80.9259\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 46403.3008 - val_loss: 80.7822\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54772.1758 - val_loss: 81.7888\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23700.8887 - val_loss: 83.6363\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20207.5781 - val_loss: 84.8879\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17181.7012 - val_loss: 83.9814\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9220.3271 - val_loss: 84.1778\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 902.1580 - val_loss: 85.6823\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37535.0898 - val_loss: 85.9400\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25089.7129 - val_loss: 85.0505\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9156.7344 - val_loss: 84.4651\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2349.0254 - val_loss: 85.7480\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40231.5195 - val_loss: 86.5591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 57 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 85.0218 - val_loss: 63.3569\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.9170 - val_loss: 15.1152\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31.5831 - val_loss: 16.9278\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24.0383 - val_loss: 29.0915\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20.3073 - val_loss: 24.1956\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.1224 - val_loss: 15.7648\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.0179 - val_loss: 14.7492\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.7749 - val_loss: 14.3257\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.2451 - val_loss: 10.6457\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2244 - val_loss: 4.3161\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3614 - val_loss: 3.5672\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0933 - val_loss: 3.2143\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5843 - val_loss: 3.1966\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2331 - val_loss: 6.7468\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5219 - val_loss: 3.0794\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7918 - val_loss: 5.6883\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7836 - val_loss: 2.8403\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4805 - val_loss: 3.0726\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6094 - val_loss: 6.0282\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9408 - val_loss: 3.2625\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6654 - val_loss: 5.4262\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1656 - val_loss: 2.7712\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8662 - val_loss: 3.9748\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7084 - val_loss: 3.1332\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5641 - val_loss: 3.4557\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6107 - val_loss: 2.8203\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4242 - val_loss: 3.5777\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.2218 - val_loss: 3.2884\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.2461 - val_loss: 2.8288\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7653 - val_loss: 2.9338\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7206 - val_loss: 4.4351\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2465 - val_loss: 2.8308\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5544 - val_loss: 2.8125\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8539 - val_loss: 2.8077\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.8028 - val_loss: 3.1894\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7935 - val_loss: 3.4576\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6481 - val_loss: 2.6617\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6370 - val_loss: 2.8169\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.6418 - val_loss: 2.8818\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9092 - val_loss: 4.2116\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9149 - val_loss: 2.9937\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5846 - val_loss: 2.7351\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5819 - val_loss: 2.9644\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4363 - val_loss: 3.1686\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.4516 - val_loss: 2.9046\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8090 - val_loss: 2.7443\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0102 - val_loss: 2.9616\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4755 - val_loss: 3.0443\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4010 - val_loss: 3.0160\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5008 - val_loss: 3.5227\n",
      "Iteration number 58 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 5182665.5000 - val_loss: 98.9624\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4310527.5000 - val_loss: 97.6350\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3778872.7500 - val_loss: 96.9113\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2219867.2500 - val_loss: 96.1115\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2254320.0000 - val_loss: 95.3471\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1819722.1250 - val_loss: 94.7150\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1227185.2500 - val_loss: 93.9089\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 890387.0625 - val_loss: 93.2578\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 369219.8125 - val_loss: 92.5693\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 167549.5625 - val_loss: 91.9929\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 473681.8438 - val_loss: 91.2386\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 803382.9375 - val_loss: 90.6090\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 325013.2812 - val_loss: 89.9545\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 488839.4062 - val_loss: 89.2880\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 105165.7656 - val_loss: 88.6478\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 315888.8438 - val_loss: 88.0013\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 697024.0000 - val_loss: 87.4450\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 902603.1875 - val_loss: 86.8623\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 950543.3750 - val_loss: 86.3107\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 559213.6250 - val_loss: 85.8506\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 528475.3125 - val_loss: 85.2501\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 559538.4375 - val_loss: 84.7649\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 586367.1875 - val_loss: 84.1492\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 561560.1250 - val_loss: 83.6226\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 492095.5938 - val_loss: 83.1017\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 531332.8125 - val_loss: 82.6128\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 548104.2500 - val_loss: 82.0400\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 596379.3750 - val_loss: 81.4950\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 296038.3750 - val_loss: 81.0405\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 193117.8750 - val_loss: 80.4946\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 487160.9062 - val_loss: 80.0507\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 521842.9375 - val_loss: 79.5582\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 488242.2500 - val_loss: 79.1295\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 471454.0938 - val_loss: 78.6893\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 128557.6484 - val_loss: 78.2627\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 147597.7344 - val_loss: 77.8882\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 180810.3594 - val_loss: 77.3445\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 160890.3281 - val_loss: 76.8560\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 157260.8750 - val_loss: 76.3386\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 154657.0312 - val_loss: 75.7984\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 158970.4688 - val_loss: 75.3355\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 186016.2031 - val_loss: 74.9352\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 378076.7812 - val_loss: 74.4649\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 636270.7500 - val_loss: 74.0925\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1053379.5000 - val_loss: 73.8329\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 312172.8438 - val_loss: 73.5620\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 232736.7344 - val_loss: 73.3324\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 320172.2500 - val_loss: 73.0423\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 113331.8438 - val_loss: 72.7192\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 321028.8750 - val_loss: 72.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 59 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 74.1189 - val_loss: 49.7629\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35.4840 - val_loss: 12.2132\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31.3260 - val_loss: 25.1044\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24.8393 - val_loss: 31.8078\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22.9921 - val_loss: 23.3178\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.4667 - val_loss: 15.9892\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.0315 - val_loss: 15.1514\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.8656 - val_loss: 16.9423\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.4340 - val_loss: 7.1974\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9612 - val_loss: 8.8777\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.7232 - val_loss: 5.8664\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.9344 - val_loss: 6.3418\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3343 - val_loss: 7.2424\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.0015 - val_loss: 4.2320\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9464 - val_loss: 9.2884\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.2345 - val_loss: 4.1377\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4060 - val_loss: 6.0775\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.3460 - val_loss: 5.1988\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8963 - val_loss: 5.8933\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7824 - val_loss: 5.6149\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.5402 - val_loss: 4.5231\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4788 - val_loss: 6.4024\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3276 - val_loss: 3.8917\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1897 - val_loss: 7.4156\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4301 - val_loss: 5.0036\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2507 - val_loss: 3.8193\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0021 - val_loss: 5.0760\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7368 - val_loss: 6.5533\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6227 - val_loss: 5.1774\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4511 - val_loss: 3.6320\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4642 - val_loss: 4.6649\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.1632 - val_loss: 4.0956\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.0628 - val_loss: 5.4356\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9295 - val_loss: 3.7741\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0417 - val_loss: 3.9363\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.7744 - val_loss: 5.2919\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7468 - val_loss: 4.1608\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.6619 - val_loss: 4.1833\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5306 - val_loss: 5.2604\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.7437 - val_loss: 4.3419\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5998 - val_loss: 2.0275\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9283 - val_loss: 7.1915\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0657 - val_loss: 3.1087\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8711 - val_loss: 2.4687\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.2990 - val_loss: 2.9290\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1874 - val_loss: 6.9642\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8325 - val_loss: 1.7760\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4253 - val_loss: 3.7392\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7002 - val_loss: 4.6808\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4302 - val_loss: 1.6556\n",
      "Iteration number 60 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 87.0844 - val_loss: 67.5338\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.6300 - val_loss: 25.6634\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.5949 - val_loss: 28.3616\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29.2408 - val_loss: 36.5468\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 26.1975 - val_loss: 32.6163\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22.8520 - val_loss: 20.4799\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18.7532 - val_loss: 16.4838\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.6064 - val_loss: 15.1548\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.5198 - val_loss: 10.8874\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2873 - val_loss: 6.5435\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1668 - val_loss: 6.9689\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3860 - val_loss: 5.3489\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1472 - val_loss: 6.6335\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.7979 - val_loss: 4.4526\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7834 - val_loss: 8.3306\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5606 - val_loss: 3.0243\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.3104 - val_loss: 4.3769\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7586 - val_loss: 4.2940\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2481 - val_loss: 5.9793\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5459 - val_loss: 2.6282\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6160 - val_loss: 5.4666\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1211 - val_loss: 3.6254\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7345 - val_loss: 3.4733\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.0936 - val_loss: 4.6085\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7329 - val_loss: 2.8992\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2989 - val_loss: 3.4340\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2901 - val_loss: 4.0304\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0593 - val_loss: 3.1035\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8662 - val_loss: 3.5396\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9716 - val_loss: 2.9890\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9960 - val_loss: 2.6744\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0902 - val_loss: 5.1479\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1766 - val_loss: 2.6212\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4715 - val_loss: 2.8430\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6952 - val_loss: 3.1395\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3645 - val_loss: 2.6489\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2556 - val_loss: 3.3071\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7569 - val_loss: 2.6064\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6530 - val_loss: 2.9350\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6942 - val_loss: 2.8062\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4776 - val_loss: 2.6322\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9374 - val_loss: 3.1128\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.4807 - val_loss: 2.4079\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4810 - val_loss: 2.4915\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7238 - val_loss: 2.3454\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7193 - val_loss: 3.1346\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.3972 - val_loss: 3.6738\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.3065 - val_loss: 3.2768\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.1786 - val_loss: 2.9999\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7636 - val_loss: 2.2113\n",
      "Iteration number 61 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 18550.9297 - val_loss: 115.0797\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 291241.6250 - val_loss: 110.4249\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 191128.0156 - val_loss: 104.4535\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53932.0703 - val_loss: 97.2562\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 100454.6797 - val_loss: 92.1032\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90953.4453 - val_loss: 97.2977\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36575.2734 - val_loss: 98.6470\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23638.5254 - val_loss: 95.2406\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52285.0664 - val_loss: 94.7360\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32695.4180 - val_loss: 96.8013\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5373.5356 - val_loss: 102.2580\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 127341.1875 - val_loss: 104.2369\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 121188.4844 - val_loss: 101.7760\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52564.8008 - val_loss: 98.8208\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5945.4829 - val_loss: 97.4039\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6877.3843 - val_loss: 99.3461\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35281.8242 - val_loss: 98.9468\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20387.0254 - val_loss: 96.0910\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40850.7188 - val_loss: 96.3149\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29387.7109 - val_loss: 99.0348\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27968.3379 - val_loss: 98.8209\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7991.4990 - val_loss: 97.6504\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6702.3457 - val_loss: 96.9551\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26743.4473 - val_loss: 97.2268\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4659.2642 - val_loss: 101.2492\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 103027.2812 - val_loss: 103.2967\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 86364.5859 - val_loss: 101.5231\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36095.6250 - val_loss: 98.6174\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7023.9805 - val_loss: 97.4880\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19738.4395 - val_loss: 98.2896\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 648.3627 - val_loss: 101.0815\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69620.7266 - val_loss: 101.6010\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62680.8555 - val_loss: 99.9389\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13123.4160 - val_loss: 97.9490\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38237.3906 - val_loss: 96.6710\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36381.5312 - val_loss: 98.1433\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2180.2368 - val_loss: 100.5560\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 49526.0391 - val_loss: 100.9419\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47572.2734 - val_loss: 100.4410\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28126.3164 - val_loss: 97.4477\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25840.2441 - val_loss: 96.9269\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42527.0391 - val_loss: 97.0825\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33881.4258 - val_loss: 99.9673\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 49855.8867 - val_loss: 101.0236\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 48259.3477 - val_loss: 99.5892\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4516.0166 - val_loss: 98.0956\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45164.0938 - val_loss: 96.9332\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40538.0547 - val_loss: 99.0456\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19320.4082 - val_loss: 99.5716\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7243.9761 - val_loss: 98.7417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 62 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 74.7477 - val_loss: 54.1404\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.1222 - val_loss: 6.6230\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27.6610 - val_loss: 21.1870\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.1457 - val_loss: 28.9997\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.6697 - val_loss: 20.1265\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.3615 - val_loss: 13.1896\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.6025 - val_loss: 18.6230\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.8314 - val_loss: 12.7490\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.8602 - val_loss: 13.0877\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6708 - val_loss: 10.8477\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.9171 - val_loss: 8.2262\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3891 - val_loss: 7.0969\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.7216 - val_loss: 5.5804\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1698 - val_loss: 6.2455\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5802 - val_loss: 3.4137\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2383 - val_loss: 5.1367\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.0000 - val_loss: 3.2247\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4075 - val_loss: 4.3950\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1826 - val_loss: 3.0780\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8568 - val_loss: 3.6857\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9061 - val_loss: 2.9836\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5566 - val_loss: 3.0750\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5486 - val_loss: 3.9166\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8508 - val_loss: 4.4430\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9957 - val_loss: 5.3815\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.2164 - val_loss: 3.6175\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4371 - val_loss: 4.8654\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9701 - val_loss: 2.7723\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5089 - val_loss: 2.7907\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3258 - val_loss: 2.8887\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2211 - val_loss: 2.9026\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3526 - val_loss: 3.2074\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8319 - val_loss: 2.8186\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1587 - val_loss: 2.9346\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0207 - val_loss: 3.0008\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8402 - val_loss: 2.5719\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6631 - val_loss: 2.6479\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6265 - val_loss: 2.7270\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9074 - val_loss: 3.0359\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7621 - val_loss: 2.6433\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6381 - val_loss: 2.9109\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8057 - val_loss: 2.4617\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6020 - val_loss: 2.6504\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4650 - val_loss: 2.6929\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7181 - val_loss: 2.5202\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.0852 - val_loss: 2.9840\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3007 - val_loss: 3.9188\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5017 - val_loss: 3.3517\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9671 - val_loss: 2.7832\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5385 - val_loss: 2.5672\n",
      "Iteration number 63 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 2494805.5000 - val_loss: 100.2677\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4343650.0000 - val_loss: 99.2557\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4516037.5000 - val_loss: 98.5782\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 997127.5000 - val_loss: 97.7368\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 919595.0625 - val_loss: 96.8748\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 320067.4375 - val_loss: 96.1270\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 661921.5625 - val_loss: 95.3337\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 928741.5000 - val_loss: 94.5655\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1085453.6250 - val_loss: 93.9167\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 550441.6875 - val_loss: 93.2631\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 292260.6875 - val_loss: 92.5108\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 628908.5000 - val_loss: 91.8852\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 839545.6875 - val_loss: 91.3718\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 820962.1250 - val_loss: 90.6534\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 448170.5938 - val_loss: 90.0867\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 700980.5625 - val_loss: 89.4969\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1008954.9375 - val_loss: 88.9878\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 996091.6875 - val_loss: 88.4793\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 944104.1875 - val_loss: 88.1783\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 659326.5000 - val_loss: 87.7224\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 427523.9375 - val_loss: 87.2688\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 485016.8438 - val_loss: 86.9076\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 227976.1875 - val_loss: 86.4750\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 120343.0938 - val_loss: 85.9716\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 321602.2500 - val_loss: 85.4712\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 94944.2109 - val_loss: 85.0116\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 127257.6172 - val_loss: 84.5593\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 164036.4531 - val_loss: 84.0691\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 121901.4844 - val_loss: 83.5673\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 164157.6250 - val_loss: 83.0989\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 165100.3906 - val_loss: 82.6745\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 311278.2500 - val_loss: 82.2619\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 562399.1875 - val_loss: 81.8706\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 167890.8281 - val_loss: 81.4662\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 198516.8594 - val_loss: 81.0577\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 460130.2500 - val_loss: 80.6638\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 361037.3750 - val_loss: 80.3332\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 102867.0781 - val_loss: 79.9903\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 143012.2344 - val_loss: 79.6618\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 119470.0625 - val_loss: 79.3624\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 132646.6094 - val_loss: 79.0244\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 125859.2500 - val_loss: 78.6800\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 129262.8984 - val_loss: 78.3831\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 130376.3828 - val_loss: 78.0842\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 120355.1719 - val_loss: 77.7788\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 137197.7969 - val_loss: 77.4458\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 122266.8281 - val_loss: 77.1776\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 137449.9688 - val_loss: 76.8867\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 122923.8672 - val_loss: 76.5977\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 132120.5312 - val_loss: 76.2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 64 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 28120.7637 - val_loss: 107.1560\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 100352.4844 - val_loss: 104.6785\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55939.1172 - val_loss: 100.2706\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52043.3477 - val_loss: 98.8414\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39130.8008 - val_loss: 102.3630\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34011.8164 - val_loss: 101.8847\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20719.4844 - val_loss: 100.1943\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30149.3555 - val_loss: 99.8512\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14238.3105 - val_loss: 101.5371\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19596.9395 - val_loss: 101.4087\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13989.4639 - val_loss: 99.9766\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40485.0273 - val_loss: 99.6211\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20667.9316 - val_loss: 101.0194\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29266.3555 - val_loss: 101.9505\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25039.8438 - val_loss: 100.1676\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40604.0781 - val_loss: 99.5727\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32977.2227 - val_loss: 101.9697\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51228.9062 - val_loss: 102.6894\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47079.8828 - val_loss: 101.0056\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13818.7734 - val_loss: 100.4663\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6309.0664 - val_loss: 102.6871\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63024.8828 - val_loss: 103.0306\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 51468.1602 - val_loss: 102.3185\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8776.9424 - val_loss: 99.5160\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73808.1328 - val_loss: 97.7976\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 63340.6133 - val_loss: 99.6379\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24089.8105 - val_loss: 101.2219\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41320.2188 - val_loss: 101.4504\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35136.7773 - val_loss: 100.3716\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3316.5659 - val_loss: 100.1767\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8296.7266 - val_loss: 100.0913\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5886.5796 - val_loss: 99.9122\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3661.7224 - val_loss: 100.3449\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8675.7158 - val_loss: 100.2262\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3769.1958 - val_loss: 99.6156\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23237.9590 - val_loss: 99.5373\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12072.5088 - val_loss: 100.1392\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12859.1113 - val_loss: 100.4015\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7440.3643 - val_loss: 99.9689\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22653.6133 - val_loss: 99.5597\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18301.7812 - val_loss: 100.7371\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35527.6875 - val_loss: 101.0935\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31380.3594 - val_loss: 100.3895\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2704.1489 - val_loss: 100.1683\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6606.3657 - val_loss: 100.0855\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12207.9912 - val_loss: 99.8981\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1231.1805 - val_loss: 100.0062\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5762.1426 - val_loss: 100.2662\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11696.0732 - val_loss: 100.2175\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2639.8323 - val_loss: 100.1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 65 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 90.4844 - val_loss: 70.1912\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42.0088 - val_loss: 19.8513\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32.1752 - val_loss: 22.0390\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24.9721 - val_loss: 30.4013\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21.9063 - val_loss: 21.6125\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.3314 - val_loss: 13.9611\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.5246 - val_loss: 16.5372\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.4696 - val_loss: 14.4114\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.2927 - val_loss: 12.0946\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.3110 - val_loss: 6.9040\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.1257 - val_loss: 7.5069\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.6952 - val_loss: 4.7975\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.9748 - val_loss: 6.1435\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4903 - val_loss: 3.7766\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.1847 - val_loss: 5.6721\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.7878 - val_loss: 3.6447\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.4754 - val_loss: 5.7676\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3352 - val_loss: 3.5204\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.8757 - val_loss: 4.5245\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8822 - val_loss: 4.0085\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9305 - val_loss: 3.0018\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9029 - val_loss: 5.3860\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5073 - val_loss: 2.3488\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6933 - val_loss: 3.9033\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6736 - val_loss: 3.5966\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.0386 - val_loss: 2.6832\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5370 - val_loss: 5.3838\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6437 - val_loss: 2.1674\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6166 - val_loss: 3.7986\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6985 - val_loss: 3.5376\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2599 - val_loss: 3.1274\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0601 - val_loss: 4.3154\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.9580 - val_loss: 3.1271\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0283 - val_loss: 3.5048\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8339 - val_loss: 3.2457\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8476 - val_loss: 4.6269\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6161 - val_loss: 3.2877\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4278 - val_loss: 3.1724\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3422 - val_loss: 3.2268\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2234 - val_loss: 2.7579\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3110 - val_loss: 2.9243\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8853 - val_loss: 4.5202\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6575 - val_loss: 2.6778\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9261 - val_loss: 3.6849\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9371 - val_loss: 2.3239\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7467 - val_loss: 4.1665\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9038 - val_loss: 3.1305\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.1414 - val_loss: 2.5803\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.5195 - val_loss: 3.6122\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.4421 - val_loss: 2.5364\n",
      "Iteration number 66 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 102.4346 - val_loss: 79.8718\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45.0232 - val_loss: 28.6956\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42.5888 - val_loss: 22.0568\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30.8140 - val_loss: 36.6549\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26.0747 - val_loss: 38.0231\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23.8256 - val_loss: 28.8384\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.5573 - val_loss: 17.2658\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18.9035 - val_loss: 17.3362\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.6513 - val_loss: 18.4627\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.9111 - val_loss: 13.4784\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.9892 - val_loss: 10.7233\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5548 - val_loss: 7.5988\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.3234 - val_loss: 9.9259\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.8921 - val_loss: 5.2651\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.1198 - val_loss: 9.6606\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6436 - val_loss: 6.4769\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3454 - val_loss: 9.5707\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4000 - val_loss: 6.8349\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9418 - val_loss: 7.1255\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7939 - val_loss: 7.3666\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6412 - val_loss: 7.0787\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4888 - val_loss: 7.3597\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2715 - val_loss: 6.8246\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2824 - val_loss: 6.0751\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2168 - val_loss: 5.5779\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8614 - val_loss: 7.0656\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8086 - val_loss: 4.1761\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7313 - val_loss: 6.5307\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.7705 - val_loss: 6.0937\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.5180 - val_loss: 3.3958\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3644 - val_loss: 7.1385\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2115 - val_loss: 4.1883\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.9513 - val_loss: 6.2767\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1457 - val_loss: 5.1302\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7880 - val_loss: 5.0118\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5672 - val_loss: 5.0468\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4422 - val_loss: 4.3307\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3859 - val_loss: 4.9918\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1749 - val_loss: 3.7264\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0207 - val_loss: 5.4882\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2868 - val_loss: 2.2898\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0949 - val_loss: 3.6267\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7519 - val_loss: 4.0671\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8807 - val_loss: 3.8992\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6948 - val_loss: 4.7998\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6159 - val_loss: 1.6711\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8988 - val_loss: 5.8361\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5554 - val_loss: 1.8993\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7485 - val_loss: 4.6558\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7909 - val_loss: 4.0008\n",
      "Iteration number 67 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 92.1184 - val_loss: 67.9599\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40.1310 - val_loss: 15.9844\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25.7555 - val_loss: 9.4668\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.9788 - val_loss: 22.5387\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19.2733 - val_loss: 25.7717\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.7102 - val_loss: 13.0762\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.7309 - val_loss: 7.6051\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.8808 - val_loss: 11.4479\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.7136 - val_loss: 10.0224\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0623 - val_loss: 7.0558\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9304 - val_loss: 6.5452\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1242 - val_loss: 6.9776\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0611 - val_loss: 6.1749\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.9591 - val_loss: 6.8024\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.6363 - val_loss: 6.2451\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6412 - val_loss: 6.7174\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9434 - val_loss: 6.0463\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4517 - val_loss: 6.6795\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8296 - val_loss: 6.0145\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.0382 - val_loss: 6.4608\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.5895 - val_loss: 6.0178\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.5141 - val_loss: 7.2971\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.7531 - val_loss: 6.1374\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.2194 - val_loss: 6.3648\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.0423 - val_loss: 6.0361\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.1489 - val_loss: 7.1730\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.7937 - val_loss: 5.9263\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.0448 - val_loss: 6.4023\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.0440 - val_loss: 6.0823\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7003 - val_loss: 5.7870\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.6545 - val_loss: 6.1929\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4.6482 - val_loss: 5.6795\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.5630 - val_loss: 7.0444\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9496 - val_loss: 5.7375\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6474 - val_loss: 5.8206\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8509 - val_loss: 6.2280\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5297 - val_loss: 5.5566\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.4343 - val_loss: 7.0969\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.1148 - val_loss: 5.4159\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5223 - val_loss: 6.2647\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.3552 - val_loss: 5.3554\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.4531 - val_loss: 6.6720\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.4216 - val_loss: 5.3091\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.2568 - val_loss: 5.8999\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.2316 - val_loss: 5.2244\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.1329 - val_loss: 5.4869\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.0446 - val_loss: 5.3420\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.9434 - val_loss: 5.1479\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.8742 - val_loss: 5.5328\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.7599 - val_loss: 5.0084\n",
      "Iteration number 68 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 80.5226 - val_loss: 58.5061\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33.1927 - val_loss: 6.8662\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25.3859 - val_loss: 2.8707\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.1645 - val_loss: 19.6879\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.6167 - val_loss: 24.4745\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.5911 - val_loss: 15.0432\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.0117 - val_loss: 7.6428\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.8662 - val_loss: 10.4895\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.8517 - val_loss: 13.0362\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.8504 - val_loss: 9.3732\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.4600 - val_loss: 8.0352\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.8242 - val_loss: 3.4342\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5032 - val_loss: 3.0636\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.7423 - val_loss: 4.8145\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.9528 - val_loss: 3.3638\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.2141 - val_loss: 4.5582\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3340 - val_loss: 4.7088\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.0067 - val_loss: 3.0299\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.6479 - val_loss: 3.1219\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5568 - val_loss: 4.1990\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.9717 - val_loss: 4.4653\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.9974 - val_loss: 3.4998\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.8279 - val_loss: 3.1763\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.8770 - val_loss: 3.2102\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.9043 - val_loss: 3.7227\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.1119 - val_loss: 3.1688\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.7131 - val_loss: 3.3083\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.7490 - val_loss: 3.4497\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.7185 - val_loss: 3.2111\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5640 - val_loss: 3.1429\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5826 - val_loss: 3.1342\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.5998 - val_loss: 3.7129\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.0819 - val_loss: 3.0739\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.5017 - val_loss: 3.0806\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.5664 - val_loss: 3.1618\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4973 - val_loss: 3.1528\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3829 - val_loss: 3.1238\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4436 - val_loss: 3.2737\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5294 - val_loss: 3.1133\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3371 - val_loss: 3.1062\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.3763 - val_loss: 3.5107\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5494 - val_loss: 3.0179\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.3802 - val_loss: 3.2734\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.6652 - val_loss: 4.6346\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0971 - val_loss: 3.4426\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.7203 - val_loss: 3.1480\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5971 - val_loss: 3.7207\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9734 - val_loss: 3.8126\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0369 - val_loss: 4.4965\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8029 - val_loss: 3.1678\n",
      "Iteration number 69 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 51.4310 - val_loss: 24.8838\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.4341 - val_loss: 5.6661\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.0572 - val_loss: 22.9343\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.6873 - val_loss: 27.0747\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.7659 - val_loss: 15.0447\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.0575 - val_loss: 8.1889\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.3201 - val_loss: 14.0643\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.5941 - val_loss: 14.6826\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.1396 - val_loss: 8.9053\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6946 - val_loss: 12.5081\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6926 - val_loss: 4.5469\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5528 - val_loss: 6.6140\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6660 - val_loss: 4.3637\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9358 - val_loss: 4.1482\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3085 - val_loss: 4.0189\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1816 - val_loss: 3.8816\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2197 - val_loss: 4.0084\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3040 - val_loss: 4.4599\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0613 - val_loss: 5.6295\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6823 - val_loss: 4.6639\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0218 - val_loss: 4.1386\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6354 - val_loss: 4.1282\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5628 - val_loss: 4.4816\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8880 - val_loss: 4.0876\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4138 - val_loss: 4.2406\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.3893 - val_loss: 4.1573\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1661 - val_loss: 4.1335\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.1358 - val_loss: 4.1447\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0917 - val_loss: 4.0645\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1760 - val_loss: 4.0886\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.2060 - val_loss: 4.4011\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4041 - val_loss: 4.0307\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9195 - val_loss: 3.9130\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8462 - val_loss: 3.9394\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1611 - val_loss: 4.4107\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4505 - val_loss: 4.1144\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8611 - val_loss: 4.2429\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0910 - val_loss: 4.0709\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8581 - val_loss: 3.9247\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9590 - val_loss: 4.0309\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7479 - val_loss: 4.1180\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7852 - val_loss: 4.1729\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8658 - val_loss: 3.8604\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5357 - val_loss: 3.9821\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8020 - val_loss: 3.7244\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3884 - val_loss: 3.7749\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4680 - val_loss: 3.8346\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.5499 - val_loss: 4.0115\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.8749 - val_loss: 3.9289\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4540 - val_loss: 3.9462\n",
      "Iteration number 70 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1868641.8750 - val_loss: 73.7066\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 878342.1875 - val_loss: 89.9292\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 337272.8125 - val_loss: 104.3337\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 392228.4375 - val_loss: 102.8928\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 212276.5781 - val_loss: 99.2928\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 204276.8906 - val_loss: 93.1998\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 341083.7812 - val_loss: 95.3240\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 105049.5469 - val_loss: 100.1793\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 127542.7109 - val_loss: 100.7042\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 136728.5938 - val_loss: 98.0197\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 120972.4062 - val_loss: 97.3055\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 58636.4609 - val_loss: 101.7288\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 269186.4062 - val_loss: 102.4869\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 169753.3906 - val_loss: 99.0593\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33123.6680 - val_loss: 98.1159\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 52541.4258 - val_loss: 99.2952\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 64196.0117 - val_loss: 97.9120\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 45283.9258 - val_loss: 100.8908\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 193159.3281 - val_loss: 101.7060\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 73791.9531 - val_loss: 97.4417\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 134579.8750 - val_loss: 96.9028\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 105965.8672 - val_loss: 99.1550\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62788.3281 - val_loss: 100.2807\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27195.5742 - val_loss: 98.9517\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28323.1113 - val_loss: 101.8159\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 131301.4219 - val_loss: 101.0836\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42710.6758 - val_loss: 99.3532\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33771.5352 - val_loss: 102.0983\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 125837.8984 - val_loss: 101.6522\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62502.9258 - val_loss: 97.8698\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 179487.5156 - val_loss: 97.7502\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 100670.0938 - val_loss: 100.3092\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 134104.3438 - val_loss: 102.5903\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 105375.3438 - val_loss: 99.3046\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 113746.8672 - val_loss: 98.9851\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 69875.0859 - val_loss: 102.2085\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 121057.8672 - val_loss: 101.2012\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19113.3750 - val_loss: 99.4071\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 101672.1875 - val_loss: 98.0434\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 124598.5625 - val_loss: 101.3656\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75754.6094 - val_loss: 100.5564\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9829.9570 - val_loss: 98.7070\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 226562.3125 - val_loss: 96.9788\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 116207.6328 - val_loss: 100.6909\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 114134.4609 - val_loss: 101.9989\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 105678.4922 - val_loss: 99.5667\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 64674.2617 - val_loss: 99.3001\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41442.8203 - val_loss: 101.3276\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 59174.0664 - val_loss: 100.0319\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 54060.5625 - val_loss: 100.4075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 71 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 144143.2656 - val_loss: 93.9451\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69968.9062 - val_loss: 100.1026\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26892.1719 - val_loss: 90.8044\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38868.5898 - val_loss: 91.0355\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35463.1367 - val_loss: 97.3786\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46888.4648 - val_loss: 98.4309\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16361.8682 - val_loss: 93.4078\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28180.8184 - val_loss: 92.2023\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26305.8691 - val_loss: 95.7460\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21777.1621 - val_loss: 96.2706\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1544.0306 - val_loss: 96.4164\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10898.2002 - val_loss: 96.5786\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12504.8750 - val_loss: 93.5796\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15783.9971 - val_loss: 94.9046\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1993.1581 - val_loss: 99.5482\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39088.5312 - val_loss: 98.4598\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23361.2031 - val_loss: 96.3783\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26110.9590 - val_loss: 92.7757\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24338.9531 - val_loss: 96.6128\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28625.0781 - val_loss: 97.6461\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9377.6221 - val_loss: 94.1825\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23363.0566 - val_loss: 93.4016\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20764.8887 - val_loss: 96.1899\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28020.8887 - val_loss: 97.9306\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2334.8843 - val_loss: 96.3382\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22392.9062 - val_loss: 97.4518\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6775.8569 - val_loss: 94.5120\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22057.4941 - val_loss: 93.8894\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19784.5859 - val_loss: 97.5962\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25145.8633 - val_loss: 97.5214\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14335.1416 - val_loss: 92.9834\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30047.3223 - val_loss: 93.6944\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21060.8359 - val_loss: 95.6289\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18445.2480 - val_loss: 97.4842\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7631.6890 - val_loss: 92.7810\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55255.9883 - val_loss: 90.9996\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46615.2031 - val_loss: 92.6657\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17936.2656 - val_loss: 98.5785\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21535.8496 - val_loss: 100.1125\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35872.1211 - val_loss: 98.2778\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16906.7754 - val_loss: 94.5882\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20757.1465 - val_loss: 95.0521\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15675.4131 - val_loss: 97.4714\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12860.2939 - val_loss: 97.1990\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2228.4941 - val_loss: 95.0008\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28275.5957 - val_loss: 94.5447\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21791.8301 - val_loss: 97.2370\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20533.9434 - val_loss: 98.4144\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6928.2886 - val_loss: 95.0206\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37889.7266 - val_loss: 93.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 72 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1720354.8750 - val_loss: 82.2321\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 685483.5000 - val_loss: 91.2005\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 212590.4219 - val_loss: 96.3483\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 178496.6094 - val_loss: 92.4116\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 319647.3750 - val_loss: 91.6452\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 186630.5000 - val_loss: 94.6161\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 230631.7344 - val_loss: 96.3033\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 125621.9453 - val_loss: 92.5802\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 309478.0312 - val_loss: 91.6552\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 227604.5312 - val_loss: 92.9609\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67291.3516 - val_loss: 95.8031\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 171788.8906 - val_loss: 94.7599\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59760.6641 - val_loss: 92.0868\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 218164.5156 - val_loss: 91.7697\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 146840.2812 - val_loss: 93.4452\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 92502.5391 - val_loss: 94.8660\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 81657.3281 - val_loss: 93.0720\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 96937.7266 - val_loss: 92.9846\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28991.3457 - val_loss: 94.2676\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 195529.6875 - val_loss: 95.9141\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 215436.7031 - val_loss: 94.3430\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50423.1094 - val_loss: 92.3448\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 181716.8750 - val_loss: 92.5073\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38870.0391 - val_loss: 93.9519\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46725.1406 - val_loss: 92.1386\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 133975.2188 - val_loss: 92.2704\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 75108.9844 - val_loss: 94.6685\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 215529.5312 - val_loss: 94.7309\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 150930.2812 - val_loss: 92.9686\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25396.3281 - val_loss: 92.9535\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 84614.9297 - val_loss: 94.1256\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 71748.7969 - val_loss: 92.5311\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 183476.0469 - val_loss: 92.1421\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 96018.9453 - val_loss: 94.0214\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34109.2812 - val_loss: 94.6577\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28535.6719 - val_loss: 94.2442\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 116510.0000 - val_loss: 94.2330\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 83249.4844 - val_loss: 96.0307\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 81638.7656 - val_loss: 95.8325\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 71091.2812 - val_loss: 95.1299\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12672.4043 - val_loss: 97.1710\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 239626.1094 - val_loss: 98.0642\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 199991.9531 - val_loss: 96.1049\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73287.1250 - val_loss: 94.0567\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 168224.5156 - val_loss: 94.5765\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67623.6953 - val_loss: 96.3850\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 144469.9219 - val_loss: 96.7609\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 130692.8516 - val_loss: 95.7430\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16471.1660 - val_loss: 94.9712\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 71571.8516 - val_loss: 95.3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 73 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 225389.8750 - val_loss: 71.9609\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22902.4336 - val_loss: 83.0532\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 101306.1016 - val_loss: 89.0479\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 129553.8281 - val_loss: 87.4517\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 76447.8594 - val_loss: 84.2368\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12305.0674 - val_loss: 82.7449\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5423.2817 - val_loss: 82.5881\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 52382.4336 - val_loss: 80.9033\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26259.2676 - val_loss: 83.2964\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37905.2188 - val_loss: 84.8955\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31251.0332 - val_loss: 83.8548\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7747.8042 - val_loss: 83.5227\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7320.5278 - val_loss: 83.3795\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4788.9482 - val_loss: 83.3001\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9635.0811 - val_loss: 83.8930\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43523.2695 - val_loss: 85.6475\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28450.9961 - val_loss: 83.5835\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35522.3086 - val_loss: 82.6516\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24285.4746 - val_loss: 83.7733\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22699.0703 - val_loss: 85.5020\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22087.0098 - val_loss: 83.8515\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21429.4492 - val_loss: 84.3831\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4848.1318 - val_loss: 86.4326\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41177.4258 - val_loss: 86.5489\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33468.7617 - val_loss: 84.7442\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19531.4668 - val_loss: 84.8055\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 419.8939 - val_loss: 84.8894\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17773.4434 - val_loss: 84.6943\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14561.2549 - val_loss: 86.2230\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36021.3242 - val_loss: 86.8975\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16205.2783 - val_loss: 84.7611\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39101.1250 - val_loss: 84.0773\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37485.5078 - val_loss: 84.7514\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6667.8618 - val_loss: 86.2662\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1234.2894 - val_loss: 86.9072\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16808.5352 - val_loss: 86.3587\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6890.1733 - val_loss: 86.7474\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13307.6572 - val_loss: 86.5537\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2833.0579 - val_loss: 87.1435\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12667.1172 - val_loss: 86.3620\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15501.6943 - val_loss: 86.3541\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 242.2429 - val_loss: 86.6201\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4172.6948 - val_loss: 87.1913\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9356.1377 - val_loss: 86.9233\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 620.5816 - val_loss: 87.3921\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22516.5176 - val_loss: 87.5324\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14272.9160 - val_loss: 85.8555\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25097.5996 - val_loss: 86.2684\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14474.0068 - val_loss: 86.9487\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21176.4805 - val_loss: 88.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 74 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 62.9749 - val_loss: 46.3094\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29.8969 - val_loss: 10.8919\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33.4016 - val_loss: 16.0011\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.6175 - val_loss: 26.9077\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.3578 - val_loss: 19.9647\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.5587 - val_loss: 7.5501\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.7214 - val_loss: 12.0906\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.5421 - val_loss: 4.5994\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7304 - val_loss: 6.7494\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9400 - val_loss: 3.3746\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9519 - val_loss: 5.2557\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4854 - val_loss: 4.8707\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2783 - val_loss: 4.7741\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2874 - val_loss: 5.6457\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7516 - val_loss: 4.0552\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0833 - val_loss: 5.8486\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3416 - val_loss: 5.8283\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6453 - val_loss: 3.2463\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9901 - val_loss: 4.1991\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3951 - val_loss: 5.4770\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4004 - val_loss: 4.1241\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0549 - val_loss: 4.6276\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0116 - val_loss: 4.9378\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0029 - val_loss: 3.3259\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1213 - val_loss: 5.5749\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0202 - val_loss: 3.6735\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6828 - val_loss: 3.9963\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9708 - val_loss: 4.3622\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0765 - val_loss: 3.7781\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.6656 - val_loss: 4.1268\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4841 - val_loss: 3.1181\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6896 - val_loss: 3.1970\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4512 - val_loss: 3.1497\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4625 - val_loss: 3.1796\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4208 - val_loss: 3.7215\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7246 - val_loss: 4.7964\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0479 - val_loss: 2.8766\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1710 - val_loss: 4.0910\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4949 - val_loss: 3.7911\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.5995 - val_loss: 2.7878\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1077 - val_loss: 4.7739\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2591 - val_loss: 3.1516\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8321 - val_loss: 2.6697\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5509 - val_loss: 3.7323\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.3596 - val_loss: 2.9727\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2713 - val_loss: 2.7200\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1774 - val_loss: 2.8439\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2063 - val_loss: 3.5657\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.1723 - val_loss: 2.5913\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9769 - val_loss: 3.5815\n",
      "Iteration number 75 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 69.1234 - val_loss: 52.0821\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31.7689 - val_loss: 18.2995\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30.2779 - val_loss: 27.5433\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22.4042 - val_loss: 33.0661\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.4018 - val_loss: 24.5635\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.5233 - val_loss: 13.6635\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.3337 - val_loss: 19.3233\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.7570 - val_loss: 16.4115\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.0178 - val_loss: 9.0129\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.6868 - val_loss: 13.0355\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.4026 - val_loss: 7.1636\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2177 - val_loss: 4.1762\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5070 - val_loss: 4.3867\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1436 - val_loss: 3.5100\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.2073 - val_loss: 3.1897\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.8439 - val_loss: 3.7460\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5736 - val_loss: 3.2507\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6864 - val_loss: 4.2190\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6809 - val_loss: 3.1454\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4846 - val_loss: 4.6113\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4896 - val_loss: 3.7284\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0593 - val_loss: 3.7727\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7696 - val_loss: 3.3869\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8085 - val_loss: 3.4045\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4624 - val_loss: 3.6217\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2366 - val_loss: 3.3792\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0502 - val_loss: 3.6386\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9924 - val_loss: 3.3065\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6793 - val_loss: 3.6001\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.5397 - val_loss: 3.3286\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2878 - val_loss: 3.1128\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1764 - val_loss: 3.3657\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9855 - val_loss: 3.7169\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1253 - val_loss: 2.9642\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7496 - val_loss: 3.3172\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5664 - val_loss: 2.8768\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3647 - val_loss: 3.8506\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6250 - val_loss: 3.3573\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5271 - val_loss: 3.2359\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0049 - val_loss: 2.7551\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9263 - val_loss: 3.4534\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2313 - val_loss: 2.6152\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.2533 - val_loss: 2.7479\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3053 - val_loss: 3.6536\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1028 - val_loss: 3.0216\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2162 - val_loss: 2.5659\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8630 - val_loss: 2.2911\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5728 - val_loss: 2.4670\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7341 - val_loss: 3.2723\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8701 - val_loss: 2.6105\n",
      "Iteration number 76 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 90937.9453 - val_loss: 93.0035\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 116423.0625 - val_loss: 94.4752\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 60356.2305 - val_loss: 90.9733\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 21121.0312 - val_loss: 83.9647\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 121680.4609 - val_loss: 82.4673\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 114777.5625 - val_loss: 85.2298\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 55661.0312 - val_loss: 88.7617\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12380.9326 - val_loss: 90.0636\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6967.3242 - val_loss: 89.3485\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6135.1724 - val_loss: 88.9501\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19788.2500 - val_loss: 89.3504\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25021.7891 - val_loss: 90.9770\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7488.6289 - val_loss: 89.2677\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14432.4570 - val_loss: 89.1346\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19958.6094 - val_loss: 90.2223\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19352.8086 - val_loss: 90.9280\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12440.3516 - val_loss: 88.0528\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66362.6641 - val_loss: 87.1876\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 62703.2812 - val_loss: 89.3739\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20308.1270 - val_loss: 91.9421\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28321.0234 - val_loss: 92.4600\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27635.0762 - val_loss: 91.1098\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12717.0410 - val_loss: 90.9800\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5445.4990 - val_loss: 93.0844\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50772.1680 - val_loss: 93.7051\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43711.7383 - val_loss: 92.2428\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 911.7878 - val_loss: 91.7947\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7801.8340 - val_loss: 91.3801\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15067.5166 - val_loss: 91.3088\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7708.5659 - val_loss: 93.2991\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50707.7266 - val_loss: 94.0761\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30756.3066 - val_loss: 92.8987\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9805.2686 - val_loss: 89.9990\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 74724.3125 - val_loss: 88.5347\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69510.8828 - val_loss: 89.8602\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32099.8613 - val_loss: 91.4060\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21497.4727 - val_loss: 94.4761\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47355.2109 - val_loss: 95.4273\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 60405.7422 - val_loss: 95.5230\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40371.7109 - val_loss: 94.2416\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16927.4570 - val_loss: 92.2522\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21099.0059 - val_loss: 91.9107\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35225.9688 - val_loss: 92.0230\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24890.2559 - val_loss: 93.8333\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17824.8281 - val_loss: 94.4306\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17476.5059 - val_loss: 93.7479\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1846.2224 - val_loss: 93.9343\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7105.3921 - val_loss: 93.6417\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9410.5879 - val_loss: 93.5797\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 175.5434 - val_loss: 94.5385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 77 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 81.7749 - val_loss: 64.6692\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 60.8235 - val_loss: 46.4818\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42.4123 - val_loss: 44.0478\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34.6311 - val_loss: 25.6920\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30.5420 - val_loss: 19.9497\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25.0290 - val_loss: 23.4957\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24.2845 - val_loss: 13.0644\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.8940 - val_loss: 6.8494\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21.0301 - val_loss: 8.1277\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.9025 - val_loss: 3.4627\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.5495 - val_loss: 7.0260\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.8420 - val_loss: 3.1460\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.9814 - val_loss: 4.5043\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.3297 - val_loss: 3.1327\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.7704 - val_loss: 3.3371\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.3141 - val_loss: 3.6064\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.7809 - val_loss: 2.8183\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.0262 - val_loss: 5.1596\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.9042 - val_loss: 3.5552\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.1075 - val_loss: 3.4383\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.4308 - val_loss: 4.1783\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.9352 - val_loss: 3.3452\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4814 - val_loss: 3.2241\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.8626 - val_loss: 3.1417\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3458 - val_loss: 3.7250\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0593 - val_loss: 3.2198\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7971 - val_loss: 3.7740\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.2525 - val_loss: 3.4198\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6405 - val_loss: 3.3217\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7294 - val_loss: 3.8359\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4262 - val_loss: 3.1672\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.7343 - val_loss: 4.0161\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.0549 - val_loss: 3.4535\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.1631 - val_loss: 4.3895\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.0739 - val_loss: 4.1697\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5666 - val_loss: 3.6550\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4846 - val_loss: 4.6417\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5192 - val_loss: 3.9512\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8177 - val_loss: 4.1328\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6080 - val_loss: 3.3466\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9880 - val_loss: 3.8618\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8678 - val_loss: 3.2746\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7616 - val_loss: 3.5745\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6517 - val_loss: 3.4919\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7437 - val_loss: 3.3261\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7970 - val_loss: 3.5770\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7057 - val_loss: 3.8175\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3114 - val_loss: 2.9630\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.3150 - val_loss: 3.6697\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5758 - val_loss: 5.4237\n",
      "Iteration number 78 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 69.5878 - val_loss: 47.2780\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27.0954 - val_loss: 5.1176\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29.0914 - val_loss: 16.2686\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.4455 - val_loss: 27.9557\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.1063 - val_loss: 25.9970\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.9938 - val_loss: 13.9917\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.8877 - val_loss: 6.9331\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.5491 - val_loss: 13.6878\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.8247 - val_loss: 9.4619\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.7976 - val_loss: 4.9681\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5791 - val_loss: 6.4286\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.1256 - val_loss: 2.5090\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3984 - val_loss: 3.6753\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.2590 - val_loss: 3.1660\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8183 - val_loss: 3.5243\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2530 - val_loss: 2.8211\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2064 - val_loss: 3.4768\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.5286 - val_loss: 2.9753\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6208 - val_loss: 4.3902\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1779 - val_loss: 2.9483\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.7623 - val_loss: 4.0531\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5211 - val_loss: 2.9751\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4010 - val_loss: 3.8396\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2679 - val_loss: 3.2723\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1217 - val_loss: 4.1503\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9655 - val_loss: 3.9056\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1786 - val_loss: 4.3838\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0344 - val_loss: 3.3153\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6877 - val_loss: 4.5579\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1946 - val_loss: 3.4712\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7228 - val_loss: 3.2887\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7496 - val_loss: 3.3257\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6738 - val_loss: 3.5504\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8079 - val_loss: 3.1893\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7133 - val_loss: 4.4532\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6998 - val_loss: 2.9799\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5955 - val_loss: 3.6313\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7699 - val_loss: 3.0928\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7491 - val_loss: 3.2348\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6511 - val_loss: 4.0420\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5424 - val_loss: 3.0760\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2696 - val_loss: 3.1751\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1666 - val_loss: 3.0776\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.1413 - val_loss: 2.9576\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0967 - val_loss: 3.3277\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1412 - val_loss: 2.9639\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9943 - val_loss: 2.9249\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.0354 - val_loss: 3.2509\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2023 - val_loss: 2.9475\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2988 - val_loss: 3.6745\n",
      "Iteration number 79 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 4749770.0000 - val_loss: 100.4075\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3814828.2500 - val_loss: 98.7893\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3732720.0000 - val_loss: 97.6544\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1310775.6250 - val_loss: 96.1586\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 862910.0000 - val_loss: 95.2983\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 748211.9375 - val_loss: 93.9874\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 778496.0625 - val_loss: 93.0150\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 463411.1562 - val_loss: 92.0694\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 779023.2500 - val_loss: 91.1079\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 218704.2031 - val_loss: 90.0809\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 177394.6250 - val_loss: 89.1606\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 309665.6875 - val_loss: 88.2918\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 692825.8750 - val_loss: 87.3733\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 598825.0625 - val_loss: 86.4821\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 681008.6875 - val_loss: 85.7058\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 279140.5000 - val_loss: 84.8133\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 236293.2969 - val_loss: 84.0805\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 577102.4375 - val_loss: 83.3548\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 665346.3750 - val_loss: 82.5534\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 173797.5625 - val_loss: 81.7675\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 426869.8125 - val_loss: 80.9306\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 673947.9375 - val_loss: 80.3454\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 309868.7500 - val_loss: 79.7085\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 131625.8750 - val_loss: 78.9557\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 398123.6562 - val_loss: 78.2243\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 648727.6875 - val_loss: 77.5977\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 277679.2812 - val_loss: 77.0629\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 143906.6250 - val_loss: 76.4312\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 155327.2812 - val_loss: 75.6702\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 152744.2969 - val_loss: 75.0401\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 195360.7188 - val_loss: 74.2771\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 243140.6562 - val_loss: 73.5394\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 577597.4375 - val_loss: 72.9697\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 460485.2500 - val_loss: 72.4992\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 598356.1875 - val_loss: 72.0453\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 206248.4062 - val_loss: 71.5997\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 124738.6016 - val_loss: 71.0163\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 411713.8438 - val_loss: 70.5126\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 537300.2500 - val_loss: 70.0211\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 198059.9844 - val_loss: 69.4682\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 168706.6562 - val_loss: 68.9978\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 133566.9219 - val_loss: 68.4815\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 170653.3906 - val_loss: 67.9851\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 153477.9688 - val_loss: 67.4754\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 142119.7031 - val_loss: 66.9045\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 131852.4219 - val_loss: 66.3303\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 166262.1875 - val_loss: 65.9289\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 155959.9531 - val_loss: 65.4773\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 137302.1250 - val_loss: 65.0282\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 141847.7969 - val_loss: 64.6346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 80 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 75.0589 - val_loss: 55.3152\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30.9972 - val_loss: 10.3572\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.3190 - val_loss: 20.5226\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22.6841 - val_loss: 32.5392\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.5679 - val_loss: 24.0125\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.7880 - val_loss: 11.3158\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.4920 - val_loss: 14.5916\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.1295 - val_loss: 9.7697\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3779 - val_loss: 5.9077\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.4164 - val_loss: 3.2144\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.9229 - val_loss: 4.7429\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.0152 - val_loss: 3.2495\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.5866 - val_loss: 4.0534\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2568 - val_loss: 2.5664\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.9485 - val_loss: 3.0507\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6396 - val_loss: 3.1705\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.6228 - val_loss: 2.7682\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0038 - val_loss: 3.3829\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0764 - val_loss: 3.0489\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8438 - val_loss: 3.7034\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0619 - val_loss: 3.0578\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7756 - val_loss: 3.7645\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.5599 - val_loss: 3.5719\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3259 - val_loss: 2.6469\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0923 - val_loss: 3.0063\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.1199 - val_loss: 3.4195\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0819 - val_loss: 2.5848\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0038 - val_loss: 2.7470\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9167 - val_loss: 3.9424\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0941 - val_loss: 2.8219\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5304 - val_loss: 3.6867\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9444 - val_loss: 4.2666\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8937 - val_loss: 3.5189\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.6680 - val_loss: 2.9731\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5084 - val_loss: 2.4369\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.4872 - val_loss: 2.7355\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1052 - val_loss: 2.3651\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9211 - val_loss: 2.9452\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.9891 - val_loss: 2.3101\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.3147 - val_loss: 2.7945\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.2574 - val_loss: 3.4266\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7118 - val_loss: 2.3393\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.6071 - val_loss: 2.7416\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6650 - val_loss: 2.9631\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.8566 - val_loss: 2.1251\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9889 - val_loss: 2.4344\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9489 - val_loss: 3.4026\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8441 - val_loss: 1.8416\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5425 - val_loss: 2.1233\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.3290 - val_loss: 3.3179\n",
      "Iteration number 81 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 4802774.5000 - val_loss: 91.6412\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3961739.2500 - val_loss: 90.5651\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3853653.0000 - val_loss: 90.3854\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1737857.8750 - val_loss: 89.7312\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 740637.8125 - val_loss: 89.0482\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1011321.5625 - val_loss: 88.4389\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1269717.8750 - val_loss: 87.6789\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 878352.5000 - val_loss: 86.9829\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 492528.5312 - val_loss: 86.2636\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 915144.1875 - val_loss: 85.6245\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 269590.2500 - val_loss: 84.8551\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 223298.2969 - val_loss: 83.9992\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 206139.4531 - val_loss: 83.2452\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 599784.0625 - val_loss: 82.6404\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 585976.1875 - val_loss: 81.9202\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 590975.4375 - val_loss: 81.2016\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 661494.9375 - val_loss: 80.6036\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 650042.8125 - val_loss: 79.9782\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 573503.6250 - val_loss: 79.4692\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 534679.5625 - val_loss: 79.0328\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 653349.5000 - val_loss: 78.5498\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 582864.6250 - val_loss: 78.1100\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 523466.2188 - val_loss: 77.6048\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 547401.8750 - val_loss: 77.1510\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 588875.2500 - val_loss: 76.7682\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 465210.0000 - val_loss: 76.2798\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 141994.3125 - val_loss: 75.7686\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 255660.3125 - val_loss: 75.1973\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 629917.6875 - val_loss: 74.7537\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 384446.6562 - val_loss: 74.2201\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 388629.5312 - val_loss: 73.7555\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 235272.1562 - val_loss: 73.2534\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 290646.2812 - val_loss: 72.8323\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89480.6562 - val_loss: 72.3694\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 402401.9375 - val_loss: 71.8511\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 614796.6250 - val_loss: 71.3657\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 268480.3125 - val_loss: 70.9565\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 137544.2500 - val_loss: 70.5042\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 164960.8438 - val_loss: 70.0196\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 465755.4062 - val_loss: 69.5604\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 520929.1562 - val_loss: 69.2713\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 230864.8438 - val_loss: 68.9168\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 184688.5781 - val_loss: 68.5507\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 474652.2188 - val_loss: 68.1473\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 531336.1875 - val_loss: 67.8791\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 149264.0469 - val_loss: 67.5053\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 150405.3750 - val_loss: 67.1296\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 135729.2969 - val_loss: 66.7118\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 354100.4062 - val_loss: 66.3600\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 528948.8125 - val_loss: 66.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 82 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 87753.6719 - val_loss: 98.9431\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 77573.6484 - val_loss: 97.6518\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31701.7344 - val_loss: 94.5834\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 61044.6133 - val_loss: 93.2153\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44093.6406 - val_loss: 96.5359\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24641.9961 - val_loss: 96.8194\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15495.9229 - val_loss: 94.4543\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35958.4688 - val_loss: 95.3067\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22070.8477 - val_loss: 97.8862\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52157.7852 - val_loss: 98.8112\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43614.6133 - val_loss: 95.6966\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 51159.6367 - val_loss: 94.7465\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42240.4883 - val_loss: 96.0132\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23334.8730 - val_loss: 99.3082\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 68500.4688 - val_loss: 100.5378\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 65383.0000 - val_loss: 99.0397\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27977.8594 - val_loss: 96.8765\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37248.8867 - val_loss: 96.5602\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31940.5684 - val_loss: 98.0055\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1865.8008 - val_loss: 97.9214\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9481.3242 - val_loss: 98.5181\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14257.6973 - val_loss: 98.4464\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1688.7246 - val_loss: 96.9073\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41317.6953 - val_loss: 96.6362\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31866.3359 - val_loss: 97.4682\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5301.8789 - val_loss: 99.3693\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42222.7266 - val_loss: 100.1512\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42860.3750 - val_loss: 99.5238\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25749.2363 - val_loss: 97.7701\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18035.1309 - val_loss: 97.8546\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18314.1934 - val_loss: 98.9935\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13101.0605 - val_loss: 98.9428\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2205.1914 - val_loss: 97.6589\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30414.4863 - val_loss: 97.6225\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25413.1367 - val_loss: 98.6272\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1231.1666 - val_loss: 98.5593\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5436.0137 - val_loss: 99.3365\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21770.1816 - val_loss: 99.4890\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2144.4111 - val_loss: 98.9360\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2021.1123 - val_loss: 98.6284\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9930.8848 - val_loss: 98.7534\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3429.7271 - val_loss: 100.7132\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49334.6094 - val_loss: 101.1069\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51709.8477 - val_loss: 100.7818\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27694.6309 - val_loss: 99.8449\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5047.1582 - val_loss: 98.8487\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8046.3257 - val_loss: 99.4440\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9077.2939 - val_loss: 99.2337\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 592.9227 - val_loss: 98.1539\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36389.2031 - val_loss: 97.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 83 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 68.6353 - val_loss: 45.8238\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25.2564 - val_loss: 8.6104\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.4770 - val_loss: 4.8480\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.8903 - val_loss: 18.4724\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.1217 - val_loss: 10.3940\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5581 - val_loss: 4.4626\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3042 - val_loss: 10.4599\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5346 - val_loss: 10.6774\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.1863 - val_loss: 5.5791\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.6161 - val_loss: 6.8564\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2780 - val_loss: 9.9278\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.5572 - val_loss: 4.7021\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1281 - val_loss: 7.8114\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.5008 - val_loss: 4.6192\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8937 - val_loss: 5.0588\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.6964 - val_loss: 3.3453\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4298 - val_loss: 3.1010\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.4348 - val_loss: 3.7847\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.1941 - val_loss: 3.1850\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.1685 - val_loss: 3.3429\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.1322 - val_loss: 3.3884\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.0083 - val_loss: 3.4828\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.9769 - val_loss: 4.1125\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.2053 - val_loss: 3.1890\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.9675 - val_loss: 3.5024\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.9562 - val_loss: 3.1915\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.8391 - val_loss: 4.0655\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.0971 - val_loss: 3.0875\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.9468 - val_loss: 3.0213\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.0769 - val_loss: 4.4960\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.3245 - val_loss: 3.0493\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.9957 - val_loss: 3.0480\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.9434 - val_loss: 3.7029\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.7643 - val_loss: 3.1907\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.7049 - val_loss: 3.8088\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.1683 - val_loss: 3.1477\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.9195 - val_loss: 3.0018\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.7985 - val_loss: 4.2572\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.0962 - val_loss: 3.0466\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.6969 - val_loss: 3.1888\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2.5470 - val_loss: 3.0591\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.6201 - val_loss: 3.1580\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.5709 - val_loss: 3.7264\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.6177 - val_loss: 3.0466\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.6609 - val_loss: 5.6293\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.1564 - val_loss: 3.4365\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.5747 - val_loss: 4.3238\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.7488 - val_loss: 2.9518\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.7450 - val_loss: 3.4742\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.5486 - val_loss: 3.1288\n",
      "Iteration number 84 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 72.2573 - val_loss: 47.9791\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.2689 - val_loss: 28.2932\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.9743 - val_loss: 32.4904\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28.5371 - val_loss: 25.0535\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23.3835 - val_loss: 13.5004\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.2446 - val_loss: 17.2707\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.8536 - val_loss: 8.9605\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.9693 - val_loss: 11.0826\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.0679 - val_loss: 8.7516\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.6718 - val_loss: 9.5742\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.0408 - val_loss: 9.0219\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.9152 - val_loss: 9.7535\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.9992 - val_loss: 8.5984\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.0424 - val_loss: 10.0482\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.1986 - val_loss: 8.9013\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.2010 - val_loss: 8.7935\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.5062 - val_loss: 9.8404\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.9900 - val_loss: 8.7452\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9179 - val_loss: 10.1217\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9109 - val_loss: 8.9038\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.6690 - val_loss: 9.0936\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.4765 - val_loss: 9.4930\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.3850 - val_loss: 9.1027\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.4109 - val_loss: 9.2408\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.1419 - val_loss: 9.2243\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.1381 - val_loss: 9.2796\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.0157 - val_loss: 9.4440\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.8825 - val_loss: 9.0080\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.8589 - val_loss: 9.7187\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.8447 - val_loss: 8.9284\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.6473 - val_loss: 8.5715\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6121 - val_loss: 8.7940\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.6197 - val_loss: 9.0275\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6298 - val_loss: 9.0065\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3306 - val_loss: 8.9658\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.2317 - val_loss: 8.6054\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.0661 - val_loss: 8.6609\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.0805 - val_loss: 8.5856\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1432 - val_loss: 8.9185\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9008 - val_loss: 8.6358\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.8736 - val_loss: 8.6521\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.7463 - val_loss: 8.3223\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.8434 - val_loss: 8.7882\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5864 - val_loss: 8.4669\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.8603 - val_loss: 8.7017\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9144 - val_loss: 8.7638\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4398 - val_loss: 8.5130\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.3389 - val_loss: 8.7472\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.5456 - val_loss: 8.3214\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5009 - val_loss: 8.4343\n",
      "Iteration number 85 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 92.0944 - val_loss: 72.3022\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48.8374 - val_loss: 30.5180\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23.9352 - val_loss: 8.7195\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21.6231 - val_loss: 20.6585\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.8485 - val_loss: 23.9333\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.9680 - val_loss: 15.9437\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.3348 - val_loss: 11.0229\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.3256 - val_loss: 13.8207\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.5030 - val_loss: 11.8582\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.9126 - val_loss: 7.4279\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.2655 - val_loss: 10.7824\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4361 - val_loss: 6.5505\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6955 - val_loss: 6.7571\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9932 - val_loss: 6.6504\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6305 - val_loss: 6.3735\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9382 - val_loss: 6.0918\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3767 - val_loss: 6.0723\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1834 - val_loss: 6.2480\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1387 - val_loss: 7.0018\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3420 - val_loss: 6.7994\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2832 - val_loss: 6.1947\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7556 - val_loss: 6.3873\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.5736 - val_loss: 6.6333\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3445 - val_loss: 6.1958\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.1350 - val_loss: 6.1740\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4657 - val_loss: 6.6766\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.4687 - val_loss: 6.0520\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1527 - val_loss: 6.2365\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9852 - val_loss: 6.1237\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7229 - val_loss: 6.1676\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7349 - val_loss: 6.3040\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6847 - val_loss: 6.1393\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6273 - val_loss: 6.1189\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7747 - val_loss: 6.0657\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5970 - val_loss: 6.5079\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.3141 - val_loss: 6.2534\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1932 - val_loss: 6.1815\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8546 - val_loss: 6.3549\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7936 - val_loss: 6.1376\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8416 - val_loss: 6.2947\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0029 - val_loss: 6.3220\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.5016 - val_loss: 6.2028\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3610 - val_loss: 6.1161\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.2234 - val_loss: 6.1912\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1754 - val_loss: 5.9965\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2458 - val_loss: 6.1134\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4866 - val_loss: 5.9142\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2759 - val_loss: 6.0368\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0615 - val_loss: 6.1611\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0961 - val_loss: 5.7699\n",
      "Iteration number 86 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 87.9591 - val_loss: 68.5423\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40.8277 - val_loss: 23.7929\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.2103 - val_loss: 14.1403\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22.0472 - val_loss: 26.4425\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19.8618 - val_loss: 24.0904\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.6446 - val_loss: 14.7270\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.1573 - val_loss: 13.5759\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.9743 - val_loss: 14.4066\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3766 - val_loss: 6.5209\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.1045 - val_loss: 10.4619\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.8227 - val_loss: 6.9801\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3640 - val_loss: 8.2968\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9786 - val_loss: 6.8198\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4794 - val_loss: 7.0296\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3827 - val_loss: 7.1655\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0980 - val_loss: 7.3106\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.9084 - val_loss: 7.4039\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8470 - val_loss: 7.1938\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7936 - val_loss: 7.0690\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.7475 - val_loss: 7.0290\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6463 - val_loss: 7.1701\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3910 - val_loss: 7.1285\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2389 - val_loss: 7.1225\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2039 - val_loss: 6.9388\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3255 - val_loss: 7.4845\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3039 - val_loss: 7.2449\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 8.1708 - val_loss: 7.5180\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.4135 - val_loss: 6.9348\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9756 - val_loss: 6.8656\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7930 - val_loss: 6.7934\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7592 - val_loss: 6.7821\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8751 - val_loss: 6.7483\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3769 - val_loss: 7.1943\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2512 - val_loss: 6.2240\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5956 - val_loss: 6.3671\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6354 - val_loss: 6.5472\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4300 - val_loss: 6.3674\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3047 - val_loss: 6.6485\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4981 - val_loss: 6.4722\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3105 - val_loss: 6.4560\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1801 - val_loss: 6.0332\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6666 - val_loss: 6.0258\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2087 - val_loss: 6.5399\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9771 - val_loss: 5.8511\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4324 - val_loss: 5.8613\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1905 - val_loss: 8.1786\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7048 - val_loss: 5.8204\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2820 - val_loss: 6.7009\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8989 - val_loss: 5.4698\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8863 - val_loss: 5.5369\n",
      "Iteration number 87 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 54294.4844 - val_loss: 126.8910\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 206543.9531 - val_loss: 132.3884\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 138083.7969 - val_loss: 122.0973\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33064.0117 - val_loss: 112.4515\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 105382.3828 - val_loss: 108.7240\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 105406.1172 - val_loss: 108.5867\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 77459.6250 - val_loss: 112.6749\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5518.9492 - val_loss: 117.5034\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 112518.9453 - val_loss: 118.5027\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 111122.6562 - val_loss: 115.7361\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 56131.7031 - val_loss: 113.2323\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15025.4277 - val_loss: 109.4034\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38020.9844 - val_loss: 108.2427\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48171.8672 - val_loss: 108.8130\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20412.7734 - val_loss: 111.0328\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10202.6689 - val_loss: 111.7896\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13708.2842 - val_loss: 110.4905\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17494.7090 - val_loss: 110.5554\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2856.1897 - val_loss: 112.2797\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22152.0566 - val_loss: 112.1598\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19644.1094 - val_loss: 111.5410\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13211.6846 - val_loss: 110.2348\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11201.3311 - val_loss: 111.6815\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19376.6094 - val_loss: 111.4137\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6236.7568 - val_loss: 110.2398\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15803.2109 - val_loss: 110.0036\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10720.8262 - val_loss: 110.8475\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14577.6973 - val_loss: 111.1239\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7530.4014 - val_loss: 109.4036\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25890.2578 - val_loss: 109.4181\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19076.8965 - val_loss: 111.1928\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22794.4434 - val_loss: 111.1910\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9252.0000 - val_loss: 109.9353\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13043.2686 - val_loss: 109.6244\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9549.1162 - val_loss: 110.3698\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14319.0771 - val_loss: 110.5961\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8758.5869 - val_loss: 108.7106\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33054.7148 - val_loss: 108.5374\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20491.9199 - val_loss: 109.5761\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11743.3623 - val_loss: 110.2663\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4459.8052 - val_loss: 109.2175\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30241.5586 - val_loss: 108.2703\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11936.1123 - val_loss: 109.5291\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1183.7706 - val_loss: 112.9857\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 88576.2578 - val_loss: 114.2869\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 90017.8750 - val_loss: 113.4870\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73866.7266 - val_loss: 111.0481\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27172.3203 - val_loss: 108.6318\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9100.8066 - val_loss: 107.7799\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16741.6562 - val_loss: 107.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 88 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 107001.8594 - val_loss: 90.6555\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 105387.3906 - val_loss: 90.9240\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50552.3906 - val_loss: 87.2553\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40859.9570 - val_loss: 86.2518\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16587.6484 - val_loss: 87.6554\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33927.6797 - val_loss: 89.3097\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37852.3164 - val_loss: 88.4736\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 507.6433 - val_loss: 85.4062\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 72444.0859 - val_loss: 84.4380\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 69299.8438 - val_loss: 86.1490\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18689.3984 - val_loss: 88.7096\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10439.2842 - val_loss: 89.4301\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23455.9043 - val_loss: 88.8128\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15060.8867 - val_loss: 88.6442\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5217.5171 - val_loss: 88.6891\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6728.9570 - val_loss: 89.4197\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12147.9756 - val_loss: 88.6049\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15950.3682 - val_loss: 89.1563\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4226.2446 - val_loss: 88.4822\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 27152.7441 - val_loss: 88.5498\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2490.4839 - val_loss: 90.0955\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20980.1270 - val_loss: 90.3530\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26336.5762 - val_loss: 89.3314\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19303.7715 - val_loss: 88.9700\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12793.9961 - val_loss: 89.7784\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6416.4839 - val_loss: 87.5821\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57809.1562 - val_loss: 87.5092\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53548.9570 - val_loss: 88.6002\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15086.6729 - val_loss: 90.2456\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7258.2739 - val_loss: 90.6886\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17691.6816 - val_loss: 90.2258\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11727.6670 - val_loss: 90.0962\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4069.5007 - val_loss: 90.1157\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18681.3066 - val_loss: 89.9041\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4770.8315 - val_loss: 90.3928\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3994.0476 - val_loss: 90.8102\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14153.4902 - val_loss: 90.5576\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5522.7095 - val_loss: 90.5771\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8991.0859 - val_loss: 90.7812\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5630.2671 - val_loss: 90.2745\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7859.8882 - val_loss: 90.4560\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2071.4548 - val_loss: 91.0255\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27249.3066 - val_loss: 91.4542\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20460.3418 - val_loss: 90.3932\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27548.4844 - val_loss: 89.9436\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10037.6260 - val_loss: 91.1344\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16307.8486 - val_loss: 91.5771\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19736.0156 - val_loss: 91.2837\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4593.2856 - val_loss: 91.0573\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4793.6001 - val_loss: 90.8243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 89 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 103.0272 - val_loss: 85.9301\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 55.6932 - val_loss: 47.9190\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41.8082 - val_loss: 18.4834\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35.4281 - val_loss: 33.7702\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29.9395 - val_loss: 38.0934\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27.2474 - val_loss: 29.8430\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.5658 - val_loss: 16.0237\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18.9269 - val_loss: 19.1280\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.0386 - val_loss: 16.4915\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.0223 - val_loss: 9.1820\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.8197 - val_loss: 8.0391\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.9050 - val_loss: 6.9575\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.4310 - val_loss: 7.3388\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.1103 - val_loss: 6.5842\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.7515 - val_loss: 6.8750\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2686 - val_loss: 6.1494\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3506 - val_loss: 8.4272\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.1798 - val_loss: 7.6118\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.0041 - val_loss: 5.9088\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.6783 - val_loss: 8.9296\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.5105 - val_loss: 6.1185\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.1234 - val_loss: 9.9301\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3192 - val_loss: 5.5984\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0876 - val_loss: 8.7986\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5390 - val_loss: 5.4715\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5538 - val_loss: 7.0291\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.0157 - val_loss: 6.0813\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1607 - val_loss: 6.4220\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.0429 - val_loss: 5.6839\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9068 - val_loss: 5.9950\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5414 - val_loss: 5.6804\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8276 - val_loss: 7.2859\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4781 - val_loss: 5.3656\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5417 - val_loss: 6.6708\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4241 - val_loss: 5.3468\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8991 - val_loss: 6.1566\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8544 - val_loss: 5.4292\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4036 - val_loss: 5.5112\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2075 - val_loss: 5.4037\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1460 - val_loss: 5.3502\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0224 - val_loss: 5.7879\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3994 - val_loss: 5.5340\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8748 - val_loss: 6.3030\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.8556 - val_loss: 5.1299\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0561 - val_loss: 5.2591\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7143 - val_loss: 6.5778\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4265 - val_loss: 5.5179\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7555 - val_loss: 4.7588\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5765 - val_loss: 6.3983\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0276 - val_loss: 4.9659\n",
      "Iteration number 90 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 233667.8438 - val_loss: 86.4621\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60440.4258 - val_loss: 94.3506\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20806.5059 - val_loss: 84.4627\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 115181.3047 - val_loss: 83.0247\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 110077.0938 - val_loss: 87.6391\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11124.3467 - val_loss: 91.5178\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33761.2266 - val_loss: 94.2757\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62467.9727 - val_loss: 94.1315\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12171.1064 - val_loss: 89.1174\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 59731.2031 - val_loss: 86.6934\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 63946.3359 - val_loss: 89.4368\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2148.6748 - val_loss: 91.9646\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15734.5645 - val_loss: 93.4351\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37586.8594 - val_loss: 91.5396\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 162.9455 - val_loss: 92.2126\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35558.1055 - val_loss: 92.6731\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25259.2129 - val_loss: 87.5965\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 83458.7031 - val_loss: 85.8639\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 73641.3516 - val_loss: 87.1984\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59596.5391 - val_loss: 92.9876\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52161.0000 - val_loss: 94.8001\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54233.3438 - val_loss: 92.9144\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12036.4766 - val_loss: 90.4052\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 45831.3750 - val_loss: 89.2592\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34714.8398 - val_loss: 90.5140\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7327.6211 - val_loss: 92.3892\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6824.4150 - val_loss: 90.3966\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35664.7070 - val_loss: 90.5277\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22042.2480 - val_loss: 92.8887\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13410.2422 - val_loss: 92.7045\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9603.5020 - val_loss: 90.7290\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32945.7617 - val_loss: 90.8171\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20118.5840 - val_loss: 93.0787\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36693.6250 - val_loss: 94.1290\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17154.1738 - val_loss: 92.1226\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3973.9382 - val_loss: 91.7787\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12262.5469 - val_loss: 92.7445\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21807.3242 - val_loss: 93.3547\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4189.5425 - val_loss: 90.8419\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 57950.9727 - val_loss: 89.3503\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47200.8477 - val_loss: 91.4251\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20477.1621 - val_loss: 94.8449\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51874.8047 - val_loss: 95.8110\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51052.1055 - val_loss: 94.5850\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15887.5508 - val_loss: 92.9353\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17345.2207 - val_loss: 92.1696\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16763.2559 - val_loss: 93.2140\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9628.6904 - val_loss: 93.3712\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 851.5771 - val_loss: 93.9292\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18839.1309 - val_loss: 93.8039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 91 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 81.4377 - val_loss: 64.9638\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63.2220 - val_loss: 45.1406\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47.2901 - val_loss: 40.4612\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.5635 - val_loss: 29.3958\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26.5900 - val_loss: 23.9730\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19.5805 - val_loss: 15.8311\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.8111 - val_loss: 6.1716\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.7136 - val_loss: 8.0698\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.2877 - val_loss: 6.0867\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.0285 - val_loss: 7.4214\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.7933 - val_loss: 5.4612\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.6407 - val_loss: 5.9310\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.3808 - val_loss: 6.0161\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1859 - val_loss: 5.4810\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.2203 - val_loss: 5.9448\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9204 - val_loss: 5.3295\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.6823 - val_loss: 6.1221\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.7337 - val_loss: 5.1315\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.0601 - val_loss: 6.0994\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.1460 - val_loss: 5.1559\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3087 - val_loss: 5.8298\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.4474 - val_loss: 4.9130\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9969 - val_loss: 6.2739\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5531 - val_loss: 5.0146\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0262 - val_loss: 4.9214\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0030 - val_loss: 4.8747\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0617 - val_loss: 5.1850\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.8992 - val_loss: 4.4948\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0353 - val_loss: 5.5373\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6407 - val_loss: 4.5279\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3114 - val_loss: 5.2289\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7120 - val_loss: 4.3911\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4832 - val_loss: 6.1034\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1993 - val_loss: 4.4048\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.3346 - val_loss: 5.7801\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7057 - val_loss: 4.2492\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.2827 - val_loss: 6.1318\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5472 - val_loss: 4.2199\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6360 - val_loss: 4.2161\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8134 - val_loss: 4.7357\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.0686 - val_loss: 4.2676\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5387 - val_loss: 5.5323\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5183 - val_loss: 4.0751\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2446 - val_loss: 4.8095\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0910 - val_loss: 4.1401\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9037 - val_loss: 4.2596\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7130 - val_loss: 4.1805\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1119 - val_loss: 4.0677\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.9320 - val_loss: 4.0820\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6598 - val_loss: 4.4690\n",
      "Iteration number 92 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 82.4664 - val_loss: 57.1688\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33.2848 - val_loss: 4.7387\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29.1305 - val_loss: 3.4930\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.5363 - val_loss: 18.7431\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.3185 - val_loss: 21.7279\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 16.4887 - val_loss: 10.2618\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.7273 - val_loss: 6.2584\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.3712 - val_loss: 9.1731\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.7935 - val_loss: 7.7996\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.8171 - val_loss: 4.2385\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.5737 - val_loss: 4.2670\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.1691 - val_loss: 5.9568\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.9517 - val_loss: 6.4570\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.7611 - val_loss: 5.6193\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.1360 - val_loss: 4.2447\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5096 - val_loss: 4.2501\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.1343 - val_loss: 5.1395\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5790 - val_loss: 4.7539\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.5603 - val_loss: 4.5607\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.2367 - val_loss: 4.2935\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8510 - val_loss: 4.2941\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6979 - val_loss: 4.3011\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5282 - val_loss: 4.2077\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3620 - val_loss: 4.1864\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3097 - val_loss: 4.2314\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0426 - val_loss: 4.0278\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6142 - val_loss: 3.9643\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6464 - val_loss: 3.9816\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8216 - val_loss: 4.0863\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.3784 - val_loss: 4.2102\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.7581 - val_loss: 4.0027\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.1105 - val_loss: 3.8028\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9511 - val_loss: 3.7374\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9950 - val_loss: 3.6624\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.1315 - val_loss: 3.9771\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1088 - val_loss: 3.5810\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5145 - val_loss: 3.6239\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.1756 - val_loss: 3.4279\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9635 - val_loss: 4.4386\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.0433 - val_loss: 3.6442\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5155 - val_loss: 3.9089\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1019 - val_loss: 3.5955\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.9412 - val_loss: 3.5155\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0565 - val_loss: 5.0671\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2137 - val_loss: 4.3043\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.3991 - val_loss: 5.0891\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.7799 - val_loss: 3.6689\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0621 - val_loss: 5.1317\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0588 - val_loss: 4.3059\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.0020 - val_loss: 3.8410\n",
      "Iteration number 93 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 78.9525 - val_loss: 62.2533\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57.1200 - val_loss: 38.8629\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46.5969 - val_loss: 47.5958\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39.3895 - val_loss: 48.1978\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35.3070 - val_loss: 33.3600\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29.7946 - val_loss: 15.7031\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25.6277 - val_loss: 19.2102\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23.5679 - val_loss: 11.3379\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21.6519 - val_loss: 8.5921\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.8893 - val_loss: 13.9124\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.7425 - val_loss: 8.3624\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.6947 - val_loss: 10.3321\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.0103 - val_loss: 4.7386\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.4264 - val_loss: 5.6733\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.7802 - val_loss: 3.8450\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.3932 - val_loss: 4.4864\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.0562 - val_loss: 4.8085\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.6229 - val_loss: 3.4949\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.1290 - val_loss: 5.0367\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.4317 - val_loss: 3.5442\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.2945 - val_loss: 5.2021\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.1655 - val_loss: 2.9038\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.6431 - val_loss: 3.1979\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.3919 - val_loss: 3.5680\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.1859 - val_loss: 3.7111\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.9237 - val_loss: 3.1290\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3399 - val_loss: 2.7616\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.2216 - val_loss: 2.9074\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9798 - val_loss: 3.4936\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0190 - val_loss: 2.7368\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.0638 - val_loss: 2.5153\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6022 - val_loss: 2.7798\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4292 - val_loss: 2.8378\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5586 - val_loss: 4.4120\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8801 - val_loss: 2.3101\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.4338 - val_loss: 2.9518\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6258 - val_loss: 2.4030\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4520 - val_loss: 2.3613\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1508 - val_loss: 2.3759\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8572 - val_loss: 2.4627\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6929 - val_loss: 2.3397\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6538 - val_loss: 2.2509\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2912 - val_loss: 1.9816\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4342 - val_loss: 2.0840\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.9189 - val_loss: 2.7172\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2589 - val_loss: 2.0964\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5102 - val_loss: 3.5603\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.3698 - val_loss: 3.4185\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.4998 - val_loss: 2.3979\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.1525 - val_loss: 2.5755\n",
      "Iteration number 94 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 82.3479 - val_loss: 52.9908\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37.3874 - val_loss: 8.1901\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.8584 - val_loss: 16.5900\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25.7291 - val_loss: 27.4907\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.4550 - val_loss: 21.9418\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20.6308 - val_loss: 10.2910\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.9991 - val_loss: 6.2277\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.3309 - val_loss: 7.1255\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.3081 - val_loss: 10.1241\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9089 - val_loss: 6.7238\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.3216 - val_loss: 6.3240\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0580 - val_loss: 6.7395\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.1517 - val_loss: 6.4106\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.2936 - val_loss: 6.3964\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9018 - val_loss: 6.1554\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5539 - val_loss: 5.9371\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3637 - val_loss: 5.6108\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3903 - val_loss: 5.6784\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.7198 - val_loss: 5.2401\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2424 - val_loss: 5.4937\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3111 - val_loss: 5.2811\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3574 - val_loss: 5.0810\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.9682 - val_loss: 5.3560\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.8024 - val_loss: 4.9551\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8842 - val_loss: 4.8891\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7902 - val_loss: 4.8795\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6236 - val_loss: 4.6960\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9495 - val_loss: 4.6127\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.7602 - val_loss: 5.6121\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.6133 - val_loss: 4.4571\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7587 - val_loss: 4.4773\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.6080 - val_loss: 4.5615\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.6432 - val_loss: 5.4872\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1419 - val_loss: 4.7445\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0705 - val_loss: 4.9941\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.3235 - val_loss: 4.2989\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.2311 - val_loss: 4.3943\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0758 - val_loss: 4.3613\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9062 - val_loss: 4.9169\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.3532 - val_loss: 4.0584\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9922 - val_loss: 4.2947\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.8027 - val_loss: 3.9285\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.0395 - val_loss: 4.1605\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.8353 - val_loss: 3.8723\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0792 - val_loss: 4.2578\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.4768 - val_loss: 3.6939\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.1887 - val_loss: 3.6784\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8043 - val_loss: 3.9899\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5550 - val_loss: 3.8862\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5953 - val_loss: 3.5889\n",
      "Iteration number 95 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 86.8824 - val_loss: 61.9417\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 44.8840 - val_loss: 18.7138\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 44.3336 - val_loss: 25.9627\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.6207 - val_loss: 38.7644\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30.7286 - val_loss: 31.7202\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24.9110 - val_loss: 17.8881\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24.3166 - val_loss: 17.6463\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.9173 - val_loss: 22.0028\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.9467 - val_loss: 13.5388\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.6908 - val_loss: 10.1817\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.6795 - val_loss: 7.9450\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.7790 - val_loss: 6.8340\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.0132 - val_loss: 6.4923\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.0823 - val_loss: 6.2234\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.7118 - val_loss: 5.7957\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.8278 - val_loss: 6.5898\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.5070 - val_loss: 5.4230\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.9729 - val_loss: 6.3854\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.8397 - val_loss: 5.0101\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.7849 - val_loss: 5.2779\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.4977 - val_loss: 5.1465\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.6840 - val_loss: 5.0716\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.3718 - val_loss: 5.8916\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.4902 - val_loss: 4.7699\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.1894 - val_loss: 5.3780\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6113 - val_loss: 4.4317\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9999 - val_loss: 5.1006\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.6387 - val_loss: 4.4913\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5329 - val_loss: 4.8454\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3872 - val_loss: 5.2775\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0697 - val_loss: 4.4358\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.0761 - val_loss: 5.0371\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9135 - val_loss: 5.0642\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8213 - val_loss: 4.7186\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7575 - val_loss: 4.3265\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9207 - val_loss: 6.0083\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.3754 - val_loss: 4.0952\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9881 - val_loss: 6.7345\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.1150 - val_loss: 4.0414\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0178 - val_loss: 5.0876\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5267 - val_loss: 4.1850\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.2316 - val_loss: 6.8488\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1326 - val_loss: 3.9192\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.1410 - val_loss: 6.2194\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.3013 - val_loss: 3.9264\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9158 - val_loss: 5.1355\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1528 - val_loss: 3.9820\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8006 - val_loss: 4.5535\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.8464 - val_loss: 4.2904\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5568 - val_loss: 4.2012\n",
      "Iteration number 96 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 64.6233 - val_loss: 43.3798\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.3654 - val_loss: 2.0146\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.6903 - val_loss: 16.2864\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.2499 - val_loss: 26.1644\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.4067 - val_loss: 16.6097\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.2644 - val_loss: 13.1373\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.6262 - val_loss: 19.0049\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.4855 - val_loss: 15.0002\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2710 - val_loss: 11.0452\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7778 - val_loss: 11.7262\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5571 - val_loss: 9.7140\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3952 - val_loss: 5.1319\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2014 - val_loss: 5.9110\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8353 - val_loss: 7.0777\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6239 - val_loss: 6.6326\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4695 - val_loss: 5.2626\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5883 - val_loss: 6.4337\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3748 - val_loss: 6.8880\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3384 - val_loss: 4.2751\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1411 - val_loss: 4.6652\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9537 - val_loss: 5.5878\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9213 - val_loss: 3.1868\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.3811 - val_loss: 6.9770\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.3641 - val_loss: 2.5631\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8975 - val_loss: 3.3780\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.6990 - val_loss: 3.0315\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7022 - val_loss: 2.3486\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5093 - val_loss: 2.4673\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.3698 - val_loss: 3.2326\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.3181 - val_loss: 2.4925\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2269 - val_loss: 2.3187\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1124 - val_loss: 2.6052\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1175 - val_loss: 2.5027\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0730 - val_loss: 2.5038\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0373 - val_loss: 2.3769\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9374 - val_loss: 2.5268\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0658 - val_loss: 2.7526\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0122 - val_loss: 2.7151\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0452 - val_loss: 2.4792\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3613 - val_loss: 2.6543\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0041 - val_loss: 2.5166\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7412 - val_loss: 2.8258\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7472 - val_loss: 2.5389\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2131 - val_loss: 2.2657\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2935 - val_loss: 3.9414\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3495 - val_loss: 2.8861\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4801 - val_loss: 2.1896\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9015 - val_loss: 2.4268\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.6016 - val_loss: 2.0931\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7201 - val_loss: 2.7753\n",
      "Iteration number 97 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 59.0739 - val_loss: 27.2121\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23.6459 - val_loss: 9.5762\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18.5173 - val_loss: 14.6649\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16.3942 - val_loss: 21.1252\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.7080 - val_loss: 12.8821\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.1847 - val_loss: 4.9206\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.7194 - val_loss: 3.2108\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.4724 - val_loss: 8.3614\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5505 - val_loss: 10.0552\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6913 - val_loss: 4.7475\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1325 - val_loss: 4.3882\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4429 - val_loss: 4.9653\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2386 - val_loss: 2.3698\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7171 - val_loss: 3.3754\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3161 - val_loss: 2.2035\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4063 - val_loss: 2.1469\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.1561 - val_loss: 3.2369\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7817 - val_loss: 4.2338\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1499 - val_loss: 5.9175\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9584 - val_loss: 2.9851\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.1599 - val_loss: 2.3788\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8522 - val_loss: 2.7602\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.6063 - val_loss: 2.4603\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8341 - val_loss: 4.8271\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8854 - val_loss: 2.2561\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7997 - val_loss: 2.6954\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5971 - val_loss: 3.6565\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4877 - val_loss: 2.3242\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5472 - val_loss: 2.8424\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.3378 - val_loss: 3.1067\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4130 - val_loss: 2.2050\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6684 - val_loss: 2.3028\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5235 - val_loss: 4.5974\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8309 - val_loss: 2.7007\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9785 - val_loss: 3.7585\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5642 - val_loss: 3.0377\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.3361 - val_loss: 2.7500\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2624 - val_loss: 3.3117\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4070 - val_loss: 3.4228\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.2059 - val_loss: 2.5356\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.0159 - val_loss: 3.0341\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0649 - val_loss: 3.7579\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.1627 - val_loss: 2.2471\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.5340 - val_loss: 2.2354\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.4245 - val_loss: 4.0707\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.2680 - val_loss: 2.2003\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.2660 - val_loss: 2.4562\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.1194 - val_loss: 4.3516\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.1105 - val_loss: 2.2590\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.9791 - val_loss: 2.8203\n",
      "Iteration number 98 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 79.5139 - val_loss: 55.2971\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39.2077 - val_loss: 19.0878\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.6320 - val_loss: 17.5495\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25.5340 - val_loss: 28.0909\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25.8569 - val_loss: 26.9918\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.7686 - val_loss: 13.5672\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18.0734 - val_loss: 13.3827\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15.4513 - val_loss: 17.3891\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.8438 - val_loss: 10.7091\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.1505 - val_loss: 11.2756\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.7297 - val_loss: 11.8902\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.0438 - val_loss: 10.3246\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.2701 - val_loss: 11.8762\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.1814 - val_loss: 10.4301\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.7875 - val_loss: 11.1597\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.5616 - val_loss: 10.6484\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.9038 - val_loss: 10.1119\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.7668 - val_loss: 10.4197\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.9851 - val_loss: 10.0430\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.5324 - val_loss: 10.1196\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.1598 - val_loss: 9.7204\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.2242 - val_loss: 9.9828\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2540 - val_loss: 9.8166\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.9587 - val_loss: 9.5290\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6398 - val_loss: 10.6183\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.5483 - val_loss: 9.4942\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.1938 - val_loss: 9.7581\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.0511 - val_loss: 9.4673\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.2365 - val_loss: 9.4282\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.0667 - val_loss: 9.3084\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9667 - val_loss: 9.0660\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.8745 - val_loss: 9.0305\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7831 - val_loss: 9.2511\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.7860 - val_loss: 9.0786\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7565 - val_loss: 9.2736\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.8877 - val_loss: 8.8870\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6229 - val_loss: 8.8313\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1782 - val_loss: 9.2000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3260 - val_loss: 9.4376\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.6522 - val_loss: 8.6333\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.4337 - val_loss: 8.7246\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9800 - val_loss: 8.8223\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5078 - val_loss: 8.6251\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.8349 - val_loss: 8.3485\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.6514 - val_loss: 9.0915\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2723 - val_loss: 8.2840\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5270 - val_loss: 8.5837\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.1592 - val_loss: 8.7810\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.9326 - val_loss: 8.3951\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.5432 - val_loss: 8.2402\n",
      "Iteration number 99 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 44859.2617 - val_loss: 113.9239\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 314769.7500 - val_loss: 116.8645\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 249520.4688 - val_loss: 108.9129\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70469.5234 - val_loss: 102.3528\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35531.4180 - val_loss: 99.4528\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38686.9414 - val_loss: 101.3177\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34457.6992 - val_loss: 102.5341\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23761.2051 - val_loss: 98.1340\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76219.9062 - val_loss: 97.7250\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70435.4453 - val_loss: 99.0373\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37668.1445 - val_loss: 102.9211\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52693.7773 - val_loss: 104.1043\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50164.6211 - val_loss: 102.7090\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21420.1133 - val_loss: 99.1738\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 70804.8359 - val_loss: 98.4852\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62360.5469 - val_loss: 99.7643\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11826.9619 - val_loss: 102.2336\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37030.4609 - val_loss: 104.3241\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52028.9570 - val_loss: 103.6686\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23566.0762 - val_loss: 101.4544\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37373.3867 - val_loss: 100.3754\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31840.9238 - val_loss: 102.2055\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3307.2693 - val_loss: 101.8148\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8996.4785 - val_loss: 102.1404\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1735.3657 - val_loss: 102.3479\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6983.9185 - val_loss: 101.3363\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20590.3555 - val_loss: 101.5992\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5481.2202 - val_loss: 103.1621\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47749.3555 - val_loss: 104.1167\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30387.3613 - val_loss: 101.8611\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14004.6562 - val_loss: 101.3700\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14834.4033 - val_loss: 102.7139\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26710.1094 - val_loss: 103.0195\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9334.7959 - val_loss: 101.5930\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33568.5156 - val_loss: 100.6376\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25136.8105 - val_loss: 101.4437\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13841.5186 - val_loss: 105.0096\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 58892.1523 - val_loss: 105.5613\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69715.9297 - val_loss: 104.3959\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38552.4609 - val_loss: 102.7778\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8535.7070 - val_loss: 101.9984\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 183.9397 - val_loss: 101.8403\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15843.3057 - val_loss: 101.5157\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15098.3008 - val_loss: 102.8868\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21766.0254 - val_loss: 102.8086\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5222.4556 - val_loss: 101.6904\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18562.8711 - val_loss: 101.4339\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16877.5527 - val_loss: 102.8091\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20300.9531 - val_loss: 102.7542\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6465.9365 - val_loss: 101.4202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-250-ff67cb46d433>:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration number 100 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 86.4527 - val_loss: 67.0498\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45.4784 - val_loss: 23.7865\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.5106 - val_loss: 7.8649\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.4102 - val_loss: 16.0520\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.0854 - val_loss: 22.6734\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.7417 - val_loss: 13.8068\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.6747 - val_loss: 7.2156\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3905 - val_loss: 11.0047\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6034 - val_loss: 14.7960\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4803 - val_loss: 10.4247\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8139 - val_loss: 6.7953\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3675 - val_loss: 9.7121\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9576 - val_loss: 8.6552\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3563 - val_loss: 6.1750\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9325 - val_loss: 6.8447\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1806 - val_loss: 5.9310\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6551 - val_loss: 5.5650\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.1572 - val_loss: 4.2235\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.8090 - val_loss: 4.4521\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.4730 - val_loss: 3.8965\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.8834 - val_loss: 3.9559\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8282 - val_loss: 3.9052\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9265 - val_loss: 4.1695\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8264 - val_loss: 4.0853\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5955 - val_loss: 4.0645\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5756 - val_loss: 3.7852\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.3730 - val_loss: 3.7204\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.3207 - val_loss: 3.7427\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.2212 - val_loss: 3.7776\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.2724 - val_loss: 3.7766\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1526 - val_loss: 3.7514\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0783 - val_loss: 3.7073\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.9954 - val_loss: 3.6980\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0401 - val_loss: 3.8431\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.2575 - val_loss: 3.6968\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6264 - val_loss: 4.1329\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4099 - val_loss: 3.7682\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0481 - val_loss: 3.8796\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0290 - val_loss: 3.5132\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.9226 - val_loss: 3.5365\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0793 - val_loss: 3.5065\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.9908 - val_loss: 3.8154\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.8978 - val_loss: 3.6004\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1036 - val_loss: 3.5368\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0329 - val_loss: 3.6844\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.8839 - val_loss: 3.5585\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.9748 - val_loss: 4.1149\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.3842 - val_loss: 4.0823\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.2786 - val_loss: 3.4580\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7837 - val_loss: 4.4859\n",
      "Iteration number 101 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 90.4131 - val_loss: 68.8780\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.0040 - val_loss: 29.1619\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33.4500 - val_loss: 20.4554\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26.9286 - val_loss: 28.8773\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23.2213 - val_loss: 32.3073\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.5498 - val_loss: 23.9477\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.6141 - val_loss: 12.1975\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.0971 - val_loss: 14.7351\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.7221 - val_loss: 18.3641\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.8034 - val_loss: 6.1022\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.1468 - val_loss: 10.7718\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.9880 - val_loss: 4.5187\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1527 - val_loss: 7.2414\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5016 - val_loss: 1.9201\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2688 - val_loss: 6.8725\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9382 - val_loss: 3.4113\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3975 - val_loss: 4.5560\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5116 - val_loss: 3.1534\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2735 - val_loss: 2.9224\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8877 - val_loss: 2.7121\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7817 - val_loss: 2.5203\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4659 - val_loss: 3.5087\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2032 - val_loss: 1.8663\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0252 - val_loss: 3.0787\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8226 - val_loss: 1.7536\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6476 - val_loss: 2.0165\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5844 - val_loss: 2.9946\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4741 - val_loss: 1.4640\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4581 - val_loss: 1.9852\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0710 - val_loss: 2.4100\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3366 - val_loss: 1.9831\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3148 - val_loss: 2.2243\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7656 - val_loss: 1.4418\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6915 - val_loss: 1.4956\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6640 - val_loss: 1.7443\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5834 - val_loss: 1.6929\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4359 - val_loss: 1.5012\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2332 - val_loss: 1.9013\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2658 - val_loss: 1.4804\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0114 - val_loss: 1.3983\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1077 - val_loss: 1.8820\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1390 - val_loss: 2.1386\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0227 - val_loss: 1.7584\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7834 - val_loss: 2.9629\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0326 - val_loss: 1.5694\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6020 - val_loss: 1.4432\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9551 - val_loss: 3.0125\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9656 - val_loss: 2.4750\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5766 - val_loss: 2.1038\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8908 - val_loss: 2.0640\n",
      "Iteration number 102 finished\n"
     ]
    }
   ],
   "source": [
    "zipcodes = df_time_series.columns\n",
    "dict_mape_skylar = {}\n",
    "dict_pred_skylar = {}\n",
    "\n",
    "for zipcode in range(len(zipcodes)):\n",
    "\n",
    "    # init a RMM model\n",
    "    rnn_model = Sequential()\n",
    "    # add 4 layers of RNN and a last layer\n",
    "\n",
    "    # we define shape on first layer, (60,1) because we use 60 inputs per prediction\n",
    "    rnn_model.add(LSTM(units= 60, return_sequences = False, input_shape=((60,1))))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # 3 other layers\n",
    "    #rnn_model.add(LSTM(units= 30, return_sequences = True))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # return_sequence is False because we want only 1 output after this layer\n",
    "    #rnn_model.add(LSTM(units= 60, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # last layer \n",
    "\n",
    "    rnn_model.add(Dense(units=1))\n",
    "\n",
    "    # compile - because this is a regression model we want to minimize MSE\n",
    "\n",
    "    rnn_model.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "\n",
    "    # We get only the specific column(Zipcode from our train and test datas)\n",
    "    train_data = train.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    test_data = test.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # We are using normalizaion rather than standascaler. \n",
    "    # In a upward trending timeseries it is better to not start from negative\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Because we are using 60 previous values to model and predict the next value, \n",
    "    # We set X_train from arrays of 60 for each y_train value\n",
    "    # Same idea for test data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(train_data_scaled)):\n",
    "        X_train.append(train_data_scaled[i-60:i])\n",
    "        y_train.append(train_data_scaled[i])\n",
    "\n",
    "    data_total = pd.concat((train.iloc[:,zipcode:zipcode+1], test.iloc[:,zipcode:zipcode+1]),axis=0)\n",
    "    inputs = data_total[len(train)-60:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(60,len(inputs)):\n",
    "        X_test.append(inputs[i-60:i])\n",
    "        y_test.append(inputs[i])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(test_data)\n",
    "\n",
    "    # We need numpy arrays for our model\n",
    "    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # We fit our data to our zipcode specific data\n",
    "    rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, scaler.transform(y_test)))\n",
    "\n",
    "    # Make predictions on the data\n",
    "\n",
    "    y_hat_raw = rnn_model.predict(X_train)\n",
    "    y_hat = scaler.inverse_transform(y_hat_raw)\n",
    "\n",
    "    # Use the score on unseen test data to calculate the MAPE\n",
    "\n",
    "    dict_mape_skylar[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_train)/y_train))      \n",
    "\n",
    "    # We get the last 60 values from our test data which is basically last 60 values in the data set\n",
    "    last_60 = df_time_series.iloc[-60:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # Before we use our data we scale it\n",
    "    last_60 = scaler.transform(last_60)\n",
    "    \n",
    "    # Our input should be in (x,60,1) format\n",
    "    x_new_pred = last_60[-60:].reshape(1,60,1)\n",
    "\n",
    "    # make a prediction, add to the last_60 for the next prediction and \n",
    "    y_pred = rnn_model.predict(x_new_pred)\n",
    "\n",
    "    # We add our predition to our list of predictions for zipcode specific predictions list\n",
    "    dict_pred_skylar[zipcodes[zipcode]]=scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(f'Iteration number {zipcode} finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89108: array([[89125.06]], dtype=float32),\n",
       " 89121: array([[75994.12]], dtype=float32),\n",
       " 89117: array([[342993.94]], dtype=float32),\n",
       " 89052: array([[421245.44]], dtype=float32),\n",
       " 89123: array([[302137.3]], dtype=float32),\n",
       " 89031: array([[120645.31]], dtype=float32),\n",
       " 89110: array([[86367.11]], dtype=float32),\n",
       " 89074: array([[313313.8]], dtype=float32),\n",
       " 89103: array([[105097.86]], dtype=float32),\n",
       " 89148: array([[304354.1]], dtype=float32),\n",
       " 89147: array([[127211.54]], dtype=float32),\n",
       " 89119: array([[95203.36]], dtype=float32),\n",
       " 89129: array([[136210.56]], dtype=float32),\n",
       " 89122: array([[99995.11]], dtype=float32),\n",
       " 89115: array([[49483.06]], dtype=float32),\n",
       " 89502: array([[103521.21]], dtype=float32),\n",
       " 89014: array([[144321.5]], dtype=float32),\n",
       " 89131: array([[340571.3]], dtype=float32),\n",
       " 89509: array([[442702.12]], dtype=float32),\n",
       " 89436: array([[174319.03]], dtype=float32),\n",
       " 89015: array([[98834.02]], dtype=float32),\n",
       " 89128: array([[138708.28]], dtype=float32),\n",
       " 89523: array([[389421.16]], dtype=float32),\n",
       " 89104: array([[76258.59]], dtype=float32),\n",
       " 89012: array([[345105.72]], dtype=float32),\n",
       " 89030: array([[86262.86]], dtype=float32),\n",
       " 89431: array([[85330.53]], dtype=float32),\n",
       " 89032: array([[86667.86]], dtype=float32),\n",
       " 89506: array([[118694.53]], dtype=float32),\n",
       " 89102: array([[76455.164]], dtype=float32),\n",
       " 89139: array([[142436.7]], dtype=float32),\n",
       " 89149: array([[151599.61]], dtype=float32),\n",
       " 89178: array([[300754.56]], dtype=float32),\n",
       " 89113: array([[304622.88]], dtype=float32),\n",
       " 89521: array([[414650.53]], dtype=float32),\n",
       " 89183: array([[124785.68]], dtype=float32),\n",
       " 89135: array([[421180.38]], dtype=float32),\n",
       " 89107: array([[81638.05]], dtype=float32),\n",
       " 89511: array([[646172.7]], dtype=float32),\n",
       " 89002: array([[308202.84]], dtype=float32),\n",
       " 89130: array([[129408.92]], dtype=float32),\n",
       " 89134: array([[320814.12]], dtype=float32),\n",
       " 89503: array([[119717.45]], dtype=float32),\n",
       " 89081: array([[114632.67]], dtype=float32),\n",
       " 89141: array([[321766.6]], dtype=float32),\n",
       " 89011: array([[272069.34]], dtype=float32),\n",
       " 89142: array([[72033.64]], dtype=float32),\n",
       " 89434: array([[129602.984]], dtype=float32),\n",
       " 89512: array([[115600.35]], dtype=float32),\n",
       " 89145: array([[92809.625]], dtype=float32),\n",
       " 89084: array([[299766.88]], dtype=float32),\n",
       " 89701: array([[265423.44]], dtype=float32),\n",
       " 89801: array([[208460.4]], dtype=float32),\n",
       " 89120: array([[100827.47]], dtype=float32),\n",
       " 89044: array([[350935.9]], dtype=float32),\n",
       " 89156: array([[82416.85]], dtype=float32),\n",
       " 89048: array([[101105.82]], dtype=float32),\n",
       " 89118: array([[148262.86]], dtype=float32),\n",
       " 89706: array([[263521.75]], dtype=float32),\n",
       " 89408: array([[144694.62]], dtype=float32),\n",
       " 89166: array([[292753.38]], dtype=float32),\n",
       " 89144: array([[355562.78]], dtype=float32),\n",
       " 89146: array([[154365.]], dtype=float32),\n",
       " 89027: array([[242222.94]], dtype=float32),\n",
       " 89403: array([[171603.86]], dtype=float32),\n",
       " 89433: array([[102987.836]], dtype=float32),\n",
       " 89005: array([[320821.78]], dtype=float32),\n",
       " 89138: array([[436478.25]], dtype=float32),\n",
       " 89460: array([[326733.5]], dtype=float32),\n",
       " 89423: array([[395983.56]], dtype=float32),\n",
       " 89410: array([[366729.84]], dtype=float32),\n",
       " 89815: array([[215286.89]], dtype=float32),\n",
       " 89029: array([[131214.25]], dtype=float32),\n",
       " 89109: array([[165541.64]], dtype=float32),\n",
       " 89508: array([[150758.38]], dtype=float32),\n",
       " 89703: array([[397177.84]], dtype=float32),\n",
       " 89441: array([[428157.22]], dtype=float32),\n",
       " 89060: array([[78774.56]], dtype=float32),\n",
       " 89143: array([[280067.12]], dtype=float32),\n",
       " 89519: array([[550517.]], dtype=float32),\n",
       " 89447: array([[116557.16]], dtype=float32),\n",
       " 89179: array([[311430.2]], dtype=float32),\n",
       " 89429: array([[109313.07]], dtype=float32),\n",
       " 89061: array([[105543.38]], dtype=float32),\n",
       " 89451: array([[931118.7]], dtype=float32),\n",
       " 89501: array([[343421.28]], dtype=float32),\n",
       " 89705: array([[321901.6]], dtype=float32),\n",
       " 89510: array([[424555.62]], dtype=float32),\n",
       " 89086: array([[120434.48]], dtype=float32),\n",
       " 89448: array([[415196.28]], dtype=float32),\n",
       " 89704: array([[425430.1]], dtype=float32),\n",
       " 89449: array([[256005.6]], dtype=float32),\n",
       " 89040: array([[209113.64]], dtype=float32),\n",
       " 89444: array([[289542.3]], dtype=float32),\n",
       " 89085: array([[331103.47]], dtype=float32),\n",
       " 89034: array([[255054.42]], dtype=float32),\n",
       " 89021: array([[230877.84]], dtype=float32),\n",
       " 89439: array([[458706.2]], dtype=float32),\n",
       " 89411: array([[515886.7]], dtype=float32),\n",
       " 89124: array([[337681.62]], dtype=float32),\n",
       " 89440: array([[99456.234]], dtype=float32),\n",
       " 89413: array([[2040080.5]], dtype=float32),\n",
       " 89155: array([[357517.4]], dtype=float32)}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_pred_skylar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89108: inf,\n",
       " 89121: inf,\n",
       " 89117: 1230066.2112004093,\n",
       " 89052: 849023.4076489556,\n",
       " 89123: 1245902.8314519874,\n",
       " 89031: inf,\n",
       " 89110: inf,\n",
       " 89074: 1235234.9873707858,\n",
       " 89103: inf,\n",
       " 89148: 1564602.609267752,\n",
       " 89147: inf,\n",
       " 89119: inf,\n",
       " 89129: inf,\n",
       " 89122: inf,\n",
       " 89115: inf,\n",
       " 89502: inf,\n",
       " 89014: inf,\n",
       " 89131: 1267790.6867763042,\n",
       " 89509: 861158.6664328449,\n",
       " 89436: inf,\n",
       " 89015: inf,\n",
       " 89128: inf,\n",
       " 89523: 1116613.6573751096,\n",
       " 89104: inf,\n",
       " 89012: 803228.1592199908,\n",
       " 89030: inf,\n",
       " 89431: inf,\n",
       " 89032: inf,\n",
       " 89506: inf,\n",
       " 89102: inf,\n",
       " 89139: inf,\n",
       " 89149: inf,\n",
       " 89178: 1263958.5142729054,\n",
       " 89113: 1231231.4229128067,\n",
       " 89521: 900697.026561388,\n",
       " 89183: inf,\n",
       " 89135: 1030794.2057844118,\n",
       " 89107: inf,\n",
       " 89511: 1099164.863237715,\n",
       " 89002: 874431.9452965424,\n",
       " 89130: inf,\n",
       " 89134: 2055561.3968449957,\n",
       " 89503: inf,\n",
       " 89081: inf,\n",
       " 89141: 1109612.7007757071,\n",
       " 89011: 1274199.9438122606,\n",
       " 89142: inf,\n",
       " 89434: inf,\n",
       " 89512: inf,\n",
       " 89145: inf,\n",
       " 89084: 1126084.1104500473,\n",
       " 89701: 717319.0582727147,\n",
       " 89801: inf,\n",
       " 89120: inf,\n",
       " 89044: 681496.2415705951,\n",
       " 89156: inf,\n",
       " 89048: inf,\n",
       " 89118: inf,\n",
       " 89706: 550594.133251606,\n",
       " 89408: inf,\n",
       " 89166: 853139.2038593336,\n",
       " 89144: 935709.0020983517,\n",
       " 89146: inf,\n",
       " 89027: 626998.6678725225,\n",
       " 89403: inf,\n",
       " 89433: inf,\n",
       " 89005: 737327.2088295636,\n",
       " 89138: 1161405.077756935,\n",
       " 89460: 576897.2225772525,\n",
       " 89423: 704213.0442148822,\n",
       " 89410: 653551.9546868667,\n",
       " 89815: inf,\n",
       " 89029: inf,\n",
       " 89109: inf,\n",
       " 89508: inf,\n",
       " 89703: 990975.8898129726,\n",
       " 89441: 1029440.0940955299,\n",
       " 89060: inf,\n",
       " 89143: 1531513.2771627223,\n",
       " 89519: 1287210.3579656263,\n",
       " 89447: inf,\n",
       " 89179: 812589.4835636253,\n",
       " 89429: inf,\n",
       " 89061: inf,\n",
       " 89451: 1162558.7394056001,\n",
       " 89501: 694543.6927779577,\n",
       " 89705: 666047.7668984331,\n",
       " 89510: 902305.1468193594,\n",
       " 89086: inf,\n",
       " 89448: inf,\n",
       " 89704: 805071.7431239514,\n",
       " 89449: inf,\n",
       " 89040: 1094984.957853918,\n",
       " 89444: 637412.1169201456,\n",
       " 89085: 1484817.5105409324,\n",
       " 89034: 959847.0209837235,\n",
       " 89021: 1018985.4868376467,\n",
       " 89439: 829505.0863944809,\n",
       " 89411: 1195062.9838804866,\n",
       " 89124: 923523.0060611685,\n",
       " 89440: inf,\n",
       " 89413: 2654001.6272303164,\n",
       " 89155: 1066815.2493125491}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_mape_skylar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95804: [0.5159191513365095, 75412.6796875, 'RNN'],\n",
       " 95817: [0.4806917270953116, 82854.0859375, 'RNN'],\n",
       " 95813: [0.013083894437494591, 341304.875, 'RNN'],\n",
       " 95785: [0.01378739311178748, 422513.25, 'RNN'],\n",
       " 95819: [0.015094171486925623, 301021.0625, 'RNN'],\n",
       " 95770: [0.44194695282497615, 105605.78125, 'RNN'],\n",
       " 95806: [0.5182788597996814, 70026.3359375, 'RNN'],\n",
       " 95790: [0.007388430655138559, 312865.75, 'RNN'],\n",
       " 95799: [0.41473107013635707, 110862.84375, 'RNN'],\n",
       " 95844: [0.014626261526478987, 297665.53125, 'RNN'],\n",
       " 95843: [0.40972854999398295, 126288.140625, 'RNN'],\n",
       " 95815: [0.4957810488444431, 84689.921875, 'RNN'],\n",
       " 95825: [0.38387902090114595, 142043.46875, 'RNN'],\n",
       " 95818: [0.4386295986242681, 94474.0703125, 'RNN'],\n",
       " 95811: [0.46491245082909255, 74676.609375, 'RNN'],\n",
       " 95931: [0.44696939316482326, 114605.4375, 'RNN'],\n",
       " 95753: [0.3965936438523714, 141604.265625, 'RNN'],\n",
       " 95827: [0.007951250432951461, 335392.75, 'RNN'],\n",
       " 95937: [0.010482319800557482, 444971.84375, 'RNN'],\n",
       " 95914: [0.4358761083009109, 168000.984375, 'RNN'],\n",
       " 95754: [0.43916482062443524, 106289.3515625, 'RNN'],\n",
       " 95824: [0.3774964689018774, 143480.625, 'RNN'],\n",
       " 95945: [0.009420181348985288, 393342.9375, 'RNN'],\n",
       " 95800: [0.4718195009651555, 84472.21875, 'RNN'],\n",
       " 95751: [0.011770262489814314, 343317.875, 'RNN'],\n",
       " 95769: [0.2418764663897689, 81770.640625, 'RNN'],\n",
       " 95909: [0.541548922420154, 80201.6171875, 'RNN'],\n",
       " 95771: [0.4449168818684283, 96661.84375, 'RNN'],\n",
       " 95935: [0.468579774527048, 115184.875, 'RNN'],\n",
       " 95798: [0.49470465844168654, 83719.421875, 'RNN'],\n",
       " 95835: [0.3906188879587259, 140822.90625, 'RNN'],\n",
       " 95845: [0.3527866797556514, 166657.90625, 'RNN'],\n",
       " 95865: [0.0060464769748770665, 294301.125, 'RNN'],\n",
       " 95809: [0.009771453341725073, 304432.59375, 'RNN'],\n",
       " 95944: [0.010799909267872594, 409787.03125, 'RNN'],\n",
       " 399671: [0.4116425192150598, 124373.84375, 'RNN'],\n",
       " 95831: [0.013558921555743184, 427525.21875, 'RNN'],\n",
       " 95803: [0.517279830987193, 71889.5390625, 'RNN'],\n",
       " 95939: [0.017354669112205005, 643723.25, 'RNN'],\n",
       " 399665: [0.014149467428044914, 302807.65625, 'RNN'],\n",
       " 95826: [0.3977985782396422, 129545.7578125, 'RNN'],\n",
       " 95830: [0.01499383163019032, 316861.25, 'RNN'],\n",
       " 95932: [0.41069818420484944, 147422.921875, 'RNN'],\n",
       " 95792: [0.41483758989555536, 114382.765625, 'RNN'],\n",
       " 95837: [0.02081529672912315, 327126.6875, 'RNN'],\n",
       " 95750: [0.015961433084506354, 267443.625, 'RNN'],\n",
       " 95838: [0.4022623108188854, 102916.2578125, 'RNN'],\n",
       " 95912: [0.4455681412177846, 132910.53125, 'RNN'],\n",
       " 95940: [0.28050054567188604, 115600.046875, 'RNN'],\n",
       " 95841: [0.3897281475301448, 120660.484375, 'RNN'],\n",
       " 95793: [0.009597087395329643, 296469.84375, 'RNN'],\n",
       " 95952: [0.009495231708585497, 266254.875, 'RNN'],\n",
       " 95963: [0.10176629964979514, 209590.125, 'RNN'],\n",
       " 95816: [0.4315038321521024, 116423.96875, 'RNN'],\n",
       " 95779: [0.011447647262227374, 356830.5, 'RNN'],\n",
       " 95852: [0.46973642009308786, 84205.7265625, 'RNN'],\n",
       " 95783: [0.3317365500787004, 106907.9921875, 'RNN'],\n",
       " 95814: [0.38382792279041755, 134058.5, 'RNN'],\n",
       " 95957: [0.012981924290519522, 267417.28125, 'RNN'],\n",
       " 95888: [0.19147234315544517, 143140.03125, 'RNN'],\n",
       " 95861: [0.014256302542522825, 286464.03125, 'RNN'],\n",
       " 95840: [0.01030218372133625, 347827.71875, 'RNN'],\n",
       " 95842: [0.36788399256165016, 167712.90625, 'RNN'],\n",
       " 95766: [0.00854011861571219, 239586.078125, 'RNN'],\n",
       " 95883: [0.1520333966450159, 175152.21875, 'RNN'],\n",
       " 95911: [0.46489085262274765, 113575.8046875, 'RNN'],\n",
       " 95744: [0.00984138429584488, 318896.78125, 'RNN'],\n",
       " 95834: [0.011436811817719347, 434530.78125, 'RNN'],\n",
       " 95928: [0.021741427708519265, 318965.125, 'RNN'],\n",
       " 95901: [0.015790881595813135, 398780.40625, 'RNN'],\n",
       " 95890: [0.01847956218986767, 367463.875, 'RNN'],\n",
       " 95966: [0.07944586290889326, 216266.828125, 'RNN'],\n",
       " 95768: [0.16659501239545244, 133545.65625, 'RNN'],\n",
       " 95805: [0.3309421671862406, 162035.734375, 'RNN'],\n",
       " 399673: [0.43961954063396863, 131789.515625, 'RNN'],\n",
       " 95954: [0.010090192830097204, 399326.6875, 'RNN'],\n",
       " 399672: [0.02068608427753164, 418189.25, 'RNN'],\n",
       " 95787: [0.32292317749437116, 81608.4609375, 'RNN'],\n",
       " 95839: [0.018493146927664354, 276744.0, 'RNN'],\n",
       " 399674: [0.013792924062759431, 540005.875, 'RNN'],\n",
       " 95922: [0.12094748056449896, 114301.2109375, 'RNN'],\n",
       " 95866: [0.008060034743548408, 306858.6875, 'RNN'],\n",
       " 95907: [0.16924311825053417, 108803.5859375, 'RNN'],\n",
       " 95788: [0.41459605477245626, 98749.265625, 'RNN'],\n",
       " 95926: [0.022131163635094733, 916679.0625, 'RNN'],\n",
       " 95930: [0.03876847845117795, 338159.3125, 'RNN'],\n",
       " 95956: [0.02446487880320502, 315065.6875, 'RNN'],\n",
       " 95938: [0.02889695214142176, 428775.71875, 'RNN'],\n",
       " 95795: [0.3838596467150377, 137223.53125, 'RNN'],\n",
       " 95923: [0.32736431115352693, 409056.8125, 'RNN'],\n",
       " 95955: [0.02124960986573491, 423724.21875, 'RNN'],\n",
       " 95924: [0.23029241142242796, 260255.78125, 'RNN'],\n",
       " 95775: [0.013657195455473416, 207778.890625, 'RNN'],\n",
       " 95919: [0.01986937571165866, 285412.59375, 'RNN'],\n",
       " 95794: [0.009203299905793253, 330588.71875, 'RNN'],\n",
       " 399666: [0.013165532119944867, 323501.25, 'RNN'],\n",
       " 95760: [0.012689090960715351, 309324.90625, 'RNN'],\n",
       " 95916: [0.013263515868673158, 456363.8125, 'RNN'],\n",
       " 95891: [0.01297970825903085, 651686.3125, 'RNN'],\n",
       " 95820: [0.026793016022013318, 333740.6875, 'RNN'],\n",
       " 95917: [0.4154968076834546, 102394.203125, 'RNN'],\n",
       " 95893: [0.026021759253071913, 2057796.75, 'RNN'],\n",
       " 95851: [0.010471334813466493, 355289.84375, 'RNN']}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89005: [0.022498635550434295, 315770.5862729762, 'FBP_scale=0.5'],\n",
       " 89011: [0.04278110779000683, 268191.1951533978, 'FBP_scale=0.5'],\n",
       " 89012: [0.03408125028112888, 346791.0020159719, 'FBP_scale=0.5'],\n",
       " 89014: [0.02982231867033438, 290775.76827606466, 'FBP_scale=0.5'],\n",
       " 89015: [0.020673062452361255, 255266.9013634051, 'FBP_scale=0.5'],\n",
       " 89021: [0.021685927237354685, 310127.47890419036, 'FBP_scale=0.5'],\n",
       " 89027: [0.023356007127800827, 240189.23249319484, 'FBP_scale=0.5'],\n",
       " 89029: [0.0280397544224704, 182509.39476487262, 'FBP_scale=0.5'],\n",
       " 89030: [0.03602921269009029, 153247.78988254067, 'FBP_scale=0.5'],\n",
       " 89031: [0.03434730300348244, 246300.94475486007, 'FBP_scale=0.5'],\n",
       " 89032: [0.045912141431496335, 234114.60925612983, 'FBP_scale=0.5'],\n",
       " 89040: [0.052278179111354565, 208033.3162393082, 'FBP_scale=0.5'],\n",
       " 89044: [0.026860553573338542, 357295.44824271597, 'FBP_scale=0.5'],\n",
       " 89048: [0.04679328785772354, 200705.8126463924, 'FBP_scale=0.5'],\n",
       " 89052: [0.025238772814148578, 421068.9254136304, 'FBP_scale=0.5'],\n",
       " 89060: [0.05044588420751083, 154590.7171150974, 'FBP_scale=0.5'],\n",
       " 89061: [0.05167060208025199, 219499.46418643033, 'FBP_scale=0.5'],\n",
       " 89074: [0.031614012629685995, 316779.48254232004, 'FBP_scale=0.5'],\n",
       " 89081: [0.04179429582249042, 255788.3319140967, 'FBP_scale=0.5'],\n",
       " 89084: [0.02960237024440737, 299204.5957428111, 'FBP_scale=0.5'],\n",
       " 89085: [0.03774310893184554, 328288.87104909273, 'FBP_scale=0.5'],\n",
       " 89086: [0.022623376705750278, 279634.99856473086, 'FBP_scale=0.5'],\n",
       " 89102: [0.040796909553926605, 220765.39635029866, 'FBP_scale=0.5'],\n",
       " 89103: [0.023349681918025767, 254729.35021436046, 'FBP_scale=0.5'],\n",
       " 89104: [0.03320603155912621, 212632.1144190938, 'FBP_scale=0.5'],\n",
       " 89107: [0.05935506051263894, 198917.1941191062, 'FBP_scale=0.5'],\n",
       " 89108: [0.053552150532358844, 212876.99612153973, 'FBP_scale=0.5'],\n",
       " 89109: [0.07727488712982523, 337940.7916967204, 'FBP_scale=0.5'],\n",
       " 89110: [0.04725188507969076, 200482.01372467002, 'FBP_scale=0.5'],\n",
       " 89113: [0.043625364435827534, 309582.4499731394, 'FBP_scale=0.5'],\n",
       " 89115: [0.04808106594745356, 180066.93932910392, 'FBP_scale=0.5'],\n",
       " 89117: [0.029426083389244503, 344299.1564222108, 'FBP_scale=0.5'],\n",
       " 89118: [0.030271458421119, 271179.49889021384, 'FBP_scale=0.5'],\n",
       " 89119: [0.026782273794856256, 241955.26361875163, 'FBP_scale=0.5'],\n",
       " 89120: [0.04554779842216769, 267252.62681162066, 'FBP_scale=0.5'],\n",
       " 89121: [0.03251929889460807, 212357.25585671476, 'FBP_scale=0.5'],\n",
       " 89122: [0.061933752527614086, 214762.9394826224, 'FBP_scale=0.5'],\n",
       " 89123: [0.04825771073766382, 306773.87555588817, 'FBP_scale=0.5'],\n",
       " 89124: [0.0937953210600353, 334290.0833986482, 'FBP_scale=0.5'],\n",
       " 89128: [0.029905361981916723, 280846.724090128, 'FBP_scale=0.5'],\n",
       " 89129: [0.026517157639345555, 286423.08475005795, 'FBP_scale=0.5'],\n",
       " 89130: [0.025429646834373133, 276657.8056960072, 'FBP_scale=0.5'],\n",
       " 89131: [0.02483231367385673, 339574.2471591072, 'FBP_scale=0.5'],\n",
       " 89134: [0.038341795950534115, 321577.72028144787, 'FBP_scale=0.5'],\n",
       " 89135: [0.024515869611043625, 425834.5057004451, 'FBP_scale=0.5'],\n",
       " 89138: [0.032858074757566254, 442950.4158662549, 'FBP_scale=0.5'],\n",
       " 89139: [0.029566433244114444, 289032.9615452033, 'FBP_scale=0.5'],\n",
       " 89141: [0.034115387972923454, 321001.58057856036, 'FBP_scale=0.5'],\n",
       " 89142: [0.04194677994191061, 213715.51190621968, 'FBP_scale=0.5'],\n",
       " 89143: [0.057232444162401676, 283231.0973787324, 'FBP_scale=0.5'],\n",
       " 89144: [0.024782252424292387, 351505.7533436969, 'FBP_scale=0.5'],\n",
       " 89145: [0.024787502553774866, 246658.82776447045, 'FBP_scale=0.5'],\n",
       " 89146: [0.042324631114278415, 320103.6004428028, 'FBP_scale=0.5'],\n",
       " 89147: [0.014973894613094363, 272818.3010017803, 'FBP_scale=0.5'],\n",
       " 89148: [0.046392384187789994, 305625.52330460254, 'FBP_scale=0.5'],\n",
       " 89149: [0.03378183762916275, 308219.1848478401, 'FBP_scale=0.5'],\n",
       " 89155: [0.01926188734707299, 362032.9962344175, 'FBP_scale=0.5'],\n",
       " 89156: [0.045454014922245524, 207605.68758203776, 'FBP_scale=0.5'],\n",
       " 89166: [0.031835900515247546, 291128.0588082098, 'FBP_scale=0.5'],\n",
       " 89178: [0.03695304263395325, 295479.7674959657, 'FBP_scale=0.5'],\n",
       " 89179: [0.017686717512439786, 305660.96584050445, 'FBP_scale=0.5'],\n",
       " 89403: [0.022850621255721595, 275411.9877160178, 'FBP_scale=0.5'],\n",
       " 89408: [0.0364164969395669, 244086.15490036257, 'FBP_scale=0.5'],\n",
       " 89410: [0.054124594959493774, 373451.8138814837, 'FBP_scale=0.5'],\n",
       " 89411: [0.03320864612697135, 659160.513359919, 'FBP_scale=0.5'],\n",
       " 89413: [0.06451534890433677, 2132853.3588797115, 'FBP_scale=0.5'],\n",
       " 89423: [0.039261552321618015, 403664.2838719558, 'FBP_scale=0.5'],\n",
       " 89429: [0.03392726123407389, 191969.94510094702, 'FBP_scale=0.5'],\n",
       " 89431: [0.040307572198368696, 251931.37670638357, 'FBP_scale=0.5'],\n",
       " 89433: [0.023971527220539444, 274932.279549524, 'FBP_scale=0.5'],\n",
       " 89434: [0.042867507086386175, 303049.82422532566, 'FBP_scale=0.5'],\n",
       " 89436: [0.03748659863446806, 373725.1710211443, 'FBP_scale=0.5'],\n",
       " 89439: [0.05640902283540983, 454322.1839203852, 'FBP_scale=0.5'],\n",
       " 89440: [0.045543683310369336, 218486.83054223805, 'FBP_scale=0.5'],\n",
       " 89444: [0.051584223018417606, 276026.96248109627, 'FBP_scale=0.5'],\n",
       " 89447: [0.03528869275268434, 168143.63871695238, 'FBP_scale=0.5'],\n",
       " 89448: [0.05224819563754419, 736841.7751282966, 'FBP_scale=0.5'],\n",
       " 89449: [0.06992530950915793, 381426.39967530925, 'FBP_scale=0.5'],\n",
       " 89451: [0.04582917758575527, 946704.3623023875, 'FBP_scale=0.5'],\n",
       " 89460: [0.058460290765724114, 324424.9757866733, 'FBP_scale=0.5'],\n",
       " 89501: [0.053482173681949546, 351052.4832722586, 'FBP_scale=0.5'],\n",
       " 89502: [0.020103747985949223, 284076.71654429485, 'FBP_scale=0.5'],\n",
       " 89503: [0.04092247748861434, 314054.913904733, 'FBP_scale=0.5'],\n",
       " 89506: [0.030989881767913532, 280461.8992750567, 'FBP_scale=0.5'],\n",
       " 89509: [0.028004390547727243, 452250.1469241155, 'FBP_scale=0.5'],\n",
       " 89510: [0.03678098305692088, 431762.4565774328, 'FBP_scale=0.5'],\n",
       " 89511: [0.027204512517963773, 666469.6560600224, 'FBP_scale=0.5'],\n",
       " 89512: [0.031919613786859626, 233341.54418264233, 'FBP_scale=0.5'],\n",
       " 89521: [0.02429083202181481, 417320.8573649556, 'FBP_scale=0.5'],\n",
       " 89523: [0.021539231083709576, 397864.98620824347, 'FBP_scale=0.5'],\n",
       " 89701: [0.02731434444478958, 270163.8202057961, 'FBP_scale=0.5'],\n",
       " 89703: [0.024193958362711956, 404803.0094934392, 'FBP_scale=0.5'],\n",
       " 89704: [0.08357990835093837, 423194.0997806724, 'FBP_scale=0.5'],\n",
       " 89705: [0.046550476695143735, 319915.2612081292, 'FBP_scale=0.5'],\n",
       " 89706: [0.027981614194214768, 268942.85774527164, 'FBP_scale=0.5'],\n",
       " 89801: [0.033157206621436924, 241310.69109952607, 'FBP_scale=0.5'],\n",
       " 89815: [0.03217108263103794, 238194.8008724951, 'FBP_scale=0.5'],\n",
       " 89002: [0.03444270744775924, 307046.4987918806, 'FBP_scale=0.5'],\n",
       " 89034: [0.036062482078580683, 332575.9172435973, 'FBP_scale=0.5'],\n",
       " 89183: [0.04578603188943014, 277916.42593488516, 'FBP_scale=0.5'],\n",
       " 89441: [0.0254675908325991, 422765.85601377813, 'FBP_scale=0.5'],\n",
       " 89508: [0.017187629795996175, 301861.70888802106, 'FBP_scale=0.5'],\n",
       " 89519: [0.02247708340155557, 540689.2117415073, 'FBP_scale=0.5']}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e81d9768a2937af9514d7fa33aa30feb69a40df5b58c34cfa60b871c6c10885"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
