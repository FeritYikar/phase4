{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>334200.0</td>\n",
       "      <td>335400.0</td>\n",
       "      <td>336500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1005500</td>\n",
       "      <td>1007500</td>\n",
       "      <td>1007800</td>\n",
       "      <td>1009600</td>\n",
       "      <td>1013300</td>\n",
       "      <td>1018700</td>\n",
       "      <td>1024400</td>\n",
       "      <td>1030700</td>\n",
       "      <td>1033800</td>\n",
       "      <td>1030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90668</td>\n",
       "      <td>75070</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>Collin</td>\n",
       "      <td>2</td>\n",
       "      <td>235700.0</td>\n",
       "      <td>236900.0</td>\n",
       "      <td>236700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>308000</td>\n",
       "      <td>310000</td>\n",
       "      <td>312500</td>\n",
       "      <td>314100</td>\n",
       "      <td>315000</td>\n",
       "      <td>316600</td>\n",
       "      <td>318100</td>\n",
       "      <td>319600</td>\n",
       "      <td>321100</td>\n",
       "      <td>321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris</td>\n",
       "      <td>3</td>\n",
       "      <td>210400.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321000</td>\n",
       "      <td>320600</td>\n",
       "      <td>320200</td>\n",
       "      <td>320400</td>\n",
       "      <td>320800</td>\n",
       "      <td>321200</td>\n",
       "      <td>321200</td>\n",
       "      <td>323000</td>\n",
       "      <td>326900</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>4</td>\n",
       "      <td>498100.0</td>\n",
       "      <td>500900.0</td>\n",
       "      <td>503100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1289800</td>\n",
       "      <td>1287700</td>\n",
       "      <td>1287400</td>\n",
       "      <td>1291500</td>\n",
       "      <td>1296600</td>\n",
       "      <td>1299000</td>\n",
       "      <td>1302700</td>\n",
       "      <td>1306400</td>\n",
       "      <td>1308500</td>\n",
       "      <td>1307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93144</td>\n",
       "      <td>79936</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>5</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119100</td>\n",
       "      <td>119400</td>\n",
       "      <td>120000</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120500</td>\n",
       "      <td>121000</td>\n",
       "      <td>121500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14718</th>\n",
       "      <td>58333</td>\n",
       "      <td>1338</td>\n",
       "      <td>Ashfield</td>\n",
       "      <td>MA</td>\n",
       "      <td>Greenfield Town</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>14719</td>\n",
       "      <td>94600.0</td>\n",
       "      <td>94300.0</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>216800</td>\n",
       "      <td>217700</td>\n",
       "      <td>218600</td>\n",
       "      <td>218500</td>\n",
       "      <td>218100</td>\n",
       "      <td>216400</td>\n",
       "      <td>213100</td>\n",
       "      <td>209800</td>\n",
       "      <td>209200</td>\n",
       "      <td>209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14719</th>\n",
       "      <td>59107</td>\n",
       "      <td>3293</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>NH</td>\n",
       "      <td>Claremont</td>\n",
       "      <td>Grafton</td>\n",
       "      <td>14720</td>\n",
       "      <td>92700.0</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>92400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>202100</td>\n",
       "      <td>208400</td>\n",
       "      <td>212200</td>\n",
       "      <td>215200</td>\n",
       "      <td>214300</td>\n",
       "      <td>213100</td>\n",
       "      <td>213700</td>\n",
       "      <td>218300</td>\n",
       "      <td>222700</td>\n",
       "      <td>225800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14720</th>\n",
       "      <td>75672</td>\n",
       "      <td>40404</td>\n",
       "      <td>Berea</td>\n",
       "      <td>KY</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Madison</td>\n",
       "      <td>14721</td>\n",
       "      <td>57100.0</td>\n",
       "      <td>57300.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121800</td>\n",
       "      <td>122800</td>\n",
       "      <td>124600</td>\n",
       "      <td>126700</td>\n",
       "      <td>128800</td>\n",
       "      <td>130600</td>\n",
       "      <td>131700</td>\n",
       "      <td>132500</td>\n",
       "      <td>133000</td>\n",
       "      <td>133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14721</th>\n",
       "      <td>93733</td>\n",
       "      <td>81225</td>\n",
       "      <td>Mount Crested Butte</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunnison</td>\n",
       "      <td>14722</td>\n",
       "      <td>191100.0</td>\n",
       "      <td>192400.0</td>\n",
       "      <td>193700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>662800</td>\n",
       "      <td>671200</td>\n",
       "      <td>682400</td>\n",
       "      <td>695600</td>\n",
       "      <td>695500</td>\n",
       "      <td>694700</td>\n",
       "      <td>706400</td>\n",
       "      <td>705300</td>\n",
       "      <td>681500</td>\n",
       "      <td>664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14722</th>\n",
       "      <td>95851</td>\n",
       "      <td>89155</td>\n",
       "      <td>Mesquite</td>\n",
       "      <td>NV</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Clark</td>\n",
       "      <td>14723</td>\n",
       "      <td>176400.0</td>\n",
       "      <td>176300.0</td>\n",
       "      <td>176100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>333800</td>\n",
       "      <td>336400</td>\n",
       "      <td>339700</td>\n",
       "      <td>343800</td>\n",
       "      <td>346800</td>\n",
       "      <td>348900</td>\n",
       "      <td>350400</td>\n",
       "      <td>353000</td>\n",
       "      <td>356000</td>\n",
       "      <td>357200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14723 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RegionID  RegionName                 City State              Metro  \\\n",
       "0         84654       60657              Chicago    IL            Chicago   \n",
       "1         90668       75070             McKinney    TX  Dallas-Fort Worth   \n",
       "2         91982       77494                 Katy    TX            Houston   \n",
       "3         84616       60614              Chicago    IL            Chicago   \n",
       "4         93144       79936              El Paso    TX            El Paso   \n",
       "...         ...         ...                  ...   ...                ...   \n",
       "14718     58333        1338             Ashfield    MA    Greenfield Town   \n",
       "14719     59107        3293            Woodstock    NH          Claremont   \n",
       "14720     75672       40404                Berea    KY           Richmond   \n",
       "14721     93733       81225  Mount Crested Butte    CO                NaN   \n",
       "14722     95851       89155             Mesquite    NV          Las Vegas   \n",
       "\n",
       "      CountyName  SizeRank   1996-04   1996-05   1996-06  ...  2017-07  \\\n",
       "0           Cook         1  334200.0  335400.0  336500.0  ...  1005500   \n",
       "1         Collin         2  235700.0  236900.0  236700.0  ...   308000   \n",
       "2         Harris         3  210400.0  212200.0  212200.0  ...   321000   \n",
       "3           Cook         4  498100.0  500900.0  503100.0  ...  1289800   \n",
       "4        El Paso         5   77300.0   77300.0   77300.0  ...   119100   \n",
       "...          ...       ...       ...       ...       ...  ...      ...   \n",
       "14718   Franklin     14719   94600.0   94300.0   94000.0  ...   216800   \n",
       "14719    Grafton     14720   92700.0   92500.0   92400.0  ...   202100   \n",
       "14720    Madison     14721   57100.0   57300.0   57500.0  ...   121800   \n",
       "14721   Gunnison     14722  191100.0  192400.0  193700.0  ...   662800   \n",
       "14722      Clark     14723  176400.0  176300.0  176100.0  ...   333800   \n",
       "\n",
       "       2017-08  2017-09  2017-10  2017-11  2017-12  2018-01  2018-02  2018-03  \\\n",
       "0      1007500  1007800  1009600  1013300  1018700  1024400  1030700  1033800   \n",
       "1       310000   312500   314100   315000   316600   318100   319600   321100   \n",
       "2       320600   320200   320400   320800   321200   321200   323000   326900   \n",
       "3      1287700  1287400  1291500  1296600  1299000  1302700  1306400  1308500   \n",
       "4       119400   120000   120300   120300   120300   120300   120500   121000   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "14718   217700   218600   218500   218100   216400   213100   209800   209200   \n",
       "14719   208400   212200   215200   214300   213100   213700   218300   222700   \n",
       "14720   122800   124600   126700   128800   130600   131700   132500   133000   \n",
       "14721   671200   682400   695600   695500   694700   706400   705300   681500   \n",
       "14722   336400   339700   343800   346800   348900   350400   353000   356000   \n",
       "\n",
       "       2018-04  \n",
       "0      1030600  \n",
       "1       321800  \n",
       "2       329900  \n",
       "3      1307000  \n",
       "4       121500  \n",
       "...        ...  \n",
       "14718   209300  \n",
       "14719   225800  \n",
       "14720   133400  \n",
       "14721   664400  \n",
       "14722   357200  \n",
       "\n",
       "[14723 rows x 272 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/zillow_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>84654</th>\n",
       "      <th>90668</th>\n",
       "      <th>91982</th>\n",
       "      <th>84616</th>\n",
       "      <th>93144</th>\n",
       "      <th>91733</th>\n",
       "      <th>61807</th>\n",
       "      <th>84640</th>\n",
       "      <th>91940</th>\n",
       "      <th>97564</th>\n",
       "      <th>...</th>\n",
       "      <th>59187</th>\n",
       "      <th>94711</th>\n",
       "      <th>62556</th>\n",
       "      <th>99032</th>\n",
       "      <th>62697</th>\n",
       "      <th>58333</th>\n",
       "      <th>59107</th>\n",
       "      <th>75672</th>\n",
       "      <th>93733</th>\n",
       "      <th>95851</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01</th>\n",
       "      <td>334200</td>\n",
       "      <td>235700</td>\n",
       "      <td>210400</td>\n",
       "      <td>498100</td>\n",
       "      <td>77300</td>\n",
       "      <td>95000</td>\n",
       "      <td>152900</td>\n",
       "      <td>216500</td>\n",
       "      <td>95400</td>\n",
       "      <td>766000</td>\n",
       "      <td>...</td>\n",
       "      <td>80800</td>\n",
       "      <td>135900</td>\n",
       "      <td>78300</td>\n",
       "      <td>136200</td>\n",
       "      <td>62500</td>\n",
       "      <td>94600</td>\n",
       "      <td>92700</td>\n",
       "      <td>57100</td>\n",
       "      <td>191100</td>\n",
       "      <td>176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01</th>\n",
       "      <td>335400</td>\n",
       "      <td>236900</td>\n",
       "      <td>212200</td>\n",
       "      <td>500900</td>\n",
       "      <td>77300</td>\n",
       "      <td>95200</td>\n",
       "      <td>152700</td>\n",
       "      <td>216700</td>\n",
       "      <td>95600</td>\n",
       "      <td>771100</td>\n",
       "      <td>...</td>\n",
       "      <td>80100</td>\n",
       "      <td>136300</td>\n",
       "      <td>78300</td>\n",
       "      <td>136600</td>\n",
       "      <td>62600</td>\n",
       "      <td>94300</td>\n",
       "      <td>92500</td>\n",
       "      <td>57300</td>\n",
       "      <td>192400</td>\n",
       "      <td>176300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01</th>\n",
       "      <td>336500</td>\n",
       "      <td>236700</td>\n",
       "      <td>212200</td>\n",
       "      <td>503100</td>\n",
       "      <td>77300</td>\n",
       "      <td>95400</td>\n",
       "      <td>152600</td>\n",
       "      <td>216900</td>\n",
       "      <td>95800</td>\n",
       "      <td>776500</td>\n",
       "      <td>...</td>\n",
       "      <td>79400</td>\n",
       "      <td>136600</td>\n",
       "      <td>78200</td>\n",
       "      <td>136800</td>\n",
       "      <td>62700</td>\n",
       "      <td>94000</td>\n",
       "      <td>92400</td>\n",
       "      <td>57500</td>\n",
       "      <td>193700</td>\n",
       "      <td>176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01</th>\n",
       "      <td>337600</td>\n",
       "      <td>235400</td>\n",
       "      <td>210700</td>\n",
       "      <td>504600</td>\n",
       "      <td>77300</td>\n",
       "      <td>95700</td>\n",
       "      <td>152400</td>\n",
       "      <td>217000</td>\n",
       "      <td>96100</td>\n",
       "      <td>781900</td>\n",
       "      <td>...</td>\n",
       "      <td>78600</td>\n",
       "      <td>136900</td>\n",
       "      <td>78200</td>\n",
       "      <td>136800</td>\n",
       "      <td>62700</td>\n",
       "      <td>93700</td>\n",
       "      <td>92200</td>\n",
       "      <td>57700</td>\n",
       "      <td>195000</td>\n",
       "      <td>176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01</th>\n",
       "      <td>338500</td>\n",
       "      <td>233300</td>\n",
       "      <td>208300</td>\n",
       "      <td>505500</td>\n",
       "      <td>77400</td>\n",
       "      <td>95900</td>\n",
       "      <td>152300</td>\n",
       "      <td>217100</td>\n",
       "      <td>96400</td>\n",
       "      <td>787300</td>\n",
       "      <td>...</td>\n",
       "      <td>77900</td>\n",
       "      <td>137100</td>\n",
       "      <td>78100</td>\n",
       "      <td>136700</td>\n",
       "      <td>62700</td>\n",
       "      <td>93400</td>\n",
       "      <td>92100</td>\n",
       "      <td>58000</td>\n",
       "      <td>196300</td>\n",
       "      <td>175900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>1018700</td>\n",
       "      <td>316600</td>\n",
       "      <td>321200</td>\n",
       "      <td>1299000</td>\n",
       "      <td>120300</td>\n",
       "      <td>162800</td>\n",
       "      <td>414300</td>\n",
       "      <td>777900</td>\n",
       "      <td>172300</td>\n",
       "      <td>3778700</td>\n",
       "      <td>...</td>\n",
       "      <td>123400</td>\n",
       "      <td>257600</td>\n",
       "      <td>171300</td>\n",
       "      <td>341000</td>\n",
       "      <td>122800</td>\n",
       "      <td>216400</td>\n",
       "      <td>213100</td>\n",
       "      <td>130600</td>\n",
       "      <td>694700</td>\n",
       "      <td>348900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>1024400</td>\n",
       "      <td>318100</td>\n",
       "      <td>321200</td>\n",
       "      <td>1302700</td>\n",
       "      <td>120300</td>\n",
       "      <td>162800</td>\n",
       "      <td>413900</td>\n",
       "      <td>778500</td>\n",
       "      <td>173300</td>\n",
       "      <td>3770800</td>\n",
       "      <td>...</td>\n",
       "      <td>124400</td>\n",
       "      <td>258000</td>\n",
       "      <td>172400</td>\n",
       "      <td>342300</td>\n",
       "      <td>123200</td>\n",
       "      <td>213100</td>\n",
       "      <td>213700</td>\n",
       "      <td>131700</td>\n",
       "      <td>706400</td>\n",
       "      <td>350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>1030700</td>\n",
       "      <td>319600</td>\n",
       "      <td>323000</td>\n",
       "      <td>1306400</td>\n",
       "      <td>120500</td>\n",
       "      <td>162900</td>\n",
       "      <td>411400</td>\n",
       "      <td>780500</td>\n",
       "      <td>174200</td>\n",
       "      <td>3763100</td>\n",
       "      <td>...</td>\n",
       "      <td>125500</td>\n",
       "      <td>260600</td>\n",
       "      <td>173600</td>\n",
       "      <td>345000</td>\n",
       "      <td>123200</td>\n",
       "      <td>209800</td>\n",
       "      <td>218300</td>\n",
       "      <td>132500</td>\n",
       "      <td>705300</td>\n",
       "      <td>353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>1033800</td>\n",
       "      <td>321100</td>\n",
       "      <td>326900</td>\n",
       "      <td>1308500</td>\n",
       "      <td>121000</td>\n",
       "      <td>163500</td>\n",
       "      <td>413200</td>\n",
       "      <td>782800</td>\n",
       "      <td>175400</td>\n",
       "      <td>3779800</td>\n",
       "      <td>...</td>\n",
       "      <td>126600</td>\n",
       "      <td>264700</td>\n",
       "      <td>175800</td>\n",
       "      <td>348000</td>\n",
       "      <td>120700</td>\n",
       "      <td>209200</td>\n",
       "      <td>222700</td>\n",
       "      <td>133000</td>\n",
       "      <td>681500</td>\n",
       "      <td>356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>1030600</td>\n",
       "      <td>321800</td>\n",
       "      <td>329900</td>\n",
       "      <td>1307000</td>\n",
       "      <td>121500</td>\n",
       "      <td>164300</td>\n",
       "      <td>417900</td>\n",
       "      <td>782800</td>\n",
       "      <td>176200</td>\n",
       "      <td>3813500</td>\n",
       "      <td>...</td>\n",
       "      <td>127500</td>\n",
       "      <td>266800</td>\n",
       "      <td>177500</td>\n",
       "      <td>349300</td>\n",
       "      <td>117700</td>\n",
       "      <td>209300</td>\n",
       "      <td>225800</td>\n",
       "      <td>133400</td>\n",
       "      <td>664400</td>\n",
       "      <td>357200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 14723 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              84654   90668   91982    84616   93144   91733   61807   84640  \\\n",
       "1996-04-01   334200  235700  210400   498100   77300   95000  152900  216500   \n",
       "1996-05-01   335400  236900  212200   500900   77300   95200  152700  216700   \n",
       "1996-06-01   336500  236700  212200   503100   77300   95400  152600  216900   \n",
       "1996-07-01   337600  235400  210700   504600   77300   95700  152400  217000   \n",
       "1996-08-01   338500  233300  208300   505500   77400   95900  152300  217100   \n",
       "...             ...     ...     ...      ...     ...     ...     ...     ...   \n",
       "2017-12-01  1018700  316600  321200  1299000  120300  162800  414300  777900   \n",
       "2018-01-01  1024400  318100  321200  1302700  120300  162800  413900  778500   \n",
       "2018-02-01  1030700  319600  323000  1306400  120500  162900  411400  780500   \n",
       "2018-03-01  1033800  321100  326900  1308500  121000  163500  413200  782800   \n",
       "2018-04-01  1030600  321800  329900  1307000  121500  164300  417900  782800   \n",
       "\n",
       "             91940    97564  ...   59187   94711   62556   99032   62697  \\\n",
       "1996-04-01   95400   766000  ...   80800  135900   78300  136200   62500   \n",
       "1996-05-01   95600   771100  ...   80100  136300   78300  136600   62600   \n",
       "1996-06-01   95800   776500  ...   79400  136600   78200  136800   62700   \n",
       "1996-07-01   96100   781900  ...   78600  136900   78200  136800   62700   \n",
       "1996-08-01   96400   787300  ...   77900  137100   78100  136700   62700   \n",
       "...            ...      ...  ...     ...     ...     ...     ...     ...   \n",
       "2017-12-01  172300  3778700  ...  123400  257600  171300  341000  122800   \n",
       "2018-01-01  173300  3770800  ...  124400  258000  172400  342300  123200   \n",
       "2018-02-01  174200  3763100  ...  125500  260600  173600  345000  123200   \n",
       "2018-03-01  175400  3779800  ...  126600  264700  175800  348000  120700   \n",
       "2018-04-01  176200  3813500  ...  127500  266800  177500  349300  117700   \n",
       "\n",
       "             58333   59107   75672   93733   95851  \n",
       "1996-04-01   94600   92700   57100  191100  176400  \n",
       "1996-05-01   94300   92500   57300  192400  176300  \n",
       "1996-06-01   94000   92400   57500  193700  176100  \n",
       "1996-07-01   93700   92200   57700  195000  176000  \n",
       "1996-08-01   93400   92100   58000  196300  175900  \n",
       "...            ...     ...     ...     ...     ...  \n",
       "2017-12-01  216400  213100  130600  694700  348900  \n",
       "2018-01-01  213100  213700  131700  706400  350400  \n",
       "2018-02-01  209800  218300  132500  705300  353000  \n",
       "2018-03-01  209200  222700  133000  681500  356000  \n",
       "2018-04-01  209300  225800  133400  664400  357200  \n",
       "\n",
       "[265 rows x 14723 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series = pd.DataFrame(index=pd.to_datetime(df.columns[7:]), data=np.ones(len(df.columns)-7))\n",
    "for i in range(df.shape[0]):\n",
    "    df_time_series[df['RegionID'][i]] = df.iloc[i,7:]\n",
    "df_time_series.drop(df_time_series.columns[0],axis=1, inplace=True)\n",
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156891"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95804"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nv = df[df['State'] == 'NV']\n",
    "nv_zipcodes = list(df_nv.RegionID)\n",
    "nv_zipcodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_time_series.iloc[:,0].plot(figsize=(16,9))\n",
    "df_time_series.iloc[:,1].plot()\n",
    "df_time_series.iloc[:,2].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(df_time_series)*.8)\n",
    "train = df_time_series.iloc[:size]\n",
    "test = df_time_series.iloc[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = df_time_series[nv_zipcodes]\n",
    "train = train[nv_zipcodes]\n",
    "test = test[nv_zipcodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying a RNN model to see how it does on our first zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "train_data = train.iloc[:,x:x+1].values.astype(int)\n",
    "test_data = test.iloc[:,x:x+1].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset with 60 timesteps (5 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60,len(train_data_scaled)):\n",
    "    X_train.append(train_data_scaled[i-60:i])\n",
    "    y_train.append(train_data_scaled[i])\n",
    "\n",
    "data_total = pd.concat((train.iloc[:,x:x+1], test.iloc[:,x:x+1]),axis=0)\n",
    "inputs = data_total[len(train)-60:].values\n",
    "inputs = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(60,len(inputs)):\n",
    "    X_test.append(inputs[i-60:i])\n",
    "    y_test.append(inputs[i])\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn data into arrays for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.add(LSTM(units= 60, return_sequences = False, input_shape=((60,1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.add(Dense(units=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60)                14880     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 14,941\n",
      "Trainable params: 14,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2913\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1091\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0371\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0362\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0174\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0178\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0159\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0113\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0100\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.0087\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0069\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0061\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0050\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0040\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0031\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0023\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0018\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0014\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0013\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0010\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0010\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.9279e-04\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.8929e-04\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.7375e-04\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.7130e-04\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.5757e-04\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.4612e-04\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 9.3379e-04\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.4216e-04\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.2077e-04\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.0334e-04\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.9738e-04\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.8246e-04\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.7587e-04\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.6334e-04\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.5805e-04\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.4655e-04\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.3893e-04\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.2785e-04\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.2164e-04\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.0948e-04\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.1172e-04\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.1538e-04\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.9874e-04\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.7809e-04\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.7618e-04\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.7354e-04\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.6498e-04\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.1054e-04\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.3458e-04\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.1020e-04\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.7896e-04\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.6056e-04\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.6068e-04\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.0436e-04\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.9430e-04\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.9527e-04\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7601e-04\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 6.7800e-04\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.6978e-04\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.5449e-04\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.4266e-04\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.4316e-04\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.4622e-04\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.2750e-04\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.1757e-04\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.1305e-04\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.9999e-04\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 5.9749e-04\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.9873e-04\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.0757e-04\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.0220e-04\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.7991e-04\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.8538e-04\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.6483e-04\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.5934e-04\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.4901e-04\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.3961e-04\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.5725e-04\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.4315e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdfd6046d60>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(X_train, y_train, epochs=100, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_raw = rnn_model.predict(X_test)\n",
    "y_hat = scaler.inverse_transform(y_hat_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test, color='red', label='Real Prices')\n",
    "plt.plot(y_hat, color='blue', label='Predicted Prices')\n",
    "plt.title('Unseen Data Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Our RNN model on all NV Zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 13344.6377 - val_loss: 88.9842\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 287148.1250 - val_loss: 88.1756\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 220756.1875 - val_loss: 94.9052\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48676.0234 - val_loss: 99.3483\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2735.2988 - val_loss: 105.4793\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 177464.5000 - val_loss: 107.8158\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 161273.7188 - val_loss: 106.7928\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 127502.5938 - val_loss: 102.9215\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46896.5625 - val_loss: 99.2472\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 62287.8164 - val_loss: 98.4469\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 69301.8516 - val_loss: 99.5992\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33627.3633 - val_loss: 101.3506\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23431.4727 - val_loss: 101.6797\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14422.3604 - val_loss: 100.7973\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2848.2715 - val_loss: 100.8482\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 297.6903 - val_loss: 99.8310\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30404.6387 - val_loss: 100.0433\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16656.1719 - val_loss: 101.3830\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34414.1914 - val_loss: 101.7859\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19438.1465 - val_loss: 100.9332\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7597.7090 - val_loss: 98.0548\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 94758.0234 - val_loss: 96.8974\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 94649.0312 - val_loss: 97.1961\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 75839.5234 - val_loss: 99.3384\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24542.9297 - val_loss: 101.7557\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52546.9883 - val_loss: 102.2684\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 59121.9805 - val_loss: 101.5312\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39163.2812 - val_loss: 99.9719\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22730.2871 - val_loss: 99.3797\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18237.8496 - val_loss: 100.9469\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34948.5898 - val_loss: 101.2439\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30419.7969 - val_loss: 100.3064\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5924.5552 - val_loss: 100.0327\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 811.2105 - val_loss: 101.2900\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49493.3633 - val_loss: 101.7331\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40189.2344 - val_loss: 100.2886\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11294.2168 - val_loss: 99.7131\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5827.1387 - val_loss: 100.1408\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28326.4121 - val_loss: 100.9938\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20790.0273 - val_loss: 100.0340\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10866.7529 - val_loss: 99.7436\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5662.5762 - val_loss: 100.2576\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11320.8730 - val_loss: 100.2997\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5590.8989 - val_loss: 99.7904\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11204.7646 - val_loss: 99.7449\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6582.6001 - val_loss: 100.5644\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22932.3867 - val_loss: 100.6204\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12224.4609 - val_loss: 99.9696\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6400.0894 - val_loss: 99.8389\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4278.5718 - val_loss: 100.7352\n",
      "Iteration number 0 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 253748.2031 - val_loss: 84.6818\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 173808.2344 - val_loss: 96.4578\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 309319.9062 - val_loss: 95.1024\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 124500.3984 - val_loss: 90.3511\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 150600.6719 - val_loss: 90.3268\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 72542.0547 - val_loss: 93.8179\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 88424.3516 - val_loss: 93.4223\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26820.7344 - val_loss: 92.5730\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20472.7227 - val_loss: 93.1677\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21117.8418 - val_loss: 91.0765\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 112160.1328 - val_loss: 90.9359\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47872.0117 - val_loss: 93.7161\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 95986.4375 - val_loss: 93.4701\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15680.9971 - val_loss: 92.7519\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10455.5459 - val_loss: 93.7518\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58520.3633 - val_loss: 94.3033\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11957.1904 - val_loss: 94.0811\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3916.8232 - val_loss: 94.6432\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12164.5107 - val_loss: 94.7532\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13453.8145 - val_loss: 95.2364\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34767.3438 - val_loss: 95.4538\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4611.5273 - val_loss: 95.5701\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9891.3564 - val_loss: 96.0443\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21419.6465 - val_loss: 95.6717\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22382.2930 - val_loss: 96.9266\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26522.7559 - val_loss: 95.9460\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 112219.3125 - val_loss: 95.3265\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52694.2266 - val_loss: 97.5427\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 148820.2031 - val_loss: 98.5286\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 116814.1875 - val_loss: 96.9018\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24491.5312 - val_loss: 95.7646\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32074.5488 - val_loss: 97.2324\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58070.3750 - val_loss: 97.4012\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20784.3926 - val_loss: 96.3913\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61067.8086 - val_loss: 96.7483\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13131.7646 - val_loss: 98.1677\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 59562.9336 - val_loss: 97.9769\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19923.0254 - val_loss: 96.3835\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 95966.4844 - val_loss: 96.4961\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 71538.0781 - val_loss: 97.1262\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28989.7539 - val_loss: 98.0153\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13187.7227 - val_loss: 97.2638\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21871.3320 - val_loss: 97.6538\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18564.4727 - val_loss: 97.3465\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31004.4238 - val_loss: 96.8103\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29525.2637 - val_loss: 97.8084\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12099.3008 - val_loss: 97.3551\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44094.2617 - val_loss: 97.3289\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25818.4121 - val_loss: 98.2333\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49236.3359 - val_loss: 97.8635\n",
      "Iteration number 1 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 75.0663 - val_loss: 60.0703\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45.1099 - val_loss: 28.0185\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.9037 - val_loss: 27.0190\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.2246 - val_loss: 32.2553\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30.2707 - val_loss: 30.1133\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24.9313 - val_loss: 18.8311\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22.9679 - val_loss: 16.2242\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.7096 - val_loss: 15.8620\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.1025 - val_loss: 6.4953\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.0361 - val_loss: 10.4410\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.1753 - val_loss: 2.7170\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.1027 - val_loss: 6.4929\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.0030 - val_loss: 2.3974\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.1092 - val_loss: 9.4222\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.8919 - val_loss: 2.8239\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.0987 - val_loss: 5.5941\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.1262 - val_loss: 3.5759\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.9635 - val_loss: 5.2064\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.4131 - val_loss: 4.0908\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.0659 - val_loss: 4.7679\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.7663 - val_loss: 4.4106\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.3145 - val_loss: 4.3517\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8956 - val_loss: 3.8192\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7867 - val_loss: 5.6515\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6829 - val_loss: 2.8062\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9801 - val_loss: 5.5243\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7404 - val_loss: 2.1471\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.2228 - val_loss: 7.2819\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8277 - val_loss: 2.5636\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.9910 - val_loss: 4.9898\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7699 - val_loss: 4.0219\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1467 - val_loss: 2.2259\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.2235 - val_loss: 6.5171\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8673 - val_loss: 1.7890\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6647 - val_loss: 3.8788\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2683 - val_loss: 3.5574\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3748 - val_loss: 3.8549\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4006 - val_loss: 2.3441\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2000 - val_loss: 5.5625\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9956 - val_loss: 2.6846\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8416 - val_loss: 3.5484\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8275 - val_loss: 4.8994\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0108 - val_loss: 2.2358\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9381 - val_loss: 4.3196\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5658 - val_loss: 3.6618\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8047 - val_loss: 3.9926\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5760 - val_loss: 2.1926\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5608 - val_loss: 5.0050\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.6643 - val_loss: 1.6407\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6122 - val_loss: 3.0696\n",
      "Iteration number 2 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 90.9460 - val_loss: 70.7899\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44.2066 - val_loss: 26.3381\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.8320 - val_loss: 3.7301\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24.5392 - val_loss: 22.0517\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18.6410 - val_loss: 29.6217\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.6953 - val_loss: 22.5895\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.4327 - val_loss: 13.8705\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.3570 - val_loss: 10.6964\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.7028 - val_loss: 12.0178\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.6733 - val_loss: 9.6628\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.3951 - val_loss: 7.1418\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3422 - val_loss: 2.5133\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5549 - val_loss: 3.9147\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.5530 - val_loss: 5.5556\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1868 - val_loss: 2.1890\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8563 - val_loss: 6.9631\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.1589 - val_loss: 5.7019\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.4648 - val_loss: 2.6279\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0278 - val_loss: 5.1339\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0452 - val_loss: 2.2242\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9537 - val_loss: 4.7982\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7211 - val_loss: 2.3488\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6057 - val_loss: 3.9647\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.5361 - val_loss: 2.2079\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3394 - val_loss: 3.4110\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1424 - val_loss: 2.3695\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4188 - val_loss: 2.5662\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1409 - val_loss: 2.8419\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9536 - val_loss: 2.8012\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7762 - val_loss: 2.3375\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5824 - val_loss: 2.9160\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5561 - val_loss: 2.4597\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5139 - val_loss: 2.2355\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5362 - val_loss: 2.2304\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3472 - val_loss: 3.1399\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5744 - val_loss: 2.1598\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3844 - val_loss: 3.0975\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2733 - val_loss: 2.2237\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0720 - val_loss: 2.9315\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0824 - val_loss: 2.6219\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5110 - val_loss: 2.0525\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7840 - val_loss: 2.2407\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6305 - val_loss: 2.6306\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9617 - val_loss: 2.2123\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5448 - val_loss: 2.0762\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6592 - val_loss: 1.9587\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5923 - val_loss: 2.1076\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.3750 - val_loss: 2.1495\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2826 - val_loss: 2.2263\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2338 - val_loss: 2.8399\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbc136790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 3 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 56.9485 - val_loss: 37.6363\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46.0574 - val_loss: 27.9619\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34.1422 - val_loss: 34.9808\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.5393 - val_loss: 24.1008\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22.7526 - val_loss: 13.7992\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19.3071 - val_loss: 14.4885\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.7203 - val_loss: 6.0370\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.2587 - val_loss: 5.8419\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4044 - val_loss: 6.1821\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.5170 - val_loss: 4.2937\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.3493 - val_loss: 7.9655\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.1872 - val_loss: 4.9594\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.1234 - val_loss: 5.9732\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2129 - val_loss: 3.2879\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.3320 - val_loss: 7.9423\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.5659 - val_loss: 3.7985\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3212 - val_loss: 5.7342\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.6305 - val_loss: 4.1084\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5831 - val_loss: 4.4476\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2444 - val_loss: 4.7481\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2714 - val_loss: 3.0773\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8266 - val_loss: 4.9509\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8596 - val_loss: 3.0769\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9561 - val_loss: 4.6728\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0784 - val_loss: 4.5164\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2286 - val_loss: 3.8389\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3430 - val_loss: 4.7355\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6389 - val_loss: 3.2365\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6826 - val_loss: 4.2091\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2996 - val_loss: 3.9197\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4467 - val_loss: 4.7640\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4434 - val_loss: 2.2658\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1809 - val_loss: 5.0496\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9097 - val_loss: 3.6661\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4387 - val_loss: 2.6088\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8428 - val_loss: 5.4525\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6540 - val_loss: 3.0476\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7012 - val_loss: 3.2840\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9918 - val_loss: 3.2772\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.7263 - val_loss: 3.1282\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6630 - val_loss: 3.6975\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5285 - val_loss: 2.5618\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8919 - val_loss: 3.0721\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9773 - val_loss: 4.6058\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5155 - val_loss: 2.2186\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9754 - val_loss: 5.6560\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5184 - val_loss: 2.3873\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0300 - val_loss: 3.7458\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9290 - val_loss: 2.2611\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4184 - val_loss: 3.4892\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc1722550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 4 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 39312.5664 - val_loss: 91.5127\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4528.5234 - val_loss: 93.0695\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26570.3594 - val_loss: 90.7983\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25665.8965 - val_loss: 91.7033\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2184.7969 - val_loss: 90.4985\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 51428.9141 - val_loss: 89.6842\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3568.1726 - val_loss: 93.6815\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 66896.1484 - val_loss: 97.5181\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 75627.9844 - val_loss: 97.1131\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 58957.6758 - val_loss: 93.5318\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36325.2383 - val_loss: 92.2015\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25373.2852 - val_loss: 95.1440\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42746.6211 - val_loss: 96.4863\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24947.5371 - val_loss: 94.5198\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20157.4141 - val_loss: 93.2855\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13886.5771 - val_loss: 94.4593\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18859.2461 - val_loss: 95.3297\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14461.3682 - val_loss: 93.6469\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34122.4609 - val_loss: 93.3599\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25780.1816 - val_loss: 95.2514\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23964.4297 - val_loss: 96.1170\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14724.4209 - val_loss: 93.9831\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20068.6465 - val_loss: 93.9059\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21622.4824 - val_loss: 94.4610\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10047.3105 - val_loss: 96.7129\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53713.0117 - val_loss: 97.5462\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46014.2812 - val_loss: 96.9596\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26712.2344 - val_loss: 95.1987\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23820.5918 - val_loss: 94.8773\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21312.8828 - val_loss: 96.0280\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1025.3420 - val_loss: 95.9301\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10612.4072 - val_loss: 96.0696\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3707.4951 - val_loss: 98.9323\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 68584.0312 - val_loss: 99.8399\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 59234.8086 - val_loss: 99.0007\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29659.5684 - val_loss: 96.9137\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11436.9883 - val_loss: 95.7526\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12889.7148 - val_loss: 96.2662\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 888.3734 - val_loss: 95.9943\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5668.7085 - val_loss: 96.7760\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15438.1152 - val_loss: 96.4429\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4188.7930 - val_loss: 95.2191\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25733.5039 - val_loss: 95.4245\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22401.3379 - val_loss: 96.4231\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10421.7148 - val_loss: 96.7429\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4779.3530 - val_loss: 96.4884\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 539.9708 - val_loss: 96.0942\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15210.8154 - val_loss: 96.2902\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7313.1128 - val_loss: 97.5263\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34402.8906 - val_loss: 98.0005\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbbf280d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 5 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 10795.9072 - val_loss: 81.1289\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 354735.8438 - val_loss: 81.4012\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 206818.2031 - val_loss: 86.9403\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 171888.3281 - val_loss: 96.3642\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38354.8242 - val_loss: 99.4427\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 50718.0469 - val_loss: 99.4900\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36417.2383 - val_loss: 95.5423\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 69782.1875 - val_loss: 94.8463\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73887.9609 - val_loss: 96.2361\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25458.6348 - val_loss: 98.1281\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11723.1562 - val_loss: 98.6846\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14158.3799 - val_loss: 97.2869\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27084.9316 - val_loss: 97.3017\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15083.7715 - val_loss: 99.5750\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42212.4336 - val_loss: 99.4607\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28753.8281 - val_loss: 98.3112\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13241.2705 - val_loss: 97.4930\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7794.3374 - val_loss: 99.5861\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55733.4688 - val_loss: 100.0379\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41441.7188 - val_loss: 98.2686\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2152.3542 - val_loss: 95.3200\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 72587.2891 - val_loss: 94.4103\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71448.4531 - val_loss: 94.9415\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25907.7656 - val_loss: 97.3047\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43201.0273 - val_loss: 99.6862\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41531.4883 - val_loss: 98.6529\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19922.5859 - val_loss: 96.2117\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54070.4805 - val_loss: 95.4200\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50769.2578 - val_loss: 97.0298\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11183.4814 - val_loss: 99.0590\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27915.1289 - val_loss: 99.1672\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29897.3418 - val_loss: 97.9661\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3295.3354 - val_loss: 96.0138\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61289.7891 - val_loss: 95.2715\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 56352.7969 - val_loss: 97.3423\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 749.8862 - val_loss: 97.7637\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2875.4268 - val_loss: 98.7744\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19474.8379 - val_loss: 98.2115\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1516.0398 - val_loss: 97.3389\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25177.4746 - val_loss: 96.9736\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18277.7852 - val_loss: 97.5265\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9308.6123 - val_loss: 100.1220\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48990.6914 - val_loss: 100.5105\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57335.2969 - val_loss: 99.6118\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36638.9180 - val_loss: 97.9573\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15737.7881 - val_loss: 97.5184\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5993.2656 - val_loss: 98.3911\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24222.4902 - val_loss: 98.9728\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18602.9609 - val_loss: 98.0627\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17424.2480 - val_loss: 97.5100\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc3455dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 6 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 90.2550 - val_loss: 78.1309\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58.6613 - val_loss: 48.9380\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52.7451 - val_loss: 36.8007\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43.8189 - val_loss: 37.9717\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34.3154 - val_loss: 29.2794\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.2084 - val_loss: 19.8104\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24.7766 - val_loss: 15.6715\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21.3378 - val_loss: 8.9321\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.2129 - val_loss: 5.7015\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18.3379 - val_loss: 4.5111\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.6141 - val_loss: 4.6671\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.9862 - val_loss: 4.9118\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.6516 - val_loss: 3.3751\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.2095 - val_loss: 3.1424\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.8917 - val_loss: 8.1443\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.1976 - val_loss: 5.5086\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.7707 - val_loss: 4.4765\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.2706 - val_loss: 3.4322\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.9553 - val_loss: 2.9054\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.2825 - val_loss: 7.5114\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.5902 - val_loss: 2.6651\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.0001 - val_loss: 7.4742\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.6698 - val_loss: 2.0513\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.1141 - val_loss: 5.2904\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.3206 - val_loss: 6.3746\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9268 - val_loss: 2.0406\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.9084 - val_loss: 5.8419\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5639 - val_loss: 4.2672\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6988 - val_loss: 4.7795\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2961 - val_loss: 4.0273\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9920 - val_loss: 4.4376\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9337 - val_loss: 4.5780\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1846 - val_loss: 4.1778\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.6354 - val_loss: 4.6843\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5267 - val_loss: 4.9433\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.0095 - val_loss: 3.4069\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1741 - val_loss: 4.8423\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6590 - val_loss: 3.8545\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8947 - val_loss: 3.4626\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5399 - val_loss: 3.9665\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8826 - val_loss: 3.5704\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8558 - val_loss: 5.5425\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6495 - val_loss: 3.3077\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5113 - val_loss: 4.1436\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7376 - val_loss: 2.1075\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8041 - val_loss: 4.1369\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6046 - val_loss: 2.6228\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9716 - val_loss: 3.6891\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.6685 - val_loss: 2.5484\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6080 - val_loss: 1.8219\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc95748b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 7 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 70143.8516 - val_loss: 114.1749\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 221221.3125 - val_loss: 117.8882\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 145897.3750 - val_loss: 108.7106\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2682.2756 - val_loss: 104.4543\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7882.1577 - val_loss: 101.3024\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64332.2969 - val_loss: 99.9744\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38688.1367 - val_loss: 105.5876\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 67670.9922 - val_loss: 107.0422\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 63851.3828 - val_loss: 104.6713\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14224.2549 - val_loss: 100.3430\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 79557.1484 - val_loss: 97.7183\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 53534.8594 - val_loss: 99.8726\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36784.1875 - val_loss: 105.9853\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 109086.3125 - val_loss: 108.6810\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 94071.7969 - val_loss: 106.4748\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45798.1016 - val_loss: 102.9612\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26620.6816 - val_loss: 100.4439\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22606.0195 - val_loss: 103.0610\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46478.8711 - val_loss: 103.8910\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35010.2148 - val_loss: 101.2176\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27588.2188 - val_loss: 100.1243\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23824.0410 - val_loss: 101.6138\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17511.9258 - val_loss: 102.0223\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4844.4839 - val_loss: 100.7260\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18701.0312 - val_loss: 100.4076\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15739.2119 - val_loss: 100.9455\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16126.1133 - val_loss: 102.0690\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14789.1729 - val_loss: 100.4272\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15005.2578 - val_loss: 100.9231\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2600.0190 - val_loss: 102.1870\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29500.1484 - val_loss: 102.4448\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20956.5547 - val_loss: 101.1129\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 525.3176 - val_loss: 101.2806\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4252.3730 - val_loss: 100.4188\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21234.6230 - val_loss: 100.3661\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9144.9023 - val_loss: 101.7712\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13570.6924 - val_loss: 101.6372\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10841.7891 - val_loss: 100.6053\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21254.0840 - val_loss: 100.1630\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7492.1733 - val_loss: 101.1197\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34466.8164 - val_loss: 102.6362\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25325.5508 - val_loss: 101.4399\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12684.5342 - val_loss: 100.4308\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1515.0532 - val_loss: 100.5704\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15170.0498 - val_loss: 100.3629\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2094.5723 - val_loss: 100.6907\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4289.7876 - val_loss: 101.2958\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17089.6855 - val_loss: 101.2279\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4730.3276 - val_loss: 99.8933\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22319.0742 - val_loss: 99.7382\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbc0753a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 8 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 66.5893 - val_loss: 55.4296\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 59.4637 - val_loss: 39.9459\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47.6209 - val_loss: 47.2944\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40.0296 - val_loss: 43.2823\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.5706 - val_loss: 24.5452\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.9571 - val_loss: 20.1821\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26.3057 - val_loss: 23.1688\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.7123 - val_loss: 10.4436\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.8789 - val_loss: 9.5405\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.9813 - val_loss: 4.8698\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.0146 - val_loss: 6.1185\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.4371 - val_loss: 3.8981\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.6086 - val_loss: 4.4964\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.6839 - val_loss: 4.5566\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.7952 - val_loss: 3.8729\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.8839 - val_loss: 3.9955\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.5946 - val_loss: 6.1390\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.4081 - val_loss: 5.7856\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.6910 - val_loss: 5.7915\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.3171 - val_loss: 4.9543\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.4134 - val_loss: 3.7851\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.9357 - val_loss: 3.4637\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.0751 - val_loss: 3.8306\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.0899 - val_loss: 3.8706\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7381 - val_loss: 3.3796\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2149 - val_loss: 2.9779\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.3738 - val_loss: 4.0539\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5812 - val_loss: 3.5499\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1305 - val_loss: 3.0354\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8620 - val_loss: 3.1932\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6237 - val_loss: 3.0761\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7773 - val_loss: 2.9056\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1739 - val_loss: 2.4539\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9939 - val_loss: 2.1989\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3593 - val_loss: 3.3419\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2702 - val_loss: 2.4561\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3328 - val_loss: 2.2698\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8011 - val_loss: 2.7689\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2413 - val_loss: 3.4960\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0442 - val_loss: 1.9932\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6003 - val_loss: 2.1905\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4123 - val_loss: 2.6289\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3111 - val_loss: 2.1617\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5730 - val_loss: 2.8873\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7285 - val_loss: 2.3828\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7762 - val_loss: 2.5104\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4950 - val_loss: 2.4053\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6498 - val_loss: 2.7637\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7123 - val_loss: 2.1941\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2716 - val_loss: 3.6882\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc8e2fe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 9 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 9563.5215 - val_loss: 94.7565\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 276297.8750 - val_loss: 92.3905\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 201160.8438 - val_loss: 97.8137\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 104272.1250 - val_loss: 103.7725\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 54407.4492 - val_loss: 106.6353\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36301.9492 - val_loss: 104.3490\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24608.4121 - val_loss: 103.6342\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19003.1895 - val_loss: 105.2367\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23312.9688 - val_loss: 105.0435\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9049.4727 - val_loss: 103.6024\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45865.0742 - val_loss: 102.6955\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33109.5703 - val_loss: 104.9512\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13967.8252 - val_loss: 104.9622\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16650.5137 - val_loss: 103.7022\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24234.1582 - val_loss: 103.3904\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9392.8838 - val_loss: 104.9663\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 41437.3516 - val_loss: 105.6884\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30461.2734 - val_loss: 104.7948\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18861.3926 - val_loss: 101.3816\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 90067.0234 - val_loss: 99.8324\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 76058.5469 - val_loss: 100.7406\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45202.2031 - val_loss: 103.3560\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23760.4043 - val_loss: 104.6905\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28759.9570 - val_loss: 104.3993\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1894.5238 - val_loss: 102.4830\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 50614.8633 - val_loss: 101.1130\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42779.9258 - val_loss: 101.9722\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12491.4141 - val_loss: 103.5595\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6925.4258 - val_loss: 103.9855\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20327.3672 - val_loss: 103.7451\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11328.6289 - val_loss: 102.0025\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38292.1328 - val_loss: 101.6488\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32813.9492 - val_loss: 102.2518\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3612.9856 - val_loss: 103.4676\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40163.8750 - val_loss: 104.8567\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36199.6836 - val_loss: 104.2011\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7312.6865 - val_loss: 102.9870\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28163.2754 - val_loss: 101.7643\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31972.7793 - val_loss: 102.3220\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12378.6992 - val_loss: 103.3888\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12983.7939 - val_loss: 103.5622\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11233.9717 - val_loss: 103.1067\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3198.9150 - val_loss: 103.0985\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1305.7699 - val_loss: 102.3586\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16238.5547 - val_loss: 102.7895\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4228.6680 - val_loss: 103.7747\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29420.6387 - val_loss: 104.0851\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22478.6738 - val_loss: 103.2054\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 622.8894 - val_loss: 101.6579\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47315.7109 - val_loss: 101.0126\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbbf284c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 10 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 151327.3125 - val_loss: 104.1126\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 69131.6484 - val_loss: 108.2868\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 142313.3281 - val_loss: 111.4962\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 97880.3516 - val_loss: 106.9913\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 97625.4766 - val_loss: 105.0847\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29650.1113 - val_loss: 108.9736\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 135242.2500 - val_loss: 111.4481\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 107915.8672 - val_loss: 108.3124\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46313.1445 - val_loss: 106.9496\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9803.1338 - val_loss: 111.0340\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 182405.2969 - val_loss: 112.7980\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 142936.9219 - val_loss: 110.2715\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40362.4414 - val_loss: 106.4280\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 74031.5703 - val_loss: 105.4906\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 97342.5000 - val_loss: 106.0894\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42940.5000 - val_loss: 109.4123\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 83286.9844 - val_loss: 110.0663\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71866.2109 - val_loss: 108.2899\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14298.2109 - val_loss: 105.3026\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 95418.4766 - val_loss: 104.6201\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 84949.8125 - val_loss: 106.0424\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3813.3989 - val_loss: 107.5322\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20875.8008 - val_loss: 106.8059\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8712.9971 - val_loss: 107.2819\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26437.7441 - val_loss: 106.9138\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6589.8027 - val_loss: 107.0781\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26677.8652 - val_loss: 107.2901\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11372.6211 - val_loss: 106.3054\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22790.3008 - val_loss: 107.4518\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29810.6973 - val_loss: 106.9860\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5738.1445 - val_loss: 106.5468\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12217.5088 - val_loss: 107.3636\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25992.5371 - val_loss: 106.8929\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34093.8711 - val_loss: 105.3447\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42790.1758 - val_loss: 106.3150\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19859.1016 - val_loss: 107.1577\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47936.6719 - val_loss: 106.0516\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3059.8943 - val_loss: 105.0804\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19460.4199 - val_loss: 105.3892\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6309.2490 - val_loss: 104.8791\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7318.3423 - val_loss: 104.7160\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17493.7090 - val_loss: 104.8957\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5871.2637 - val_loss: 103.9049\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33444.1719 - val_loss: 104.2414\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3512.7939 - val_loss: 104.2577\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20567.9141 - val_loss: 104.6166\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11496.1406 - val_loss: 104.4004\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11440.8467 - val_loss: 104.9857\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17229.4688 - val_loss: 104.7066\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12936.8623 - val_loss: 104.6445\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6e721f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 11 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 218597.9844 - val_loss: 91.0625\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 165501.8438 - val_loss: 97.4292\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 101911.4688 - val_loss: 91.4309\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 91814.7734 - val_loss: 91.0920\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38555.6836 - val_loss: 94.6588\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 129264.8125 - val_loss: 96.9906\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 78686.2109 - val_loss: 94.9072\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57796.7617 - val_loss: 91.8551\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33439.6211 - val_loss: 94.1050\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 60696.3164 - val_loss: 95.6059\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46778.5586 - val_loss: 93.4198\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40983.5742 - val_loss: 93.4595\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24062.7988 - val_loss: 94.8170\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24223.5469 - val_loss: 91.7179\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 89495.4219 - val_loss: 91.6071\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 69073.8594 - val_loss: 94.4241\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 66150.5000 - val_loss: 95.5478\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21605.1699 - val_loss: 93.4370\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35452.0117 - val_loss: 92.4491\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41363.0195 - val_loss: 93.7087\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10365.8984 - val_loss: 94.3320\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9282.2490 - val_loss: 93.9733\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16406.5273 - val_loss: 95.6124\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34424.0586 - val_loss: 95.5993\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 4813.9014 - val_loss: 94.6793\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7000.4077 - val_loss: 95.8261\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 44451.8711 - val_loss: 95.3198\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21245.2695 - val_loss: 93.4561\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41210.9336 - val_loss: 93.3709\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28167.3223 - val_loss: 94.6825\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31036.0488 - val_loss: 95.3135\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18390.7559 - val_loss: 94.6030\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2283.1497 - val_loss: 95.3751\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6895.7021 - val_loss: 94.8451\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40034.1992 - val_loss: 95.0951\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18645.8398 - val_loss: 97.3903\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 93806.4297 - val_loss: 98.1336\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 58722.9609 - val_loss: 96.7262\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14951.8174 - val_loss: 94.5344\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 61280.8750 - val_loss: 94.8129\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35569.8867 - val_loss: 96.7760\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15053.9258 - val_loss: 96.7657\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3002.7104 - val_loss: 96.5404\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12283.4834 - val_loss: 96.8310\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20530.8281 - val_loss: 95.2569\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37221.2031 - val_loss: 94.9840\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10662.7598 - val_loss: 95.9781\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 61337.6133 - val_loss: 97.4556\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 67660.4766 - val_loss: 95.6542\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14086.8125 - val_loss: 95.6059\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbd1ed430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 12 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 353605.2188 - val_loss: 89.0833\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 120581.7656 - val_loss: 99.6729\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 94381.8984 - val_loss: 97.1776\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3596.8667 - val_loss: 98.5469\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37335.0039 - val_loss: 97.7623\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39485.1523 - val_loss: 97.7654\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17439.2617 - val_loss: 100.1390\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 72175.7734 - val_loss: 98.9442\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28576.9473 - val_loss: 94.3336\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 187513.0000 - val_loss: 93.4877\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 159865.6250 - val_loss: 96.0826\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26361.2324 - val_loss: 99.8075\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 101556.0312 - val_loss: 100.4089\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 110161.2422 - val_loss: 98.2065\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32139.2930 - val_loss: 94.4344\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 130535.7656 - val_loss: 94.1908\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 122115.2266 - val_loss: 97.0800\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23123.9180 - val_loss: 99.3938\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54199.8633 - val_loss: 98.9965\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9030.7793 - val_loss: 97.3695\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30406.0566 - val_loss: 98.0760\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5351.4888 - val_loss: 97.2911\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24997.6074 - val_loss: 97.7824\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9025.7090 - val_loss: 97.4257\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8336.2236 - val_loss: 97.7385\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9591.4609 - val_loss: 97.4178\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5345.3662 - val_loss: 97.4011\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19899.1621 - val_loss: 97.5362\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9091.0967 - val_loss: 96.9453\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6743.6812 - val_loss: 97.4617\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24970.7969 - val_loss: 96.7473\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42175.3164 - val_loss: 96.4159\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26472.2246 - val_loss: 97.9800\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44922.3242 - val_loss: 97.5163\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41363.1133 - val_loss: 95.5573\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 51983.6797 - val_loss: 96.9806\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29468.1719 - val_loss: 98.4856\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49292.4453 - val_loss: 97.6763\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25352.0781 - val_loss: 95.8991\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51920.4062 - val_loss: 96.4673\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21372.0664 - val_loss: 97.7894\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4149.3643 - val_loss: 97.7256\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6294.6787 - val_loss: 96.5990\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50051.8555 - val_loss: 96.7443\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17452.9062 - val_loss: 98.2163\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33172.7070 - val_loss: 98.4089\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23942.4492 - val_loss: 97.3525\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 36811.9336 - val_loss: 96.6582\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19295.1777 - val_loss: 97.8836\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5012.3848 - val_loss: 97.4332\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbc391b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 13 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 22402.0156 - val_loss: 75.7784\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 85331.3516 - val_loss: 81.7865\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 76828.0547 - val_loss: 81.0907\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24482.5254 - val_loss: 74.9504\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 105391.3125 - val_loss: 71.6271\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 84907.4844 - val_loss: 75.0978\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 58533.4883 - val_loss: 80.8251\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41209.4258 - val_loss: 82.7797\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40123.7656 - val_loss: 82.4427\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11223.0371 - val_loss: 80.1055\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45016.9297 - val_loss: 79.5680\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 41179.4727 - val_loss: 80.6581\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20552.1152 - val_loss: 84.5914\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 52143.8047 - val_loss: 86.0976\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 54512.7344 - val_loss: 85.2876\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27596.8184 - val_loss: 83.3500\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23150.2129 - val_loss: 83.0574\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17963.5664 - val_loss: 84.7416\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13614.2197 - val_loss: 84.7842\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3810.2126 - val_loss: 83.6644\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31876.2754 - val_loss: 83.2284\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23203.8887 - val_loss: 84.7487\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9713.8848 - val_loss: 85.2476\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2301.3975 - val_loss: 84.4742\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16986.9160 - val_loss: 84.4742\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12519.4023 - val_loss: 85.8422\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11026.0156 - val_loss: 85.5864\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1477.5426 - val_loss: 84.8254\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30980.8223 - val_loss: 84.1279\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26386.0547 - val_loss: 86.5178\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35492.2891 - val_loss: 87.5442\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19109.4121 - val_loss: 86.6355\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21569.4023 - val_loss: 85.3715\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19825.2031 - val_loss: 87.0918\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9141.6875 - val_loss: 87.0001\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2402.1890 - val_loss: 86.2198\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28843.4082 - val_loss: 85.7718\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14094.2686 - val_loss: 87.2252\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13595.5508 - val_loss: 87.9932\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13757.5938 - val_loss: 87.6317\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7319.5229 - val_loss: 87.3707\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 109.7411 - val_loss: 88.4644\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33660.4102 - val_loss: 89.1556\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29968.6152 - val_loss: 87.7129\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3991.3450 - val_loss: 87.8703\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3507.2429 - val_loss: 88.2808\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18881.2852 - val_loss: 89.0846\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16474.1387 - val_loss: 88.6464\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6752.9570 - val_loss: 86.9751\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43879.1055 - val_loss: 86.4923\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc90253a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 14 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 94733.3828 - val_loss: 90.6907\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 80901.6875 - val_loss: 94.0783\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20779.5762 - val_loss: 91.6051\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34755.4180 - val_loss: 89.7278\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48858.1797 - val_loss: 91.6380\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15570.0605 - val_loss: 91.5861\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24832.8223 - val_loss: 91.4716\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2674.6355 - val_loss: 91.8754\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6085.1763 - val_loss: 92.7854\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 51153.8750 - val_loss: 93.8608\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31056.2266 - val_loss: 90.5980\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 75108.3672 - val_loss: 89.3980\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 66354.1719 - val_loss: 91.2947\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5531.4844 - val_loss: 94.0202\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27971.4434 - val_loss: 94.6795\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42855.1836 - val_loss: 93.4902\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6848.1860 - val_loss: 90.9815\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45661.7812 - val_loss: 91.0622\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43613.6250 - val_loss: 91.6606\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10423.2891 - val_loss: 93.2074\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 625.3608 - val_loss: 91.2516\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 69118.7656 - val_loss: 90.6659\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57823.3945 - val_loss: 92.3779\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4680.5029 - val_loss: 94.7797\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 59584.9414 - val_loss: 96.2364\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 53359.4141 - val_loss: 95.4803\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19691.9414 - val_loss: 92.6278\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 50036.7812 - val_loss: 91.5757\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 50919.6250 - val_loss: 92.8648\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7655.7837 - val_loss: 94.4763\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 54061.5977 - val_loss: 95.2545\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43368.0664 - val_loss: 93.9101\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15307.0889 - val_loss: 93.6733\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6507.8877 - val_loss: 95.1691\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33730.7852 - val_loss: 95.3031\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28043.0664 - val_loss: 94.1812\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18042.1133 - val_loss: 94.0197\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11488.7061 - val_loss: 95.5356\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43024.5508 - val_loss: 95.9489\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33717.5742 - val_loss: 94.9663\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10909.9600 - val_loss: 93.0401\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 60986.1992 - val_loss: 92.4024\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 58608.7188 - val_loss: 93.6362\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19784.9727 - val_loss: 94.9891\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30974.2168 - val_loss: 95.8044\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21120.6699 - val_loss: 94.7543\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8795.7314 - val_loss: 94.6070\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6750.6079 - val_loss: 94.9609\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1425.1461 - val_loss: 95.1800\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7566.4736 - val_loss: 94.5625\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbcb6dc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 15 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 158127.1719 - val_loss: 97.3676\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 228300.8438 - val_loss: 95.2801\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 72551.9453 - val_loss: 91.6827\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 104155.5234 - val_loss: 89.2204\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 64730.6836 - val_loss: 91.5388\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47276.0508 - val_loss: 91.9365\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16997.0234 - val_loss: 90.5365\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14454.2266 - val_loss: 91.6302\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 75622.1562 - val_loss: 92.0531\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15698.2744 - val_loss: 90.5866\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12784.9746 - val_loss: 91.3554\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27760.3984 - val_loss: 91.7093\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19858.6719 - val_loss: 90.6041\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41276.6641 - val_loss: 90.4595\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23332.5391 - val_loss: 91.7435\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55516.9414 - val_loss: 92.9089\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52577.1914 - val_loss: 90.9611\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49164.3828 - val_loss: 90.2458\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30213.4316 - val_loss: 92.4823\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56718.2227 - val_loss: 92.6242\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42456.1680 - val_loss: 91.1287\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23206.4746 - val_loss: 91.5507\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4487.2690 - val_loss: 90.8014\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 71212.4219 - val_loss: 90.5793\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28020.4219 - val_loss: 91.7858\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13900.1748 - val_loss: 90.8761\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17380.9883 - val_loss: 92.6159\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 92269.2812 - val_loss: 92.5170\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 59079.5859 - val_loss: 91.5472\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42251.3867 - val_loss: 89.5945\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 87934.3594 - val_loss: 90.0082\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42470.0039 - val_loss: 91.6880\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14635.6348 - val_loss: 92.0567\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11236.7393 - val_loss: 90.6651\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53866.1758 - val_loss: 91.1361\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18986.3301 - val_loss: 92.0163\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12684.4326 - val_loss: 92.0098\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13012.2617 - val_loss: 92.8447\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11187.2842 - val_loss: 92.6050\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6489.8296 - val_loss: 92.9197\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7554.9854 - val_loss: 93.2626\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11292.1572 - val_loss: 93.5765\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33476.9531 - val_loss: 94.1701\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17345.2480 - val_loss: 93.1621\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37118.1289 - val_loss: 93.1639\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20660.8320 - val_loss: 94.0831\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6930.2358 - val_loss: 94.2658\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6690.6602 - val_loss: 93.7482\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31236.1113 - val_loss: 94.5493\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2810.2085 - val_loss: 95.0988\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc34d9b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 16 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 79.4679 - val_loss: 63.3638\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49.4668 - val_loss: 30.7909\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.1838 - val_loss: 35.2367\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.9273 - val_loss: 43.2935\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.3991 - val_loss: 35.4234\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.7118 - val_loss: 17.5086\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24.1251 - val_loss: 17.1333\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.5520 - val_loss: 17.3094\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.3785 - val_loss: 5.6494\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.8112 - val_loss: 7.4948\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.7545 - val_loss: 2.5858\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4439 - val_loss: 5.6581\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.2205 - val_loss: 2.2368\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.4793 - val_loss: 7.1796\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.8221 - val_loss: 2.4222\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.4798 - val_loss: 3.3905\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.2130 - val_loss: 2.2942\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.3408 - val_loss: 2.6950\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5936 - val_loss: 2.3310\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.9370 - val_loss: 2.0287\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.6569 - val_loss: 2.2951\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.0149 - val_loss: 2.5775\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3067 - val_loss: 2.4446\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6515 - val_loss: 2.1554\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3905 - val_loss: 2.1982\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0868 - val_loss: 1.8998\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1277 - val_loss: 2.6125\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.3401 - val_loss: 2.1167\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7294 - val_loss: 1.7179\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3312 - val_loss: 1.7122\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2499 - val_loss: 2.2608\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0103 - val_loss: 1.7463\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7619 - val_loss: 2.4782\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6210 - val_loss: 1.7647\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8937 - val_loss: 5.1879\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6197 - val_loss: 3.1903\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6654 - val_loss: 6.6329\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3171 - val_loss: 3.1088\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4382 - val_loss: 2.3840\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0211 - val_loss: 2.1650\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7208 - val_loss: 3.5575\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.5745 - val_loss: 1.8810\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1234 - val_loss: 1.7397\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.9574 - val_loss: 2.0978\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9461 - val_loss: 1.9071\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0690 - val_loss: 2.9323\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6905 - val_loss: 1.7861\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2967 - val_loss: 2.1996\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2244 - val_loss: 1.7962\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.1627 - val_loss: 1.9459\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6374dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 17 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 48.7789 - val_loss: 22.7145\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24.5665 - val_loss: 12.1784\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18.7615 - val_loss: 27.9464\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18.7002 - val_loss: 25.6591\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.9038 - val_loss: 13.6631\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.7719 - val_loss: 14.9834\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.9258 - val_loss: 15.4538\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.3227 - val_loss: 9.4404\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8731 - val_loss: 8.2907\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3571 - val_loss: 5.4343\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7459 - val_loss: 1.6795\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8117 - val_loss: 3.6702\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9440 - val_loss: 2.1687\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4560 - val_loss: 2.5901\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0712 - val_loss: 1.8198\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.7916 - val_loss: 2.1619\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3596 - val_loss: 2.8541\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.4735 - val_loss: 2.5325\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3638 - val_loss: 2.7250\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.2220 - val_loss: 2.8650\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.1630 - val_loss: 3.1650\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5422 - val_loss: 2.4870\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1412 - val_loss: 2.8264\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0353 - val_loss: 3.8675\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6497 - val_loss: 3.5096\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9294 - val_loss: 2.6915\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3839 - val_loss: 2.3958\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3573 - val_loss: 2.8865\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2963 - val_loss: 3.2470\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.9542 - val_loss: 2.5255\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5734 - val_loss: 2.5473\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.4262 - val_loss: 2.7616\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.9423 - val_loss: 2.3383\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.7854 - val_loss: 2.5225\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.6593 - val_loss: 2.6373\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.5656 - val_loss: 2.4992\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.4851 - val_loss: 2.5500\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.5292 - val_loss: 2.6442\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.4079 - val_loss: 2.4160\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.8646 - val_loss: 2.2818\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.5292 - val_loss: 2.4599\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3258 - val_loss: 2.8382\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.4191 - val_loss: 2.5492\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.4808 - val_loss: 2.3535\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.1455 - val_loss: 2.5806\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0375 - val_loss: 2.5293\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.9774 - val_loss: 2.2447\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8806 - val_loss: 2.5186\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.0557 - val_loss: 2.5640\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.0753 - val_loss: 2.0595\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbbf288b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 18 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 62922.1328 - val_loss: 107.3051\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 208232.7344 - val_loss: 111.8505\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 119170.2500 - val_loss: 105.3605\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 58950.6367 - val_loss: 96.9785\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 170017.2344 - val_loss: 93.3054\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 159187.2500 - val_loss: 97.2294\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 70394.2734 - val_loss: 101.1921\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44748.2305 - val_loss: 102.0703\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40553.7383 - val_loss: 100.0969\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12741.7744 - val_loss: 100.4054\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5425.4473 - val_loss: 99.7788\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29732.1016 - val_loss: 99.6232\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19269.8262 - val_loss: 102.0521\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44868.2812 - val_loss: 102.1833\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37787.0508 - val_loss: 100.5081\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16446.0156 - val_loss: 100.5176\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5666.3989 - val_loss: 102.5059\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61207.2188 - val_loss: 103.0231\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45187.5156 - val_loss: 101.8944\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 159.7493 - val_loss: 101.1280\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8826.9404 - val_loss: 100.7893\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21180.1875 - val_loss: 100.4890\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9731.8438 - val_loss: 102.1953\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56077.8008 - val_loss: 102.9935\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38919.3867 - val_loss: 101.2527\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20960.5781 - val_loss: 100.3964\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18321.1719 - val_loss: 101.8468\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37349.9648 - val_loss: 102.3022\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24062.2012 - val_loss: 100.3267\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30503.1484 - val_loss: 99.9860\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31167.2754 - val_loss: 100.5224\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5484.8999 - val_loss: 102.2245\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27977.7871 - val_loss: 102.4663\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37093.5508 - val_loss: 102.2426\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 602.7401 - val_loss: 101.3410\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3795.3679 - val_loss: 100.8292\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12026.9854 - val_loss: 101.4355\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9856.5449 - val_loss: 101.0611\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8773.9297 - val_loss: 101.3771\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17330.3965 - val_loss: 101.5809\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1835.2812 - val_loss: 101.3251\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6131.4082 - val_loss: 100.8315\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21520.5938 - val_loss: 100.6711\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5665.9102 - val_loss: 101.6376\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19529.9512 - val_loss: 101.8874\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18577.1621 - val_loss: 100.9875\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5771.1714 - val_loss: 101.3271\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8249.3877 - val_loss: 101.1917\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7551.8511 - val_loss: 100.9366\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6921.1309 - val_loss: 101.8068\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc7f35820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 19 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 113683.6875 - val_loss: 98.4259\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23956.1816 - val_loss: 98.9566\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25512.1465 - val_loss: 99.1710\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3349.6748 - val_loss: 108.3983\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 137658.7031 - val_loss: 109.0099\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 144695.5625 - val_loss: 107.7159\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 105762.1484 - val_loss: 102.6712\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27917.5293 - val_loss: 96.4622\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 123343.2891 - val_loss: 94.2459\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 110967.5625 - val_loss: 96.3597\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49678.5742 - val_loss: 99.1778\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19106.6816 - val_loss: 103.7763\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 71334.8906 - val_loss: 104.2432\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 83904.5391 - val_loss: 103.5066\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 59057.3672 - val_loss: 100.2869\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17166.6172 - val_loss: 99.5162\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9169.6973 - val_loss: 100.7056\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25563.2461 - val_loss: 101.1829\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17475.5098 - val_loss: 99.3254\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24055.1719 - val_loss: 99.4527\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14752.2568 - val_loss: 101.5332\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37602.7188 - val_loss: 101.6267\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23555.4941 - val_loss: 100.0147\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3719.4700 - val_loss: 100.1318\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 193.8165 - val_loss: 101.2603\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42897.8242 - val_loss: 101.9507\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25052.9219 - val_loss: 99.6868\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17942.8223 - val_loss: 99.1194\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20104.7578 - val_loss: 100.0307\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9989.2920 - val_loss: 100.0832\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6974.1240 - val_loss: 100.0811\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27500.2715 - val_loss: 101.0939\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22587.0098 - val_loss: 98.7473\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43750.2578 - val_loss: 98.0212\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34493.5625 - val_loss: 99.0044\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18491.1133 - val_loss: 101.6917\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53257.2188 - val_loss: 102.3541\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 51903.3359 - val_loss: 100.9215\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11001.6914 - val_loss: 99.4822\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15444.9277 - val_loss: 99.0196\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16868.1055 - val_loss: 100.2066\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18947.7871 - val_loss: 100.3278\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11687.0566 - val_loss: 98.4957\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27458.8047 - val_loss: 98.6380\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22344.1426 - val_loss: 99.1118\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13795.6289 - val_loss: 100.2107\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 602.9258 - val_loss: 99.2776\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 41062.8242 - val_loss: 97.9292\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33175.0352 - val_loss: 98.8244\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2275.0288 - val_loss: 100.4659\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfcdd81dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 20 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 29032.5293 - val_loss: 84.1626\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 107096.8359 - val_loss: 92.3340\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 102118.3125 - val_loss: 87.7191\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 843.7681 - val_loss: 82.3818\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 77319.1484 - val_loss: 81.9331\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 72732.8125 - val_loss: 84.3056\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26682.4297 - val_loss: 89.9424\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 77647.5625 - val_loss: 93.3572\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56773.9023 - val_loss: 91.1507\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9142.2266 - val_loss: 89.3114\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1877.3999 - val_loss: 88.7787\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23173.8711 - val_loss: 89.1806\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9942.0078 - val_loss: 89.9841\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12970.8877 - val_loss: 89.6793\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5171.2642 - val_loss: 92.4652\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46271.5391 - val_loss: 92.3531\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30005.0781 - val_loss: 90.9916\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12303.0439 - val_loss: 90.0475\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3070.9478 - val_loss: 91.9493\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32727.5293 - val_loss: 92.1064\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23128.1289 - val_loss: 90.9806\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2478.1521 - val_loss: 90.9215\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3316.6353 - val_loss: 89.2716\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38587.8906 - val_loss: 89.2178\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20279.6582 - val_loss: 91.5347\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11747.4248 - val_loss: 91.6897\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12868.1074 - val_loss: 89.9740\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24563.0352 - val_loss: 90.5063\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4287.0464 - val_loss: 91.9377\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14593.2500 - val_loss: 91.9877\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14470.5029 - val_loss: 90.3031\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26987.6777 - val_loss: 90.4687\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10118.4150 - val_loss: 92.2830\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31788.8086 - val_loss: 92.8462\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24515.2773 - val_loss: 91.5713\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5415.5225 - val_loss: 91.6316\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4662.1343 - val_loss: 91.1973\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18116.3027 - val_loss: 91.1503\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9562.1328 - val_loss: 93.2085\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30133.7109 - val_loss: 92.9269\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21368.8145 - val_loss: 91.7914\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20682.4941 - val_loss: 91.1098\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2885.3708 - val_loss: 91.7416\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17895.7031 - val_loss: 91.3436\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3650.6130 - val_loss: 92.3241\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25552.8340 - val_loss: 93.3979\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29955.4766 - val_loss: 92.9646\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18075.5566 - val_loss: 90.7131\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29717.6641 - val_loss: 90.7334\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30751.4336 - val_loss: 91.6016\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6234670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 21 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 85.3820 - val_loss: 70.6366\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.9038 - val_loss: 33.4920\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.6650 - val_loss: 31.5963\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.5323 - val_loss: 37.5336\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.2391 - val_loss: 26.4034\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.6564 - val_loss: 11.9008\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21.3096 - val_loss: 17.7798\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.5395 - val_loss: 6.5161\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.8469 - val_loss: 8.6683\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.1919 - val_loss: 7.7970\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.3411 - val_loss: 3.5727\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.0497 - val_loss: 7.8926\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.2425 - val_loss: 2.7525\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.2407 - val_loss: 5.5089\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.8710 - val_loss: 4.0621\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8109 - val_loss: 3.2022\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.4439 - val_loss: 3.1242\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6391 - val_loss: 3.4990\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7883 - val_loss: 2.6594\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2606 - val_loss: 3.6922\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9644 - val_loss: 2.2927\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9838 - val_loss: 2.6974\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4706 - val_loss: 3.2008\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7296 - val_loss: 2.1569\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4684 - val_loss: 3.0633\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0560 - val_loss: 2.1644\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6366 - val_loss: 4.7339\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0948 - val_loss: 2.9595\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8051 - val_loss: 4.3155\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3275 - val_loss: 2.2110\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4996 - val_loss: 2.2664\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8559 - val_loss: 3.0929\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8763 - val_loss: 2.2837\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1725 - val_loss: 2.6171\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2832 - val_loss: 2.2360\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4571 - val_loss: 3.4443\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5601 - val_loss: 2.6893\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2360 - val_loss: 3.5947\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3540 - val_loss: 2.3255\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7113 - val_loss: 2.3697\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8885 - val_loss: 3.2636\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9003 - val_loss: 3.4514\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3216 - val_loss: 5.7462\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6291 - val_loss: 2.5798\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3733 - val_loss: 2.2178\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2375 - val_loss: 4.2994\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3057 - val_loss: 3.0512\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5716 - val_loss: 3.1023\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5967 - val_loss: 2.1477\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2115 - val_loss: 2.2341\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc772c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 22 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 16279.2686 - val_loss: 70.4636\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 194668.4844 - val_loss: 75.2279\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 93544.0547 - val_loss: 78.9680\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 65100.3750 - val_loss: 88.7409\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 87728.2188 - val_loss: 90.6786\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 113799.3438 - val_loss: 90.4917\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 61081.8633 - val_loss: 88.1784\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9954.1494 - val_loss: 85.6675\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - -0s -5230us/step - loss: 14908.4883 - val_loss: 87.4384\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33540.8438 - val_loss: 87.8601\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22340.2227 - val_loss: 84.9154\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46215.8828 - val_loss: 84.9770\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33115.5742 - val_loss: 86.0145\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3941.1995 - val_loss: 87.3631\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5605.1084 - val_loss: 85.9221\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36069.8750 - val_loss: 86.0506\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20585.1699 - val_loss: 88.3779\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41986.7383 - val_loss: 89.2251\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35671.4492 - val_loss: 86.9824\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18118.0332 - val_loss: 87.2013\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2909.6943 - val_loss: 88.2030\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 40201.6562 - val_loss: 89.7869\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38928.7773 - val_loss: 88.6753\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1558.9558 - val_loss: 88.2460\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11374.8057 - val_loss: 87.8024\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4395.6865 - val_loss: 88.6656\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11937.2051 - val_loss: 87.5129\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15300.4404 - val_loss: 88.2595\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5490.0718 - val_loss: 87.5764\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23848.1504 - val_loss: 87.4552\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11337.4482 - val_loss: 88.5783\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 788.3524 - val_loss: 86.2391\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41648.6289 - val_loss: 86.3012\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42377.0312 - val_loss: 87.7323\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1215.4652 - val_loss: 88.3348\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17260.4668 - val_loss: 88.1626\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8494.7275 - val_loss: 89.8709\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28637.2109 - val_loss: 89.8877\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19086.1309 - val_loss: 88.6975\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20131.4199 - val_loss: 88.1987\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14781.4307 - val_loss: 90.1774\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42893.2734 - val_loss: 90.8966\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31812.5332 - val_loss: 88.8042\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28578.8496 - val_loss: 88.0214\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22157.2031 - val_loss: 88.7585\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12588.2988 - val_loss: 91.8738\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 49197.1133 - val_loss: 92.4347\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 60788.3945 - val_loss: 91.9712\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46342.5117 - val_loss: 90.1502\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5459.7070 - val_loss: 87.9449\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc3455af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 23 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 64.9732 - val_loss: 43.5130\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.0303 - val_loss: 9.4411\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26.7811 - val_loss: 25.0856\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.5899 - val_loss: 30.0485\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.0817 - val_loss: 20.3124\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.5778 - val_loss: 13.4354\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.9902 - val_loss: 13.7197\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.2574 - val_loss: 6.5652\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.1792 - val_loss: 5.9786\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.1472 - val_loss: 2.6628\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.6570 - val_loss: 5.6702\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.3473 - val_loss: 4.7472\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.9188 - val_loss: 5.3326\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7204 - val_loss: 6.3744\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4861 - val_loss: 3.7363\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0871 - val_loss: 4.6768\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2168 - val_loss: 2.9947\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8731 - val_loss: 4.7121\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6128 - val_loss: 3.2509\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5403 - val_loss: 3.7313\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2544 - val_loss: 4.0958\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1437 - val_loss: 3.3697\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0545 - val_loss: 4.3247\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0279 - val_loss: 3.7779\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7837 - val_loss: 3.4121\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6900 - val_loss: 3.1156\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6155 - val_loss: 4.7076\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7697 - val_loss: 2.7762\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4905 - val_loss: 2.8862\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4762 - val_loss: 4.0739\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.2226 - val_loss: 2.1020\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3324 - val_loss: 4.1511\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.7697 - val_loss: 1.8096\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1489 - val_loss: 5.4201\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9888 - val_loss: 2.2904\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3138 - val_loss: 4.6397\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7814 - val_loss: 1.7367\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6194 - val_loss: 4.2870\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5937 - val_loss: 3.1643\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4942 - val_loss: 1.6874\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5355 - val_loss: 3.0641\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1033 - val_loss: 2.2640\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9505 - val_loss: 2.5878\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7327 - val_loss: 2.8158\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6792 - val_loss: 2.0384\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6142 - val_loss: 2.9824\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4403 - val_loss: 1.7488\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5320 - val_loss: 4.3392\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8340 - val_loss: 1.7542\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4683 - val_loss: 2.5286\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbc085ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 24 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 4684140.0000 - val_loss: 97.6221\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3870911.2500 - val_loss: 96.7048\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3372064.0000 - val_loss: 96.2941\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2068375.6250 - val_loss: 95.5294\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2195068.0000 - val_loss: 94.7331\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1520084.0000 - val_loss: 93.9509\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1301265.2500 - val_loss: 93.0661\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1219533.2500 - val_loss: 92.3358\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1176307.6250 - val_loss: 91.4134\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1261311.0000 - val_loss: 90.7098\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1508507.1250 - val_loss: 89.9513\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1039169.8750 - val_loss: 89.1810\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 369736.3750 - val_loss: 88.6128\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 526096.6875 - val_loss: 87.8106\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 577257.8125 - val_loss: 87.0218\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 160212.6250 - val_loss: 86.4360\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 404739.5938 - val_loss: 85.5455\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 582855.5000 - val_loss: 84.8449\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 346000.1250 - val_loss: 84.0667\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 633091.1250 - val_loss: 83.3550\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 221414.6250 - val_loss: 82.7212\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 149229.6250 - val_loss: 82.0296\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 189528.4688 - val_loss: 81.2544\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 177338.3594 - val_loss: 80.5905\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 155680.2812 - val_loss: 79.8579\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 139846.6406 - val_loss: 79.0357\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 402409.2188 - val_loss: 78.3926\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 543432.8125 - val_loss: 77.9230\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 365867.7188 - val_loss: 77.3238\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 572673.2500 - val_loss: 76.7343\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 218662.2969 - val_loss: 76.1655\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 151786.4844 - val_loss: 75.6066\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 166832.4844 - val_loss: 75.1359\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 173589.3750 - val_loss: 74.4589\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 139080.1094 - val_loss: 73.7918\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 552153.8750 - val_loss: 73.2758\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 457910.0938 - val_loss: 72.8450\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 482871.6250 - val_loss: 72.4716\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 368486.5312 - val_loss: 72.1462\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 509150.9375 - val_loss: 71.8450\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 426291.0625 - val_loss: 71.5898\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 382067.8438 - val_loss: 71.2344\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 126103.1484 - val_loss: 70.9287\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 331049.0938 - val_loss: 70.5324\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80711.2500 - val_loss: 70.1457\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 228415.3906 - val_loss: 69.5709\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 451674.9062 - val_loss: 69.2376\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 386670.0625 - val_loss: 69.0263\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 111632.7891 - val_loss: 68.6694\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 122265.0000 - val_loss: 68.3481\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc1722af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 25 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 143021.5000 - val_loss: 99.9134\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 97145.9531 - val_loss: 111.8813\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 161997.5781 - val_loss: 115.3845\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 140962.0625 - val_loss: 113.9808\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 74187.4766 - val_loss: 109.6525\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39738.3828 - val_loss: 106.6225\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25698.9316 - val_loss: 108.2756\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30640.4219 - val_loss: 108.6995\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20602.3906 - val_loss: 107.7691\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22141.0566 - val_loss: 107.0843\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11562.5654 - val_loss: 108.2143\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33156.2617 - val_loss: 108.4548\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20372.9941 - val_loss: 107.7595\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31586.7969 - val_loss: 106.4901\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27568.3184 - val_loss: 108.0848\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 44782.7891 - val_loss: 108.6324\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38542.2656 - val_loss: 106.6557\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37717.0742 - val_loss: 105.9917\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33709.8867 - val_loss: 107.2470\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10071.8604 - val_loss: 107.0816\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1110.2588 - val_loss: 105.7559\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 51362.4688 - val_loss: 105.4499\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36546.5977 - val_loss: 106.3117\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10661.8965 - val_loss: 108.2226\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56011.6055 - val_loss: 108.8020\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56489.3164 - val_loss: 107.9055\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16111.3877 - val_loss: 106.8956\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3881.4753 - val_loss: 104.3798\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 97353.2266 - val_loss: 103.3396\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 99691.2344 - val_loss: 103.5423\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 63716.3750 - val_loss: 104.8465\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38099.3477 - val_loss: 107.1223\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19654.0918 - val_loss: 107.7279\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46513.1562 - val_loss: 107.7004\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36060.1289 - val_loss: 106.5911\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1288.2417 - val_loss: 105.1917\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48431.0508 - val_loss: 104.7317\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 48179.9531 - val_loss: 105.0377\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33027.1094 - val_loss: 106.1899\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6062.8218 - val_loss: 106.3755\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6905.9722 - val_loss: 106.1382\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17669.5469 - val_loss: 105.6067\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14333.7334 - val_loss: 105.8829\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16383.5771 - val_loss: 106.5063\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7233.5073 - val_loss: 105.8530\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6219.9990 - val_loss: 105.7764\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8168.3496 - val_loss: 106.2933\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18101.9961 - val_loss: 106.3873\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10395.6094 - val_loss: 105.5018\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14813.1533 - val_loss: 105.5355\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc3455a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 26 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 73070.3984 - val_loss: 89.3195\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 192002.9062 - val_loss: 84.0842\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 146674.7344 - val_loss: 93.3934\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23119.0684 - val_loss: 97.5772\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16677.9922 - val_loss: 93.9426\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 59999.6719 - val_loss: 93.8034\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49253.5195 - val_loss: 95.5243\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3063.6270 - val_loss: 96.2899\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4377.8662 - val_loss: 97.6589\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21731.9316 - val_loss: 96.4224\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13245.3965 - val_loss: 96.3248\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6209.4297 - val_loss: 96.6131\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 444.8568 - val_loss: 95.8083\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42997.6992 - val_loss: 94.2382\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39837.7422 - val_loss: 95.6903\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 595.6171 - val_loss: 98.4963\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38685.3242 - val_loss: 98.8398\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46930.6250 - val_loss: 97.7768\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19484.9629 - val_loss: 94.9705\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27514.0059 - val_loss: 94.8714\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29745.9512 - val_loss: 95.9907\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2101.9407 - val_loss: 98.7012\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43891.1133 - val_loss: 98.8615\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47167.5742 - val_loss: 98.4188\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36785.0234 - val_loss: 94.9557\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 58961.3242 - val_loss: 93.7044\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56890.0312 - val_loss: 94.8815\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35879.3711 - val_loss: 97.5202\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15518.4473 - val_loss: 97.6662\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16761.5000 - val_loss: 96.4147\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18259.4355 - val_loss: 96.5479\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8124.9673 - val_loss: 98.3205\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48791.3438 - val_loss: 98.9309\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30408.4180 - val_loss: 97.4398\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4432.8320 - val_loss: 96.7634\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4245.1011 - val_loss: 98.0688\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29318.6875 - val_loss: 98.0493\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13989.8223 - val_loss: 97.1181\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13408.7266 - val_loss: 96.7076\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10019.4404 - val_loss: 97.7746\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13340.8252 - val_loss: 97.4839\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3159.9978 - val_loss: 96.9545\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20500.8066 - val_loss: 96.2750\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21953.9473 - val_loss: 96.6039\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5064.6270 - val_loss: 97.4026\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3534.8298 - val_loss: 96.2422\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33719.2227 - val_loss: 96.0605\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25335.6094 - val_loss: 97.4303\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7726.0903 - val_loss: 97.5424\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4208.2461 - val_loss: 96.4306\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfcbca0dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 27 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 125629.8984 - val_loss: 97.3026\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6644.7803 - val_loss: 95.2979\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23622.8613 - val_loss: 97.9410\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 63745.6562 - val_loss: 98.9843\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37394.0898 - val_loss: 93.8098\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56259.3945 - val_loss: 92.7826\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57833.8867 - val_loss: 93.7686\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36313.5898 - val_loss: 97.7650\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43424.5352 - val_loss: 98.1011\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46023.6406 - val_loss: 97.0628\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 496.1211 - val_loss: 94.9377\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39460.6484 - val_loss: 94.3388\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 42886.7227 - val_loss: 95.9301\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1215.7955 - val_loss: 98.3900\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 55861.7500 - val_loss: 99.2216\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 52190.6758 - val_loss: 97.3160\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3872.2327 - val_loss: 97.0219\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5249.0688 - val_loss: 96.0850\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24773.3008 - val_loss: 96.0791\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1577.5863 - val_loss: 96.7047\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5015.7681 - val_loss: 97.5624\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20697.2246 - val_loss: 97.2869\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8577.7227 - val_loss: 95.3609\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34206.4961 - val_loss: 95.7597\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24342.6582 - val_loss: 97.2443\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19080.0527 - val_loss: 97.4163\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10221.4766 - val_loss: 95.6399\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37433.0078 - val_loss: 95.8839\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26823.5742 - val_loss: 97.5589\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22504.1250 - val_loss: 98.0645\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7927.8330 - val_loss: 96.8572\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25011.4414 - val_loss: 96.3302\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18565.2656 - val_loss: 97.1336\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3737.8354 - val_loss: 97.2259\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2475.9094 - val_loss: 98.1641\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31564.6504 - val_loss: 98.3315\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11097.1270 - val_loss: 97.3403\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 818.0157 - val_loss: 96.7775\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16613.8926 - val_loss: 97.5006\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4989.8740 - val_loss: 97.0991\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17319.0371 - val_loss: 97.0652\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8830.3945 - val_loss: 97.7298\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5136.5059 - val_loss: 96.2714\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34090.5312 - val_loss: 96.4452\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22841.0332 - val_loss: 97.5409\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1267.9242 - val_loss: 99.7757\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49866.6133 - val_loss: 99.8917\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 52063.2031 - val_loss: 99.0405\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26714.0430 - val_loss: 97.5088\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19100.0273 - val_loss: 97.1500\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc1722b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 28 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 243335.3906 - val_loss: 87.3133\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 122933.7344 - val_loss: 99.6400\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25684.7695 - val_loss: 102.0243\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42699.0117 - val_loss: 99.5763\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12856.0654 - val_loss: 99.3363\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10348.4902 - val_loss: 97.6445\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40191.4492 - val_loss: 97.0954\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15667.4180 - val_loss: 102.3679\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85110.5000 - val_loss: 103.8781\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 81505.2266 - val_loss: 102.7884\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30577.6836 - val_loss: 98.2286\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37136.0508 - val_loss: 95.8253\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48313.3828 - val_loss: 96.3095\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32141.1211 - val_loss: 99.9549\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33441.0156 - val_loss: 99.8410\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33501.3750 - val_loss: 97.6234\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13601.0088 - val_loss: 97.7017\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10601.3232 - val_loss: 97.7948\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7616.5552 - val_loss: 97.4883\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4051.8142 - val_loss: 99.6758\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39808.0742 - val_loss: 99.2548\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22238.7070 - val_loss: 97.3442\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33281.8945 - val_loss: 96.1705\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21286.7637 - val_loss: 99.0846\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 24886.1230 - val_loss: 99.1851\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27243.4121 - val_loss: 98.3754\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5550.4868 - val_loss: 95.3611\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 42191.0156 - val_loss: 95.1138\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47637.8867 - val_loss: 95.7907\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33313.8867 - val_loss: 98.8527\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38774.9883 - val_loss: 99.5116\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32530.5684 - val_loss: 98.7802\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21963.6387 - val_loss: 95.0985\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 80338.2891 - val_loss: 93.4559\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73730.5547 - val_loss: 95.3702\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 27884.6113 - val_loss: 97.6389\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27179.6406 - val_loss: 98.7931\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25920.7598 - val_loss: 97.6180\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12966.6104 - val_loss: 97.1338\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7398.0059 - val_loss: 99.4171\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 61706.7578 - val_loss: 100.3444\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53915.6719 - val_loss: 98.5689\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15349.3438 - val_loss: 96.3399\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38367.4766 - val_loss: 95.6302\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38600.0312 - val_loss: 96.1511\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11399.8779 - val_loss: 97.4344\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 775.7590 - val_loss: 100.4004\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 70373.9609 - val_loss: 101.2056\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82009.6094 - val_loss: 100.9908\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 73180.9219 - val_loss: 99.2270\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbc136ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 29 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 87825.1641 - val_loss: 102.6805\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 174265.6562 - val_loss: 107.9844\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 87463.7500 - val_loss: 102.6234\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11934.4512 - val_loss: 98.1302\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23125.4785 - val_loss: 98.7830\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2670.1768 - val_loss: 102.9716\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 107283.4688 - val_loss: 104.3008\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 100085.2891 - val_loss: 101.6509\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 44894.6094 - val_loss: 98.0803\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26508.1758 - val_loss: 98.2333\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26377.5996 - val_loss: 100.4291\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32305.4043 - val_loss: 101.0634\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23586.4297 - val_loss: 97.5059\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 53224.3438 - val_loss: 97.0570\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51608.6953 - val_loss: 98.3353\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10132.6924 - val_loss: 100.5546\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25836.8418 - val_loss: 101.2950\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31081.4570 - val_loss: 100.8738\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12397.5977 - val_loss: 99.4530\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7969.7993 - val_loss: 101.8321\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39891.3086 - val_loss: 101.6695\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35840.1367 - val_loss: 100.3015\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6079.9956 - val_loss: 99.9466\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9141.8389 - val_loss: 99.8540\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12703.8633 - val_loss: 99.6867\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2338.1882 - val_loss: 99.4075\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13600.6475 - val_loss: 99.9834\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1682.7770 - val_loss: 99.0843\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21983.2871 - val_loss: 99.5327\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7771.3618 - val_loss: 101.7670\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38065.0391 - val_loss: 101.6153\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33448.6211 - val_loss: 100.8541\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2250.8674 - val_loss: 98.9708\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20006.0469 - val_loss: 98.5330\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30358.0234 - val_loss: 99.4593\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 595.4372 - val_loss: 99.5882\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10919.1143 - val_loss: 100.0776\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2720.3674 - val_loss: 99.2178\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20199.5566 - val_loss: 99.6143\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3573.2229 - val_loss: 101.4494\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49024.8281 - val_loss: 102.1196\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41601.9883 - val_loss: 100.9023\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19378.3203 - val_loss: 98.4564\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31990.1152 - val_loss: 98.3161\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35323.3320 - val_loss: 99.2840\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7009.0815 - val_loss: 100.8505\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37512.0000 - val_loss: 101.6177\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33965.5117 - val_loss: 100.4281\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4860.9692 - val_loss: 98.5799\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36958.6758 - val_loss: 98.2784\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6301f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 30 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 64095.0508 - val_loss: 80.2292\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24831.0645 - val_loss: 84.4297\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32404.5469 - val_loss: 80.9295\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28308.7207 - val_loss: 83.0255\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1756.5676 - val_loss: 88.1309\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 107162.4922 - val_loss: 90.0215\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 58706.8867 - val_loss: 86.5747\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1452.3656 - val_loss: 83.7101\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19714.0879 - val_loss: 84.5541\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2564.7683 - val_loss: 89.3926\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 88447.7422 - val_loss: 90.5070\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 74886.3828 - val_loss: 89.5050\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24719.7969 - val_loss: 85.4297\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 56468.3477 - val_loss: 83.0067\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56942.1719 - val_loss: 85.5559\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17776.3496 - val_loss: 89.0085\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46671.4805 - val_loss: 89.3070\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39004.8086 - val_loss: 87.5118\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1052.5475 - val_loss: 87.8461\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14489.1895 - val_loss: 87.4687\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14773.7266 - val_loss: 87.1380\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3724.0806 - val_loss: 87.1365\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16484.6309 - val_loss: 87.4107\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5578.3882 - val_loss: 87.3636\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5639.9375 - val_loss: 88.2382\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13061.7861 - val_loss: 87.5204\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17541.2773 - val_loss: 87.3569\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4518.5996 - val_loss: 89.8643\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 61240.6641 - val_loss: 91.0732\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 50319.8789 - val_loss: 88.6621\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7892.9941 - val_loss: 85.2903\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 65360.5977 - val_loss: 84.8577\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 67071.6484 - val_loss: 86.3892\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37213.5898 - val_loss: 88.9197\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2099.0840 - val_loss: 89.1216\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3654.0071 - val_loss: 88.2583\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24276.7598 - val_loss: 88.2527\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8962.9697 - val_loss: 89.2411\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19430.7969 - val_loss: 90.3566\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23293.6309 - val_loss: 89.8870\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2447.7180 - val_loss: 89.5221\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7978.1528 - val_loss: 89.1431\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16653.7070 - val_loss: 88.9083\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1378.9723 - val_loss: 89.2939\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7146.3379 - val_loss: 89.6991\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3687.6274 - val_loss: 89.3045\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6928.8608 - val_loss: 89.9988\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22421.2227 - val_loss: 90.4458\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1739.6520 - val_loss: 88.7050\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34304.3242 - val_loss: 87.8909\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6234dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 31 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 79.8344 - val_loss: 62.7621\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49.4242 - val_loss: 35.0580\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42.9899 - val_loss: 37.7620\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34.9122 - val_loss: 37.7360\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.0105 - val_loss: 23.1338\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25.0348 - val_loss: 21.5582\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20.6657 - val_loss: 11.1875\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18.6569 - val_loss: 9.2072\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.4407 - val_loss: 3.9639\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4874 - val_loss: 4.2213\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.8116 - val_loss: 4.2429\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.8948 - val_loss: 3.5266\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.2233 - val_loss: 5.7650\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.3466 - val_loss: 3.9310\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.7852 - val_loss: 5.3628\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.5268 - val_loss: 3.1632\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.5474 - val_loss: 5.0484\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5012 - val_loss: 2.9345\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.2021 - val_loss: 4.3557\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.0952 - val_loss: 2.8244\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6684 - val_loss: 3.8600\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1300 - val_loss: 2.4825\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9786 - val_loss: 5.1003\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1295 - val_loss: 2.5668\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8817 - val_loss: 3.5193\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.3354 - val_loss: 3.3587\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1568 - val_loss: 2.8191\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2102 - val_loss: 5.0971\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3553 - val_loss: 2.5584\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.8064 - val_loss: 2.2105\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.3375 - val_loss: 2.3590\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7278 - val_loss: 4.1399\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3641 - val_loss: 3.1286\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3573 - val_loss: 1.8568\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.6534 - val_loss: 3.9289\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2186 - val_loss: 2.0534\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.4491 - val_loss: 1.8865\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3736 - val_loss: 5.0566\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9543 - val_loss: 2.2489\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6410 - val_loss: 1.3907\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5153 - val_loss: 2.1270\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3291 - val_loss: 2.3370\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2782 - val_loss: 3.8737\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4259 - val_loss: 2.9672\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5558 - val_loss: 5.0035\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7884 - val_loss: 1.3748\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2993 - val_loss: 3.2758\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0813 - val_loss: 1.9581\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3135 - val_loss: 1.6010\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0822 - val_loss: 1.6742\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbc136280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 32 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 92.5501 - val_loss: 80.5673\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 54.2947 - val_loss: 50.3314\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45.9435 - val_loss: 37.5650\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38.2358 - val_loss: 36.5527\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.2790 - val_loss: 27.4631\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22.1805 - val_loss: 13.3604\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.0790 - val_loss: 7.2382\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.9677 - val_loss: 8.9943\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.2782 - val_loss: 6.0437\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.2477 - val_loss: 5.6518\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.0083 - val_loss: 4.5222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.5315 - val_loss: 7.3732\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.1508 - val_loss: 3.4800\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.4817 - val_loss: 6.7556\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.7144 - val_loss: 3.6483\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.5872 - val_loss: 5.2784\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.7329 - val_loss: 5.4297\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.7691 - val_loss: 3.3967\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.7270 - val_loss: 3.4206\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.1067 - val_loss: 4.2662\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.0654 - val_loss: 4.8167\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2275 - val_loss: 3.8569\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1754 - val_loss: 3.1737\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5115 - val_loss: 3.5884\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6229 - val_loss: 3.4454\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2828 - val_loss: 4.0717\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8957 - val_loss: 2.8529\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1304 - val_loss: 5.1457\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9146 - val_loss: 2.2662\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.9521 - val_loss: 5.7699\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3228 - val_loss: 2.2042\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7241 - val_loss: 4.2959\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.4385 - val_loss: 2.3452\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7638 - val_loss: 2.0773\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0209 - val_loss: 2.2702\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0184 - val_loss: 2.4562\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7024 - val_loss: 2.4045\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5658 - val_loss: 2.4913\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4888 - val_loss: 2.2316\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6988 - val_loss: 2.7567\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3741 - val_loss: 2.1756\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4699 - val_loss: 2.4143\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3569 - val_loss: 2.8132\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1459 - val_loss: 2.2902\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1063 - val_loss: 2.1636\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0211 - val_loss: 2.0766\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0474 - val_loss: 2.9382\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8955 - val_loss: 1.9277\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0695 - val_loss: 2.2120\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7690 - val_loss: 2.5065\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd4d2a9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 33 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 70.6029 - val_loss: 49.6376\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31.5890 - val_loss: 14.0121\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.0789 - val_loss: 24.1425\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23.0269 - val_loss: 33.1992\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23.1490 - val_loss: 25.3857\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19.0374 - val_loss: 14.3863\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16.5584 - val_loss: 15.3454\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.7337 - val_loss: 13.7705\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.5350 - val_loss: 5.3896\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.1426 - val_loss: 2.7504\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.1264 - val_loss: 3.0831\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8668 - val_loss: 3.3097\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.5796 - val_loss: 3.0257\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4589 - val_loss: 2.6288\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2949 - val_loss: 2.7592\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8557 - val_loss: 2.6695\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2126 - val_loss: 3.4282\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.2373 - val_loss: 3.1546\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1024 - val_loss: 3.1598\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5958 - val_loss: 3.1061\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3995 - val_loss: 3.5175\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7478 - val_loss: 2.9414\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2322 - val_loss: 2.7618\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0535 - val_loss: 2.8418\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.8883 - val_loss: 2.8073\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8456 - val_loss: 2.8858\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7647 - val_loss: 2.7177\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5872 - val_loss: 2.7070\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4498 - val_loss: 2.6550\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3070 - val_loss: 2.6973\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4978 - val_loss: 2.5242\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2570 - val_loss: 2.8019\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1951 - val_loss: 2.5303\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9949 - val_loss: 2.6248\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2820 - val_loss: 2.9546\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7507 - val_loss: 2.6277\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7166 - val_loss: 3.4230\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5945 - val_loss: 2.3173\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9195 - val_loss: 1.9497\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8612 - val_loss: 2.5200\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.8863 - val_loss: 1.8505\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.7298 - val_loss: 2.3123\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7875 - val_loss: 2.3828\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6244 - val_loss: 2.0198\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8775 - val_loss: 2.6317\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5767 - val_loss: 1.7847\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4173 - val_loss: 2.3038\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.0740 - val_loss: 1.7218\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2385 - val_loss: 1.6828\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1094 - val_loss: 2.3103\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc3455d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 34 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 192950.1562 - val_loss: 109.7326\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 198712.3906 - val_loss: 106.2342\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 73076.5703 - val_loss: 101.4659\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73764.5156 - val_loss: 99.7518\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33921.5078 - val_loss: 102.2935\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 76938.3359 - val_loss: 103.7483\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64675.3281 - val_loss: 101.8691\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 66925.4141 - val_loss: 100.1500\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21705.7773 - val_loss: 101.8502\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13964.5508 - val_loss: 101.8422\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17535.5156 - val_loss: 99.9650\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 82581.6719 - val_loss: 100.1341\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16342.4395 - val_loss: 103.5954\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27915.0137 - val_loss: 102.9310\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31091.2734 - val_loss: 105.0508\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32017.9941 - val_loss: 105.3544\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38168.4648 - val_loss: 104.4206\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21718.3789 - val_loss: 104.7623\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32330.1680 - val_loss: 102.7868\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28790.5293 - val_loss: 101.9573\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2990.7925 - val_loss: 104.6499\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 123294.0156 - val_loss: 104.6744\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 87147.1094 - val_loss: 103.1847\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34279.5977 - val_loss: 100.9184\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64399.9414 - val_loss: 102.1546\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14763.2207 - val_loss: 104.0164\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 70560.8281 - val_loss: 105.3586\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 63591.5469 - val_loss: 103.7006\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32384.9277 - val_loss: 101.8811\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 63885.5117 - val_loss: 103.6271\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8283.3984 - val_loss: 104.3537\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9349.5605 - val_loss: 104.4844\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12652.6035 - val_loss: 104.0877\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17994.6328 - val_loss: 104.5562\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14797.4258 - val_loss: 104.1688\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13039.0381 - val_loss: 104.6230\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20949.0820 - val_loss: 104.1563\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38082.4258 - val_loss: 103.6542\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18675.4238 - val_loss: 104.1731\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33281.4453 - val_loss: 102.5329\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3558.3184 - val_loss: 102.6845\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32125.6680 - val_loss: 102.1323\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4569.3252 - val_loss: 101.7641\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16206.8389 - val_loss: 101.6991\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9909.3750 - val_loss: 102.4640\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43174.5664 - val_loss: 102.6813\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28550.4512 - val_loss: 99.8979\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 132310.1719 - val_loss: 99.0010\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 103678.6484 - val_loss: 100.5731\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33702.1836 - val_loss: 103.0395\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6374af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 35 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 73.3361 - val_loss: 46.7068\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26.7842 - val_loss: 8.5627\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.6650 - val_loss: 20.7156\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.3674 - val_loss: 32.2923\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.6571 - val_loss: 22.7112\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.0240 - val_loss: 11.3507\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.3686 - val_loss: 15.4286\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.6145 - val_loss: 15.0795\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.5646 - val_loss: 6.1693\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1544 - val_loss: 7.5089\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1550 - val_loss: 3.1898\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6266 - val_loss: 5.3237\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7851 - val_loss: 3.8588\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7712 - val_loss: 6.0018\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5588 - val_loss: 3.0588\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5104 - val_loss: 4.8343\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3538 - val_loss: 3.4886\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1020 - val_loss: 3.5971\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9689 - val_loss: 3.6440\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9584 - val_loss: 2.5936\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9682 - val_loss: 3.6752\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8328 - val_loss: 2.2740\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7254 - val_loss: 3.7574\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7455 - val_loss: 2.2489\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3495 - val_loss: 3.0721\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3481 - val_loss: 3.2301\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3485 - val_loss: 1.9494\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2253 - val_loss: 2.5655\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9683 - val_loss: 2.4388\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0580 - val_loss: 1.9595\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9192 - val_loss: 2.3740\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8250 - val_loss: 2.4129\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7043 - val_loss: 2.3578\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5596 - val_loss: 2.3024\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5056 - val_loss: 2.9213\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6053 - val_loss: 2.0097\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3089 - val_loss: 2.1915\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2692 - val_loss: 1.9800\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.2950 - val_loss: 2.1908\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3126 - val_loss: 2.7669\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1930 - val_loss: 3.1697\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4609 - val_loss: 2.1303\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0183 - val_loss: 1.9398\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8406 - val_loss: 1.9777\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8870 - val_loss: 3.8065\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7342 - val_loss: 3.9635\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9666 - val_loss: 2.7227\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8381 - val_loss: 1.7043\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7458 - val_loss: 1.8682\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7135 - val_loss: 3.1665\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc62345e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 36 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 51066.4414 - val_loss: 87.4167\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 99137.4219 - val_loss: 94.9926\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 88192.2266 - val_loss: 91.2396\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33468.6406 - val_loss: 90.6696\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15540.8652 - val_loss: 93.0796\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8819.7959 - val_loss: 93.4242\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8058.7173 - val_loss: 92.3014\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36957.7969 - val_loss: 91.9212\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16616.9492 - val_loss: 93.4114\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9967.1748 - val_loss: 94.6482\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21276.0469 - val_loss: 94.0024\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12845.4277 - val_loss: 93.8303\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6150.2803 - val_loss: 93.8813\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4677.1577 - val_loss: 94.6561\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12867.2324 - val_loss: 93.7978\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8724.7891 - val_loss: 94.6345\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12766.0381 - val_loss: 94.1040\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4212.8042 - val_loss: 94.8370\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16497.7969 - val_loss: 94.5633\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14593.9248 - val_loss: 94.0854\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7405.6548 - val_loss: 96.8864\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50921.0625 - val_loss: 97.1321\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52456.1484 - val_loss: 95.9788\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14499.1016 - val_loss: 94.4902\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40058.1719 - val_loss: 93.6254\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22038.3594 - val_loss: 94.8002\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16654.7090 - val_loss: 96.1403\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19917.0059 - val_loss: 95.8557\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 116.4220 - val_loss: 95.8407\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8284.6104 - val_loss: 95.3315\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12967.0537 - val_loss: 95.5637\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6208.4570 - val_loss: 95.7367\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19222.4043 - val_loss: 95.1766\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11242.8926 - val_loss: 96.6487\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40760.4844 - val_loss: 97.3781\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36951.2227 - val_loss: 96.0722\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9511.0498 - val_loss: 95.8734\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4518.5659 - val_loss: 96.5793\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15987.0020 - val_loss: 96.5892\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8971.7686 - val_loss: 96.0831\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18277.6816 - val_loss: 95.6319\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2843.3276 - val_loss: 96.5091\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33231.8438 - val_loss: 97.5798\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29079.8887 - val_loss: 97.0041\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8277.0830 - val_loss: 95.7962\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43647.6953 - val_loss: 95.2034\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34058.8320 - val_loss: 96.0998\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10419.5459 - val_loss: 97.2206\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28661.1641 - val_loss: 97.4482\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26727.6953 - val_loss: 96.6899\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd1fa7e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 37 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 87.3562 - val_loss: 65.0738\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.0759 - val_loss: 14.8569\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25.3603 - val_loss: 17.4465\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.3647 - val_loss: 30.4754\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.9705 - val_loss: 20.8083\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.8712 - val_loss: 10.8417\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.9712 - val_loss: 15.2647\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.1468 - val_loss: 16.0430\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.3918 - val_loss: 6.4184\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4879 - val_loss: 11.1205\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8012 - val_loss: 3.6201\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2777 - val_loss: 4.2346\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2771 - val_loss: 2.9284\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4034 - val_loss: 3.2075\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9611 - val_loss: 3.1214\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8193 - val_loss: 2.8173\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6325 - val_loss: 3.4126\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5137 - val_loss: 2.8601\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2074 - val_loss: 2.9307\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1064 - val_loss: 2.8804\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.2124 - val_loss: 3.4051\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1840 - val_loss: 2.6087\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9373 - val_loss: 2.6246\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7253 - val_loss: 2.8514\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3581 - val_loss: 4.0060\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0184 - val_loss: 2.8726\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5903 - val_loss: 2.5809\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1996 - val_loss: 3.1839\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2128 - val_loss: 2.8841\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1725 - val_loss: 3.6125\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6643 - val_loss: 3.2881\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.8926 - val_loss: 2.6423\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5398 - val_loss: 3.0424\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2166 - val_loss: 3.6298\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1600 - val_loss: 2.6723\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1547 - val_loss: 2.8548\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6344 - val_loss: 2.5789\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1925 - val_loss: 2.9019\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3198 - val_loss: 2.9058\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.6761 - val_loss: 2.9303\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.5070 - val_loss: 2.8078\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.4916 - val_loss: 3.3725\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2360 - val_loss: 3.3779\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3415 - val_loss: 3.5597\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.1510 - val_loss: 3.3370\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2397 - val_loss: 2.9445\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.1057 - val_loss: 3.5671\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8379 - val_loss: 2.9460\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9151 - val_loss: 2.9795\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.7915 - val_loss: 3.3820\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbd5c9670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 38 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 59.2056 - val_loss: 39.9673\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.2870 - val_loss: 19.9422\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28.6684 - val_loss: 27.0796\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23.2112 - val_loss: 27.7242\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.7525 - val_loss: 13.9779\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.0421 - val_loss: 10.6295\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.1219 - val_loss: 7.9927\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.1657 - val_loss: 4.0654\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5360 - val_loss: 4.1554\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8011 - val_loss: 2.1911\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9519 - val_loss: 6.1776\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.4443 - val_loss: 2.4550\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.6413 - val_loss: 6.4214\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7874 - val_loss: 3.3275\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5424 - val_loss: 2.4962\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8206 - val_loss: 4.2652\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8906 - val_loss: 3.1656\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3646 - val_loss: 2.8274\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.0841 - val_loss: 3.1569\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9861 - val_loss: 2.5667\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2995 - val_loss: 5.1507\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2301 - val_loss: 2.5239\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4118 - val_loss: 4.5223\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1123 - val_loss: 3.2213\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9698 - val_loss: 3.7770\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8448 - val_loss: 2.9898\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3108 - val_loss: 4.4860\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6685 - val_loss: 2.9835\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1434 - val_loss: 3.6646\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6192 - val_loss: 3.3889\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5574 - val_loss: 2.8830\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2929 - val_loss: 3.4595\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3288 - val_loss: 4.2201\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2482 - val_loss: 2.7506\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2865 - val_loss: 4.2147\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.8923 - val_loss: 3.6149\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.7802 - val_loss: 3.5920\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7134 - val_loss: 2.9773\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8227 - val_loss: 4.0899\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5886 - val_loss: 2.9206\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8113 - val_loss: 3.0219\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6628 - val_loss: 3.5818\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4225 - val_loss: 3.3627\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4697 - val_loss: 3.5265\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.4330 - val_loss: 2.9607\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3852 - val_loss: 2.9105\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4073 - val_loss: 3.2459\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5170 - val_loss: 2.9285\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.0026 - val_loss: 3.1244\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.5520 - val_loss: 3.2253\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd4f0f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 39 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 197812.0312 - val_loss: 101.3782\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 284406.4062 - val_loss: 102.8059\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 137158.0938 - val_loss: 96.7019\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 82543.7188 - val_loss: 94.1064\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 51922.8750 - val_loss: 96.1432\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 50455.6914 - val_loss: 96.5898\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27494.5605 - val_loss: 94.9098\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 98219.4609 - val_loss: 93.6033\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40908.3555 - val_loss: 95.9708\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 94062.7734 - val_loss: 97.8154\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 89575.9219 - val_loss: 95.4306\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32231.9277 - val_loss: 95.9166\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21698.4414 - val_loss: 97.6954\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15131.4248 - val_loss: 97.3779\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 58507.2578 - val_loss: 96.4545\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43073.5117 - val_loss: 98.6633\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24498.7871 - val_loss: 99.1625\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19926.5508 - val_loss: 97.8984\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10697.4453 - val_loss: 97.3898\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6516.2710 - val_loss: 94.9694\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13148.9609 - val_loss: 94.6662\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37457.0977 - val_loss: 94.0310\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18499.7285 - val_loss: 92.3134\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29316.7344 - val_loss: 92.2866\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10886.9404 - val_loss: 93.5592\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43841.5703 - val_loss: 93.7800\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25022.1875 - val_loss: 93.6176\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14706.7383 - val_loss: 95.3535\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17350.0469 - val_loss: 96.3495\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13462.5967 - val_loss: 99.5275\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 86022.4219 - val_loss: 100.3067\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 55217.0859 - val_loss: 98.5780\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25349.5801 - val_loss: 98.5490\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8017.5132 - val_loss: 100.1479\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 57191.7891 - val_loss: 99.8054\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33226.8086 - val_loss: 98.5091\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37510.6133 - val_loss: 98.2131\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 24658.9219 - val_loss: 99.6618\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 62971.0508 - val_loss: 100.1664\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27680.9629 - val_loss: 98.6377\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7791.4878 - val_loss: 97.5514\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45945.0273 - val_loss: 97.5982\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14483.4346 - val_loss: 100.0176\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 110835.6562 - val_loss: 100.6748\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 111391.5234 - val_loss: 99.3639\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34823.0664 - val_loss: 97.4942\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 87472.1094 - val_loss: 97.0492\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 75374.2031 - val_loss: 98.3252\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2063.3354 - val_loss: 98.9251\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15024.6348 - val_loss: 97.9187\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7d6a5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 40 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 79.0158 - val_loss: 65.3225\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 61.2434 - val_loss: 43.9394\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43.8996 - val_loss: 26.7628\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.6600 - val_loss: 19.8791\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33.3329 - val_loss: 22.3319\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.1871 - val_loss: 13.0465\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.4330 - val_loss: 11.0762\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23.8696 - val_loss: 7.7519\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.8813 - val_loss: 5.1261\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.4572 - val_loss: 4.7539\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.3820 - val_loss: 3.7932\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.1929 - val_loss: 7.8754\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.2681 - val_loss: 4.2013\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.5292 - val_loss: 5.8021\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.1436 - val_loss: 3.1119\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.2502 - val_loss: 8.1926\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9824 - val_loss: 4.3272\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.8024 - val_loss: 2.6950\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.1738 - val_loss: 5.9172\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9679 - val_loss: 6.7151\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.9448 - val_loss: 2.5893\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.9558 - val_loss: 5.0640\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0139 - val_loss: 4.6373\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7195 - val_loss: 6.0884\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5896 - val_loss: 2.2762\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5700 - val_loss: 5.7205\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1753 - val_loss: 3.6935\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5514 - val_loss: 5.5804\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2944 - val_loss: 2.3123\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9685 - val_loss: 4.7409\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.8374 - val_loss: 3.8207\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7234 - val_loss: 5.8533\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5332 - val_loss: 2.3141\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.9089 - val_loss: 7.8430\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3031 - val_loss: 2.7048\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.8031 - val_loss: 3.2618\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3728 - val_loss: 3.9429\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5471 - val_loss: 2.8663\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1748 - val_loss: 3.1367\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5082 - val_loss: 3.8776\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1724 - val_loss: 3.1899\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8225 - val_loss: 4.0314\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6074 - val_loss: 3.5678\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0613 - val_loss: 2.9589\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9955 - val_loss: 3.5189\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8770 - val_loss: 3.5611\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9634 - val_loss: 3.1750\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8273 - val_loss: 3.7104\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8216 - val_loss: 3.0753\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1735 - val_loss: 4.1117\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd2425af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 41 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 268485.8125 - val_loss: 69.6061\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 78816.9141 - val_loss: 80.6990\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 109322.2109 - val_loss: 84.3223\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 105734.9375 - val_loss: 81.7172\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2192.8459 - val_loss: 79.4311\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 97597.4766 - val_loss: 76.4325\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 91815.4922 - val_loss: 79.9234\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5121.7178 - val_loss: 83.0608\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55990.2617 - val_loss: 83.9852\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 58522.7422 - val_loss: 82.8531\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7527.5708 - val_loss: 81.1664\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42102.3203 - val_loss: 80.4379\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39567.8516 - val_loss: 81.1298\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4819.7437 - val_loss: 84.1476\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44846.9609 - val_loss: 84.9970\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 61383.0664 - val_loss: 84.1655\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27061.7441 - val_loss: 82.8065\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13817.1689 - val_loss: 82.6985\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9951.7861 - val_loss: 83.9640\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27582.5898 - val_loss: 83.8631\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9446.0635 - val_loss: 83.1855\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14655.3916 - val_loss: 82.6036\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23780.8691 - val_loss: 83.0741\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7424.5586 - val_loss: 83.4755\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 126.8004 - val_loss: 84.2949\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29481.0488 - val_loss: 84.2200\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8425.5820 - val_loss: 82.7060\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34023.1172 - val_loss: 82.4917\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32558.5293 - val_loss: 83.1709\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6798.4863 - val_loss: 83.8717\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5424.6841 - val_loss: 84.0910\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6502.7896 - val_loss: 83.4324\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15159.5811 - val_loss: 84.0559\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5044.3496 - val_loss: 83.6583\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16026.1064 - val_loss: 84.0320\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2527.6406 - val_loss: 85.6026\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57069.1133 - val_loss: 86.0399\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42957.5820 - val_loss: 85.2350\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24358.1309 - val_loss: 83.1444\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56232.2109 - val_loss: 82.7109\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 54986.0625 - val_loss: 83.8252\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19207.1230 - val_loss: 85.3347\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26328.7559 - val_loss: 85.9452\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24400.6172 - val_loss: 85.2249\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13662.1133 - val_loss: 85.0990\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7211.7319 - val_loss: 86.4669\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47020.8203 - val_loss: 86.8855\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39698.7617 - val_loss: 85.9881\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9385.4590 - val_loss: 85.6175\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11438.2559 - val_loss: 86.0201\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfcdd81c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 42 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 14967.2617 - val_loss: 109.3653\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 204082.6094 - val_loss: 106.8889\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 139044.4844 - val_loss: 102.5390\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28896.5723 - val_loss: 98.1672\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12868.2578 - val_loss: 97.4183\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32173.6406 - val_loss: 98.2976\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15064.1494 - val_loss: 99.4865\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15119.1182 - val_loss: 98.7635\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3466.9304 - val_loss: 101.5346\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 68428.0625 - val_loss: 102.8338\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43392.0195 - val_loss: 100.4269\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17886.1523 - val_loss: 95.9519\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 71265.2656 - val_loss: 95.1898\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 76072.3906 - val_loss: 96.4568\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39484.4297 - val_loss: 98.7179\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9136.3711 - val_loss: 100.1870\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7355.9834 - val_loss: 98.4087\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26139.5059 - val_loss: 99.0440\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11584.1572 - val_loss: 100.1623\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4068.5781 - val_loss: 100.0867\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2289.6096 - val_loss: 98.4746\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38906.3555 - val_loss: 98.2554\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25370.3906 - val_loss: 100.0039\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23893.4785 - val_loss: 101.0677\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19366.2207 - val_loss: 98.7492\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41009.8867 - val_loss: 98.0705\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37064.3789 - val_loss: 99.8684\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4939.2666 - val_loss: 100.0464\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7936.1938 - val_loss: 100.1231\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16219.7471 - val_loss: 100.8781\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11042.6357 - val_loss: 99.8231\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13107.2324 - val_loss: 99.8372\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7328.3208 - val_loss: 101.0907\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20431.9941 - val_loss: 100.9978\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10369.0371 - val_loss: 100.1764\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21561.0254 - val_loss: 99.4360\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7208.6177 - val_loss: 100.8047\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15820.5078 - val_loss: 101.2558\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17991.3145 - val_loss: 100.7923\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4446.4883 - val_loss: 100.4342\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3977.8264 - val_loss: 100.0849\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7025.7822 - val_loss: 100.6362\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6901.8413 - val_loss: 100.2096\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15592.0742 - val_loss: 99.9420\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2835.3030 - val_loss: 100.4145\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2771.5957 - val_loss: 101.0287\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20110.7969 - val_loss: 101.2118\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2649.7607 - val_loss: 100.5664\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1433.9470 - val_loss: 100.2027\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6203.6914 - val_loss: 101.0717\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfdaf3a790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 43 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 73.6327 - val_loss: 57.3214\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 42.2957 - val_loss: 27.5317\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38.8965 - val_loss: 33.7800\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.7964 - val_loss: 39.3910\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30.5195 - val_loss: 34.8576\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26.1438 - val_loss: 21.2312\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23.8465 - val_loss: 14.8848\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19.1770 - val_loss: 18.7588\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.6584 - val_loss: 7.1938\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.0551 - val_loss: 5.8055\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.4198 - val_loss: 6.2782\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.9003 - val_loss: 5.4372\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.1872 - val_loss: 6.6816\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.6232 - val_loss: 3.5880\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.3842 - val_loss: 6.5382\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9626 - val_loss: 2.8646\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.0290 - val_loss: 3.0000\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2235 - val_loss: 2.7244\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1569 - val_loss: 2.8474\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6709 - val_loss: 3.0747\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2498 - val_loss: 2.9415\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1182 - val_loss: 2.5907\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8801 - val_loss: 2.2856\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9599 - val_loss: 2.2655\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3053 - val_loss: 3.1476\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1864 - val_loss: 1.7445\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1463 - val_loss: 2.5610\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3429 - val_loss: 1.8527\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7191 - val_loss: 1.8095\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8466 - val_loss: 2.1051\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4008 - val_loss: 1.6614\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3277 - val_loss: 1.5171\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.8981 - val_loss: 3.5128\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6350 - val_loss: 1.6441\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0635 - val_loss: 1.8107\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.6186 - val_loss: 3.8164\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2659 - val_loss: 1.3474\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3614 - val_loss: 1.5083\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3509 - val_loss: 3.5042\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6899 - val_loss: 1.3552\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.1417 - val_loss: 2.0040\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6169 - val_loss: 2.9524\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0071 - val_loss: 3.0634\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1593 - val_loss: 1.5707\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7194 - val_loss: 1.6503\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.8935 - val_loss: 2.4262\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.8553 - val_loss: 1.5102\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6690 - val_loss: 6.6208\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.5639 - val_loss: 2.9900\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0534 - val_loss: 5.1752\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7d6a430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 44 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 93.9689 - val_loss: 74.9374\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 65.4700 - val_loss: 45.8152\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56.1879 - val_loss: 44.8208\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40.4727 - val_loss: 37.7072\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.9653 - val_loss: 25.9384\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 30.3861 - val_loss: 21.0812\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24.9371 - val_loss: 19.0494\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23.0058 - val_loss: 8.0721\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.1207 - val_loss: 8.6150\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.6565 - val_loss: 5.0950\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.1435 - val_loss: 7.1481\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.9181 - val_loss: 4.6866\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.4103 - val_loss: 9.3471\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.1593 - val_loss: 4.4927\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16.3279 - val_loss: 4.5557\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.7456 - val_loss: 4.7545\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.2639 - val_loss: 6.9822\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1654 - val_loss: 4.1364\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.3027 - val_loss: 7.8213\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6179 - val_loss: 4.3959\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.4667 - val_loss: 6.0734\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9505 - val_loss: 4.7901\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6263 - val_loss: 6.7498\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5472 - val_loss: 6.5443\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6387 - val_loss: 5.8701\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4437 - val_loss: 5.4507\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0775 - val_loss: 7.8644\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7627 - val_loss: 3.7363\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9696 - val_loss: 7.8830\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7554 - val_loss: 3.9944\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.2911 - val_loss: 6.2183\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1110 - val_loss: 5.5949\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1049 - val_loss: 4.6828\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0311 - val_loss: 7.2008\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.9111 - val_loss: 3.7025\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8370 - val_loss: 7.0859\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2900 - val_loss: 3.7897\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9588 - val_loss: 6.4011\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0164 - val_loss: 4.5791\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8653 - val_loss: 5.0471\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.8324 - val_loss: 5.9138\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3718 - val_loss: 4.1773\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1462 - val_loss: 5.7042\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.1510 - val_loss: 4.7110\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1219 - val_loss: 5.1819\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0439 - val_loss: 4.7411\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6526 - val_loss: 5.7650\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4515 - val_loss: 4.6807\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1636 - val_loss: 4.3384\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4028 - val_loss: 4.3928\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfcdd34ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 45 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 143635.9531 - val_loss: 60.3108\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 51438.3086 - val_loss: 76.1154\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 156663.5781 - val_loss: 79.5523\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 135963.2656 - val_loss: 78.4996\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44450.0586 - val_loss: 75.8761\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46365.0312 - val_loss: 73.0052\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49123.6992 - val_loss: 74.0826\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14206.0791 - val_loss: 76.3847\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3814.4255 - val_loss: 76.5952\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25232.8691 - val_loss: 77.1447\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1236.7281 - val_loss: 74.7468\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 71729.7344 - val_loss: 73.6627\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 69079.6172 - val_loss: 76.0405\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27791.5059 - val_loss: 78.9713\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50720.5938 - val_loss: 80.0175\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40894.6680 - val_loss: 79.2590\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15588.7598 - val_loss: 76.8710\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 61746.5781 - val_loss: 76.0482\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54011.7812 - val_loss: 77.0926\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42719.3984 - val_loss: 80.6624\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36348.1875 - val_loss: 81.4662\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40130.5859 - val_loss: 80.7567\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1364.7159 - val_loss: 79.2658\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39132.8672 - val_loss: 78.0025\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45682.5000 - val_loss: 78.8953\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14338.6846 - val_loss: 80.9991\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30720.2266 - val_loss: 82.3125\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 28854.9141 - val_loss: 81.6562\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7087.0444 - val_loss: 81.2623\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1919.0648 - val_loss: 83.3792\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64787.6445 - val_loss: 84.3044\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53389.7891 - val_loss: 83.1778\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16010.6279 - val_loss: 81.4897\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30314.3906 - val_loss: 80.9231\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33281.5508 - val_loss: 81.5300\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14195.2549 - val_loss: 83.2255\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18229.2422 - val_loss: 83.7384\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20158.4004 - val_loss: 83.4182\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5954.8530 - val_loss: 83.0353\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2978.6504 - val_loss: 83.0072\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6096.1812 - val_loss: 83.5130\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6566.8335 - val_loss: 83.1542\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7473.1021 - val_loss: 83.2781\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19824.8262 - val_loss: 84.0868\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16257.8408 - val_loss: 82.6132\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 24855.8809 - val_loss: 82.6435\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21689.1191 - val_loss: 83.8861\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10276.0449 - val_loss: 83.9770\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1501.5416 - val_loss: 82.8750\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39240.9766 - val_loss: 82.4161\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd2bc0700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 46 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 276483.8438 - val_loss: 80.1608\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 90476.5938 - val_loss: 92.8839\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36128.0195 - val_loss: 94.6993\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 57967.0117 - val_loss: 93.3713\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10343.3730 - val_loss: 92.8346\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15654.4668 - val_loss: 92.3537\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8452.5234 - val_loss: 93.7048\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23416.2520 - val_loss: 92.5066\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19415.9805 - val_loss: 92.9607\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7314.9062 - val_loss: 92.1179\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17600.0000 - val_loss: 93.5176\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12672.9141 - val_loss: 92.1466\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18351.5254 - val_loss: 93.5408\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11842.8896 - val_loss: 92.2239\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18245.1367 - val_loss: 93.5984\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23275.7656 - val_loss: 93.4543\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16303.2021 - val_loss: 92.9199\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27215.6660 - val_loss: 94.0727\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11261.0322 - val_loss: 91.1916\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 59569.3242 - val_loss: 90.8866\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57150.5195 - val_loss: 92.5997\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21058.5371 - val_loss: 95.5661\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55472.5391 - val_loss: 96.0286\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50460.1641 - val_loss: 95.1242\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17090.5547 - val_loss: 92.9702\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 68746.4297 - val_loss: 91.9721\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 58457.9492 - val_loss: 94.0384\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7198.2788 - val_loss: 94.8950\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 336.4115 - val_loss: 95.5229\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17232.6094 - val_loss: 95.1651\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1070.7750 - val_loss: 94.2182\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30570.2871 - val_loss: 94.2465\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21692.8516 - val_loss: 94.9659\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17842.1855 - val_loss: 95.6440\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12287.5225 - val_loss: 93.9285\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45614.0820 - val_loss: 93.8571\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41939.7305 - val_loss: 94.8996\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5706.6865 - val_loss: 96.3411\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52342.7930 - val_loss: 97.2258\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35444.9883 - val_loss: 96.5232\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24039.8711 - val_loss: 94.3270\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 77892.7266 - val_loss: 93.3900\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 68871.4219 - val_loss: 94.3532\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35577.8633 - val_loss: 95.8988\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5297.0605 - val_loss: 98.2551\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 75206.6641 - val_loss: 99.2113\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 70243.4219 - val_loss: 98.4214\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38363.5820 - val_loss: 97.5044\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22293.0430 - val_loss: 95.9975\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 49584.6641 - val_loss: 95.4154\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd4c4a8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 47 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2263\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7960790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 48 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 69691.1250 - val_loss: 77.4913\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 179598.2656 - val_loss: 69.0961\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 97124.6875 - val_loss: 77.8399\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7978.2246 - val_loss: 88.8728\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 123823.5000 - val_loss: 91.0440\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 151940.4062 - val_loss: 90.5998\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 97408.5156 - val_loss: 87.0602\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 193.7037 - val_loss: 82.5123\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72409.8516 - val_loss: 79.1107\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 93142.7734 - val_loss: 80.5964\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50737.5586 - val_loss: 83.0619\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9011.9307 - val_loss: 84.7042\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1860.0748 - val_loss: 85.1101\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49744.6133 - val_loss: 86.9840\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37684.8867 - val_loss: 83.9299\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23354.8809 - val_loss: 83.6713\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18959.1855 - val_loss: 85.6920\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22855.3086 - val_loss: 85.4883\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2962.9023 - val_loss: 84.3585\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23694.2344 - val_loss: 83.3781\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32656.9434 - val_loss: 84.5199\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10205.5469 - val_loss: 87.9190\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52021.4922 - val_loss: 87.9845\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50669.5000 - val_loss: 86.4377\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13055.2002 - val_loss: 83.6437\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 68379.8359 - val_loss: 82.3300\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 62530.6172 - val_loss: 85.4566\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2074.1592 - val_loss: 85.8008\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4201.1157 - val_loss: 86.5193\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16698.4648 - val_loss: 86.4478\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4438.0352 - val_loss: 85.0158\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28465.8086 - val_loss: 85.0524\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17585.1504 - val_loss: 85.9033\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4476.0439 - val_loss: 86.7138\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8959.5605 - val_loss: 85.2904\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31612.2832 - val_loss: 85.2268\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8512.5039 - val_loss: 86.6248\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4713.1880 - val_loss: 87.4706\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26803.4785 - val_loss: 87.2421\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15128.9092 - val_loss: 84.6975\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44483.6992 - val_loss: 84.5754\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40136.9492 - val_loss: 86.1087\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1508.4995 - val_loss: 88.2583\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39292.6562 - val_loss: 88.8053\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40477.0547 - val_loss: 88.2319\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10752.9189 - val_loss: 86.4697\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20596.2090 - val_loss: 85.8972\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26343.9316 - val_loss: 86.4653\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1005.9075 - val_loss: 86.9252\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12253.2959 - val_loss: 87.0974\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7ea0550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 49 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 72.0180 - val_loss: 52.8419\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44.2651 - val_loss: 32.2300\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.2878 - val_loss: 29.9282\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.3326 - val_loss: 29.9000\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23.6147 - val_loss: 18.3153\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19.7205 - val_loss: 13.3975\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.7517 - val_loss: 4.8952\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.7608 - val_loss: 8.4639\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.3258 - val_loss: 2.2810\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.5731 - val_loss: 6.2773\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.2536 - val_loss: 4.1373\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.3352 - val_loss: 2.8357\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.6267 - val_loss: 5.2334\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.4300 - val_loss: 3.9132\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.1555 - val_loss: 4.0348\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1284 - val_loss: 4.0184\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.2156 - val_loss: 4.2843\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.9552 - val_loss: 2.5726\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.6607 - val_loss: 2.9349\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5542 - val_loss: 2.9661\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5517 - val_loss: 3.0471\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3426 - val_loss: 2.8655\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3545 - val_loss: 2.5273\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7403 - val_loss: 2.4702\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.8400 - val_loss: 3.2636\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0991 - val_loss: 3.2435\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.0683 - val_loss: 2.8061\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4117 - val_loss: 2.4340\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9033 - val_loss: 2.9022\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8748 - val_loss: 2.7724\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7362 - val_loss: 2.9612\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7065 - val_loss: 2.7073\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3621 - val_loss: 2.5816\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1425 - val_loss: 2.7278\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1809 - val_loss: 3.0173\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1893 - val_loss: 2.2291\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1027 - val_loss: 3.4936\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.2944 - val_loss: 2.2319\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0531 - val_loss: 3.0042\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.9368 - val_loss: 2.4037\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2685 - val_loss: 2.3597\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8050 - val_loss: 2.8644\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7748 - val_loss: 2.3996\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5532 - val_loss: 4.5880\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6703 - val_loss: 2.4123\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9554 - val_loss: 4.0268\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4480 - val_loss: 2.8769\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3713 - val_loss: 3.9439\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6884 - val_loss: 2.1356\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3041 - val_loss: 2.4330\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe07a6940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 50 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 72.2293 - val_loss: 51.1975\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.9903 - val_loss: 16.0593\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32.0327 - val_loss: 29.3548\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25.3183 - val_loss: 29.2930\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.2849 - val_loss: 14.0228\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.3618 - val_loss: 15.8959\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.4844 - val_loss: 7.0140\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.0030 - val_loss: 6.0159\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5146 - val_loss: 4.1490\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.8607 - val_loss: 3.9943\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.1764 - val_loss: 3.7719\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.0483 - val_loss: 5.6288\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7088 - val_loss: 5.8682\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6303 - val_loss: 5.1117\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2485 - val_loss: 3.8060\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.7003 - val_loss: 4.4957\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.4222 - val_loss: 4.5751\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6414 - val_loss: 5.2579\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5527 - val_loss: 3.1741\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9006 - val_loss: 4.7247\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7364 - val_loss: 3.2853\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6617 - val_loss: 3.9980\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4626 - val_loss: 3.1723\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7446 - val_loss: 4.2251\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.0884 - val_loss: 3.0871\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.4973 - val_loss: 3.0818\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2007 - val_loss: 4.0515\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.0457 - val_loss: 3.2898\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1293 - val_loss: 2.9666\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.8778 - val_loss: 3.8089\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9559 - val_loss: 3.7212\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8407 - val_loss: 4.1639\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6010 - val_loss: 3.1952\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2457 - val_loss: 3.5156\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7107 - val_loss: 2.8596\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4467 - val_loss: 2.8171\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2088 - val_loss: 3.6700\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1168 - val_loss: 3.5646\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7491 - val_loss: 2.7866\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4921 - val_loss: 2.8261\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.5768 - val_loss: 3.3865\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4490 - val_loss: 2.8099\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4329 - val_loss: 3.0112\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6807 - val_loss: 2.8584\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6952 - val_loss: 3.1675\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.8285 - val_loss: 3.3607\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8183 - val_loss: 2.7703\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5178 - val_loss: 2.7282\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5718 - val_loss: 3.0677\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3795 - val_loss: 2.6179\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfcdd813a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 51 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 47471.5352 - val_loss: 78.9060\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 587103.8125 - val_loss: 81.0063\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 420025.0938 - val_loss: 87.6227\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 194708.6406 - val_loss: 96.0592\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 91732.3672 - val_loss: 100.1208\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 86025.6719 - val_loss: 95.7431\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38855.7812 - val_loss: 97.0487\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1768.4858 - val_loss: 101.4452\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 141622.7031 - val_loss: 100.9467\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 108284.0156 - val_loss: 96.6082\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 77583.7891 - val_loss: 95.1022\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26203.2812 - val_loss: 99.6105\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 121154.0938 - val_loss: 101.2288\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 114757.1875 - val_loss: 99.0301\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8535.0146 - val_loss: 95.3294\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 144925.7031 - val_loss: 92.5209\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 108987.9062 - val_loss: 95.1298\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15252.7881 - val_loss: 97.2748\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17058.6484 - val_loss: 97.5487\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25148.1719 - val_loss: 96.8753\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9269.1035 - val_loss: 98.1964\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44231.1719 - val_loss: 97.7730\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6122.4067 - val_loss: 97.8384\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18304.0723 - val_loss: 96.1695\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55015.7734 - val_loss: 96.0138\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13464.5723 - val_loss: 97.3479\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8286.1074 - val_loss: 97.9381\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53616.1914 - val_loss: 98.4796\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35938.3633 - val_loss: 94.9164\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 108999.4609 - val_loss: 93.9830\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 89777.3125 - val_loss: 96.8660\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28612.7305 - val_loss: 97.8364\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1696.2241 - val_loss: 96.0091\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 70506.9766 - val_loss: 95.2350\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56592.6172 - val_loss: 97.1370\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41781.3789 - val_loss: 98.3032\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12582.6309 - val_loss: 97.4017\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25568.3809 - val_loss: 97.6728\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6066.7256 - val_loss: 97.7930\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 69942.6250 - val_loss: 99.3917\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50174.8711 - val_loss: 96.3001\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 86742.4219 - val_loss: 94.8369\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 50639.3633 - val_loss: 97.1180\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52437.7031 - val_loss: 98.9073\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44011.5234 - val_loss: 95.8875\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 82197.3203 - val_loss: 95.0511\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 57526.2891 - val_loss: 96.2824\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2578.9844 - val_loss: 97.6922\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6537.1484 - val_loss: 95.9489\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47210.5000 - val_loss: 96.8307\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc8e1a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 52 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 61780.7383 - val_loss: 89.6516\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 135834.8125 - val_loss: 92.3785\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 80803.2578 - val_loss: 97.7551\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27559.2930 - val_loss: 98.5120\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4832.6221 - val_loss: 95.0742\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 53672.7812 - val_loss: 94.7775\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 41876.9688 - val_loss: 97.7950\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15717.3916 - val_loss: 97.4462\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3088.4434 - val_loss: 98.7167\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29991.3125 - val_loss: 97.9666\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11615.8564 - val_loss: 94.1480\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48292.8984 - val_loss: 94.7867\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36039.0703 - val_loss: 97.4743\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5649.0117 - val_loss: 96.7665\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5552.9697 - val_loss: 98.9827\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48353.7852 - val_loss: 99.4437\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12810.5840 - val_loss: 95.8809\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64491.8242 - val_loss: 93.2325\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52261.5508 - val_loss: 95.5968\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9708.3779 - val_loss: 99.5111\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 85289.4688 - val_loss: 101.4231\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 80129.7656 - val_loss: 98.3570\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15318.3242 - val_loss: 95.4213\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53651.0742 - val_loss: 93.7268\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35348.6641 - val_loss: 95.3578\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22684.8457 - val_loss: 100.0485\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 78675.0312 - val_loss: 101.2278\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 74460.6328 - val_loss: 100.2518\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 51558.7188 - val_loss: 97.4574\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6261.6064 - val_loss: 93.7329\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 83875.2812 - val_loss: 93.2040\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 62461.8750 - val_loss: 94.3196\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38403.2188 - val_loss: 97.7231\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29809.8984 - val_loss: 98.3291\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32222.7305 - val_loss: 97.3351\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1764.1566 - val_loss: 96.9065\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11059.4043 - val_loss: 96.7872\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1929.1562 - val_loss: 97.1102\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10735.1914 - val_loss: 96.4637\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4903.1646 - val_loss: 97.1272\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12518.1221 - val_loss: 96.7306\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11212.9678 - val_loss: 96.4837\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5282.5625 - val_loss: 98.6455\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 62125.6562 - val_loss: 99.5156\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47239.6523 - val_loss: 98.6164\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21957.5801 - val_loss: 96.4985\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18757.7949 - val_loss: 95.7836\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32467.5488 - val_loss: 95.8344\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9214.3906 - val_loss: 97.0980\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24709.6230 - val_loss: 98.3264\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe1789e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 53 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 75.9608 - val_loss: 52.0279\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.7451 - val_loss: 7.0964\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27.3825 - val_loss: 19.6273\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21.2367 - val_loss: 31.3274\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20.7390 - val_loss: 24.7530\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.6673 - val_loss: 14.3991\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.4526 - val_loss: 13.1093\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.5062 - val_loss: 18.4359\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.8468 - val_loss: 12.5716\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.8991 - val_loss: 7.9121\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.7261 - val_loss: 10.3664\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.0321 - val_loss: 4.8398\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5603 - val_loss: 3.0501\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2311 - val_loss: 4.2554\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3928 - val_loss: 3.1395\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.0581 - val_loss: 4.2992\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2914 - val_loss: 2.8595\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2996 - val_loss: 5.0850\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.1000 - val_loss: 2.8765\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6938 - val_loss: 4.0082\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7542 - val_loss: 2.9786\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0713 - val_loss: 2.9329\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9992 - val_loss: 2.8985\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.6195 - val_loss: 3.2572\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3689 - val_loss: 3.2191\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2836 - val_loss: 3.0630\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0763 - val_loss: 2.7470\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9285 - val_loss: 3.3731\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8157 - val_loss: 2.7292\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5790 - val_loss: 2.7558\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6594 - val_loss: 3.4522\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6850 - val_loss: 3.1332\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1259 - val_loss: 2.7174\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.3619 - val_loss: 3.4926\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0282 - val_loss: 2.6144\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9364 - val_loss: 2.4100\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.5154 - val_loss: 2.7707\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2162 - val_loss: 2.8107\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.4111 - val_loss: 3.4053\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4264 - val_loss: 2.4392\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.2490 - val_loss: 2.4671\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5370 - val_loss: 2.7259\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.3874 - val_loss: 2.6034\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1640 - val_loss: 3.3259\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.0178 - val_loss: 2.5596\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.8554 - val_loss: 2.8012\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9394 - val_loss: 2.3587\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9218 - val_loss: 2.9493\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.2472 - val_loss: 3.2320\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.0194 - val_loss: 2.6567\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd9985280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 54 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 124558.3125 - val_loss: 102.8043\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 100177.0391 - val_loss: 97.4380\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 65707.7031 - val_loss: 95.3251\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34618.0586 - val_loss: 97.6517\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 107142.7344 - val_loss: 99.5596\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 93638.7656 - val_loss: 96.3686\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 58758.7500 - val_loss: 95.0726\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12994.1875 - val_loss: 97.5603\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43527.4375 - val_loss: 97.8490\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49478.6562 - val_loss: 96.8477\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40697.4570 - val_loss: 94.5233\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 67288.3047 - val_loss: 95.5071\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1777.2335 - val_loss: 95.6303\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22699.9570 - val_loss: 95.5570\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13843.8730 - val_loss: 96.2233\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37666.8555 - val_loss: 95.5960\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6961.3892 - val_loss: 95.4954\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1264.3707 - val_loss: 94.4721\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38554.9961 - val_loss: 95.0499\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6719.0171 - val_loss: 95.2726\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22798.9180 - val_loss: 94.7903\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16741.9629 - val_loss: 96.5649\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 64301.6641 - val_loss: 97.1060\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40114.7266 - val_loss: 96.1380\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 26217.8086 - val_loss: 94.4164\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 85924.2344 - val_loss: 94.8102\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53611.9375 - val_loss: 96.3632\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12410.7334 - val_loss: 96.3194\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13054.0986 - val_loss: 95.8608\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23908.9629 - val_loss: 96.4119\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13757.1562 - val_loss: 97.0811\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19449.3809 - val_loss: 96.5898\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23832.2188 - val_loss: 96.4095\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4164.6230 - val_loss: 96.6543\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6393.6919 - val_loss: 96.0645\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40554.8164 - val_loss: 95.6683\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19517.1719 - val_loss: 97.0907\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 65052.0312 - val_loss: 97.5807\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 52096.3398 - val_loss: 96.7359\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1994.8351 - val_loss: 95.2484\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 66061.6562 - val_loss: 94.7099\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 63893.8438 - val_loss: 95.6763\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29239.9434 - val_loss: 97.6742\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55481.2305 - val_loss: 98.0362\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 58569.8750 - val_loss: 97.5850\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16239.6250 - val_loss: 96.1683\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11851.8252 - val_loss: 96.7650\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13653.5000 - val_loss: 96.5242\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12334.7764 - val_loss: 96.1654\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15906.3408 - val_loss: 96.7086\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6f86820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 55 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 7133.2739 - val_loss: 118.2793\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 282255.8438 - val_loss: 118.1263\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 197813.7656 - val_loss: 111.2791\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 68964.4766 - val_loss: 104.5329\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4764.0205 - val_loss: 102.1647\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17008.4531 - val_loss: 104.4789\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36964.1602 - val_loss: 104.0142\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12730.3867 - val_loss: 100.6726\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41412.3242 - val_loss: 100.8589\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37258.7617 - val_loss: 103.3723\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21585.0898 - val_loss: 103.2881\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 600.2252 - val_loss: 100.8915\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 69322.7031 - val_loss: 99.4198\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 61814.8281 - val_loss: 103.0853\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4896.5034 - val_loss: 103.0526\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4706.8057 - val_loss: 102.3570\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28178.0000 - val_loss: 101.2283\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27441.1523 - val_loss: 103.2659\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19722.3496 - val_loss: 103.1481\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3768.5295 - val_loss: 103.0286\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14123.6484 - val_loss: 103.2887\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10639.5342 - val_loss: 101.2054\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41463.2383 - val_loss: 100.8537\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25687.8262 - val_loss: 102.9216\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27519.9062 - val_loss: 103.8985\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21263.4844 - val_loss: 101.9252\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12512.9766 - val_loss: 102.2751\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4723.6982 - val_loss: 103.9671\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25718.9297 - val_loss: 103.4640\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16874.6523 - val_loss: 101.4163\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34966.6562 - val_loss: 101.0035\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27541.6016 - val_loss: 103.3705\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38522.0000 - val_loss: 104.2107\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27252.0723 - val_loss: 101.6480\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22199.6895 - val_loss: 101.2255\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21119.4102 - val_loss: 101.9447\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1753.4768 - val_loss: 104.4578\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61677.6172 - val_loss: 105.4566\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56383.0781 - val_loss: 104.5075\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30273.9941 - val_loss: 102.2048\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29594.8281 - val_loss: 100.8309\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16447.8926 - val_loss: 101.8485\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11264.0977 - val_loss: 102.8966\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17337.0059 - val_loss: 102.6427\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3202.5525 - val_loss: 102.0370\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 343.8722 - val_loss: 102.5157\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21940.3105 - val_loss: 103.2239\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21952.2129 - val_loss: 102.8078\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5056.0366 - val_loss: 101.8787\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 1742.4095 - val_loss: 102.3788\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc34d9040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 56 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 131985.8906 - val_loss: 96.2353\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 68288.4609 - val_loss: 101.0241\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35127.9648 - val_loss: 93.1634\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 67655.3438 - val_loss: 91.4696\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 65614.1094 - val_loss: 92.3719\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26912.2598 - val_loss: 95.8528\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19714.0977 - val_loss: 96.3323\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28737.6484 - val_loss: 94.8618\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5869.4639 - val_loss: 95.3834\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11370.1807 - val_loss: 94.3649\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18891.0820 - val_loss: 94.7561\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3351.9326 - val_loss: 94.3743\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19508.1719 - val_loss: 94.7812\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4942.2471 - val_loss: 97.6206\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 66279.2891 - val_loss: 98.4138\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52040.6953 - val_loss: 96.9602\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3462.9766 - val_loss: 94.5484\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 61435.6367 - val_loss: 91.9536\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57411.2031 - val_loss: 93.4273\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22705.3906 - val_loss: 95.8855\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39187.5273 - val_loss: 97.3275\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35409.5977 - val_loss: 95.0725\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16649.2910 - val_loss: 94.7378\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6357.5283 - val_loss: 95.4746\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32301.9512 - val_loss: 96.8339\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29239.1406 - val_loss: 95.0513\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16389.8672 - val_loss: 94.8460\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6256.9932 - val_loss: 95.5517\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2716.0066 - val_loss: 95.9800\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12078.2471 - val_loss: 95.2164\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4726.9961 - val_loss: 95.7638\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10554.4834 - val_loss: 95.5391\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1658.7416 - val_loss: 93.6212\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56599.0781 - val_loss: 92.8918\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39508.3789 - val_loss: 94.0653\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29527.2793 - val_loss: 97.0394\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46378.3164 - val_loss: 97.9917\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49784.9219 - val_loss: 97.4580\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33048.4141 - val_loss: 96.0543\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5624.8164 - val_loss: 94.1860\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41060.8828 - val_loss: 93.9632\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41381.0117 - val_loss: 94.8932\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20014.4590 - val_loss: 96.6454\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22462.3242 - val_loss: 96.9461\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14291.2500 - val_loss: 95.9312\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3483.6411 - val_loss: 96.0232\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 210.2596 - val_loss: 96.6672\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20699.0684 - val_loss: 96.7618\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11480.0059 - val_loss: 96.2549\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1854.8383 - val_loss: 95.8214\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfddce35e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 57 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 85.3628 - val_loss: 65.0606\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.3605 - val_loss: 17.9605\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32.5206 - val_loss: 17.1115\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23.3346 - val_loss: 28.1489\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.4406 - val_loss: 26.6102\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17.7414 - val_loss: 17.5669\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.7881 - val_loss: 14.9120\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.4821 - val_loss: 16.3126\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.2925 - val_loss: 9.2933\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.2306 - val_loss: 6.1070\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1061 - val_loss: 2.8626\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0077 - val_loss: 2.8840\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9723 - val_loss: 4.0847\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8679 - val_loss: 2.9282\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.2476 - val_loss: 4.7925\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6365 - val_loss: 3.1347\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6459 - val_loss: 4.6886\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6811 - val_loss: 3.0871\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3315 - val_loss: 3.4958\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3697 - val_loss: 5.1067\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8310 - val_loss: 3.5443\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6323 - val_loss: 4.2016\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.3137 - val_loss: 4.0773\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0837 - val_loss: 3.1177\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8864 - val_loss: 3.9142\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5917 - val_loss: 3.4994\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7439 - val_loss: 3.0143\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4744 - val_loss: 3.6661\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1514 - val_loss: 3.3209\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1669 - val_loss: 3.6440\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1433 - val_loss: 3.3841\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.0450 - val_loss: 4.2083\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2601 - val_loss: 3.6037\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.0540 - val_loss: 3.2930\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8926 - val_loss: 3.5960\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.9473 - val_loss: 3.6609\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9292 - val_loss: 3.9410\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9387 - val_loss: 3.6938\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8113 - val_loss: 4.1140\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8333 - val_loss: 3.1312\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8524 - val_loss: 3.2323\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.0200 - val_loss: 3.1605\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.6571 - val_loss: 3.1932\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9548 - val_loss: 4.4832\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2107 - val_loss: 3.8787\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.0963 - val_loss: 3.8927\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2248 - val_loss: 3.0128\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.4984 - val_loss: 3.5340\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9031 - val_loss: 3.8985\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2788 - val_loss: 3.1184\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc8e2f5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 58 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 4769036.0000 - val_loss: 109.6772\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3798569.2500 - val_loss: 108.3048\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4219948.0000 - val_loss: 107.1450\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3840302.7500 - val_loss: 105.6518\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1624805.0000 - val_loss: 103.9645\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1228269.1250 - val_loss: 102.7280\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1055012.8750 - val_loss: 101.7600\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 496681.0000 - val_loss: 100.8463\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 159204.0625 - val_loss: 99.7889\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 512572.2188 - val_loss: 98.8779\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 688603.0625 - val_loss: 98.0400\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 229689.0781 - val_loss: 97.1263\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 188828.9062 - val_loss: 96.2776\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 158004.3906 - val_loss: 95.4906\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 445555.9375 - val_loss: 94.7616\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 635558.7500 - val_loss: 94.0072\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 328361.0938 - val_loss: 93.1197\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 221775.2656 - val_loss: 92.3398\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 407338.7812 - val_loss: 91.5571\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 748324.1875 - val_loss: 90.7973\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1212388.2500 - val_loss: 90.1463\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 354542.0938 - val_loss: 89.3944\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 259917.7969 - val_loss: 88.7680\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 207981.0469 - val_loss: 88.1348\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 344540.8438 - val_loss: 87.4565\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 103020.5078 - val_loss: 86.7783\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 365437.3125 - val_loss: 86.1019\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 149828.5469 - val_loss: 85.4976\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 214268.3594 - val_loss: 84.9225\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 481171.2500 - val_loss: 84.3537\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 562905.8125 - val_loss: 83.8314\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 147740.6406 - val_loss: 83.3501\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 361116.8438 - val_loss: 82.8468\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 588201.6875 - val_loss: 82.4498\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 238187.9688 - val_loss: 82.0622\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 399577.3125 - val_loss: 81.6638\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 565204.5000 - val_loss: 81.2894\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 183409.7500 - val_loss: 80.9171\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 120796.9844 - val_loss: 80.5184\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 126526.5000 - val_loss: 80.1098\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 313272.3125 - val_loss: 79.7063\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 516994.0000 - val_loss: 79.3627\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 263742.2500 - val_loss: 79.0537\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 160250.0000 - val_loss: 78.7502\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 393119.1875 - val_loss: 78.4300\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 466178.6250 - val_loss: 78.1095\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 196807.3594 - val_loss: 77.8734\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 118044.9766 - val_loss: 77.5008\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 157611.3750 - val_loss: 77.1209\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 144928.7969 - val_loss: 76.7703\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7f919d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 59 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 98.0585 - val_loss: 67.8428\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39.6472 - val_loss: 9.9749\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 41.0631 - val_loss: 18.4873\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 27.6075 - val_loss: 36.4609\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27.2812 - val_loss: 31.4567\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21.0265 - val_loss: 16.4320\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.9222 - val_loss: 12.7495\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.0687 - val_loss: 20.1466\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.0524 - val_loss: 12.2703\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.2304 - val_loss: 6.8665\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.8861 - val_loss: 8.7061\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.0742 - val_loss: 5.7546\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.5372 - val_loss: 8.0154\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.9369 - val_loss: 5.6084\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6557 - val_loss: 8.1573\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3535 - val_loss: 4.2146\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.5741 - val_loss: 7.6497\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9022 - val_loss: 3.6559\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7697 - val_loss: 6.8660\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6534 - val_loss: 4.1465\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.2887 - val_loss: 6.2218\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.0826 - val_loss: 5.1632\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.8261 - val_loss: 6.8585\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9074 - val_loss: 4.2837\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6225 - val_loss: 6.3850\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4398 - val_loss: 5.0627\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2464 - val_loss: 6.1850\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2376 - val_loss: 4.8288\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9585 - val_loss: 7.0966\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9964 - val_loss: 3.3003\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.9403 - val_loss: 6.2436\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7762 - val_loss: 3.9906\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.6148 - val_loss: 5.2896\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9494 - val_loss: 5.0009\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1918 - val_loss: 3.6656\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.1982 - val_loss: 5.0764\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.1758 - val_loss: 4.8972\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0418 - val_loss: 2.7121\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2617 - val_loss: 4.7044\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8319 - val_loss: 3.2079\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.9498 - val_loss: 3.7325\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7146 - val_loss: 5.1840\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.9548 - val_loss: 2.4775\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5436 - val_loss: 3.7923\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.2927 - val_loss: 2.4816\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6384 - val_loss: 4.8170\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1795 - val_loss: 3.1199\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0030 - val_loss: 2.6630\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8791 - val_loss: 4.6894\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9564 - val_loss: 3.6370\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbc0850d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 60 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 82.3211 - val_loss: 64.2209\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38.2790 - val_loss: 23.7325\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.9353 - val_loss: 26.2049\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26.7613 - val_loss: 33.9504\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.3803 - val_loss: 26.1758\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.0337 - val_loss: 15.3811\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.3443 - val_loss: 15.1227\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.5420 - val_loss: 6.1685\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.9412 - val_loss: 5.5790\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.1476 - val_loss: 7.2578\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.5905 - val_loss: 11.0121\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.9519 - val_loss: 6.3059\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.8770 - val_loss: 9.1736\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.5715 - val_loss: 5.4338\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.1090 - val_loss: 3.5547\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.2483 - val_loss: 6.5251\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6473 - val_loss: 5.7932\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.7524 - val_loss: 3.8567\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1247 - val_loss: 4.8133\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.0024 - val_loss: 4.6738\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9166 - val_loss: 3.5358\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9027 - val_loss: 3.6936\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.7287 - val_loss: 4.6300\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.4332 - val_loss: 2.7358\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2828 - val_loss: 4.4237\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0518 - val_loss: 3.2689\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7353 - val_loss: 3.5030\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4830 - val_loss: 4.0544\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.9121 - val_loss: 3.1228\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4421 - val_loss: 2.9266\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6196 - val_loss: 4.8604\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6068 - val_loss: 2.9788\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.3287 - val_loss: 3.5936\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8665 - val_loss: 2.8940\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.5524 - val_loss: 3.0732\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4336 - val_loss: 3.1345\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3390 - val_loss: 2.7390\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.6938 - val_loss: 2.6347\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.1627 - val_loss: 3.0106\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8004 - val_loss: 3.5497\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4149 - val_loss: 3.3212\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9354 - val_loss: 4.5756\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.2005 - val_loss: 3.0918\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8581 - val_loss: 3.5473\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9789 - val_loss: 2.7513\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.9527 - val_loss: 3.0862\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9212 - val_loss: 3.3657\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4919 - val_loss: 2.8616\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2330 - val_loss: 2.5094\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0946 - val_loss: 2.2596\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe6b190d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 61 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 135630.4062 - val_loss: 83.8360\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67976.0469 - val_loss: 86.4926\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18132.1270 - val_loss: 82.5818\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26911.8574 - val_loss: 83.0097\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25295.6816 - val_loss: 87.3856\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61452.8359 - val_loss: 88.2838\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28976.6309 - val_loss: 85.2995\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 44076.1758 - val_loss: 83.3801\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31843.8223 - val_loss: 85.7114\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5108.4980 - val_loss: 91.7680\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 87942.4688 - val_loss: 92.4567\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 93804.7656 - val_loss: 91.1818\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 64778.6641 - val_loss: 87.2115\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39504.5781 - val_loss: 86.1181\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25377.8906 - val_loss: 88.0014\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31880.4121 - val_loss: 89.6380\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24694.5938 - val_loss: 86.4161\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 68776.3516 - val_loss: 85.2595\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39638.2383 - val_loss: 87.4600\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7956.9385 - val_loss: 92.7167\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 90637.1562 - val_loss: 94.1961\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 99773.6016 - val_loss: 93.8072\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 76095.5781 - val_loss: 91.4934\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20838.1445 - val_loss: 88.9333\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28682.1113 - val_loss: 88.8781\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36525.1055 - val_loss: 89.6755\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22451.7480 - val_loss: 92.8507\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61283.9688 - val_loss: 93.8254\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54442.9023 - val_loss: 91.5446\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6700.4053 - val_loss: 91.0169\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5891.5190 - val_loss: 90.8708\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11624.3408 - val_loss: 90.9510\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3023.2131 - val_loss: 90.6048\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13192.2861 - val_loss: 91.0411\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 551.0696 - val_loss: 92.7478\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42377.9727 - val_loss: 92.7435\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32321.4746 - val_loss: 91.9927\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17905.1016 - val_loss: 89.7208\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41519.9414 - val_loss: 89.4588\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41698.1758 - val_loss: 90.7771\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4628.8174 - val_loss: 92.1164\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39053.9883 - val_loss: 93.1780\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31797.4414 - val_loss: 91.6726\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21106.0293 - val_loss: 91.0150\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16755.6914 - val_loss: 92.9292\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35640.8945 - val_loss: 93.3481\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28573.2402 - val_loss: 92.8912\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19949.4805 - val_loss: 90.5382\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62857.0391 - val_loss: 89.5300\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53142.4766 - val_loss: 90.6342\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfdd806700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 62 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 102.8846 - val_loss: 84.9969\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 61.4420 - val_loss: 43.8569\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33.0177 - val_loss: 10.4397\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.3638 - val_loss: 29.4395\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25.1403 - val_loss: 33.7684\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.6567 - val_loss: 25.5452\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.4392 - val_loss: 16.7802\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.2555 - val_loss: 20.9704\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.7714 - val_loss: 18.5603\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.4648 - val_loss: 13.7044\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.2877 - val_loss: 16.0254\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.6992 - val_loss: 8.2168\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.2433 - val_loss: 10.5355\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.7031 - val_loss: 9.4514\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.7401 - val_loss: 5.1136\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2543 - val_loss: 7.5864\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.6960 - val_loss: 4.0326\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0346 - val_loss: 5.9255\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8289 - val_loss: 3.5224\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3498 - val_loss: 4.4092\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7904 - val_loss: 3.1833\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.4585 - val_loss: 4.3120\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0039 - val_loss: 3.1475\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1068 - val_loss: 5.0669\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5869 - val_loss: 2.9611\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4566 - val_loss: 2.9342\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0075 - val_loss: 3.7347\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8066 - val_loss: 2.9017\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6975 - val_loss: 2.9133\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6743 - val_loss: 3.1335\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4022 - val_loss: 3.3412\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5129 - val_loss: 3.0964\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9779 - val_loss: 3.6822\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6480 - val_loss: 5.0737\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9565 - val_loss: 2.8622\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2264 - val_loss: 2.9279\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1237 - val_loss: 2.9964\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0218 - val_loss: 2.7888\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.9073 - val_loss: 4.2323\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6613 - val_loss: 2.7264\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9086 - val_loss: 3.1894\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.1690 - val_loss: 4.8559\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5083 - val_loss: 2.6934\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.0686 - val_loss: 2.6911\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7277 - val_loss: 2.9821\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6391 - val_loss: 3.1620\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8124 - val_loss: 4.1538\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0788 - val_loss: 3.7075\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1219 - val_loss: 2.6211\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7488 - val_loss: 2.5068\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbbf28790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 63 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 1260089.5000 - val_loss: 92.4166\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5055188.0000 - val_loss: 91.2612\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4925738.5000 - val_loss: 90.2322\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1886312.2500 - val_loss: 89.4010\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1012658.3125 - val_loss: 88.8187\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 395197.2188 - val_loss: 88.1214\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 618305.2500 - val_loss: 87.3873\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 994390.9375 - val_loss: 86.7961\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1642555.3750 - val_loss: 86.0499\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 405441.9062 - val_loss: 85.3344\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 336231.0000 - val_loss: 84.5913\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 329950.1562 - val_loss: 83.8605\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 706764.8125 - val_loss: 83.0182\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 497228.5312 - val_loss: 82.3877\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 447165.6875 - val_loss: 81.6771\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 822662.9375 - val_loss: 81.0370\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 917143.5000 - val_loss: 80.4431\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 761342.4375 - val_loss: 79.8292\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 282087.4062 - val_loss: 79.2976\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 425221.9062 - val_loss: 78.7287\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 322764.4688 - val_loss: 78.1576\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 186496.0312 - val_loss: 77.6322\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 255596.6094 - val_loss: 76.9409\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 529913.0625 - val_loss: 76.3072\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 600009.8750 - val_loss: 75.8852\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 163709.2031 - val_loss: 75.3472\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 417567.4062 - val_loss: 74.8576\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 566907.6875 - val_loss: 74.3656\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 437079.0000 - val_loss: 73.9153\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 585408.5000 - val_loss: 73.5694\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 493076.4688 - val_loss: 73.2303\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 449000.9062 - val_loss: 72.9292\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 152111.4688 - val_loss: 72.4235\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 184138.3750 - val_loss: 71.9599\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 147371.2188 - val_loss: 71.5377\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 141018.6562 - val_loss: 71.0942\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 185117.5781 - val_loss: 70.6561\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 163846.9375 - val_loss: 70.2099\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 162399.0156 - val_loss: 69.7901\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 144871.2031 - val_loss: 69.2974\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 156813.3281 - val_loss: 68.9386\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 448560.1562 - val_loss: 68.5466\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 496899.5938 - val_loss: 68.2306\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 331646.5938 - val_loss: 67.9869\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 539456.7500 - val_loss: 67.7030\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 226605.8906 - val_loss: 67.4613\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 251680.5469 - val_loss: 67.2069\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 257394.3125 - val_loss: 66.9731\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 228210.0000 - val_loss: 66.6859\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 244192.7969 - val_loss: 66.3683\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd2bc0040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 64 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 27601.6055 - val_loss: 78.7581\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 163531.2031 - val_loss: 75.4846\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 114143.7344 - val_loss: 82.7227\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32212.7246 - val_loss: 85.7056\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16350.6064 - val_loss: 84.7551\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26622.7910 - val_loss: 85.4837\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16914.7363 - val_loss: 86.4363\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45900.6758 - val_loss: 88.1571\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27815.3594 - val_loss: 87.2400\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17553.0059 - val_loss: 86.9666\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12670.4287 - val_loss: 88.1880\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21939.3320 - val_loss: 88.3071\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9329.0352 - val_loss: 87.3429\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26868.5215 - val_loss: 87.4857\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17710.0215 - val_loss: 88.8618\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23997.8203 - val_loss: 88.9303\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10950.0664 - val_loss: 88.0308\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36556.1250 - val_loss: 87.7217\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30176.7441 - val_loss: 89.4991\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21709.9961 - val_loss: 89.6633\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10482.8018 - val_loss: 88.9061\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27605.9473 - val_loss: 88.8774\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20628.9863 - val_loss: 90.3528\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38349.5312 - val_loss: 90.9292\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31885.5723 - val_loss: 89.5149\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47914.5000 - val_loss: 89.0600\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35028.0039 - val_loss: 90.6018\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6937.9507 - val_loss: 91.2670\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3933.4705 - val_loss: 90.8313\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14936.2686 - val_loss: 91.1425\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8997.0938 - val_loss: 92.1311\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28553.1934 - val_loss: 92.2351\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20743.3535 - val_loss: 91.3160\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30110.7012 - val_loss: 91.0694\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9450.5537 - val_loss: 92.0961\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27799.3066 - val_loss: 93.1698\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32305.6504 - val_loss: 93.1545\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18282.3242 - val_loss: 92.2944\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21026.9844 - val_loss: 92.2664\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19543.1719 - val_loss: 92.9299\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4066.5530 - val_loss: 92.8718\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4904.3384 - val_loss: 93.3017\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9350.1553 - val_loss: 93.0120\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4889.6230 - val_loss: 93.3063\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16694.8281 - val_loss: 93.5127\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2767.0227 - val_loss: 92.5629\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39817.4961 - val_loss: 92.1527\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38590.9883 - val_loss: 93.1206\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8734.8721 - val_loss: 94.0944\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12256.6562 - val_loss: 94.2878\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe7ba88b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 65 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 53.0749 - val_loss: 29.4824\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.9219 - val_loss: 7.0758\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22.4393 - val_loss: 22.9143\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.5833 - val_loss: 22.4429\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.3361 - val_loss: 12.5038\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.8025 - val_loss: 12.3552\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.0527 - val_loss: 12.3084\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.5832 - val_loss: 7.9209\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.8192 - val_loss: 8.2826\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.1361 - val_loss: 2.9408\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7188 - val_loss: 6.3628\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8494 - val_loss: 2.6458\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5881 - val_loss: 3.2739\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3191 - val_loss: 3.3280\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4081 - val_loss: 2.7347\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7062 - val_loss: 5.3940\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3860 - val_loss: 2.2398\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5696 - val_loss: 5.6603\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3857 - val_loss: 2.0942\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1653 - val_loss: 4.2567\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5994 - val_loss: 2.2685\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.4123 - val_loss: 4.2897\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6755 - val_loss: 2.9892\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5602 - val_loss: 3.3950\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9899 - val_loss: 4.8227\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2893 - val_loss: 3.3089\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9496 - val_loss: 3.3947\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8820 - val_loss: 3.3027\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7368 - val_loss: 3.6108\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8505 - val_loss: 2.7020\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4394 - val_loss: 5.1937\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7195 - val_loss: 2.4317\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7348 - val_loss: 3.9980\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1185 - val_loss: 2.7308\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.0018 - val_loss: 3.8394\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.1577 - val_loss: 2.4121\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8901 - val_loss: 4.1939\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9236 - val_loss: 3.3454\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7586 - val_loss: 2.9170\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.5878 - val_loss: 3.8614\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3719 - val_loss: 2.7164\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8434 - val_loss: 5.1362\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7842 - val_loss: 2.4325\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8809 - val_loss: 3.7140\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8162 - val_loss: 2.9776\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6042 - val_loss: 2.8727\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4732 - val_loss: 4.2460\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4027 - val_loss: 2.3314\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1239 - val_loss: 4.4223\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5105 - val_loss: 2.5293\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfdaf3a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 66 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 70.2134 - val_loss: 55.7255\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.7779 - val_loss: 20.6399\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26.1842 - val_loss: 23.9830\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.4408 - val_loss: 29.7159\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.6879 - val_loss: 23.6467\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.6151 - val_loss: 11.7812\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.8405 - val_loss: 13.4700\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.4835 - val_loss: 5.3550\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.6068 - val_loss: 9.3742\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.4539 - val_loss: 3.9317\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3146 - val_loss: 7.3025\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.5175 - val_loss: 6.5066\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7957 - val_loss: 6.9021\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4752 - val_loss: 5.2571\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3466 - val_loss: 4.8546\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1684 - val_loss: 5.1405\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.1225 - val_loss: 4.0207\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.0473 - val_loss: 6.4368\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9764 - val_loss: 4.2515\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.7014 - val_loss: 6.2855\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6511 - val_loss: 4.1914\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5291 - val_loss: 5.7165\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3087 - val_loss: 3.8187\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.3303 - val_loss: 4.5788\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1293 - val_loss: 4.7989\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2138 - val_loss: 3.1708\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1114 - val_loss: 6.9178\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0013 - val_loss: 2.5340\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9750 - val_loss: 7.1762\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8308 - val_loss: 2.2395\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6612 - val_loss: 5.7257\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7058 - val_loss: 1.9249\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3688 - val_loss: 5.8703\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4320 - val_loss: 1.8958\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3879 - val_loss: 3.4431\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6822 - val_loss: 2.7656\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6123 - val_loss: 2.2641\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5924 - val_loss: 2.6907\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.4292 - val_loss: 2.9817\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2229 - val_loss: 2.1791\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0823 - val_loss: 2.5416\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.3186 - val_loss: 3.3738\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2998 - val_loss: 1.6716\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2541 - val_loss: 3.6151\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0812 - val_loss: 2.7423\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8272 - val_loss: 1.7178\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6143 - val_loss: 2.3870\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.3295 - val_loss: 2.3770\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.2488 - val_loss: 1.8632\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.2383 - val_loss: 2.4982\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbd5c9310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 67 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 53.9529 - val_loss: 28.6520\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22.8751 - val_loss: 6.5103\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.6219 - val_loss: 17.0569\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.6186 - val_loss: 20.8089\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.3777 - val_loss: 12.7776\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.4599 - val_loss: 8.3546\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0588 - val_loss: 11.7049\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.7663 - val_loss: 7.2635\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.2258 - val_loss: 7.9869\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9914 - val_loss: 4.5546\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8716 - val_loss: 6.0663\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4196 - val_loss: 5.5568\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6823 - val_loss: 5.5607\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.3510 - val_loss: 4.8519\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1537 - val_loss: 5.1414\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1816 - val_loss: 4.8428\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.1479 - val_loss: 5.3954\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8628 - val_loss: 5.7202\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8719 - val_loss: 5.0267\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9130 - val_loss: 4.7584\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6373 - val_loss: 4.7420\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6156 - val_loss: 5.2694\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7580 - val_loss: 5.4825\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1799 - val_loss: 4.7290\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8610 - val_loss: 6.4191\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3130 - val_loss: 4.8136\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5097 - val_loss: 5.9934\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3451 - val_loss: 4.5932\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7783 - val_loss: 4.7052\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5146 - val_loss: 5.6251\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4792 - val_loss: 4.5963\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2442 - val_loss: 5.0288\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1107 - val_loss: 4.5816\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.0406 - val_loss: 4.6467\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2479 - val_loss: 5.0419\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0563 - val_loss: 4.7039\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.8020 - val_loss: 4.6951\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7642 - val_loss: 4.6954\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.8277 - val_loss: 4.6281\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7655 - val_loss: 4.5218\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8338 - val_loss: 5.2428\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.8676 - val_loss: 4.4860\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.9432 - val_loss: 4.4894\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6570 - val_loss: 4.8602\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.6272 - val_loss: 4.4778\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.6728 - val_loss: 4.6796\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4634 - val_loss: 4.4600\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4652 - val_loss: 4.5888\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4373 - val_loss: 4.4578\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.5361 - val_loss: 4.8211\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6f86dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 68 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 92.4040 - val_loss: 69.3763\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42.1069 - val_loss: 18.2829\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24.1005 - val_loss: 3.2960\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22.3450 - val_loss: 17.8517\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.5070 - val_loss: 23.7134\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.9259 - val_loss: 14.8180\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.6729 - val_loss: 7.6204\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.3040 - val_loss: 13.0232\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.7196 - val_loss: 9.4384\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2774 - val_loss: 5.0299\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2138 - val_loss: 5.2651\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1118 - val_loss: 3.2111\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4178 - val_loss: 3.4314\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7146 - val_loss: 3.6084\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5349 - val_loss: 3.4989\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8546 - val_loss: 4.7816\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0548 - val_loss: 3.7872\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5238 - val_loss: 4.6797\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.0862 - val_loss: 3.4875\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.2178 - val_loss: 4.9496\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3071 - val_loss: 3.9687\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.0602 - val_loss: 4.4813\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7596 - val_loss: 3.5449\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6606 - val_loss: 3.9337\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.2777 - val_loss: 3.5489\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2788 - val_loss: 3.5952\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1672 - val_loss: 3.8267\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1368 - val_loss: 3.6079\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7664 - val_loss: 4.6998\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.7283 - val_loss: 3.5870\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1731 - val_loss: 3.8384\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8777 - val_loss: 3.4923\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8588 - val_loss: 3.5089\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.8216 - val_loss: 3.4878\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.0321 - val_loss: 4.0699\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.8320 - val_loss: 3.5067\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0252 - val_loss: 3.5353\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2387 - val_loss: 4.4761\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.9425 - val_loss: 3.4918\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.9222 - val_loss: 3.5129\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8097 - val_loss: 3.8583\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.7482 - val_loss: 3.5456\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.9856 - val_loss: 3.5848\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.6405 - val_loss: 3.4508\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.5041 - val_loss: 3.3580\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5725 - val_loss: 3.7646\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.6130 - val_loss: 3.3970\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4799 - val_loss: 3.3571\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.5695 - val_loss: 3.5306\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4600 - val_loss: 3.3564\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfecdadc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 69 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 88.7062 - val_loss: 68.0856\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.5222 - val_loss: 20.9460\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26.0260 - val_loss: 5.2864\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22.7575 - val_loss: 19.6536\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.2025 - val_loss: 26.4132\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.8038 - val_loss: 20.5204\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.0854 - val_loss: 10.8725\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.5793 - val_loss: 11.2674\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.7644 - val_loss: 14.8348\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.7932 - val_loss: 9.6174\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6773 - val_loss: 7.7338\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5122 - val_loss: 6.1035\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1151 - val_loss: 4.4337\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6699 - val_loss: 5.0493\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5476 - val_loss: 5.5593\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3353 - val_loss: 5.1905\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1116 - val_loss: 5.2904\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9002 - val_loss: 4.7988\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7137 - val_loss: 4.7849\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3790 - val_loss: 5.1400\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0672 - val_loss: 5.1829\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0047 - val_loss: 5.1595\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7393 - val_loss: 4.9366\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.5482 - val_loss: 5.0048\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.6085 - val_loss: 5.2462\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9803 - val_loss: 4.7490\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.8975 - val_loss: 4.7921\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8021 - val_loss: 5.2417\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8363 - val_loss: 5.1410\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.1570 - val_loss: 5.3321\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.9838 - val_loss: 4.8242\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1476 - val_loss: 4.9388\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8809 - val_loss: 4.6953\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7315 - val_loss: 4.5426\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4086 - val_loss: 4.7210\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3009 - val_loss: 4.6758\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1055 - val_loss: 4.6759\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.0516 - val_loss: 4.5876\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.0679 - val_loss: 4.5197\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.8483 - val_loss: 4.6319\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.0151 - val_loss: 4.3135\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.8837 - val_loss: 4.3253\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.6844 - val_loss: 4.3936\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7249 - val_loss: 4.4104\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7583 - val_loss: 4.3027\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7948 - val_loss: 4.0866\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.6028 - val_loss: 4.1128\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.5171 - val_loss: 4.1322\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.5135 - val_loss: 4.0517\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4270 - val_loss: 3.8877\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7f91a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 70 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 1397629.3750 - val_loss: 80.8077\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 627018.5000 - val_loss: 97.7619\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 532285.8750 - val_loss: 102.5691\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 399344.4062 - val_loss: 98.3071\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43501.5859 - val_loss: 90.4962\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 495830.5312 - val_loss: 87.0471\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 440320.5312 - val_loss: 90.5634\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 184307.8125 - val_loss: 95.6838\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37789.2852 - val_loss: 96.6023\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52572.1289 - val_loss: 94.5972\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 77463.8125 - val_loss: 95.5361\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46744.7734 - val_loss: 97.6534\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 80362.8281 - val_loss: 95.7442\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34965.4492 - val_loss: 96.8986\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27442.7734 - val_loss: 97.9341\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 105801.1406 - val_loss: 97.2431\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 118580.0625 - val_loss: 94.2941\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 142058.8750 - val_loss: 96.1117\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 117011.8516 - val_loss: 100.7341\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 198111.0156 - val_loss: 99.7909\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 89116.5547 - val_loss: 96.4559\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 175945.3438 - val_loss: 95.1538\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 109203.4531 - val_loss: 97.4985\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53390.6211 - val_loss: 98.8592\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33140.4648 - val_loss: 97.3032\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 131289.2031 - val_loss: 95.8531\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 99355.5234 - val_loss: 98.7610\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 136970.8125 - val_loss: 99.7732\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62562.4531 - val_loss: 95.8088\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 149080.5938 - val_loss: 95.0989\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 163215.5781 - val_loss: 97.9321\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57122.7109 - val_loss: 98.1045\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37082.7578 - val_loss: 97.8419\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30687.8164 - val_loss: 98.5017\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 26657.4375 - val_loss: 96.9065\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 101224.1875 - val_loss: 96.1582\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 83351.7891 - val_loss: 99.3839\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 160361.3281 - val_loss: 99.8222\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 94862.8516 - val_loss: 97.5305\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38541.7539 - val_loss: 97.4388\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53139.3516 - val_loss: 98.7938\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49956.1953 - val_loss: 96.9464\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73586.0625 - val_loss: 96.8687\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53528.1133 - val_loss: 99.1208\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 96864.6484 - val_loss: 99.4544\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 70371.0469 - val_loss: 96.6960\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 88080.4688 - val_loss: 97.0096\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46581.1797 - val_loss: 99.0922\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 62840.6367 - val_loss: 98.6267\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23808.6074 - val_loss: 96.3061\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7960dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 71 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 62159.7578 - val_loss: 84.4741\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 96670.3750 - val_loss: 96.5545\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 82358.3516 - val_loss: 88.5799\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10101.9121 - val_loss: 77.0035\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 123919.9609 - val_loss: 75.1767\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 110419.5938 - val_loss: 81.2346\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33231.4492 - val_loss: 87.7587\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27879.0332 - val_loss: 90.9761\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28903.2441 - val_loss: 89.8812\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17614.0488 - val_loss: 86.9541\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12535.8320 - val_loss: 89.4273\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30161.6504 - val_loss: 91.2592\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20657.4922 - val_loss: 86.9657\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35036.8672 - val_loss: 86.4313\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19085.0762 - val_loss: 88.7062\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27162.1816 - val_loss: 92.1479\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26775.0254 - val_loss: 88.5737\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23907.0254 - val_loss: 88.1429\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10785.3252 - val_loss: 92.8245\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45594.9688 - val_loss: 93.8455\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35380.3281 - val_loss: 91.6645\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17350.9531 - val_loss: 85.2104\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 79269.5078 - val_loss: 82.5465\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 65704.1562 - val_loss: 86.7324\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34801.6562 - val_loss: 93.3006\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37799.8008 - val_loss: 94.6419\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 41187.7617 - val_loss: 93.0922\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23027.6816 - val_loss: 88.4993\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25098.1016 - val_loss: 88.5916\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24954.2012 - val_loss: 89.9100\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6856.4370 - val_loss: 91.2810\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1576.1050 - val_loss: 86.7784\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 51457.6562 - val_loss: 86.3922\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48042.3438 - val_loss: 87.8259\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16006.5498 - val_loss: 90.8915\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7006.9229 - val_loss: 93.1236\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24516.9746 - val_loss: 92.9263\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11919.2080 - val_loss: 89.5191\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32824.2305 - val_loss: 88.7671\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28080.5371 - val_loss: 90.7935\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7635.6973 - val_loss: 92.0289\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12451.3604 - val_loss: 91.0732\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2775.8796 - val_loss: 94.8764\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44280.5195 - val_loss: 95.9494\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41210.3984 - val_loss: 94.7402\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20022.7402 - val_loss: 91.3666\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25532.6719 - val_loss: 89.6819\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22734.9980 - val_loss: 90.6064\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9475.2207 - val_loss: 92.6628\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3987.9429 - val_loss: 89.9913\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe9f94a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 72 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 212693.5469 - val_loss: 97.3678\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 186288.5312 - val_loss: 99.6286\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55577.7891 - val_loss: 96.2645\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 82819.2500 - val_loss: 97.6507\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 133338.5938 - val_loss: 96.6887\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22853.4004 - val_loss: 97.8010\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 262200.8750 - val_loss: 97.7933\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 84764.9766 - val_loss: 96.0420\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34327.1758 - val_loss: 98.7020\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 280045.2500 - val_loss: 98.9943\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 113184.7500 - val_loss: 94.7295\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 305473.2812 - val_loss: 93.5520\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 289708.8438 - val_loss: 95.4749\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 44598.3828 - val_loss: 96.9604\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 52805.9023 - val_loss: 95.2280\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 189166.8438 - val_loss: 96.1244\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47504.3750 - val_loss: 96.5400\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75067.9453 - val_loss: 95.0996\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 190952.8750 - val_loss: 96.1720\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 112480.3281 - val_loss: 98.4411\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 82400.7266 - val_loss: 97.2703\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 111484.6484 - val_loss: 97.4510\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38774.9531 - val_loss: 98.2854\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53947.3438 - val_loss: 96.9536\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 114447.0625 - val_loss: 97.2593\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 43311.3711 - val_loss: 98.3436\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 74356.8984 - val_loss: 97.4937\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 87543.2031 - val_loss: 97.6196\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20340.0293 - val_loss: 98.5284\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29933.6738 - val_loss: 98.6106\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13023.8213 - val_loss: 99.0621\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24561.7871 - val_loss: 98.2177\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 86013.1562 - val_loss: 98.6385\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18278.8379 - val_loss: 98.7011\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 125035.7500 - val_loss: 98.0941\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 92093.6562 - val_loss: 99.7541\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 102080.6016 - val_loss: 99.6273\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41880.1602 - val_loss: 97.7588\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 163594.6719 - val_loss: 97.8031\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 97493.5469 - val_loss: 98.8217\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 111415.9219 - val_loss: 99.6663\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50581.4258 - val_loss: 98.6467\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22882.7988 - val_loss: 98.9585\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45013.6523 - val_loss: 98.0384\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57550.2227 - val_loss: 99.1739\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 180082.6250 - val_loss: 99.6783\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 157160.2031 - val_loss: 97.3257\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 118305.5391 - val_loss: 97.0737\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89110.3281 - val_loss: 98.1531\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14891.6201 - val_loss: 97.9945\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfee575af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 73 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 7265.3164 - val_loss: 107.5186\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 326252.8438 - val_loss: 112.3181\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 241321.8125 - val_loss: 105.1941\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 63191.2031 - val_loss: 99.8520\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42734.6211 - val_loss: 95.6666\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 51384.9961 - val_loss: 97.1304\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14630.0264 - val_loss: 99.9709\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 60867.2773 - val_loss: 99.8679\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47025.9727 - val_loss: 98.1887\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5701.3638 - val_loss: 95.0081\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 86926.5234 - val_loss: 93.7306\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 77753.6562 - val_loss: 94.6488\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29954.8184 - val_loss: 97.7723\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32198.1094 - val_loss: 99.3673\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44098.5000 - val_loss: 98.9772\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8589.4336 - val_loss: 97.3544\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6981.1035 - val_loss: 96.4094\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31242.9629 - val_loss: 97.1811\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4113.6245 - val_loss: 98.9174\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 43295.3867 - val_loss: 99.4527\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36391.7188 - val_loss: 98.2424\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7780.1577 - val_loss: 97.7100\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1409.1162 - val_loss: 99.6992\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50092.1914 - val_loss: 99.6228\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 39921.6953 - val_loss: 98.1028\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10567.7314 - val_loss: 97.6422\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1729.3179 - val_loss: 97.1957\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14051.4395 - val_loss: 97.8859\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8059.4937 - val_loss: 97.6261\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18320.7695 - val_loss: 97.3639\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 771.8697 - val_loss: 98.6523\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19429.4004 - val_loss: 98.7443\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21497.5215 - val_loss: 97.3735\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22327.4277 - val_loss: 97.2191\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9708.1367 - val_loss: 99.0720\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 54641.0117 - val_loss: 99.9364\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39225.5742 - val_loss: 98.1380\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22175.5684 - val_loss: 97.0578\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17703.4355 - val_loss: 99.0562\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41497.8984 - val_loss: 99.3843\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34818.1523 - val_loss: 98.1061\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9168.5557 - val_loss: 97.7204\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3556.6545 - val_loss: 97.5879\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14487.8896 - val_loss: 97.6562\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 319.1625 - val_loss: 97.3151\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19673.0176 - val_loss: 97.4959\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5639.3325 - val_loss: 98.9913\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27417.9629 - val_loss: 98.8886\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24434.9473 - val_loss: 97.8549\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9330.9141 - val_loss: 97.8197\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe7ba84c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 74 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 82.0666 - val_loss: 64.7664\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.4437 - val_loss: 22.6267\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36.1812 - val_loss: 20.9641\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27.3882 - val_loss: 30.6036\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23.8779 - val_loss: 25.5347\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.9543 - val_loss: 12.6015\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 14.5122 - val_loss: 16.1684\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.1316 - val_loss: 6.5460\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.7552 - val_loss: 5.3845\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5627 - val_loss: 3.4556\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.1647 - val_loss: 4.0768\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.5557 - val_loss: 3.5043\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8381 - val_loss: 5.5577\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.6017 - val_loss: 4.8348\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.1904 - val_loss: 4.3014\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.0147 - val_loss: 5.2906\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.9723 - val_loss: 3.5183\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.7263 - val_loss: 5.2701\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.6875 - val_loss: 3.4792\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.4101 - val_loss: 4.3399\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.0618 - val_loss: 4.3234\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1736 - val_loss: 3.4669\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.9724 - val_loss: 3.5212\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.9132 - val_loss: 6.4245\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.8141 - val_loss: 3.1111\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.3083 - val_loss: 4.3684\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.8855 - val_loss: 3.5210\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 5.0917 - val_loss: 3.1391\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.3545 - val_loss: 5.9315\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.9205 - val_loss: 3.1495\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.7705 - val_loss: 4.2947\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.5779 - val_loss: 3.7540\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.6519 - val_loss: 3.2410\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.2280 - val_loss: 5.6622\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.0349 - val_loss: 3.2279\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1492 - val_loss: 3.6003\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.5778 - val_loss: 2.9070\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7925 - val_loss: 3.6309\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.4845 - val_loss: 3.7954\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.4066 - val_loss: 2.8899\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.4490 - val_loss: 4.7708\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7271 - val_loss: 2.7542\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.8172 - val_loss: 3.8450\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.5195 - val_loss: 3.4854\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.2843 - val_loss: 2.7711\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.3097 - val_loss: 3.0717\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.1111 - val_loss: 3.4255\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.1053 - val_loss: 2.9997\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.9857 - val_loss: 2.6160\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.0114 - val_loss: 2.6686\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfdaf839d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 75 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 76.6323 - val_loss: 60.0112\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.1641 - val_loss: 20.8432\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 32.6508 - val_loss: 22.6718\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23.3696 - val_loss: 32.4759\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22.1468 - val_loss: 26.8406\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.4639 - val_loss: 12.0344\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.2638 - val_loss: 15.2438\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.2522 - val_loss: 11.6644\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.3722 - val_loss: 5.9215\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.7380 - val_loss: 7.5561\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.6766 - val_loss: 3.8048\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.0390 - val_loss: 4.4659\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3927 - val_loss: 4.0436\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.3008 - val_loss: 4.0329\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7747 - val_loss: 4.4806\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.6854 - val_loss: 3.8112\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9329 - val_loss: 4.5873\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7565 - val_loss: 3.7563\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.0684 - val_loss: 4.6161\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9456 - val_loss: 3.8683\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.9370 - val_loss: 4.2343\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4939 - val_loss: 4.2415\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7788 - val_loss: 3.5132\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1789 - val_loss: 4.3976\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.4758 - val_loss: 3.6813\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0353 - val_loss: 4.3872\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.1627 - val_loss: 3.6613\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4371 - val_loss: 3.3740\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3068 - val_loss: 3.4391\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0194 - val_loss: 3.6374\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8563 - val_loss: 3.5044\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8612 - val_loss: 4.0648\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8160 - val_loss: 4.5859\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8017 - val_loss: 3.9006\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.6942 - val_loss: 3.3368\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3084 - val_loss: 4.4246\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8326 - val_loss: 3.1512\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2331 - val_loss: 3.6098\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.6902 - val_loss: 3.5307\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5896 - val_loss: 3.5966\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4487 - val_loss: 3.7685\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.3407 - val_loss: 3.6702\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0883 - val_loss: 3.8854\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.1897 - val_loss: 4.0836\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3.9818 - val_loss: 4.3723\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.7564 - val_loss: 4.3545\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.8943 - val_loss: 5.2031\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.5158 - val_loss: 4.6914\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.8115 - val_loss: 4.1178\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1034 - val_loss: 4.6921\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe6b19a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 76 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 105855.1406 - val_loss: 76.9046\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 506.1426 - val_loss: 82.1557\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1601.7275 - val_loss: 85.2595\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50886.4648 - val_loss: 85.2832\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33616.9297 - val_loss: 81.7149\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 59980.1172 - val_loss: 80.5616\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41158.4570 - val_loss: 84.8966\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51693.3633 - val_loss: 86.7708\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43460.3125 - val_loss: 85.7386\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23197.6777 - val_loss: 82.0137\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84841.1719 - val_loss: 80.6415\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62576.0117 - val_loss: 83.4732\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38417.6367 - val_loss: 88.1865\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35331.0273 - val_loss: 88.7771\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 42325.2852 - val_loss: 87.8990\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16101.2266 - val_loss: 85.2110\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 46591.4492 - val_loss: 84.7798\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 37980.2656 - val_loss: 86.8171\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6752.7642 - val_loss: 87.2323\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 618.1508 - val_loss: 88.3775\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 28738.3359 - val_loss: 88.4253\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15292.3730 - val_loss: 86.6608\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27300.9629 - val_loss: 86.6213\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23168.9727 - val_loss: 87.4720\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9816.7129 - val_loss: 90.0410\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53863.3086 - val_loss: 90.6905\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50620.5938 - val_loss: 89.5815\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13748.2012 - val_loss: 88.1362\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19872.2520 - val_loss: 87.5326\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18703.2129 - val_loss: 88.1001\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10257.6533 - val_loss: 91.0263\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 66247.8203 - val_loss: 92.1514\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61163.1914 - val_loss: 91.7308\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43449.4609 - val_loss: 89.0770\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16937.9141 - val_loss: 88.8097\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17056.0781 - val_loss: 89.8776\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9730.7822 - val_loss: 90.0906\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1284.6576 - val_loss: 88.8956\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 23833.4785 - val_loss: 89.1417\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19660.7188 - val_loss: 90.1592\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7646.5806 - val_loss: 90.2596\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4172.1504 - val_loss: 90.3026\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7055.6372 - val_loss: 90.5064\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5206.9224 - val_loss: 89.6702\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23007.1309 - val_loss: 89.4867\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12593.4971 - val_loss: 90.3657\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10122.8682 - val_loss: 90.7875\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8072.3091 - val_loss: 89.7962\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23717.2695 - val_loss: 89.6655\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11410.8545 - val_loss: 90.4236\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfecdb43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 77 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 82.3535 - val_loss: 65.7532\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 60.2182 - val_loss: 46.6580\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 42.5936 - val_loss: 47.8362\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.2327 - val_loss: 31.5311\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 34.4890 - val_loss: 20.6447\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29.9554 - val_loss: 29.0920\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 27.6027 - val_loss: 27.6612\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25.3161 - val_loss: 21.8937\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22.2101 - val_loss: 14.0503\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19.9813 - val_loss: 12.1122\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.7056 - val_loss: 7.0944\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.7962 - val_loss: 3.3822\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.3048 - val_loss: 4.4739\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.9400 - val_loss: 3.1848\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.1131 - val_loss: 3.6851\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.5812 - val_loss: 3.1032\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.7051 - val_loss: 2.9846\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.2151 - val_loss: 4.4527\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.8302 - val_loss: 3.2643\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.7913 - val_loss: 3.4083\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.8678 - val_loss: 3.1972\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.9262 - val_loss: 3.1527\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.6724 - val_loss: 3.9273\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.7975 - val_loss: 3.1654\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3473 - val_loss: 3.3484\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.0517 - val_loss: 5.7662\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.7210 - val_loss: 2.9362\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1784 - val_loss: 3.3344\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6174 - val_loss: 3.1362\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1143 - val_loss: 4.0136\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8885 - val_loss: 3.0181\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6671 - val_loss: 4.0531\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.8145 - val_loss: 3.1152\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0752 - val_loss: 4.7982\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9591 - val_loss: 3.3392\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6990 - val_loss: 3.1941\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2359 - val_loss: 3.5957\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.2223 - val_loss: 3.5684\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1083 - val_loss: 3.2838\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9354 - val_loss: 3.6392\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.8403 - val_loss: 3.0832\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.3173 - val_loss: 4.8251\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0663 - val_loss: 2.8658\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2222 - val_loss: 4.8760\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6603 - val_loss: 2.9964\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.4977 - val_loss: 5.7309\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6088 - val_loss: 3.1403\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.6777 - val_loss: 3.7403\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9443 - val_loss: 3.2561\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4631 - val_loss: 4.5705\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe632caf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 78 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 93.1249 - val_loss: 72.1827\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.8648 - val_loss: 23.9722\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.3881 - val_loss: 14.7702\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 27.1690 - val_loss: 28.2016\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23.6152 - val_loss: 32.3746\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 22.2017 - val_loss: 23.6409\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.7892 - val_loss: 13.1544\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.3844 - val_loss: 13.1174\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.9771 - val_loss: 16.2580\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.4247 - val_loss: 12.4567\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.0221 - val_loss: 9.7471\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.5720 - val_loss: 10.2153\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.5435 - val_loss: 5.0893\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.7738 - val_loss: 3.9438\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.5482 - val_loss: 4.3970\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.6891 - val_loss: 2.9352\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.2694 - val_loss: 4.2529\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.9513 - val_loss: 3.4934\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.6885 - val_loss: 3.0450\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7494 - val_loss: 5.5255\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6920 - val_loss: 2.9308\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1665 - val_loss: 3.6114\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6367 - val_loss: 3.1674\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.4931 - val_loss: 4.5509\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1210 - val_loss: 3.5136\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.1403 - val_loss: 3.9274\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.9972 - val_loss: 3.5175\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0237 - val_loss: 3.8167\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.1048 - val_loss: 4.2115\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.9760 - val_loss: 3.5447\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0902 - val_loss: 3.7722\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9492 - val_loss: 3.5846\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.8623 - val_loss: 3.5609\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8127 - val_loss: 3.7144\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9174 - val_loss: 3.4958\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.2318 - val_loss: 3.9094\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.9549 - val_loss: 3.7380\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7424 - val_loss: 4.2797\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8612 - val_loss: 3.3855\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.2392 - val_loss: 3.3065\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0138 - val_loss: 4.1701\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.9872 - val_loss: 3.3960\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7496 - val_loss: 4.1952\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7692 - val_loss: 3.4819\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6867 - val_loss: 3.6634\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5151 - val_loss: 3.3515\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5668 - val_loss: 3.4895\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6677 - val_loss: 3.5381\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5362 - val_loss: 4.4354\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8433 - val_loss: 3.4002\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbd5c95e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 79 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 2653335.2500 - val_loss: 101.4323\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4951468.5000 - val_loss: 99.1978\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3296362.7500 - val_loss: 97.9436\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2744325.2500 - val_loss: 96.7283\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1484886.3750 - val_loss: 95.7664\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 575817.1875 - val_loss: 94.6802\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 689055.5000 - val_loss: 93.7382\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 706338.5625 - val_loss: 92.7441\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 198848.9531 - val_loss: 91.9252\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 462685.0938 - val_loss: 90.8578\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 760222.1250 - val_loss: 90.0248\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 956040.1875 - val_loss: 89.0953\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 742887.0625 - val_loss: 88.2845\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 325346.9062 - val_loss: 87.5644\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 442438.7500 - val_loss: 86.7496\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 771874.8125 - val_loss: 86.0470\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 918503.1875 - val_loss: 85.1872\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 683032.1875 - val_loss: 84.4699\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 887384.1250 - val_loss: 83.8592\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 643071.3750 - val_loss: 83.2965\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 822286.6250 - val_loss: 82.7556\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 618155.5000 - val_loss: 82.1973\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 838803.5000 - val_loss: 81.7175\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 496947.9062 - val_loss: 81.2199\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 231966.9531 - val_loss: 80.7357\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 262777.2188 - val_loss: 80.2168\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 315925.9062 - val_loss: 79.6697\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 107197.8984 - val_loss: 79.0659\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 266414.2188 - val_loss: 78.4331\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 246705.5469 - val_loss: 77.8749\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 298209.6250 - val_loss: 77.3283\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 288164.8125 - val_loss: 76.7333\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 250304.3125 - val_loss: 76.2722\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 297423.0000 - val_loss: 75.8438\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 223680.9688 - val_loss: 75.2903\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 229849.4531 - val_loss: 74.8290\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 309675.7500 - val_loss: 74.2925\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 111056.7266 - val_loss: 73.7568\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 280688.4688 - val_loss: 73.2604\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 273719.2812 - val_loss: 72.8868\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 223227.2969 - val_loss: 72.5195\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 215292.3125 - val_loss: 72.0790\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 66001.4141 - val_loss: 71.5951\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 314426.9688 - val_loss: 71.1501\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 229446.0312 - val_loss: 70.7785\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 264618.5938 - val_loss: 70.4091\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 246076.7344 - val_loss: 70.0702\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 247825.9531 - val_loss: 69.7434\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 291283.8125 - val_loss: 69.4520\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 66317.6719 - val_loss: 69.1257\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6234310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 80 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 46.7942 - val_loss: 22.2670\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 26.5479 - val_loss: 13.3890\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20.7349 - val_loss: 28.2276\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19.6330 - val_loss: 24.9378\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.0037 - val_loss: 16.9082\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.5802 - val_loss: 13.3218\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.1777 - val_loss: 15.1683\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.5163 - val_loss: 7.0784\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7368 - val_loss: 7.2169\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.5334 - val_loss: 2.4104\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.8755 - val_loss: 7.4749\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.9101 - val_loss: 2.0156\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.7738 - val_loss: 5.8892\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.6698 - val_loss: 2.6884\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4584 - val_loss: 2.9096\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.9339 - val_loss: 4.0391\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9390 - val_loss: 2.5328\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8332 - val_loss: 2.7013\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3594 - val_loss: 2.6548\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.2072 - val_loss: 2.8597\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2006 - val_loss: 2.5382\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5948 - val_loss: 2.6103\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0198 - val_loss: 2.9473\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0003 - val_loss: 2.5260\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5355 - val_loss: 2.8493\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.4520 - val_loss: 2.3893\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2688 - val_loss: 2.4872\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2380 - val_loss: 2.5110\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1736 - val_loss: 2.9031\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2667 - val_loss: 2.6694\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4411 - val_loss: 2.4586\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.3429 - val_loss: 2.5561\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0793 - val_loss: 3.1462\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2647 - val_loss: 3.2053\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4541 - val_loss: 2.7904\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7708 - val_loss: 1.9532\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7271 - val_loss: 2.1329\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6300 - val_loss: 2.2355\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5748 - val_loss: 2.2232\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.8816 - val_loss: 3.6434\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.2655 - val_loss: 2.1367\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0894 - val_loss: 2.8499\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7612 - val_loss: 3.8515\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1784 - val_loss: 2.8226\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.7708 - val_loss: 2.7946\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.7767 - val_loss: 2.3584\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.2831 - val_loss: 1.7619\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.2512 - val_loss: 2.2142\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.2019 - val_loss: 2.2873\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2009 - val_loss: 2.0187\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe9e03040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 81 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 4786135.5000 - val_loss: 96.5876\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3909435.0000 - val_loss: 95.9415\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3306549.0000 - val_loss: 95.1720\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2769839.0000 - val_loss: 94.1662\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1560337.6250 - val_loss: 93.4949\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 486092.2188 - val_loss: 92.7994\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 808598.5000 - val_loss: 92.2260\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 604602.5625 - val_loss: 91.6065\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 211882.0469 - val_loss: 90.9218\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 630444.1875 - val_loss: 90.1649\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 691795.7500 - val_loss: 89.5214\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 315498.7500 - val_loss: 88.8261\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 223890.6250 - val_loss: 88.0930\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 213549.0781 - val_loss: 87.4384\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 205040.3281 - val_loss: 86.7637\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 176224.4688 - val_loss: 86.0355\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 234342.8750 - val_loss: 85.3749\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 181556.5000 - val_loss: 84.6412\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 238796.1094 - val_loss: 83.9702\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 182089.5781 - val_loss: 83.2951\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 240477.7656 - val_loss: 82.7090\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 179371.3750 - val_loss: 81.9822\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 235809.3750 - val_loss: 81.1730\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 211501.2344 - val_loss: 80.4824\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 195986.6719 - val_loss: 79.7158\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 178447.7344 - val_loss: 79.0939\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 212575.3438 - val_loss: 78.3206\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 170075.2344 - val_loss: 77.6889\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 232922.4219 - val_loss: 77.0378\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 286011.3125 - val_loss: 76.4597\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 684674.7500 - val_loss: 75.9293\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 578421.0000 - val_loss: 75.3595\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 537199.9375 - val_loss: 74.8257\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 528477.5000 - val_loss: 74.3313\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 580624.8125 - val_loss: 73.8901\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 509511.2188 - val_loss: 73.5642\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 533660.5625 - val_loss: 73.0655\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 502551.0938 - val_loss: 72.7213\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 513375.0625 - val_loss: 72.3464\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 455164.9062 - val_loss: 72.0121\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 128981.8984 - val_loss: 71.6141\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 177581.3750 - val_loss: 71.1822\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 144055.1719 - val_loss: 70.7466\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 170152.1250 - val_loss: 70.2823\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 151754.5781 - val_loss: 69.8194\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 517460.4062 - val_loss: 69.4553\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 489737.8438 - val_loss: 69.1282\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 508943.2188 - val_loss: 68.8392\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 379471.9062 - val_loss: 68.6072\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 432548.7812 - val_loss: 68.4818\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff2484e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 82 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 62677.9609 - val_loss: 114.2867\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 137767.2031 - val_loss: 112.8723\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 68489.7422 - val_loss: 108.8764\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10441.5527 - val_loss: 101.9969\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 101996.8828 - val_loss: 100.4559\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 105022.8750 - val_loss: 101.3288\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 56573.4688 - val_loss: 104.2602\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15050.1807 - val_loss: 106.0943\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12075.4385 - val_loss: 104.4988\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30846.1816 - val_loss: 104.1543\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18438.9121 - val_loss: 106.1430\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36110.4023 - val_loss: 106.3822\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21412.2578 - val_loss: 105.0636\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22227.8418 - val_loss: 104.1247\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9781.0928 - val_loss: 105.0296\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3121.2588 - val_loss: 105.5512\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20863.4570 - val_loss: 105.3266\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6342.7974 - val_loss: 104.5932\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2254.9656 - val_loss: 105.7519\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33710.1680 - val_loss: 105.8965\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23293.7227 - val_loss: 104.0948\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17693.5332 - val_loss: 104.0582\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9192.2549 - val_loss: 105.5420\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38050.4570 - val_loss: 105.9383\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23609.0801 - val_loss: 104.6387\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9917.4854 - val_loss: 104.0254\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4841.9268 - val_loss: 105.0841\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23389.0762 - val_loss: 104.9782\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13626.2422 - val_loss: 103.7591\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9302.1328 - val_loss: 103.9306\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3882.1646 - val_loss: 105.1603\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23068.9004 - val_loss: 104.7279\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13353.7842 - val_loss: 103.3473\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29450.3711 - val_loss: 102.9118\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16457.2949 - val_loss: 103.9346\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19702.6016 - val_loss: 104.6138\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15014.7529 - val_loss: 103.2622\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26909.0703 - val_loss: 102.8209\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19010.6602 - val_loss: 104.1940\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21791.4727 - val_loss: 104.3923\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11649.4326 - val_loss: 103.7270\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13941.9014 - val_loss: 102.9191\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15594.0078 - val_loss: 103.7406\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18134.9746 - val_loss: 104.0385\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12479.2061 - val_loss: 102.0276\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39487.7891 - val_loss: 101.7114\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38270.4492 - val_loss: 102.0114\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16969.3945 - val_loss: 103.8085\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13852.7686 - val_loss: 104.1943\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29239.2539 - val_loss: 104.1063\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfde877f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 83 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 92.3377 - val_loss: 72.4702\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 53.8438 - val_loss: 32.3907\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.3244 - val_loss: 8.5623\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.0775 - val_loss: 15.4222\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.5428 - val_loss: 19.2066\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6349 - val_loss: 8.2335\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4213 - val_loss: 6.9596\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5127 - val_loss: 12.4560\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4420 - val_loss: 9.3946\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5084 - val_loss: 6.5178\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3146 - val_loss: 8.1171\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7304 - val_loss: 6.5324\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.1726 - val_loss: 5.4725\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.7557 - val_loss: 4.4390\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.2172 - val_loss: 5.1965\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.8001 - val_loss: 3.5855\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.8181 - val_loss: 3.3047\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.4084 - val_loss: 6.5868\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.4284 - val_loss: 3.7193\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7569 - val_loss: 4.8212\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.9871 - val_loss: 3.3144\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.5538 - val_loss: 3.2943\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.3715 - val_loss: 3.4588\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.4116 - val_loss: 3.6763\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.4068 - val_loss: 3.6594\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.4445 - val_loss: 3.1913\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.3877 - val_loss: 3.6167\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.5440 - val_loss: 3.9295\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.6793 - val_loss: 3.3757\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4501 - val_loss: 3.7121\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0398 - val_loss: 3.1668\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1144 - val_loss: 3.4780\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.0295 - val_loss: 3.4837\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.0887 - val_loss: 3.4891\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.9935 - val_loss: 3.1475\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.1658 - val_loss: 4.5309\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3403 - val_loss: 3.0655\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.0953 - val_loss: 3.4130\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9851 - val_loss: 3.2611\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.0235 - val_loss: 3.1321\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.9051 - val_loss: 3.2723\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.9177 - val_loss: 3.0916\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.9252 - val_loss: 3.8992\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1397 - val_loss: 3.0895\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.9512 - val_loss: 3.0396\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.8080 - val_loss: 3.1086\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.0033 - val_loss: 3.1160\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.0682 - val_loss: 4.0561\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.1795 - val_loss: 3.2023\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.8584 - val_loss: 3.8270\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7dd1dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 84 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 87.9973 - val_loss: 68.5639\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49.2029 - val_loss: 28.8708\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39.0369 - val_loss: 32.7385\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30.2020 - val_loss: 34.3583\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27.9042 - val_loss: 24.9146\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22.7306 - val_loss: 13.8379\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.4154 - val_loss: 18.5661\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.5303 - val_loss: 9.1839\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.7189 - val_loss: 10.5429\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.8629 - val_loss: 9.3660\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.3768 - val_loss: 9.3718\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.4170 - val_loss: 9.4826\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.8945 - val_loss: 9.4651\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.8809 - val_loss: 10.2123\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.5893 - val_loss: 9.3992\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.4844 - val_loss: 10.4438\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.6683 - val_loss: 9.6368\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.7046 - val_loss: 9.5731\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.1250 - val_loss: 9.6318\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.2541 - val_loss: 9.4409\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.8494 - val_loss: 10.5446\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.6367 - val_loss: 9.4392\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.6416 - val_loss: 10.1101\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.5277 - val_loss: 9.4430\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.1718 - val_loss: 10.0724\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.2490 - val_loss: 9.5753\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.0191 - val_loss: 10.2205\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.2466 - val_loss: 9.2994\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.9879 - val_loss: 10.1299\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.6564 - val_loss: 9.6499\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.4845 - val_loss: 9.2129\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.5813 - val_loss: 9.4346\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.4773 - val_loss: 9.1823\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.3486 - val_loss: 9.8706\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.3780 - val_loss: 9.4855\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.0404 - val_loss: 9.3007\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.2075 - val_loss: 9.2810\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.0461 - val_loss: 8.8963\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.2643 - val_loss: 9.4047\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.1173 - val_loss: 8.8276\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.1702 - val_loss: 9.0801\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.8680 - val_loss: 9.0392\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.5747 - val_loss: 8.5487\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.7560 - val_loss: 8.6136\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.3796 - val_loss: 8.7670\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.4219 - val_loss: 8.3805\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.9144 - val_loss: 8.8234\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.6261 - val_loss: 8.5104\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6004 - val_loss: 8.2624\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.6030 - val_loss: 8.2895\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff0031790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 85 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 95.8543 - val_loss: 73.0297\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44.1656 - val_loss: 19.5403\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29.0370 - val_loss: 10.2966\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24.2855 - val_loss: 24.6213\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.2095 - val_loss: 25.0731\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.8673 - val_loss: 16.7426\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.0734 - val_loss: 12.2846\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.4622 - val_loss: 13.5553\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.1061 - val_loss: 15.6843\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.0214 - val_loss: 9.0600\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.6849 - val_loss: 8.7782\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.9471 - val_loss: 7.2053\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1981 - val_loss: 6.9721\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5565 - val_loss: 7.0079\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8048 - val_loss: 6.3072\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2135 - val_loss: 6.2877\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8295 - val_loss: 7.1440\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5144 - val_loss: 6.7370\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2181 - val_loss: 7.8644\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1355 - val_loss: 6.7373\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.0799 - val_loss: 7.3184\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1897 - val_loss: 7.2045\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9235 - val_loss: 8.1392\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.9284 - val_loss: 6.8724\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6512 - val_loss: 6.9091\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2295 - val_loss: 6.7256\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4166 - val_loss: 6.7618\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.4598 - val_loss: 6.8572\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.0059 - val_loss: 6.6402\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.1546 - val_loss: 6.5387\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8361 - val_loss: 6.6404\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9486 - val_loss: 6.6069\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9484 - val_loss: 6.9070\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8249 - val_loss: 6.5107\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8700 - val_loss: 6.6022\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.7876 - val_loss: 6.3359\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.6883 - val_loss: 6.3789\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.7882 - val_loss: 6.4772\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.8359 - val_loss: 6.3925\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.7466 - val_loss: 6.2816\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7209 - val_loss: 6.9180\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.8156 - val_loss: 6.1675\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.6178 - val_loss: 6.1552\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5019 - val_loss: 6.2493\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.6715 - val_loss: 6.0925\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.5624 - val_loss: 6.2295\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.7149 - val_loss: 6.1526\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4867 - val_loss: 5.9291\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.5051 - val_loss: 5.9811\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.4167 - val_loss: 5.9897\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff3cfaaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 86 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 79.6772 - val_loss: 55.6586\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36.0822 - val_loss: 12.5927\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30.2679 - val_loss: 21.7018\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22.9919 - val_loss: 31.4701\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.5945 - val_loss: 21.6383\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.8538 - val_loss: 15.5125\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.0605 - val_loss: 16.3305\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.4062 - val_loss: 13.7155\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.4846 - val_loss: 9.9038\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.7584 - val_loss: 7.4738\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.8302 - val_loss: 7.3490\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4745 - val_loss: 7.2358\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1117 - val_loss: 8.3309\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.2618 - val_loss: 8.2527\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.6434 - val_loss: 7.4154\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.0497 - val_loss: 7.4635\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.5432 - val_loss: 7.1640\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.1626 - val_loss: 7.1222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0478 - val_loss: 7.2312\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0536 - val_loss: 7.1099\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.6779 - val_loss: 7.1324\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6820 - val_loss: 7.1798\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5549 - val_loss: 7.0961\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4453 - val_loss: 6.9443\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2212 - val_loss: 6.9960\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2200 - val_loss: 6.8305\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2771 - val_loss: 7.1799\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.5702 - val_loss: 6.7108\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1904 - val_loss: 7.2429\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1296 - val_loss: 6.7516\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4046 - val_loss: 7.6633\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5060 - val_loss: 6.5779\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3784 - val_loss: 7.0076\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0606 - val_loss: 6.2392\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7251 - val_loss: 6.3134\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8882 - val_loss: 6.2683\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6802 - val_loss: 6.1243\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.4872 - val_loss: 6.5707\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3871 - val_loss: 6.3217\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.1855 - val_loss: 7.1870\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6636 - val_loss: 6.0793\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0120 - val_loss: 7.5558\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.2262 - val_loss: 5.8310\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2542 - val_loss: 6.1515\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6204 - val_loss: 5.5640\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9756 - val_loss: 5.9953\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9285 - val_loss: 5.6483\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.2875 - val_loss: 5.7200\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1180 - val_loss: 5.4468\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.8205 - val_loss: 6.1564\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfecdb4dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 87 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 118243.2891 - val_loss: 93.9508\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57510.5938 - val_loss: 99.0481\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30074.5625 - val_loss: 92.4001\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 89215.0625 - val_loss: 89.9010\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 79845.6250 - val_loss: 92.9778\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14978.3750 - val_loss: 96.2647\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 24907.2852 - val_loss: 97.2874\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 29614.1016 - val_loss: 96.3078\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 461.8346 - val_loss: 96.0582\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17061.8711 - val_loss: 96.0324\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23264.0859 - val_loss: 94.4832\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8282.2256 - val_loss: 97.2778\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39753.5117 - val_loss: 98.2944\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34302.5273 - val_loss: 97.6158\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8443.8486 - val_loss: 95.9542\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1376.6031 - val_loss: 95.6146\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10852.4414 - val_loss: 96.5369\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6805.2700 - val_loss: 95.6488\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13620.0371 - val_loss: 96.2795\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7474.9087 - val_loss: 96.1350\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13247.5518 - val_loss: 95.9191\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5741.6055 - val_loss: 98.4053\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51653.8672 - val_loss: 99.0824\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46579.8242 - val_loss: 96.9058\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 389.6674 - val_loss: 94.5704\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36419.5078 - val_loss: 94.0462\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38667.3672 - val_loss: 94.5120\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23018.2832 - val_loss: 97.5707\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42823.6992 - val_loss: 98.9442\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42323.8047 - val_loss: 98.1472\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26126.7949 - val_loss: 96.0092\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30767.1309 - val_loss: 95.3148\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25546.1875 - val_loss: 96.3268\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3307.8582 - val_loss: 98.2923\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 46595.8555 - val_loss: 99.0258\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44474.6289 - val_loss: 97.5106\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8979.7900 - val_loss: 95.9991\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19308.7891 - val_loss: 95.3997\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17496.6191 - val_loss: 96.7367\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6276.2324 - val_loss: 96.7168\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3499.9014 - val_loss: 97.2180\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10330.8662 - val_loss: 96.9979\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1539.0177 - val_loss: 97.3631\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8515.4346 - val_loss: 96.9251\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4735.0332 - val_loss: 97.1202\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8934.6240 - val_loss: 97.1124\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2640.1421 - val_loss: 95.8029\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24347.5449 - val_loss: 96.0193\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18451.0996 - val_loss: 96.6073\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3382.4272 - val_loss: 97.0226\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6301280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 88 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 26081.5352 - val_loss: 109.1777\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 214851.8438 - val_loss: 105.8406\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 128266.8516 - val_loss: 102.5331\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 64863.0781 - val_loss: 96.4512\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 112005.2266 - val_loss: 93.4453\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 92254.1172 - val_loss: 96.5997\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14046.2402 - val_loss: 99.7163\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 66597.9375 - val_loss: 100.3318\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69518.9766 - val_loss: 99.9061\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45058.8398 - val_loss: 96.8943\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23415.8906 - val_loss: 96.5743\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35384.0898 - val_loss: 97.9784\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3887.8113 - val_loss: 100.1352\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 63519.2500 - val_loss: 100.5512\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50559.5469 - val_loss: 99.9799\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9230.3887 - val_loss: 97.9219\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 55760.4531 - val_loss: 96.6503\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57851.0508 - val_loss: 97.7490\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29179.1738 - val_loss: 99.4744\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18044.3027 - val_loss: 99.4184\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14685.0674 - val_loss: 98.5060\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29463.6973 - val_loss: 98.1386\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7403.0098 - val_loss: 99.4736\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23406.5820 - val_loss: 99.9497\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28428.5527 - val_loss: 99.3975\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2142.9265 - val_loss: 99.1982\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4806.2593 - val_loss: 98.6169\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18690.1484 - val_loss: 98.7434\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8782.0635 - val_loss: 100.3725\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43586.4062 - val_loss: 100.5028\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38024.6484 - val_loss: 99.9670\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3419.0188 - val_loss: 98.8182\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31519.7012 - val_loss: 97.8262\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40344.3477 - val_loss: 98.3813\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23274.6484 - val_loss: 99.7925\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16626.0195 - val_loss: 99.7043\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12053.2148 - val_loss: 99.3571\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3343.2910 - val_loss: 97.3544\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 70167.7969 - val_loss: 96.7991\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 71504.4766 - val_loss: 97.2234\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 54945.7891 - val_loss: 98.6946\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6448.5244 - val_loss: 100.2273\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 45964.9336 - val_loss: 101.0214\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 46276.2148 - val_loss: 100.6845\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20025.6250 - val_loss: 99.8220\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7868.4458 - val_loss: 99.0575\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13174.9180 - val_loss: 99.5965\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5485.1997 - val_loss: 99.2998\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5838.5537 - val_loss: 99.7353\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10940.8633 - val_loss: 99.5106\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfde877550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 89 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 100.0332 - val_loss: 82.5503\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 55.1281 - val_loss: 46.2455\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.0347 - val_loss: 17.9236\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.9040 - val_loss: 25.9585\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25.7422 - val_loss: 33.1519\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23.8553 - val_loss: 27.4120\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20.0316 - val_loss: 14.1267\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.5684 - val_loss: 18.2023\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.5335 - val_loss: 16.0155\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.1155 - val_loss: 10.8230\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.8641 - val_loss: 10.5516\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.5938 - val_loss: 6.2014\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.4924 - val_loss: 8.1272\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.0460 - val_loss: 5.1025\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.5568 - val_loss: 6.8377\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.7943 - val_loss: 5.4280\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.3849 - val_loss: 7.2921\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.8837 - val_loss: 5.9009\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.7238 - val_loss: 7.2874\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.4180 - val_loss: 6.1447\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6283 - val_loss: 6.2606\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.4318 - val_loss: 5.7058\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3306 - val_loss: 7.1055\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4122 - val_loss: 5.0742\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.1865 - val_loss: 7.2269\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.0476 - val_loss: 5.0914\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.9563 - val_loss: 6.8109\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8681 - val_loss: 5.1702\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2590 - val_loss: 5.8491\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2033 - val_loss: 4.9769\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0501 - val_loss: 5.6024\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.6912 - val_loss: 5.2704\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.5436 - val_loss: 6.0140\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.3895 - val_loss: 4.7211\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.4960 - val_loss: 4.9540\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.3166 - val_loss: 5.2598\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3420 - val_loss: 4.6473\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.8920 - val_loss: 5.6479\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6490 - val_loss: 4.5185\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.4755 - val_loss: 4.4296\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4362 - val_loss: 5.3374\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5480 - val_loss: 4.3534\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0293 - val_loss: 4.8815\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8870 - val_loss: 4.6111\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1988 - val_loss: 4.4607\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5265 - val_loss: 5.0984\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9918 - val_loss: 4.5093\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9236 - val_loss: 4.8115\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3285 - val_loss: 5.0466\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3667 - val_loss: 4.6926\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfeb19d8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 90 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 126862.0234 - val_loss: 88.0717\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 115787.0938 - val_loss: 93.2606\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64735.9062 - val_loss: 86.5785\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9271.1689 - val_loss: 86.6763\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6866.7310 - val_loss: 88.6783\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33920.0703 - val_loss: 88.7930\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16997.3496 - val_loss: 85.8845\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23903.9961 - val_loss: 86.6010\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10275.5615 - val_loss: 88.1093\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6876.3496 - val_loss: 89.0514\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23077.0352 - val_loss: 87.5388\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12506.4502 - val_loss: 88.2694\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7952.3608 - val_loss: 86.6173\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32537.5586 - val_loss: 87.2579\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4110.7866 - val_loss: 87.7562\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17939.8750 - val_loss: 87.5687\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11943.7959 - val_loss: 90.8987\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36768.0977 - val_loss: 90.0426\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21631.7832 - val_loss: 86.7994\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43700.2344 - val_loss: 86.8007\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31685.4336 - val_loss: 90.4879\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36370.6641 - val_loss: 90.9897\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24235.8535 - val_loss: 88.4302\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15677.8984 - val_loss: 88.9928\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7812.8403 - val_loss: 91.2839\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 48172.9531 - val_loss: 92.2978\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33722.2188 - val_loss: 88.9162\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16420.6484 - val_loss: 88.7950\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20495.2070 - val_loss: 90.8126\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18800.9316 - val_loss: 90.6993\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 854.2860 - val_loss: 88.6796\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 27467.0898 - val_loss: 88.8399\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 25918.2520 - val_loss: 90.2277\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15042.2617 - val_loss: 91.1065\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11023.4941 - val_loss: 90.3755\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5827.3086 - val_loss: 90.6178\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2051.1055 - val_loss: 91.9396\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29837.3184 - val_loss: 92.1629\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15404.7061 - val_loss: 89.1419\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59644.7812 - val_loss: 87.6969\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 49018.2109 - val_loss: 89.8451\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16088.8564 - val_loss: 92.9788\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55200.7109 - val_loss: 94.5721\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51954.1016 - val_loss: 92.6706\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2808.9524 - val_loss: 92.0203\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12407.0420 - val_loss: 92.3944\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2558.9895 - val_loss: 91.0590\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23420.9590 - val_loss: 90.9523\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19973.3027 - val_loss: 91.9630\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 654.5803 - val_loss: 91.9363\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe07a6c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 91 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 89.5367 - val_loss: 72.5145\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 68.5609 - val_loss: 50.7126\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56.5966 - val_loss: 46.8143\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.1943 - val_loss: 41.0047\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31.2785 - val_loss: 36.6808\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26.9382 - val_loss: 24.3178\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21.7102 - val_loss: 15.1995\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.3572 - val_loss: 14.1370\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.8735 - val_loss: 6.3762\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.3212 - val_loss: 5.6435\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.8809 - val_loss: 7.6553\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.3279 - val_loss: 6.9495\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.5232 - val_loss: 5.6404\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.5230 - val_loss: 5.6575\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.2792 - val_loss: 6.4613\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.8765 - val_loss: 5.7696\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.7428 - val_loss: 5.7619\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.8940 - val_loss: 5.9999\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.3969 - val_loss: 5.9109\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.9792 - val_loss: 5.4192\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.0744 - val_loss: 6.8640\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5624 - val_loss: 5.3038\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.9760 - val_loss: 6.0876\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.8400 - val_loss: 5.4970\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.0029 - val_loss: 5.5029\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.3598 - val_loss: 5.2724\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.4221 - val_loss: 5.2472\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.7001 - val_loss: 5.1901\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2251 - val_loss: 4.7399\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.0459 - val_loss: 4.7677\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8547 - val_loss: 5.5116\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.8611 - val_loss: 4.5616\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.7804 - val_loss: 4.5154\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4644 - val_loss: 5.0483\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.5060 - val_loss: 4.9735\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1478 - val_loss: 4.6659\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3756 - val_loss: 4.8934\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.8994 - val_loss: 4.4154\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.4708 - val_loss: 5.4803\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.6163 - val_loss: 4.3180\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2701 - val_loss: 4.3384\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4697 - val_loss: 4.9667\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.2694 - val_loss: 4.6868\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.8073 - val_loss: 4.8585\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.0278 - val_loss: 4.3316\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.8396 - val_loss: 4.5597\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9371 - val_loss: 4.1605\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4877 - val_loss: 4.7015\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3254 - val_loss: 4.1741\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.2334 - val_loss: 4.2761\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfdd73b160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 92 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 74.4020 - val_loss: 47.8052\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.6629 - val_loss: 3.2867\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27.7941 - val_loss: 10.2046\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19.1757 - val_loss: 22.2985\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18.3072 - val_loss: 16.8151\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.4412 - val_loss: 6.4910\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.0036 - val_loss: 9.8841\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.3652 - val_loss: 10.0469\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.3536 - val_loss: 4.9805\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.4853 - val_loss: 3.8896\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.0765 - val_loss: 3.9817\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9830 - val_loss: 4.4467\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.4765 - val_loss: 4.2732\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3876 - val_loss: 4.2544\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1602 - val_loss: 4.4059\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6125 - val_loss: 4.2847\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4389 - val_loss: 4.3108\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.5694 - val_loss: 4.3083\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.5120 - val_loss: 4.2657\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.7370 - val_loss: 4.2656\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4424 - val_loss: 4.2591\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.5006 - val_loss: 4.2289\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2734 - val_loss: 4.1938\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4328 - val_loss: 4.1037\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2956 - val_loss: 4.0140\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.7733 - val_loss: 3.8757\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9403 - val_loss: 3.8378\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4747 - val_loss: 3.8393\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2966 - val_loss: 4.8184\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.1869 - val_loss: 4.3436\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9708 - val_loss: 5.8347\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1902 - val_loss: 3.8268\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8906 - val_loss: 4.7150\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.5049 - val_loss: 3.5406\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.4053 - val_loss: 4.4845\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.1048 - val_loss: 3.4756\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.0788 - val_loss: 3.9626\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8268 - val_loss: 3.3855\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7711 - val_loss: 4.3553\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7360 - val_loss: 3.3415\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4921 - val_loss: 3.8912\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.5435 - val_loss: 3.9261\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.3877 - val_loss: 3.2182\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.4091 - val_loss: 4.4204\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.4836 - val_loss: 4.7112\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.3683 - val_loss: 3.1770\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2620 - val_loss: 3.7382\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4328 - val_loss: 4.9955\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3601 - val_loss: 3.0285\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.5313 - val_loss: 3.6974\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7dd1b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 93 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 51.8970 - val_loss: 35.4896\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.1373 - val_loss: 32.6728\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29.4967 - val_loss: 26.6317\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24.7035 - val_loss: 19.1808\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.5219 - val_loss: 5.6264\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.5670 - val_loss: 7.3082\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.5262 - val_loss: 3.7133\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.0316 - val_loss: 7.5226\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.4924 - val_loss: 4.1248\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.8366 - val_loss: 6.4430\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.1090 - val_loss: 3.3319\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.7802 - val_loss: 3.9394\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.6013 - val_loss: 3.5019\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.3645 - val_loss: 3.0263\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.7949 - val_loss: 3.3675\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.0578 - val_loss: 3.3821\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.7706 - val_loss: 3.1320\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.2563 - val_loss: 2.9533\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.1224 - val_loss: 2.8620\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.7151 - val_loss: 3.2117\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5124 - val_loss: 3.4609\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1881 - val_loss: 3.2543\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9412 - val_loss: 5.1183\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5742 - val_loss: 2.7773\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.0344 - val_loss: 3.2082\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6826 - val_loss: 2.5768\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6155 - val_loss: 4.0221\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4935 - val_loss: 2.6313\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.2863 - val_loss: 3.5870\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9696 - val_loss: 2.0687\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8117 - val_loss: 2.0795\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1508 - val_loss: 2.9474\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6064 - val_loss: 3.9931\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3457 - val_loss: 2.7934\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5261 - val_loss: 3.1427\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.3689 - val_loss: 2.1992\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4460 - val_loss: 2.3315\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9563 - val_loss: 2.5518\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8605 - val_loss: 2.2454\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8357 - val_loss: 3.2016\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7177 - val_loss: 2.0669\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3054 - val_loss: 3.6287\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7694 - val_loss: 1.9027\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5881 - val_loss: 2.8024\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1910 - val_loss: 2.3372\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.6562 - val_loss: 3.3782\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9711 - val_loss: 2.1107\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5677 - val_loss: 3.1852\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0184 - val_loss: 2.5994\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6354 - val_loss: 2.6339\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7beb5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 94 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 49.0137 - val_loss: 22.8107\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23.3867 - val_loss: 6.4290\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20.5367 - val_loss: 13.5800\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19.4464 - val_loss: 20.5854\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.8331 - val_loss: 10.1745\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.6357 - val_loss: 5.6337\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.2085 - val_loss: 6.2169\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.0192 - val_loss: 8.6261\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1708 - val_loss: 4.8231\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5700 - val_loss: 5.3563\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3883 - val_loss: 5.0370\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1565 - val_loss: 5.0122\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6302 - val_loss: 4.9304\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5474 - val_loss: 4.7037\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5242 - val_loss: 4.5972\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4595 - val_loss: 4.4894\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4635 - val_loss: 5.0403\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5936 - val_loss: 7.0826\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9722 - val_loss: 4.7222\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5797 - val_loss: 3.9758\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5182 - val_loss: 4.1075\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9904 - val_loss: 3.9879\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9203 - val_loss: 4.3859\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8479 - val_loss: 3.9342\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9539 - val_loss: 3.7075\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7937 - val_loss: 3.7554\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5882 - val_loss: 3.5864\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6340 - val_loss: 3.6057\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6137 - val_loss: 3.5547\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0375 - val_loss: 3.5150\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5334 - val_loss: 3.5441\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3444 - val_loss: 3.6285\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4601 - val_loss: 3.9515\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6366 - val_loss: 3.7079\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.4823 - val_loss: 3.3249\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3942 - val_loss: 3.3034\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3411 - val_loss: 3.5360\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2596 - val_loss: 3.2679\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9496 - val_loss: 3.3126\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.0246 - val_loss: 3.2076\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1662 - val_loss: 3.3313\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8406 - val_loss: 3.1044\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0461 - val_loss: 3.0530\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8369 - val_loss: 3.0913\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9875 - val_loss: 3.0173\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6951 - val_loss: 3.3924\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9145 - val_loss: 2.9726\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6663 - val_loss: 3.2673\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.3500 - val_loss: 3.6893\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6038 - val_loss: 4.0204\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff7355940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 95 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 96.6589 - val_loss: 73.7800\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48.8327 - val_loss: 25.7233\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 48.4320 - val_loss: 19.7666\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.1203 - val_loss: 37.3762\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32.2746 - val_loss: 35.1245\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26.6474 - val_loss: 20.4123\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23.2411 - val_loss: 19.2008\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.3633 - val_loss: 21.8151\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18.6879 - val_loss: 10.6111\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.9618 - val_loss: 9.9954\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.2657 - val_loss: 8.5832\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.3456 - val_loss: 6.7946\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.0729 - val_loss: 6.7094\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.7027 - val_loss: 7.3380\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.6968 - val_loss: 6.2253\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.4490 - val_loss: 7.5663\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.3231 - val_loss: 6.3676\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.9895 - val_loss: 8.2832\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.9969 - val_loss: 5.6185\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.8884 - val_loss: 6.0650\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.7587 - val_loss: 6.5227\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.2179 - val_loss: 5.5054\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.1610 - val_loss: 6.8221\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.8392 - val_loss: 5.1862\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.0396 - val_loss: 6.7871\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.2546 - val_loss: 5.0128\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.3601 - val_loss: 7.2438\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.1753 - val_loss: 5.1904\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.8066 - val_loss: 5.1891\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.6558 - val_loss: 6.0390\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.6403 - val_loss: 5.8021\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5198 - val_loss: 5.0461\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.1880 - val_loss: 6.0192\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.2439 - val_loss: 5.5067\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.7196 - val_loss: 5.2844\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.6912 - val_loss: 4.6414\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8584 - val_loss: 5.0450\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.7564 - val_loss: 5.6656\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.8417 - val_loss: 4.6119\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2078 - val_loss: 5.2479\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1732 - val_loss: 4.3459\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.3003 - val_loss: 5.4278\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3926 - val_loss: 4.7140\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6983 - val_loss: 4.1101\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.1478 - val_loss: 4.8691\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9526 - val_loss: 5.0781\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8974 - val_loss: 4.0358\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.2469 - val_loss: 4.0352\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.3281 - val_loss: 5.4913\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.6125 - val_loss: 3.8856\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff7355280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 96 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 97.8515 - val_loss: 76.7788\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 50.7307 - val_loss: 31.8740\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.5185 - val_loss: 7.2215\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.8820 - val_loss: 23.1012\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.7032 - val_loss: 28.7597\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.4814 - val_loss: 18.2444\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.4793 - val_loss: 16.2856\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.0562 - val_loss: 20.9980\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2058 - val_loss: 16.0077\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.9243 - val_loss: 14.0932\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.7077 - val_loss: 14.2247\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.6958 - val_loss: 10.0791\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8447 - val_loss: 9.5983\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5322 - val_loss: 8.4609\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5641 - val_loss: 6.4470\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4502 - val_loss: 5.6111\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0954 - val_loss: 7.5780\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1438 - val_loss: 5.2489\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9059 - val_loss: 6.9844\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.0972 - val_loss: 7.6041\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1485 - val_loss: 3.6121\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0973 - val_loss: 6.0671\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9484 - val_loss: 6.7133\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8632 - val_loss: 2.9478\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.9199 - val_loss: 6.1853\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0138 - val_loss: 3.9862\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0646 - val_loss: 3.5914\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.7252 - val_loss: 4.4860\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1740 - val_loss: 3.6045\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.0688 - val_loss: 3.1907\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.0093 - val_loss: 3.8811\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0111 - val_loss: 2.7529\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1723 - val_loss: 3.7135\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.0527 - val_loss: 3.3739\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7115 - val_loss: 2.7036\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.7948 - val_loss: 2.9724\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6836 - val_loss: 3.6038\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6473 - val_loss: 2.7790\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.8141 - val_loss: 2.5342\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4656 - val_loss: 2.8609\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5862 - val_loss: 2.7111\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4720 - val_loss: 3.0140\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6907 - val_loss: 3.0455\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6996 - val_loss: 3.1161\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8937 - val_loss: 2.5216\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5704 - val_loss: 3.7696\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6580 - val_loss: 2.4827\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2782 - val_loss: 2.3110\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1651 - val_loss: 2.3091\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2666 - val_loss: 2.6092\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff0031280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 97 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 66.7017 - val_loss: 40.1443\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25.7309 - val_loss: 4.2501\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.8400 - val_loss: 6.7346\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.5197 - val_loss: 18.3346\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.2877 - val_loss: 10.9867\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.6261 - val_loss: 4.7839\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.3666 - val_loss: 5.5338\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4340 - val_loss: 5.4148\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.6541 - val_loss: 2.5490\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3417 - val_loss: 2.5577\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9987 - val_loss: 2.7250\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.8834 - val_loss: 2.6608\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.6052 - val_loss: 2.4487\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2793 - val_loss: 2.5232\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2424 - val_loss: 2.9784\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.0780 - val_loss: 2.8607\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1481 - val_loss: 2.5102\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9278 - val_loss: 4.4886\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.0676 - val_loss: 3.2382\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.5483 - val_loss: 2.8691\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.8326 - val_loss: 4.8557\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8403 - val_loss: 2.4663\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.6506 - val_loss: 3.3107\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5126 - val_loss: 2.7368\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4371 - val_loss: 3.0114\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 3.4486 - val_loss: 3.7173\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.3880 - val_loss: 3.2956\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.2605 - val_loss: 3.5815\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.3171 - val_loss: 2.8303\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.2179 - val_loss: 2.6480\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.6475 - val_loss: 4.0999\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.6653 - val_loss: 4.7717\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5724 - val_loss: 5.5461\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.6291 - val_loss: 2.7941\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.6110 - val_loss: 2.6556\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.3427 - val_loss: 4.9948\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.4150 - val_loss: 4.2483\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.4290 - val_loss: 2.7606\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.4428 - val_loss: 2.4623\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.1386 - val_loss: 3.2698\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.0874 - val_loss: 3.5786\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.0767 - val_loss: 2.7285\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.4185 - val_loss: 3.1996\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.2555 - val_loss: 5.4219\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.0170 - val_loss: 2.4602\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.1211 - val_loss: 2.9090\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.4523 - val_loss: 4.4585\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.0001 - val_loss: 3.8146\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.9505 - val_loss: 4.1594\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.8557 - val_loss: 2.6487\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7fd9160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 98 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 68.9522 - val_loss: 42.9878\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 36.7516 - val_loss: 17.0734\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31.1755 - val_loss: 17.8674\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22.5521 - val_loss: 26.1936\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20.1004 - val_loss: 18.4273\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.5608 - val_loss: 12.0211\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.6851 - val_loss: 15.9782\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.4019 - val_loss: 11.8868\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.4420 - val_loss: 10.0854\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.3550 - val_loss: 9.8923\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.4670 - val_loss: 9.9342\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.8217 - val_loss: 9.3396\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.6577 - val_loss: 10.1535\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3464 - val_loss: 9.6520\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.0862 - val_loss: 10.0314\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.9083 - val_loss: 9.5020\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.7101 - val_loss: 9.1767\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.4922 - val_loss: 8.9528\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3835 - val_loss: 8.8601\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.3339 - val_loss: 8.8571\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.3978 - val_loss: 8.6792\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4449 - val_loss: 9.3735\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.2111 - val_loss: 8.6106\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.3165 - val_loss: 8.6597\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5736 - val_loss: 8.5226\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3993 - val_loss: 8.5578\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.7139 - val_loss: 8.3003\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.2840 - val_loss: 8.2782\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.9386 - val_loss: 8.2656\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8064 - val_loss: 8.2605\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.7265 - val_loss: 8.0983\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9094 - val_loss: 8.2210\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6314 - val_loss: 8.2746\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1041 - val_loss: 7.9330\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1570 - val_loss: 7.9341\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0840 - val_loss: 7.9318\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.8817 - val_loss: 8.3543\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6507 - val_loss: 7.8641\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7137 - val_loss: 7.9986\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.8803 - val_loss: 7.9041\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9256 - val_loss: 7.6237\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.9143 - val_loss: 8.0522\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9911 - val_loss: 7.4942\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6771 - val_loss: 7.4908\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3844 - val_loss: 8.3090\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9151 - val_loss: 7.7597\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.1348 - val_loss: 7.3099\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 6.8165 - val_loss: 9.2721\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.9394 - val_loss: 7.1759\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3622 - val_loss: 7.6718\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff55a6ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 99 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 71032.9453 - val_loss: 90.1300\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 108091.5781 - val_loss: 86.1282\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 69598.0547 - val_loss: 93.8284\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51865.5508 - val_loss: 95.8152\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37316.6289 - val_loss: 92.7815\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 27542.5391 - val_loss: 93.2679\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14466.4980 - val_loss: 96.9096\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50467.2383 - val_loss: 96.8430\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27633.8789 - val_loss: 95.5972\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35867.4961 - val_loss: 93.2504\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20126.9766 - val_loss: 95.4187\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30894.6113 - val_loss: 96.9112\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23626.0391 - val_loss: 95.2882\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25341.7949 - val_loss: 94.6176\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10972.5596 - val_loss: 96.3026\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18448.1543 - val_loss: 96.7349\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14892.6133 - val_loss: 95.0778\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27564.2148 - val_loss: 95.0985\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14690.7305 - val_loss: 97.3715\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29444.6914 - val_loss: 97.5014\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21426.2910 - val_loss: 95.8156\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10385.0186 - val_loss: 96.3342\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2230.1973 - val_loss: 98.3719\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34885.5117 - val_loss: 97.9057\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24464.0137 - val_loss: 95.9988\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23517.0879 - val_loss: 95.9964\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14627.8867 - val_loss: 98.1987\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41426.7305 - val_loss: 98.7853\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30313.0527 - val_loss: 97.3304\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5113.4824 - val_loss: 94.5054\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 59424.3477 - val_loss: 94.1996\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59503.5273 - val_loss: 95.8032\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23752.2441 - val_loss: 97.6283\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21514.7578 - val_loss: 98.5540\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15402.7236 - val_loss: 98.0154\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1665.0687 - val_loss: 97.5051\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5908.5527 - val_loss: 98.4125\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19628.4570 - val_loss: 98.3667\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4942.9385 - val_loss: 97.4009\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9686.3340 - val_loss: 97.3879\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10530.6865 - val_loss: 98.5445\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22454.8438 - val_loss: 98.7056\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13247.4082 - val_loss: 97.2617\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15340.1855 - val_loss: 97.3782\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13740.9980 - val_loss: 98.5673\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14224.4189 - val_loss: 98.3579\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3887.4329 - val_loss: 97.1555\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33333.9688 - val_loss: 96.7928\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24055.1719 - val_loss: 97.6854\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11009.5459 - val_loss: 99.8300\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff287a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 100 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 87.5640 - val_loss: 65.7523\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40.6959 - val_loss: 13.7898\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19.5576 - val_loss: 5.2017\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.9139 - val_loss: 22.1620\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.0351 - val_loss: 21.2170\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.8179 - val_loss: 8.3762\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.7225 - val_loss: 7.8895\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.0320 - val_loss: 16.6736\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9565 - val_loss: 14.2021\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6668 - val_loss: 7.5675\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2712 - val_loss: 9.0498\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.7607 - val_loss: 10.6322\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2277 - val_loss: 7.2746\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.7520 - val_loss: 7.3602\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4507 - val_loss: 7.8131\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9489 - val_loss: 4.4425\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3795 - val_loss: 6.4328\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.9519 - val_loss: 4.7555\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.3440 - val_loss: 4.2110\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.1478 - val_loss: 4.6795\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.8508 - val_loss: 4.3218\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.6638 - val_loss: 4.3839\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.0152 - val_loss: 4.8014\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.9114 - val_loss: 4.2563\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8789 - val_loss: 5.1200\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.6402 - val_loss: 4.0953\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5379 - val_loss: 4.0127\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.3306 - val_loss: 3.9812\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3053 - val_loss: 4.1471\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2506 - val_loss: 3.9759\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4214 - val_loss: 3.9460\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4822 - val_loss: 4.9794\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7708 - val_loss: 4.0199\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0221 - val_loss: 3.9523\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.3691 - val_loss: 4.2755\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4707 - val_loss: 3.7634\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4171 - val_loss: 3.7874\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.1304 - val_loss: 4.1873\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.2443 - val_loss: 3.8710\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0332 - val_loss: 3.6998\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.0221 - val_loss: 3.8887\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0228 - val_loss: 3.9680\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.0328 - val_loss: 3.6372\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.0583 - val_loss: 3.7286\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.1527 - val_loss: 4.8629\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4839 - val_loss: 3.9858\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1635 - val_loss: 3.8804\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.9669 - val_loss: 3.7284\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8547 - val_loss: 3.5718\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.9117 - val_loss: 3.7787\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbc314c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 101 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 55.5081 - val_loss: 30.0496\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.9869 - val_loss: 10.0209\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.4158 - val_loss: 24.7709\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23.5205 - val_loss: 30.7648\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.1867 - val_loss: 19.5008\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.2844 - val_loss: 7.0442\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.7724 - val_loss: 12.6754\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.7504 - val_loss: 4.8835\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.3466 - val_loss: 4.0035\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.6505 - val_loss: 4.6164\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.2218 - val_loss: 4.1676\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.0947 - val_loss: 5.0755\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7876 - val_loss: 3.4120\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7975 - val_loss: 2.2905\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6943 - val_loss: 4.1359\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3152 - val_loss: 1.9032\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9332 - val_loss: 3.8075\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2410 - val_loss: 1.9557\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6883 - val_loss: 2.2766\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8227 - val_loss: 2.4530\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1626 - val_loss: 2.5243\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0189 - val_loss: 1.8395\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9508 - val_loss: 2.3767\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7447 - val_loss: 1.9511\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7550 - val_loss: 1.4660\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5121 - val_loss: 2.5526\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3271 - val_loss: 1.7087\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2726 - val_loss: 1.7925\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0678 - val_loss: 1.3182\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9902 - val_loss: 2.4541\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8158 - val_loss: 1.3887\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7774 - val_loss: 1.3386\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7160 - val_loss: 1.4462\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4806 - val_loss: 1.5614\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3594 - val_loss: 1.3226\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3806 - val_loss: 2.7656\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6599 - val_loss: 1.5817\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1746 - val_loss: 1.4138\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2077 - val_loss: 1.9475\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9645 - val_loss: 2.6449\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0790 - val_loss: 2.2848\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.9529 - val_loss: 1.4035\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.6181 - val_loss: 1.3810\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6125 - val_loss: 2.1653\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6329 - val_loss: 2.0627\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4791 - val_loss: 1.8178\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.4210 - val_loss: 1.3126\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4978 - val_loss: 1.8708\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5731 - val_loss: 1.4484\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4665 - val_loss: 2.4578\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfdaf3a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 102 finished\n"
     ]
    }
   ],
   "source": [
    "zipcodes = nv_zipcodes\n",
    "dict_mape = {}\n",
    "dict_pred = {}\n",
    "\n",
    "for zipcode in range(len(zipcodes)):\n",
    "\n",
    "    # init a RMM model\n",
    "    rnn_model = Sequential()\n",
    "    # add 4 layers of RNN and a last layer\n",
    "\n",
    "    # we define shape on first layer, (60,1) because we use 60 inputs per prediction\n",
    "    rnn_model.add(LSTM(units= 60, return_sequences = False, input_shape=((60,1))))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # 3 other layers\n",
    "    #rnn_model.add(LSTM(units= 30, return_sequences = True))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # return_sequence is False because we want only 1 output after this layer\n",
    "    #rnn_model.add(LSTM(units= 60, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # last layer \n",
    "\n",
    "    rnn_model.add(Dense(units=1))\n",
    "\n",
    "    # compile - because this is a regression model we want to minimize MSE\n",
    "\n",
    "    rnn_model.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "\n",
    "    # We get only the specific column(Zipcode from our train and test datas)\n",
    "    train_data = train.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    test_data = test.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # We are using normalizaion rather than standascaler. \n",
    "    # In a upward trending timeseries it is better to not start from negative\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Because we are using 60 previous values to model and predict the next value, \n",
    "    # We set X_train from arrays of 60 for each y_train value\n",
    "    # Same idea for test data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(train_data_scaled)):\n",
    "        X_train.append(train_data_scaled[i-60:i])\n",
    "        y_train.append(train_data_scaled[i])\n",
    "\n",
    "    data_total = pd.concat((train.iloc[:,zipcode:zipcode+1], test.iloc[:,zipcode:zipcode+1]),axis=0)\n",
    "    inputs = data_total[len(train)-60:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(60,len(inputs)):\n",
    "        X_test.append(inputs[i-60:i])\n",
    "        y_test.append(inputs[i])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(test_data)\n",
    "\n",
    "    # We need numpy arrays for our model\n",
    "    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # We fit our data to our zipcode specific data\n",
    "    rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, scaler.transform(y_test)))\n",
    "\n",
    "    # Make predictions on the data\n",
    "\n",
    "    y_hat_raw = rnn_model.predict(X_test)\n",
    "    y_hat = scaler.inverse_transform(y_hat_raw)\n",
    "\n",
    "    # Use the score on unseen test data to calculate the MAPE\n",
    "\n",
    "    dict_mape[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_test)/y_test))      \n",
    "\n",
    "    # We get the last 60 values from our test data which is basically last 60 values in the data set\n",
    "    last_60 = df_time_series.iloc[-60:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # Before we use our data we scale it\n",
    "    last_60 = scaler.transform(last_60)\n",
    "    \n",
    "    # Our input should be in (x,60,1) format\n",
    "    x_new_pred = last_60[-60:].reshape(1,60,1)\n",
    "\n",
    "    # make a prediction, add to the last_60 for the next prediction and \n",
    "    y_pred = rnn_model.predict(x_new_pred)\n",
    "\n",
    "    # We add our predition to our list of predictions for zipcode specific predictions list\n",
    "    dict_pred[zipcodes[zipcode]]=scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(f'Iteration number {zipcode} finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_keys = list(dict_mape.keys())\n",
    "rnn_mape = list(dict_mape.values())\n",
    "rnn_pred = []\n",
    "rnn_dict = {}\n",
    "for zipcode in dict_pred.keys():\n",
    "    rnn_pred.append(dict_pred[zipcode].astype(int)[0][0])\n",
    "for zc in rnn_keys:\n",
    "    a = []\n",
    "    a.append(dict_mape[zc])\n",
    "    a.append(dict_pred[zc].astype(float)[0][0])\n",
    "    a.append('RNN')\n",
    "    rnn_dict[zc] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95804: [0.5159191513365095, 75412.6796875, 'RNN'],\n",
       " 95817: [0.4806917270953116, 82854.0859375, 'RNN'],\n",
       " 95813: [0.013083894437494591, 341304.875, 'RNN'],\n",
       " 95785: [0.01378739311178748, 422513.25, 'RNN'],\n",
       " 95819: [0.015094171486925623, 301021.0625, 'RNN'],\n",
       " 95770: [0.44194695282497615, 105605.78125, 'RNN'],\n",
       " 95806: [0.5182788597996814, 70026.3359375, 'RNN'],\n",
       " 95790: [0.007388430655138559, 312865.75, 'RNN'],\n",
       " 95799: [0.41473107013635707, 110862.84375, 'RNN'],\n",
       " 95844: [0.014626261526478987, 297665.53125, 'RNN'],\n",
       " 95843: [0.40972854999398295, 126288.140625, 'RNN'],\n",
       " 95815: [0.4957810488444431, 84689.921875, 'RNN'],\n",
       " 95825: [0.38387902090114595, 142043.46875, 'RNN'],\n",
       " 95818: [0.4386295986242681, 94474.0703125, 'RNN'],\n",
       " 95811: [0.46491245082909255, 74676.609375, 'RNN'],\n",
       " 95931: [0.44696939316482326, 114605.4375, 'RNN'],\n",
       " 95753: [0.3965936438523714, 141604.265625, 'RNN'],\n",
       " 95827: [0.007951250432951461, 335392.75, 'RNN'],\n",
       " 95937: [0.010482319800557482, 444971.84375, 'RNN'],\n",
       " 95914: [0.4358761083009109, 168000.984375, 'RNN'],\n",
       " 95754: [0.43916482062443524, 106289.3515625, 'RNN'],\n",
       " 95824: [0.3774964689018774, 143480.625, 'RNN'],\n",
       " 95945: [0.009420181348985288, 393342.9375, 'RNN'],\n",
       " 95800: [0.4718195009651555, 84472.21875, 'RNN'],\n",
       " 95751: [0.011770262489814314, 343317.875, 'RNN'],\n",
       " 95769: [0.2418764663897689, 81770.640625, 'RNN'],\n",
       " 95909: [0.541548922420154, 80201.6171875, 'RNN'],\n",
       " 95771: [0.4449168818684283, 96661.84375, 'RNN'],\n",
       " 95935: [0.468579774527048, 115184.875, 'RNN'],\n",
       " 95798: [0.49470465844168654, 83719.421875, 'RNN'],\n",
       " 95835: [0.3906188879587259, 140822.90625, 'RNN'],\n",
       " 95845: [0.3527866797556514, 166657.90625, 'RNN'],\n",
       " 95865: [0.0060464769748770665, 294301.125, 'RNN'],\n",
       " 95809: [0.009771453341725073, 304432.59375, 'RNN'],\n",
       " 95944: [0.010799909267872594, 409787.03125, 'RNN'],\n",
       " 399671: [0.4116425192150598, 124373.84375, 'RNN'],\n",
       " 95831: [0.013558921555743184, 427525.21875, 'RNN'],\n",
       " 95803: [0.517279830987193, 71889.5390625, 'RNN'],\n",
       " 95939: [0.017354669112205005, 643723.25, 'RNN'],\n",
       " 399665: [0.014149467428044914, 302807.65625, 'RNN'],\n",
       " 95826: [0.3977985782396422, 129545.7578125, 'RNN'],\n",
       " 95830: [0.01499383163019032, 316861.25, 'RNN'],\n",
       " 95932: [0.41069818420484944, 147422.921875, 'RNN'],\n",
       " 95792: [0.41483758989555536, 114382.765625, 'RNN'],\n",
       " 95837: [0.02081529672912315, 327126.6875, 'RNN'],\n",
       " 95750: [0.015961433084506354, 267443.625, 'RNN'],\n",
       " 95838: [0.4022623108188854, 102916.2578125, 'RNN'],\n",
       " 95912: [0.4455681412177846, 132910.53125, 'RNN'],\n",
       " 95940: [0.28050054567188604, 115600.046875, 'RNN'],\n",
       " 95841: [0.3897281475301448, 120660.484375, 'RNN'],\n",
       " 95793: [0.009597087395329643, 296469.84375, 'RNN'],\n",
       " 95952: [0.009495231708585497, 266254.875, 'RNN'],\n",
       " 95963: [0.10176629964979514, 209590.125, 'RNN'],\n",
       " 95816: [0.4315038321521024, 116423.96875, 'RNN'],\n",
       " 95779: [0.011447647262227374, 356830.5, 'RNN'],\n",
       " 95852: [0.46973642009308786, 84205.7265625, 'RNN'],\n",
       " 95783: [0.3317365500787004, 106907.9921875, 'RNN'],\n",
       " 95814: [0.38382792279041755, 134058.5, 'RNN'],\n",
       " 95957: [0.012981924290519522, 267417.28125, 'RNN'],\n",
       " 95888: [0.19147234315544517, 143140.03125, 'RNN'],\n",
       " 95861: [0.014256302542522825, 286464.03125, 'RNN'],\n",
       " 95840: [0.01030218372133625, 347827.71875, 'RNN'],\n",
       " 95842: [0.36788399256165016, 167712.90625, 'RNN'],\n",
       " 95766: [0.00854011861571219, 239586.078125, 'RNN'],\n",
       " 95883: [0.1520333966450159, 175152.21875, 'RNN'],\n",
       " 95911: [0.46489085262274765, 113575.8046875, 'RNN'],\n",
       " 95744: [0.00984138429584488, 318896.78125, 'RNN'],\n",
       " 95834: [0.011436811817719347, 434530.78125, 'RNN'],\n",
       " 95928: [0.021741427708519265, 318965.125, 'RNN'],\n",
       " 95901: [0.015790881595813135, 398780.40625, 'RNN'],\n",
       " 95890: [0.01847956218986767, 367463.875, 'RNN'],\n",
       " 95966: [0.07944586290889326, 216266.828125, 'RNN'],\n",
       " 95768: [0.16659501239545244, 133545.65625, 'RNN'],\n",
       " 95805: [0.3309421671862406, 162035.734375, 'RNN'],\n",
       " 399673: [0.43961954063396863, 131789.515625, 'RNN'],\n",
       " 95954: [0.010090192830097204, 399326.6875, 'RNN'],\n",
       " 399672: [0.02068608427753164, 418189.25, 'RNN'],\n",
       " 95787: [0.32292317749437116, 81608.4609375, 'RNN'],\n",
       " 95839: [0.018493146927664354, 276744.0, 'RNN'],\n",
       " 399674: [0.013792924062759431, 540005.875, 'RNN'],\n",
       " 95922: [0.12094748056449896, 114301.2109375, 'RNN'],\n",
       " 95866: [0.008060034743548408, 306858.6875, 'RNN'],\n",
       " 95907: [0.16924311825053417, 108803.5859375, 'RNN'],\n",
       " 95788: [0.41459605477245626, 98749.265625, 'RNN'],\n",
       " 95926: [0.022131163635094733, 916679.0625, 'RNN'],\n",
       " 95930: [0.03876847845117795, 338159.3125, 'RNN'],\n",
       " 95956: [0.02446487880320502, 315065.6875, 'RNN'],\n",
       " 95938: [0.02889695214142176, 428775.71875, 'RNN'],\n",
       " 95795: [0.3838596467150377, 137223.53125, 'RNN'],\n",
       " 95923: [0.32736431115352693, 409056.8125, 'RNN'],\n",
       " 95955: [0.02124960986573491, 423724.21875, 'RNN'],\n",
       " 95924: [0.23029241142242796, 260255.78125, 'RNN'],\n",
       " 95775: [0.013657195455473416, 207778.890625, 'RNN'],\n",
       " 95919: [0.01986937571165866, 285412.59375, 'RNN'],\n",
       " 95794: [0.009203299905793253, 330588.71875, 'RNN'],\n",
       " 399666: [0.013165532119944867, 323501.25, 'RNN'],\n",
       " 95760: [0.012689090960715351, 309324.90625, 'RNN'],\n",
       " 95916: [0.013263515868673158, 456363.8125, 'RNN'],\n",
       " 95891: [0.01297970825903085, 651686.3125, 'RNN'],\n",
       " 95820: [0.026793016022013318, 333740.6875, 'RNN'],\n",
       " 95917: [0.4154968076834546, 102394.203125, 'RNN'],\n",
       " 95893: [0.026021759253071913, 2057796.75, 'RNN'],\n",
       " 95851: [0.010471334813466493, 355289.84375, 'RNN']}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.201744244348875"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 8016.3657 - val_loss: 116.9793\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 289439.8438 - val_loss: 114.8002\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 171865.0781 - val_loss: 109.7558\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67592.4609 - val_loss: 103.9603\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 92420.1016 - val_loss: 101.8322\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82672.1484 - val_loss: 102.9477\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7458.7935 - val_loss: 104.3932\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 56210.8750 - val_loss: 104.0278\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 56789.8086 - val_loss: 102.5874\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3860.0498 - val_loss: 100.9176\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65583.7031 - val_loss: 100.1592\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57507.4727 - val_loss: 101.5199\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6485.3242 - val_loss: 102.0467\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6876.9136 - val_loss: 102.1024\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2741.3926 - val_loss: 101.2461\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37951.5742 - val_loss: 101.0646\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14181.1807 - val_loss: 102.6352\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43794.4688 - val_loss: 103.1240\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44556.1562 - val_loss: 102.6765\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16597.4492 - val_loss: 100.5760\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24983.0254 - val_loss: 100.1505\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41924.9922 - val_loss: 100.4110\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12191.7734 - val_loss: 101.4117\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11666.8105 - val_loss: 102.0973\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28406.9043 - val_loss: 102.0259\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13448.2529 - val_loss: 100.2640\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62393.5000 - val_loss: 99.3803\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58117.6445 - val_loss: 100.7004\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1792.6182 - val_loss: 101.7206\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17318.4062 - val_loss: 101.8216\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25782.4023 - val_loss: 101.1664\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5266.1436 - val_loss: 99.2958\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57081.7422 - val_loss: 98.7449\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38812.1094 - val_loss: 99.7410\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17778.4629 - val_loss: 101.7992\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49849.6133 - val_loss: 102.3833\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48317.5742 - val_loss: 101.1620\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 139.1605 - val_loss: 99.7962\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42861.8125 - val_loss: 98.6472\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43697.2812 - val_loss: 99.5271\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18450.5820 - val_loss: 101.5338\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 46812.4102 - val_loss: 102.2590\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33784.1406 - val_loss: 101.6854\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4132.8784 - val_loss: 100.4104\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32698.0664 - val_loss: 99.7318\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37505.1133 - val_loss: 100.1553\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22035.4395 - val_loss: 100.9532\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6774.6992 - val_loss: 100.8304\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1794.1548 - val_loss: 100.5686\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5063.5664 - val_loss: 100.4090\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfeb32cb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 0 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 183221.9844 - val_loss: 93.5919\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 173404.6250 - val_loss: 96.4776\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23133.1777 - val_loss: 93.7106\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 139361.4531 - val_loss: 95.7096\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55925.9258 - val_loss: 99.5528\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 74184.3984 - val_loss: 97.9105\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23425.5527 - val_loss: 98.4409\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22356.2930 - val_loss: 99.3670\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 61262.9062 - val_loss: 97.9655\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39528.1953 - val_loss: 101.3310\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 167989.9531 - val_loss: 101.9545\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 124703.4766 - val_loss: 98.0372\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36923.8008 - val_loss: 97.8042\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41539.6250 - val_loss: 99.5592\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 64242.2383 - val_loss: 99.0499\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61249.0781 - val_loss: 98.1185\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 74781.4375 - val_loss: 100.4468\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45600.3281 - val_loss: 100.6047\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24834.6445 - val_loss: 99.0544\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 133027.1250 - val_loss: 99.4655\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33201.2422 - val_loss: 102.4021\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 142887.2812 - val_loss: 102.2602\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 86630.7266 - val_loss: 98.5999\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 101559.3984 - val_loss: 99.3820\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16464.9004 - val_loss: 100.0436\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36660.5039 - val_loss: 98.2508\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79212.4766 - val_loss: 100.2051\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71377.2344 - val_loss: 99.7574\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19062.0566 - val_loss: 99.0009\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22859.2891 - val_loss: 99.9103\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43255.4609 - val_loss: 99.6074\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2871.4851 - val_loss: 100.3195\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 64665.5508 - val_loss: 100.0064\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20715.6504 - val_loss: 99.4757\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6363.9004 - val_loss: 100.6925\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 82122.3047 - val_loss: 100.7829\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 64375.3242 - val_loss: 99.4057\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 57584.1250 - val_loss: 99.2526\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 29177.9941 - val_loss: 100.0121\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12320.6172 - val_loss: 99.5202\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17591.6250 - val_loss: 99.5603\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 29813.6484 - val_loss: 99.0154\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 36721.6602 - val_loss: 99.6439\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 26013.0488 - val_loss: 100.6121\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 75303.1484 - val_loss: 100.0933\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17631.8730 - val_loss: 99.3382\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 66263.4219 - val_loss: 99.5544\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 28492.8125 - val_loss: 100.7410\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38622.9258 - val_loss: 100.4921\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34484.6484 - val_loss: 99.8433\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbca08310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 1 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 72.1814 - val_loss: 42.8305\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 60.2571 - val_loss: 38.7098\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.1891 - val_loss: 49.3656\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42.7925 - val_loss: 46.1726\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.8472 - val_loss: 24.3895\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.4068 - val_loss: 24.4128\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28.8104 - val_loss: 26.1462\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24.2253 - val_loss: 10.6263\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21.1327 - val_loss: 10.1704\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20.1728 - val_loss: 11.5747\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19.1223 - val_loss: 3.4169\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18.3084 - val_loss: 7.1260\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.6778 - val_loss: 3.5197\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.9927 - val_loss: 4.0185\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.4758 - val_loss: 6.4665\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.0077 - val_loss: 4.1300\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.6529 - val_loss: 5.9002\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.2085 - val_loss: 3.7143\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.1220 - val_loss: 4.3522\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.6054 - val_loss: 5.0124\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9688 - val_loss: 4.0852\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.9109 - val_loss: 6.3739\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.1922 - val_loss: 3.8219\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.1900 - val_loss: 5.9887\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.8933 - val_loss: 3.3074\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.3280 - val_loss: 4.5059\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.0009 - val_loss: 4.7752\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.6111 - val_loss: 5.3847\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.0505 - val_loss: 5.3390\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 9.6406 - val_loss: 4.5016\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1932 - val_loss: 3.4083\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4223 - val_loss: 6.1785\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.4621 - val_loss: 4.7109\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.5320 - val_loss: 6.6437\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9457 - val_loss: 5.0215\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5130 - val_loss: 7.1120\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3984 - val_loss: 8.5826\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6027 - val_loss: 3.9628\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.2886 - val_loss: 2.6739\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0483 - val_loss: 3.9956\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.4379 - val_loss: 8.5848\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.9556 - val_loss: 1.4980\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.7503 - val_loss: 3.2692\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6412 - val_loss: 8.1523\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.7175 - val_loss: 2.5336\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.1407 - val_loss: 6.1388\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.8568 - val_loss: 2.8930\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.7413 - val_loss: 1.9121\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0901 - val_loss: 2.4481\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.1956 - val_loss: 2.5977\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfdaf83940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 2 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 64.7469 - val_loss: 24.3696\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.5033 - val_loss: 13.5159\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24.1394 - val_loss: 32.2417\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22.4656 - val_loss: 25.6305\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19.9389 - val_loss: 15.9055\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.7796 - val_loss: 17.4533\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.6585 - val_loss: 18.8719\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.2581 - val_loss: 9.5634\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.2888 - val_loss: 12.7673\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0325 - val_loss: 5.9809\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6495 - val_loss: 4.3212\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3972 - val_loss: 6.1054\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6529 - val_loss: 4.1068\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1988 - val_loss: 2.8368\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1148 - val_loss: 2.6940\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.7925 - val_loss: 3.2563\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6832 - val_loss: 3.8810\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6832 - val_loss: 3.6141\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.4845 - val_loss: 3.6369\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5873 - val_loss: 6.1694\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.2206 - val_loss: 3.1691\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.2797 - val_loss: 2.5548\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8545 - val_loss: 2.9332\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.9565 - val_loss: 4.0309\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.2526 - val_loss: 4.6702\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8320 - val_loss: 3.2434\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2257 - val_loss: 3.6151\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.2366 - val_loss: 4.1307\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.4542 - val_loss: 3.4991\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0092 - val_loss: 3.8920\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.1011 - val_loss: 3.8338\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6142 - val_loss: 8.2062\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.2018 - val_loss: 2.7052\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.4251 - val_loss: 3.6130\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3791 - val_loss: 5.6329\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.9943 - val_loss: 2.9268\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.5490 - val_loss: 3.0825\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.4844 - val_loss: 3.3948\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.4157 - val_loss: 2.6152\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.3784 - val_loss: 3.4936\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.2960 - val_loss: 3.7610\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.0992 - val_loss: 4.0129\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9342 - val_loss: 2.8768\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.0376 - val_loss: 4.2632\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.0523 - val_loss: 2.9578\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.9330 - val_loss: 3.0203\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8017 - val_loss: 5.3211\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8104 - val_loss: 2.6894\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.7601 - val_loss: 2.8504\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.2208 - val_loss: 6.9474\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe0053f1b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 3 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 72.3668 - val_loss: 56.9032\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56.5749 - val_loss: 47.3230\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.5050 - val_loss: 47.6083\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.9021 - val_loss: 31.5736\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31.2897 - val_loss: 23.3028\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24.0787 - val_loss: 16.5741\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20.1071 - val_loss: 6.6682\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.6920 - val_loss: 5.6950\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.7720 - val_loss: 10.4044\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.3959 - val_loss: 6.7198\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.7690 - val_loss: 7.3679\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.7154 - val_loss: 5.3862\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.7545 - val_loss: 8.7836\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.0989 - val_loss: 5.5424\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.7417 - val_loss: 9.5441\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.8579 - val_loss: 5.2849\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.4805 - val_loss: 12.3500\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.6362 - val_loss: 4.0508\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.3890 - val_loss: 8.6758\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.2003 - val_loss: 4.6231\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.6771 - val_loss: 6.2624\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.8989 - val_loss: 5.8054\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.7791 - val_loss: 4.3887\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.4492 - val_loss: 7.1789\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3887 - val_loss: 4.6796\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.6136 - val_loss: 6.1090\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0470 - val_loss: 5.0210\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.5099 - val_loss: 6.2455\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1323 - val_loss: 5.1556\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.0128 - val_loss: 5.5359\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.5918 - val_loss: 4.8969\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9039 - val_loss: 7.6340\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8497 - val_loss: 5.1252\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.7753 - val_loss: 2.9267\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6439 - val_loss: 8.0404\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2365 - val_loss: 3.8415\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.0306 - val_loss: 5.9007\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9928 - val_loss: 4.5796\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.9499 - val_loss: 6.7477\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6298 - val_loss: 2.8451\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.6091 - val_loss: 6.9583\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.3177 - val_loss: 3.9422\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0310 - val_loss: 4.5093\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.7314 - val_loss: 4.1496\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.0943 - val_loss: 4.7909\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8367 - val_loss: 3.2722\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.4792 - val_loss: 4.7725\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3715 - val_loss: 4.1300\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.9108 - val_loss: 3.3368\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3932 - val_loss: 6.1911\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfad331310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 4 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 246345.7031 - val_loss: 87.0032\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 171813.3125 - val_loss: 107.4648\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 167842.8438 - val_loss: 109.5634\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 151191.4375 - val_loss: 106.8308\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 107392.5234 - val_loss: 98.4859\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66033.5312 - val_loss: 97.9876\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45696.4844 - val_loss: 100.5689\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28071.5371 - val_loss: 101.2415\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3787.9849 - val_loss: 100.0367\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65504.0742 - val_loss: 98.1380\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62424.8633 - val_loss: 99.1694\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 251.5964 - val_loss: 100.2277\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24657.8184 - val_loss: 100.1574\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10672.2422 - val_loss: 102.4840\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59906.4883 - val_loss: 102.3614\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40622.4375 - val_loss: 101.4528\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14176.3418 - val_loss: 100.0020\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13411.4229 - val_loss: 101.6384\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30843.8320 - val_loss: 100.9939\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14324.8311 - val_loss: 99.0479\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37199.0508 - val_loss: 99.4683\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25664.2129 - val_loss: 101.2448\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22044.2754 - val_loss: 100.7542\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6092.3091 - val_loss: 99.4623\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32714.6152 - val_loss: 99.4583\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18847.1699 - val_loss: 100.1809\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5089.2764 - val_loss: 103.5447\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 96703.7656 - val_loss: 104.2273\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 102579.0000 - val_loss: 102.9036\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 64134.5742 - val_loss: 101.0142\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4087.9099 - val_loss: 98.8697\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36428.4414 - val_loss: 98.4858\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50548.8086 - val_loss: 98.8451\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31594.1211 - val_loss: 100.7393\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41713.7539 - val_loss: 101.6488\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25113.2363 - val_loss: 100.4494\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24890.8320 - val_loss: 99.5005\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10163.7979 - val_loss: 100.5868\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9109.9072 - val_loss: 100.7111\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13143.8330 - val_loss: 99.8708\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25253.8184 - val_loss: 99.5503\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2497.7991 - val_loss: 100.9462\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50950.6797 - val_loss: 101.9912\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47544.6875 - val_loss: 100.4917\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9048.4971 - val_loss: 100.0828\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4239.1968 - val_loss: 101.3725\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41350.6992 - val_loss: 101.4672\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32652.5254 - val_loss: 100.3543\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4396.5815 - val_loss: 98.5674\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44260.9922 - val_loss: 98.5065\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd6fcf280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 5 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 90761.6016 - val_loss: 105.6658\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 198772.2031 - val_loss: 111.4187\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 141392.5469 - val_loss: 103.2334\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20158.0684 - val_loss: 94.0738\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 195947.8438 - val_loss: 91.2471\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 169446.1562 - val_loss: 95.2105\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 91909.8906 - val_loss: 100.7278\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54458.4570 - val_loss: 102.1835\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36800.3867 - val_loss: 99.3416\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16527.5312 - val_loss: 99.1358\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3521.7068 - val_loss: 100.1665\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57744.8945 - val_loss: 102.2610\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37665.3633 - val_loss: 100.9678\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24387.5508 - val_loss: 99.0633\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17826.2363 - val_loss: 100.8171\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21220.8555 - val_loss: 100.6642\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16587.4062 - val_loss: 99.2459\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34219.1055 - val_loss: 99.0309\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16060.1641 - val_loss: 100.2375\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20914.1406 - val_loss: 100.7996\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16482.5176 - val_loss: 99.8708\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18944.8496 - val_loss: 99.7248\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7179.9219 - val_loss: 100.8814\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37895.8984 - val_loss: 101.4063\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28162.0254 - val_loss: 100.2319\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22285.7168 - val_loss: 99.5168\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16630.6191 - val_loss: 101.4874\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42320.5742 - val_loss: 101.6414\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39246.5117 - val_loss: 100.3818\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9313.1504 - val_loss: 100.0064\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3229.1360 - val_loss: 99.9799\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5607.9727 - val_loss: 100.5144\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23035.4258 - val_loss: 100.6896\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12646.1562 - val_loss: 99.2777\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27534.1934 - val_loss: 99.1837\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22460.6719 - val_loss: 100.2007\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13431.8018 - val_loss: 100.2643\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3763.1924 - val_loss: 99.0563\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26057.6758 - val_loss: 99.2260\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19015.3828 - val_loss: 99.6608\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6515.5771 - val_loss: 100.2716\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6906.7617 - val_loss: 99.2675\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23617.1641 - val_loss: 99.5222\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5728.6748 - val_loss: 100.1568\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 35360.1953 - val_loss: 101.2055\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24041.3105 - val_loss: 100.5032\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3253.2581 - val_loss: 99.7560\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5964.3569 - val_loss: 100.5752\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22529.3945 - val_loss: 100.4381\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8001.2695 - val_loss: 99.4315\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe0051bb160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 6 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 59.7872 - val_loss: 42.1292\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.6313 - val_loss: 43.8135\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38.7393 - val_loss: 32.0947\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.0921 - val_loss: 26.4904\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27.1713 - val_loss: 18.1420\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21.5086 - val_loss: 4.6185\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20.7046 - val_loss: 11.3191\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.8185 - val_loss: 4.2920\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.5828 - val_loss: 5.7442\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.7729 - val_loss: 11.7733\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.9539 - val_loss: 3.4233\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.1457 - val_loss: 10.8516\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.5858 - val_loss: 4.2832\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.2579 - val_loss: 6.9058\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.7957 - val_loss: 6.1683\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.3691 - val_loss: 8.0789\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.6735 - val_loss: 4.6668\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.0609 - val_loss: 4.9920\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.9572 - val_loss: 4.8896\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.9089 - val_loss: 5.3556\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.5064 - val_loss: 6.3373\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.6276 - val_loss: 5.5374\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.1989 - val_loss: 6.3968\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.8168 - val_loss: 4.0602\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.5895 - val_loss: 10.2676\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.0880 - val_loss: 2.7976\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.7578 - val_loss: 7.7839\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.9872 - val_loss: 4.5852\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6767 - val_loss: 8.6209\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.8315 - val_loss: 6.2030\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.8140 - val_loss: 5.9865\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.7411 - val_loss: 4.4226\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.5772 - val_loss: 10.0155\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3324 - val_loss: 4.3060\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5855 - val_loss: 7.4426\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.5764 - val_loss: 4.3157\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4575 - val_loss: 7.3897\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.1126 - val_loss: 4.4766\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.9769 - val_loss: 3.4933\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.7624 - val_loss: 7.1946\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.4339 - val_loss: 1.6682\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6373 - val_loss: 7.4171\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5152 - val_loss: 1.8693\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.2751 - val_loss: 6.0506\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.2595 - val_loss: 4.6671\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.9975 - val_loss: 4.9287\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.7635 - val_loss: 4.3165\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.2515 - val_loss: 4.0386\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.0941 - val_loss: 4.1604\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8207 - val_loss: 1.9864\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb09243a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 7 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 109863.5781 - val_loss: 109.6758\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 128367.2344 - val_loss: 104.8690\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38096.0859 - val_loss: 101.2468\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16217.7422 - val_loss: 98.6787\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30970.7246 - val_loss: 100.1196\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24217.6152 - val_loss: 100.1358\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9078.4873 - val_loss: 100.0112\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48609.8281 - val_loss: 101.8125\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20414.9434 - val_loss: 99.4035\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36231.9844 - val_loss: 98.3629\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33247.0781 - val_loss: 99.5507\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4437.6616 - val_loss: 100.0271\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9012.2402 - val_loss: 100.9330\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13237.0879 - val_loss: 100.1680\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3478.7615 - val_loss: 101.6598\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35486.0508 - val_loss: 101.2633\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2617.1555 - val_loss: 99.7636\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13152.2471 - val_loss: 98.8955\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34013.3789 - val_loss: 99.9356\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6003.0352 - val_loss: 100.2725\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25465.7266 - val_loss: 99.5092\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17177.6738 - val_loss: 101.4002\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 40058.5469 - val_loss: 102.0217\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33338.4727 - val_loss: 99.9816\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25007.5605 - val_loss: 99.7936\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9736.0742 - val_loss: 100.6535\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2268.3730 - val_loss: 101.1595\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15178.1377 - val_loss: 100.2861\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20373.1953 - val_loss: 99.9901\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5321.5137 - val_loss: 100.5735\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7118.5254 - val_loss: 100.6253\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21879.3340 - val_loss: 101.3631\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13349.4365 - val_loss: 100.7040\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22706.1660 - val_loss: 99.6439\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21731.8828 - val_loss: 100.4902\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2486.4985 - val_loss: 102.5795\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46490.2422 - val_loss: 102.5822\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46947.6875 - val_loss: 101.6179\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20106.3926 - val_loss: 99.9635\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21564.0176 - val_loss: 99.7494\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19953.6016 - val_loss: 100.6553\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13240.8496 - val_loss: 100.8978\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 486.4355 - val_loss: 100.0860\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14723.6172 - val_loss: 100.0507\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16132.8516 - val_loss: 100.3484\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5391.4214 - val_loss: 100.7902\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4075.5522 - val_loss: 99.9693\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21139.7910 - val_loss: 99.8583\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12664.3389 - val_loss: 100.9851\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29547.6621 - val_loss: 101.4910\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfeac8d940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 8 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 76.5967 - val_loss: 45.1910\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 53.4357 - val_loss: 49.7954\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41.8056 - val_loss: 40.1749\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.2424 - val_loss: 25.3227\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.1235 - val_loss: 23.8633\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26.2823 - val_loss: 15.6258\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23.6784 - val_loss: 5.9518\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22.0279 - val_loss: 6.4293\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20.1978 - val_loss: 6.2430\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.4902 - val_loss: 6.2543\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.5601 - val_loss: 6.3515\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.7220 - val_loss: 6.8402\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19.7003 - val_loss: 8.9197\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.4976 - val_loss: 6.2023\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.5198 - val_loss: 5.0122\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.4741 - val_loss: 6.0981\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.1432 - val_loss: 5.0777\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.9560 - val_loss: 4.7467\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.7967 - val_loss: 7.4011\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.3617 - val_loss: 5.0645\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.2736 - val_loss: 6.0319\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.4803 - val_loss: 5.1800\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.4509 - val_loss: 4.5874\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.2924 - val_loss: 4.7181\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.1248 - val_loss: 5.4348\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.9489 - val_loss: 4.6500\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.6912 - val_loss: 3.9189\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.6826 - val_loss: 5.3701\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.4958 - val_loss: 5.2060\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.6905 - val_loss: 4.3988\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.6650 - val_loss: 3.3991\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.1545 - val_loss: 3.8633\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0828 - val_loss: 3.3213\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.6489 - val_loss: 3.6721\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9387 - val_loss: 5.3136\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7301 - val_loss: 4.4491\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.6641 - val_loss: 4.4270\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7631 - val_loss: 6.3089\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.9660 - val_loss: 3.5401\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4248 - val_loss: 3.0742\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1706 - val_loss: 5.9138\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.0240 - val_loss: 3.4480\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.9091 - val_loss: 3.9934\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.6094 - val_loss: 4.7737\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.7979 - val_loss: 3.0989\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.4883 - val_loss: 3.8009\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.3052 - val_loss: 4.5836\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.2422 - val_loss: 4.2580\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4459 - val_loss: 2.7382\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0943 - val_loss: 5.4692\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe0077ad0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 9 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 270135.8438 - val_loss: 94.1858\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 119107.3672 - val_loss: 112.9699\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 262443.7188 - val_loss: 117.1978\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 205227.4375 - val_loss: 111.3258\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 119137.5781 - val_loss: 103.1854\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 110857.6562 - val_loss: 99.6586\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73140.3125 - val_loss: 102.6291\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18477.7754 - val_loss: 103.4050\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16268.6748 - val_loss: 101.5430\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46119.5898 - val_loss: 100.9748\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23249.2500 - val_loss: 102.3913\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24905.1133 - val_loss: 103.0002\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18515.6035 - val_loss: 101.6879\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20327.3809 - val_loss: 101.7235\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3606.3704 - val_loss: 102.5190\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46755.5781 - val_loss: 103.8383\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45376.3359 - val_loss: 102.4580\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10550.1377 - val_loss: 99.9271\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 88395.4688 - val_loss: 98.9136\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75465.3594 - val_loss: 100.9850\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25485.6152 - val_loss: 103.6746\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58018.0312 - val_loss: 104.1067\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61653.0117 - val_loss: 103.7312\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41355.0039 - val_loss: 101.2555\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25764.9531 - val_loss: 100.5871\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32778.3789 - val_loss: 101.3118\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5870.2808 - val_loss: 102.8355\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40551.0703 - val_loss: 102.9497\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36587.6719 - val_loss: 102.0948\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4608.3564 - val_loss: 100.5018\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51080.5234 - val_loss: 99.6899\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48213.3242 - val_loss: 100.6533\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15835.6631 - val_loss: 102.2233\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50365.2383 - val_loss: 102.9656\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45939.8945 - val_loss: 101.3364\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1745.5439 - val_loss: 99.3765\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 52039.5586 - val_loss: 99.2508\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54917.8203 - val_loss: 100.1326\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19656.4746 - val_loss: 101.0613\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17449.4199 - val_loss: 101.6575\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14251.3467 - val_loss: 100.7291\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10724.3994 - val_loss: 100.9295\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 872.2391 - val_loss: 101.3331\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29976.3066 - val_loss: 102.0366\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29246.9238 - val_loss: 101.0940\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2841.7625 - val_loss: 99.6835\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48856.0352 - val_loss: 99.4054\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43018.5469 - val_loss: 100.0725\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19398.4551 - val_loss: 101.4240\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23328.7402 - val_loss: 101.6448\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe00b165040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 10 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 165505.2812 - val_loss: 90.3593\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 91084.5156 - val_loss: 85.8260\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 137900.8438 - val_loss: 95.0551\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 108458.1250 - val_loss: 95.9269\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43700.0703 - val_loss: 89.0691\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 245044.0312 - val_loss: 87.3456\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 157345.6094 - val_loss: 93.0236\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49012.9961 - val_loss: 95.6577\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37206.7344 - val_loss: 92.0138\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 98532.4062 - val_loss: 93.3271\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26178.7285 - val_loss: 96.0639\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 78356.6562 - val_loss: 96.4363\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49704.0742 - val_loss: 94.9274\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20270.8945 - val_loss: 94.6420\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11828.2197 - val_loss: 95.5095\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18451.9609 - val_loss: 95.3957\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3217.4875 - val_loss: 95.9967\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12338.5117 - val_loss: 95.1578\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51079.0938 - val_loss: 95.4330\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5205.4858 - val_loss: 95.3205\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22302.6074 - val_loss: 95.7306\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38156.1172 - val_loss: 96.3989\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16806.3613 - val_loss: 95.0078\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55978.4805 - val_loss: 95.8573\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3996.6567 - val_loss: 96.9461\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28784.5762 - val_loss: 96.8518\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7692.1357 - val_loss: 96.9325\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23881.2168 - val_loss: 97.5685\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1700.2852 - val_loss: 96.7238\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63088.8867 - val_loss: 96.9224\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11929.3174 - val_loss: 97.7719\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32625.2363 - val_loss: 97.3958\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26962.1367 - val_loss: 99.2421\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 79061.4375 - val_loss: 98.6626\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20366.1719 - val_loss: 97.4351\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16598.2129 - val_loss: 99.0107\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41578.9219 - val_loss: 98.7902\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 29008.3945 - val_loss: 97.8583\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22729.2344 - val_loss: 99.5378\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45622.1719 - val_loss: 99.5476\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28812.8066 - val_loss: 97.6966\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 92658.9062 - val_loss: 97.0516\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61559.9531 - val_loss: 99.0770\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41955.6641 - val_loss: 99.4768\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44509.5195 - val_loss: 97.7888\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51288.1367 - val_loss: 97.7762\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19618.5996 - val_loss: 98.8756\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37192.7539 - val_loss: 99.3606\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30928.0137 - val_loss: 98.2710\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30793.8027 - val_loss: 98.2577\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd9985b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 11 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 116433.7500 - val_loss: 130.3151\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 736890.4375 - val_loss: 131.7154\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 396989.2812 - val_loss: 119.4912\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33557.0312 - val_loss: 108.0011\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 244811.2656 - val_loss: 105.5591\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 261437.8750 - val_loss: 107.8972\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74948.3984 - val_loss: 111.2687\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 153826.1094 - val_loss: 111.8620\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 107260.6562 - val_loss: 109.6041\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26076.8027 - val_loss: 108.6361\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17686.7500 - val_loss: 109.3543\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35207.2266 - val_loss: 108.2219\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24459.2539 - val_loss: 108.4707\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12507.5850 - val_loss: 108.2743\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10997.1533 - val_loss: 108.1963\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6494.7383 - val_loss: 106.9632\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 55404.3164 - val_loss: 107.1675\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44210.8867 - val_loss: 108.6096\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 80429.0469 - val_loss: 107.7758\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43562.1680 - val_loss: 105.5368\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86112.7578 - val_loss: 106.1451\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19601.5781 - val_loss: 108.6701\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 94600.4375 - val_loss: 108.7964\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93866.1406 - val_loss: 107.6451\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34856.6562 - val_loss: 105.8159\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40948.9258 - val_loss: 106.6047\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46345.3320 - val_loss: 108.6548\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 93174.7422 - val_loss: 107.2663\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21379.6445 - val_loss: 106.0798\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43780.2734 - val_loss: 106.5415\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26911.5391 - val_loss: 106.8674\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24960.0879 - val_loss: 105.5728\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41293.9375 - val_loss: 106.1902\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17059.6934 - val_loss: 106.3220\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7951.3340 - val_loss: 106.0358\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6844.9492 - val_loss: 106.1406\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18185.9375 - val_loss: 106.0944\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27771.2441 - val_loss: 106.2405\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3713.7402 - val_loss: 106.7865\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46967.0977 - val_loss: 106.6282\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20207.5723 - val_loss: 104.5509\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 83820.1875 - val_loss: 104.2763\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72022.1016 - val_loss: 105.5227\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43019.9414 - val_loss: 106.8519\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 78019.5781 - val_loss: 105.6178\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19892.4785 - val_loss: 104.1523\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38144.3242 - val_loss: 104.1338\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28810.5762 - val_loss: 105.0962\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53199.6406 - val_loss: 103.9258\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28783.2363 - val_loss: 102.6898\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc7a06040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 12 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 336942.0938 - val_loss: 120.8876\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 362305.2812 - val_loss: 109.0225\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 139610.3906 - val_loss: 103.3979\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 96028.7734 - val_loss: 106.6055\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 93846.4922 - val_loss: 102.1293\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 90952.5625 - val_loss: 101.7929\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30662.6875 - val_loss: 104.1811\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26924.5957 - val_loss: 102.9774\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 91560.8984 - val_loss: 101.7684\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39368.4648 - val_loss: 103.4329\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4016.1646 - val_loss: 101.3152\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 104559.8672 - val_loss: 101.5680\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55922.0586 - val_loss: 103.1619\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 77329.3203 - val_loss: 104.5473\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40140.0664 - val_loss: 102.9379\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 95644.8672 - val_loss: 100.6665\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77696.7266 - val_loss: 102.2921\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53084.3555 - val_loss: 104.3728\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 98747.3438 - val_loss: 103.1446\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10767.1641 - val_loss: 101.5907\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10863.7422 - val_loss: 102.1695\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51363.7188 - val_loss: 101.6682\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16035.6182 - val_loss: 100.5553\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12323.8682 - val_loss: 101.5881\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39627.6367 - val_loss: 101.0412\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7281.2920 - val_loss: 100.4248\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17605.6504 - val_loss: 101.0665\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21563.6387 - val_loss: 99.9258\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25562.2344 - val_loss: 100.5064\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3179.3467 - val_loss: 100.2672\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8498.3730 - val_loss: 100.3061\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5520.9248 - val_loss: 99.7769\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5802.7896 - val_loss: 99.6993\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8428.4326 - val_loss: 98.2786\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48241.9727 - val_loss: 98.4051\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17430.3066 - val_loss: 99.5417\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35406.8633 - val_loss: 99.7967\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20968.1328 - val_loss: 98.8345\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65655.1484 - val_loss: 98.2315\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50704.8008 - val_loss: 100.0186\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33574.9062 - val_loss: 100.2959\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23471.1895 - val_loss: 99.1083\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53087.1211 - val_loss: 98.8442\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38290.8242 - val_loss: 100.2233\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37111.7617 - val_loss: 100.4244\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14929.2832 - val_loss: 99.2029\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53349.7773 - val_loss: 99.0624\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32894.1836 - val_loss: 100.2867\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30062.4707 - val_loss: 100.6310\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24668.3145 - val_loss: 99.1583\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfae4630d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 13 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 189622.5781 - val_loss: 77.5748\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 149785.0469 - val_loss: 95.2185\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 128807.1562 - val_loss: 85.9559\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91218.8203 - val_loss: 84.4980\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57184.3633 - val_loss: 90.2221\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33314.8438 - val_loss: 91.1392\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15665.1611 - val_loss: 88.4707\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49630.8594 - val_loss: 88.7718\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24781.8066 - val_loss: 90.5551\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51168.1484 - val_loss: 93.4200\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48689.9805 - val_loss: 91.4072\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3041.4695 - val_loss: 92.4995\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23309.7812 - val_loss: 92.3468\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21165.7129 - val_loss: 91.4818\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13856.4570 - val_loss: 93.0252\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12831.5586 - val_loss: 92.8533\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4449.3550 - val_loss: 90.7047\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60978.4414 - val_loss: 90.8104\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45331.4258 - val_loss: 94.3003\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23527.7891 - val_loss: 94.0633\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12924.7783 - val_loss: 91.7018\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70283.2266 - val_loss: 91.1073\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32852.2969 - val_loss: 94.2439\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2272.0803 - val_loss: 95.1316\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20020.6953 - val_loss: 94.3650\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28728.2363 - val_loss: 93.9049\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18810.9160 - val_loss: 97.5262\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 90765.7266 - val_loss: 98.8347\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86028.5391 - val_loss: 97.0169\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17478.0059 - val_loss: 95.1994\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32749.8945 - val_loss: 94.4436\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31866.4941 - val_loss: 95.3736\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 433.1385 - val_loss: 97.7438\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39411.3438 - val_loss: 98.1885\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48089.2812 - val_loss: 97.5372\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14886.1924 - val_loss: 95.7448\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22924.0918 - val_loss: 95.7147\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25713.5938 - val_loss: 97.0765\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12894.0234 - val_loss: 96.7473\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8505.5293 - val_loss: 96.9419\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16782.9824 - val_loss: 97.1598\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8293.5996 - val_loss: 95.3108\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52606.5977 - val_loss: 95.1377\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42035.5859 - val_loss: 96.3807\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16559.8457 - val_loss: 98.7774\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65594.2812 - val_loss: 99.6318\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58724.7109 - val_loss: 98.9846\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35408.2188 - val_loss: 97.0585\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36473.8242 - val_loss: 96.3291\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32693.5996 - val_loss: 97.5038\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe0051bbe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 14 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 40879.1719 - val_loss: 80.0407\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 502901.6875 - val_loss: 78.4756\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 283003.9688 - val_loss: 86.3722\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 226779.6250 - val_loss: 98.0933\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67553.5938 - val_loss: 101.0229\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83902.1875 - val_loss: 99.8842\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3345.8127 - val_loss: 99.5138\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52180.8438 - val_loss: 100.7301\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9423.7314 - val_loss: 99.1432\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13402.8594 - val_loss: 98.2620\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59471.9883 - val_loss: 98.2559\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4148.6509 - val_loss: 100.2571\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39218.0117 - val_loss: 101.5808\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62535.9609 - val_loss: 100.8022\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31249.2559 - val_loss: 99.3033\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49509.3984 - val_loss: 98.6234\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34533.2500 - val_loss: 100.4397\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51547.7695 - val_loss: 101.1398\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46943.7617 - val_loss: 99.7584\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20797.0469 - val_loss: 99.4779\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11997.0059 - val_loss: 101.0363\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57803.4258 - val_loss: 101.2053\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43929.2109 - val_loss: 100.1785\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10173.7295 - val_loss: 99.7134\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1288.5103 - val_loss: 99.3085\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28133.0879 - val_loss: 99.4198\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10832.9785 - val_loss: 100.7670\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32349.5762 - val_loss: 100.6419\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27302.8184 - val_loss: 99.6579\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23680.9844 - val_loss: 99.4063\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2911.5393 - val_loss: 100.1855\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11569.7998 - val_loss: 100.6486\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33543.4297 - val_loss: 100.4274\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19573.7363 - val_loss: 98.6878\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57450.4922 - val_loss: 98.3645\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49001.0469 - val_loss: 99.0069\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30816.8789 - val_loss: 100.9429\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68268.1094 - val_loss: 101.7525\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54080.1484 - val_loss: 100.5506\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21602.4844 - val_loss: 98.5832\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 78913.0391 - val_loss: 97.7666\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 74535.9141 - val_loss: 99.2071\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21592.5859 - val_loss: 100.7694\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32190.1445 - val_loss: 101.0555\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32875.8164 - val_loss: 100.4805\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13132.9180 - val_loss: 98.9207\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65767.7891 - val_loss: 98.3213\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49502.1562 - val_loss: 99.5716\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7563.8760 - val_loss: 100.2179\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 700.6730 - val_loss: 100.4126\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfad3319d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 15 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 371149.9688 - val_loss: 75.1934\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 265973.2812 - val_loss: 90.8372\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42514.1953 - val_loss: 93.8295\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37519.6602 - val_loss: 92.0128\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 82688.7344 - val_loss: 94.6607\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 127185.5234 - val_loss: 96.4285\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43485.8164 - val_loss: 90.9135\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 320272.4375 - val_loss: 88.0458\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 198679.7031 - val_loss: 91.3067\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 17517.2617 - val_loss: 94.8610\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26719.1367 - val_loss: 92.5875\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 142982.1719 - val_loss: 92.3146\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 67789.1875 - val_loss: 95.6187\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 24673.5781 - val_loss: 96.3557\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 57478.8164 - val_loss: 95.6586\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 45103.8867 - val_loss: 95.0241\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11571.9238 - val_loss: 96.5097\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 78964.2734 - val_loss: 96.3832\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 57269.4219 - val_loss: 93.3721\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 165849.0938 - val_loss: 92.5027\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 130934.0000 - val_loss: 93.7180\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46564.1758 - val_loss: 96.9560\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 154558.0781 - val_loss: 98.7627\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 142174.5625 - val_loss: 98.0873\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40369.6797 - val_loss: 96.4775\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 94422.6250 - val_loss: 95.2836\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 91502.3984 - val_loss: 96.3153\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5162.7095 - val_loss: 97.8253\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 60837.7422 - val_loss: 98.1287\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 66799.8047 - val_loss: 96.6577\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5158.5933 - val_loss: 97.1398\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13037.1230 - val_loss: 96.5915\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35904.2500 - val_loss: 96.3531\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3340.5317 - val_loss: 97.1884\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10592.2773 - val_loss: 96.9748\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29951.5000 - val_loss: 97.2316\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15062.5791 - val_loss: 97.5136\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4340.9150 - val_loss: 97.4940\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4655.3330 - val_loss: 97.6235\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16610.8379 - val_loss: 97.0097\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17034.6406 - val_loss: 97.6999\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22826.7637 - val_loss: 97.2951\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2993.0217 - val_loss: 97.9598\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 54377.0703 - val_loss: 97.8546\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3794.8071 - val_loss: 96.7062\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 81902.6484 - val_loss: 96.0862\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 67597.6484 - val_loss: 96.9630\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 20630.8184 - val_loss: 98.9730\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 116381.5625 - val_loss: 99.7658\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 111728.2500 - val_loss: 99.2081\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfaee62d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 16 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 307ms/step - loss: 72.3014 - val_loss: 50.2178\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 55.4286 - val_loss: 40.7744\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43.8855 - val_loss: 52.7095\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 40.0214 - val_loss: 45.6654\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.1815 - val_loss: 28.4960\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31.3461 - val_loss: 19.6476\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25.5396 - val_loss: 21.4584\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22.0516 - val_loss: 4.0794\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 21.8249 - val_loss: 11.3118\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 20.1002 - val_loss: 6.8088\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.2180 - val_loss: 12.1665\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.6473 - val_loss: 4.2159\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.0073 - val_loss: 3.9951\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.1461 - val_loss: 4.0314\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.7731 - val_loss: 4.8370\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.9254 - val_loss: 5.7871\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.9696 - val_loss: 8.5380\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 16.2889 - val_loss: 3.6382\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.6421 - val_loss: 3.2991\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.0760 - val_loss: 4.1105\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.9646 - val_loss: 3.5048\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 12.3044 - val_loss: 4.0412\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.2060 - val_loss: 3.0917\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.7738 - val_loss: 4.0550\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.9001 - val_loss: 3.4030\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 11.4601 - val_loss: 3.0184\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.8185 - val_loss: 2.8050\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.9416 - val_loss: 2.8677\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2448 - val_loss: 2.0442\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.7196 - val_loss: 7.0065\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.8506 - val_loss: 3.1603\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.5154 - val_loss: 2.2933\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.6652 - val_loss: 6.2431\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6430 - val_loss: 3.0391\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.9433 - val_loss: 7.0266\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.6139 - val_loss: 3.0416\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.8236 - val_loss: 4.2219\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.6576 - val_loss: 3.0556\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.2946 - val_loss: 2.6692\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.1629 - val_loss: 10.0313\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.1078 - val_loss: 1.9930\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.2328 - val_loss: 3.4769\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.8892 - val_loss: 5.5745\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2952 - val_loss: 3.8036\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.5144 - val_loss: 3.3632\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.3568 - val_loss: 5.3131\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.1625 - val_loss: 2.2877\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.3886 - val_loss: 4.9391\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.7913 - val_loss: 4.0054\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.5824 - val_loss: 3.6109\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd4f0f8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 17 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 57.2202 - val_loss: 26.5483\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32.1743 - val_loss: 27.5425\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25.4748 - val_loss: 41.1258\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24.2396 - val_loss: 27.8824\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20.7812 - val_loss: 19.3800\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.2299 - val_loss: 23.6411\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.2934 - val_loss: 11.7384\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.7422 - val_loss: 7.8832\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.3871 - val_loss: 2.9521\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.0860 - val_loss: 5.1492\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7982 - val_loss: 3.4782\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.2837 - val_loss: 3.0549\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.2112 - val_loss: 2.9832\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5680 - val_loss: 3.5184\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4457 - val_loss: 4.1331\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.1898 - val_loss: 4.0191\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.8022 - val_loss: 5.5114\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.8132 - val_loss: 4.4166\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5309 - val_loss: 4.4073\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5373 - val_loss: 4.8587\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.2659 - val_loss: 5.0365\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5583 - val_loss: 5.3337\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4230 - val_loss: 4.7778\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0366 - val_loss: 4.9449\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0963 - val_loss: 6.4505\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4010 - val_loss: 4.4453\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.5285 - val_loss: 3.6248\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.6464 - val_loss: 4.9898\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5375 - val_loss: 4.2855\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.3672 - val_loss: 3.9915\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0390 - val_loss: 4.4955\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7268 - val_loss: 4.4525\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.4072 - val_loss: 3.8771\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.3138 - val_loss: 3.8928\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.0174 - val_loss: 4.2820\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.0442 - val_loss: 4.1359\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9627 - val_loss: 3.7050\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.1821 - val_loss: 3.8554\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.7063 - val_loss: 4.2529\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8306 - val_loss: 4.1718\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.4523 - val_loss: 3.8876\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.6662 - val_loss: 3.8194\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.4179 - val_loss: 3.7962\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9291 - val_loss: 3.4036\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.5965 - val_loss: 4.1443\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.0985 - val_loss: 4.2063\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.1161 - val_loss: 3.0678\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8276 - val_loss: 2.7626\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.3706 - val_loss: 3.7503\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.1867 - val_loss: 2.6078\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe5e0a9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 18 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 227364.3906 - val_loss: 99.8580\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 88333.2734 - val_loss: 103.6765\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2773.0679 - val_loss: 99.3793\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33128.2188 - val_loss: 97.4303\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 76683.3750 - val_loss: 98.4029\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2143.4990 - val_loss: 100.8111\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 107571.7031 - val_loss: 103.8819\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 82715.6719 - val_loss: 102.1570\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13061.2686 - val_loss: 98.3135\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33115.2031 - val_loss: 97.0448\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66099.4453 - val_loss: 97.7369\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28775.9746 - val_loss: 99.4506\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35396.6992 - val_loss: 99.9424\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21635.4570 - val_loss: 99.0271\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35880.6055 - val_loss: 98.2288\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21794.8379 - val_loss: 100.1028\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51241.4062 - val_loss: 100.5317\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42490.9414 - val_loss: 99.9371\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29158.7266 - val_loss: 97.1611\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 91067.9766 - val_loss: 96.1705\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 85848.1484 - val_loss: 96.8498\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46503.5234 - val_loss: 98.1712\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 714.6382 - val_loss: 98.7934\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1141.3564 - val_loss: 98.1256\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28123.5586 - val_loss: 98.4685\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15743.4668 - val_loss: 99.4766\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44072.2461 - val_loss: 99.7983\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16797.1191 - val_loss: 98.9683\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30248.4668 - val_loss: 98.1052\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34330.1992 - val_loss: 98.6163\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9304.6689 - val_loss: 99.6537\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46468.5000 - val_loss: 100.0219\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42528.9688 - val_loss: 99.0663\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6531.7935 - val_loss: 98.8432\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 548.6635 - val_loss: 99.7866\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37569.1562 - val_loss: 99.6590\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32295.8613 - val_loss: 98.9214\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6430.0249 - val_loss: 98.9193\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9697.5400 - val_loss: 98.9293\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4234.9321 - val_loss: 98.8258\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1207.3417 - val_loss: 99.2904\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22446.7344 - val_loss: 99.2438\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13010.2324 - val_loss: 98.6914\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26517.5703 - val_loss: 98.3574\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6022.5894 - val_loss: 99.0088\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24934.1094 - val_loss: 99.6067\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 31534.3652 - val_loss: 99.2276\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3118.5586 - val_loss: 98.7087\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16643.6621 - val_loss: 98.3070\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25591.6816 - val_loss: 98.6745\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfae463820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 19 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 86049.2734 - val_loss: 117.8549\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 362650.0312 - val_loss: 124.2642\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 214655.2031 - val_loss: 114.0222\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23891.4395 - val_loss: 104.1821\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 186684.4375 - val_loss: 97.8787\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 175795.9531 - val_loss: 102.3295\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 70983.5625 - val_loss: 106.8507\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 49088.7188 - val_loss: 107.1275\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44231.2227 - val_loss: 104.9811\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17476.8320 - val_loss: 104.7273\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9160.9062 - val_loss: 104.6369\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35427.4727 - val_loss: 103.4851\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 27159.1270 - val_loss: 105.4050\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 27392.3633 - val_loss: 105.2435\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10536.7002 - val_loss: 103.9880\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23278.9551 - val_loss: 103.7687\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13006.5049 - val_loss: 104.5050\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15606.3750 - val_loss: 105.2084\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22346.4668 - val_loss: 104.1458\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11600.6143 - val_loss: 104.3738\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9901.8604 - val_loss: 103.9708\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13531.6191 - val_loss: 104.2395\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8827.4424 - val_loss: 103.8612\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26158.5020 - val_loss: 103.4845\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11304.0938 - val_loss: 105.6300\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 47864.7734 - val_loss: 105.6545\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 39534.4727 - val_loss: 103.9122\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7542.1685 - val_loss: 103.9974\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8396.7656 - val_loss: 103.2208\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25406.5801 - val_loss: 103.2592\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11633.0654 - val_loss: 105.4107\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59171.5117 - val_loss: 105.5571\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40791.5352 - val_loss: 104.5440\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9014.7588 - val_loss: 103.0463\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8958.6211 - val_loss: 104.4418\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43891.2109 - val_loss: 104.5516\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 29529.1680 - val_loss: 102.5651\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 14801.6729 - val_loss: 102.5642\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12206.5684 - val_loss: 103.7096\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25051.3320 - val_loss: 103.4223\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11007.6377 - val_loss: 101.8844\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 49695.3867 - val_loss: 101.1762\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31128.8027 - val_loss: 102.8816\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23439.9570 - val_loss: 103.4332\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21611.4180 - val_loss: 102.2430\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 13249.8818 - val_loss: 102.3631\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2857.1926 - val_loss: 102.0631\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 19676.0117 - val_loss: 102.0190\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 2521.7637 - val_loss: 102.9495\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24295.0156 - val_loss: 103.1082\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb958a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 20 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 208134.9531 - val_loss: 83.3579\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 70624.3125 - val_loss: 91.3101\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 7242.9927 - val_loss: 86.6507\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 126582.2266 - val_loss: 83.8241\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 99245.0781 - val_loss: 87.8845\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22031.8066 - val_loss: 90.3920\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 18617.7188 - val_loss: 90.2186\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1747.7272 - val_loss: 89.4590\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 28752.8379 - val_loss: 91.2210\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4499.2832 - val_loss: 89.8666\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 44898.5195 - val_loss: 90.2205\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11515.7832 - val_loss: 93.2767\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 78116.7266 - val_loss: 94.8543\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 67584.8516 - val_loss: 93.3266\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 124.4438 - val_loss: 90.7817\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 82218.5625 - val_loss: 89.3026\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 73586.6328 - val_loss: 90.4664\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 30906.7539 - val_loss: 94.2127\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 25995.0469 - val_loss: 95.0736\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 43845.4648 - val_loss: 93.7335\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1621.6908 - val_loss: 89.4283\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 98271.8828 - val_loss: 90.8968\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 58288.1758 - val_loss: 94.3859\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25172.7324 - val_loss: 95.7268\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1913.5105 - val_loss: 95.6519\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8023.1572 - val_loss: 95.2541\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14263.4570 - val_loss: 95.9122\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8917.3252 - val_loss: 95.4191\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24867.0059 - val_loss: 95.4724\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4420.8633 - val_loss: 95.7489\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25108.0703 - val_loss: 95.3513\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11432.6484 - val_loss: 96.1986\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8684.9971 - val_loss: 96.2094\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8481.1797 - val_loss: 95.5215\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 35323.5547 - val_loss: 95.1236\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6112.5122 - val_loss: 96.3589\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 34160.0938 - val_loss: 97.4607\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 45133.0898 - val_loss: 97.1251\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28049.2598 - val_loss: 95.6148\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29481.3789 - val_loss: 95.6503\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23770.5195 - val_loss: 96.5638\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18861.4766 - val_loss: 97.1311\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1971.2179 - val_loss: 96.9182\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4683.1025 - val_loss: 96.3416\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16676.4238 - val_loss: 96.8728\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 233.5062 - val_loss: 96.3725\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 18882.0957 - val_loss: 96.9239\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1490.0651 - val_loss: 98.3766\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 62968.4336 - val_loss: 98.9546\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43716.7266 - val_loss: 98.0199\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfae8a88b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 21 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 72.4999 - val_loss: 45.3815\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 46.2399 - val_loss: 41.6619\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 38.9144 - val_loss: 46.5226\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 33.2286 - val_loss: 28.3501\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 27.8103 - val_loss: 20.5353\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 22.3954 - val_loss: 14.8141\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19.5145 - val_loss: 9.1884\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19.5171 - val_loss: 4.3215\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.9047 - val_loss: 4.0993\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.0250 - val_loss: 6.7260\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.7375 - val_loss: 4.8181\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.7219 - val_loss: 6.4242\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.3187 - val_loss: 6.5797\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.5222 - val_loss: 7.7895\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.5844 - val_loss: 6.7836\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.2340 - val_loss: 6.6443\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.7206 - val_loss: 7.5189\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.9870 - val_loss: 5.6122\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.9739 - val_loss: 5.3756\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.8335 - val_loss: 7.1866\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.2515 - val_loss: 4.7922\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.8477 - val_loss: 5.2728\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.9810 - val_loss: 5.0453\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.3327 - val_loss: 4.6072\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.0500 - val_loss: 6.8561\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.0524 - val_loss: 4.3127\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.3060 - val_loss: 4.3224\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9489 - val_loss: 5.0601\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.4474 - val_loss: 4.0343\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.0960 - val_loss: 5.7768\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4721 - val_loss: 5.1070\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6170 - val_loss: 2.5811\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.3314 - val_loss: 3.7639\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.0997 - val_loss: 3.4783\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.7721 - val_loss: 2.6301\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.0867 - val_loss: 3.3833\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.6069 - val_loss: 4.7775\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9293 - val_loss: 2.6831\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.9225 - val_loss: 2.4926\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.8643 - val_loss: 2.5646\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8807 - val_loss: 3.9320\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.5300 - val_loss: 3.0884\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7035 - val_loss: 3.4688\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.6714 - val_loss: 2.5116\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.3810 - val_loss: 2.8541\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.2623 - val_loss: 2.5322\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.4620 - val_loss: 3.5416\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.0726 - val_loss: 2.4763\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 4.5361 - val_loss: 3.1294\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.4035 - val_loss: 3.2775\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe00b1655e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 22 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 61639.2812 - val_loss: 108.2163\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 154789.2344 - val_loss: 107.7854\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 69652.3125 - val_loss: 104.0294\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15347.2695 - val_loss: 100.4621\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20912.0352 - val_loss: 101.2081\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44074.4922 - val_loss: 103.4747\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36879.8711 - val_loss: 101.2869\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27544.4160 - val_loss: 100.3709\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18212.6504 - val_loss: 103.8007\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67850.7344 - val_loss: 104.6055\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47275.4492 - val_loss: 102.5706\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 626.3094 - val_loss: 98.5487\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 65689.4688 - val_loss: 97.5394\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 72405.9766 - val_loss: 98.3721\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 28871.4473 - val_loss: 100.5864\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29528.9043 - val_loss: 102.8671\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 34815.0625 - val_loss: 102.3195\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6644.9678 - val_loss: 99.9528\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 59081.1992 - val_loss: 98.8662\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50562.6992 - val_loss: 100.3731\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15524.3848 - val_loss: 103.1951\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 62063.6836 - val_loss: 103.9742\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 52083.2383 - val_loss: 101.4781\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5697.1401 - val_loss: 100.7107\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9428.9561 - val_loss: 100.2462\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16041.7471 - val_loss: 100.2152\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3905.1562 - val_loss: 100.0888\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16855.6719 - val_loss: 100.2058\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1614.3336 - val_loss: 102.2248\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 63230.3438 - val_loss: 103.1514\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 52091.0234 - val_loss: 101.3670\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5990.3223 - val_loss: 99.3447\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 58628.1250 - val_loss: 98.6652\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 52819.8867 - val_loss: 99.7083\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 30822.8945 - val_loss: 102.5708\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36482.6406 - val_loss: 102.9095\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24508.1914 - val_loss: 101.1274\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12278.0635 - val_loss: 100.5230\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4102.6548 - val_loss: 101.3399\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20978.8086 - val_loss: 101.2786\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16649.0469 - val_loss: 100.0862\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20148.6055 - val_loss: 99.8248\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14776.6484 - val_loss: 101.0612\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25554.0137 - val_loss: 101.1953\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18301.8750 - val_loss: 100.3898\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3843.5786 - val_loss: 100.3531\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1004.2081 - val_loss: 99.7422\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23265.5059 - val_loss: 99.6459\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17386.0488 - val_loss: 100.9164\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19002.5801 - val_loss: 100.9442\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb96cbdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 23 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 337ms/step - loss: 62.2654 - val_loss: 29.1438\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37.9532 - val_loss: 26.8510\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32.1522 - val_loss: 43.5015\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28.2573 - val_loss: 25.5067\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23.3084 - val_loss: 15.2635\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.8435 - val_loss: 21.3278\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.7733 - val_loss: 6.2581\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.1559 - val_loss: 12.5204\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.4180 - val_loss: 5.7352\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.3127 - val_loss: 5.6442\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.2143 - val_loss: 9.7145\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.9390 - val_loss: 4.6806\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.4992 - val_loss: 7.8088\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.2067 - val_loss: 5.3742\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.7495 - val_loss: 5.5492\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7158 - val_loss: 3.4932\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.4211 - val_loss: 6.7598\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.7448 - val_loss: 3.7989\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.2483 - val_loss: 5.0439\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.1623 - val_loss: 4.4976\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.0967 - val_loss: 3.8356\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4901 - val_loss: 4.1208\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.1007 - val_loss: 4.4369\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.9884 - val_loss: 4.5353\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5060 - val_loss: 3.8258\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.9204 - val_loss: 4.3714\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.0705 - val_loss: 4.3991\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8847 - val_loss: 5.3388\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.7526 - val_loss: 4.8417\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.5716 - val_loss: 4.2131\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.0789 - val_loss: 2.8150\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.6623 - val_loss: 2.9320\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.2204 - val_loss: 4.8529\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.2736 - val_loss: 2.9442\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.7974 - val_loss: 2.8051\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.7650 - val_loss: 3.6329\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.4841 - val_loss: 2.8991\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.3288 - val_loss: 2.6872\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.2607 - val_loss: 4.3871\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.4903 - val_loss: 2.8747\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.6979 - val_loss: 2.4203\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.0245 - val_loss: 4.6587\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.6761 - val_loss: 3.0700\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.6488 - val_loss: 2.4185\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.8521 - val_loss: 5.7764\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.8589 - val_loss: 7.6955\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.1942 - val_loss: 3.9286\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.6513 - val_loss: 2.5925\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 5.5896 - val_loss: 3.7210\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.7800 - val_loss: 3.1896\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe07a65e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 24 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 6243611.0000 - val_loss: 100.0036\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3211035.2500 - val_loss: 99.6177\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1850332.0000 - val_loss: 99.5257\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 879630.0000 - val_loss: 99.5799\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1155022.1250 - val_loss: 99.4447\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 950270.5000 - val_loss: 99.4790\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 759793.7500 - val_loss: 99.3745\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 835202.8125 - val_loss: 99.1917\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 776721.7500 - val_loss: 99.0304\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 781739.3750 - val_loss: 98.8486\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 614316.3750 - val_loss: 98.6708\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 802300.2500 - val_loss: 98.5585\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 321719.2812 - val_loss: 98.4326\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 333278.9375 - val_loss: 98.3370\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 770524.8125 - val_loss: 98.1967\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 952136.0000 - val_loss: 98.1984\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 994721.0625 - val_loss: 98.0850\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 486079.5938 - val_loss: 98.0837\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 145601.1875 - val_loss: 98.0356\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 323446.7500 - val_loss: 97.9884\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 309641.8125 - val_loss: 97.9381\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 546284.1250 - val_loss: 97.8481\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 845865.1875 - val_loss: 97.9153\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1000879.5625 - val_loss: 97.8959\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 513702.0625 - val_loss: 97.9137\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 294721.9062 - val_loss: 97.9271\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 269602.7500 - val_loss: 97.9079\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 221719.7656 - val_loss: 97.8877\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 316739.3125 - val_loss: 97.8867\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 355657.8750 - val_loss: 97.8886\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 279289.1562 - val_loss: 97.8909\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 245855.7344 - val_loss: 97.8968\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 268045.4688 - val_loss: 97.8769\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 98738.4609 - val_loss: 97.8562\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 354625.9375 - val_loss: 97.8676\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 158163.0938 - val_loss: 97.8577\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 127889.0000 - val_loss: 97.8376\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 349222.9062 - val_loss: 97.8351\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 295029.5938 - val_loss: 97.8523\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 612739.7500 - val_loss: 97.8376\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 752604.3125 - val_loss: 97.9193\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 615625.5625 - val_loss: 97.9431\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 229959.1875 - val_loss: 97.9696\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 305119.4062 - val_loss: 98.0044\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 270570.4062 - val_loss: 98.0523\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 233028.0312 - val_loss: 98.0775\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 272166.5312 - val_loss: 98.0930\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 280174.2500 - val_loss: 98.1000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 251336.0000 - val_loss: 98.1126\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 277414.1562 - val_loss: 98.1393\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe0077ad790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 25 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 61378.9531 - val_loss: 74.3763\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60224.7031 - val_loss: 80.7179\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72624.9453 - val_loss: 81.0627\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 34783.4805 - val_loss: 78.6874\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9529.9170 - val_loss: 80.7391\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27178.6504 - val_loss: 80.9821\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15342.4277 - val_loss: 84.7048\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 79239.5000 - val_loss: 86.2869\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59941.3555 - val_loss: 84.0779\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5301.6572 - val_loss: 84.6806\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11507.2012 - val_loss: 85.9706\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34956.0273 - val_loss: 87.2629\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13111.5391 - val_loss: 85.3305\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59194.4141 - val_loss: 84.6305\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52446.3281 - val_loss: 86.5897\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8548.1465 - val_loss: 89.2631\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 69677.7188 - val_loss: 90.9634\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64509.7695 - val_loss: 90.1162\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4711.4160 - val_loss: 90.2508\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1100.1039 - val_loss: 89.8542\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30667.0000 - val_loss: 90.0345\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7708.0972 - val_loss: 92.3130\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52335.0938 - val_loss: 93.2014\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49758.3125 - val_loss: 92.2383\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8227.5908 - val_loss: 91.3191\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31752.6543 - val_loss: 91.2160\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24816.8652 - val_loss: 91.9910\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9282.8750 - val_loss: 94.2237\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 78333.2578 - val_loss: 95.0066\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 60282.7422 - val_loss: 94.3552\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27523.8828 - val_loss: 93.3924\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29895.5254 - val_loss: 93.1422\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15381.7354 - val_loss: 94.4665\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18167.4980 - val_loss: 95.0917\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14048.5723 - val_loss: 94.4632\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15850.4355 - val_loss: 94.3603\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9085.0127 - val_loss: 95.2094\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20777.5234 - val_loss: 95.2200\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11274.8740 - val_loss: 94.8117\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15542.6543 - val_loss: 94.5436\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9546.6553 - val_loss: 95.1437\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13189.3516 - val_loss: 95.2305\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6737.7451 - val_loss: 95.0110\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13897.9980 - val_loss: 94.7206\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14715.5312 - val_loss: 95.1389\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6360.6963 - val_loss: 95.2311\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4074.1484 - val_loss: 95.3615\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12557.7236 - val_loss: 95.4971\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 786.8963 - val_loss: 95.4775\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4760.3145 - val_loss: 95.4837\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff8780280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 26 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 181041.3750 - val_loss: 88.7994\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 145461.5938 - val_loss: 87.3186\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 66052.9609 - val_loss: 98.2913\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 69016.3906 - val_loss: 98.5800\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44422.5781 - val_loss: 95.7639\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36232.1602 - val_loss: 96.2212\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 909.8546 - val_loss: 98.2636\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24826.6895 - val_loss: 99.3822\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 52877.4414 - val_loss: 97.9641\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18447.5566 - val_loss: 96.9965\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 30678.0762 - val_loss: 98.0236\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15087.7236 - val_loss: 94.7939\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72440.7578 - val_loss: 94.2700\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59061.8008 - val_loss: 97.4411\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21850.5215 - val_loss: 97.1892\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 827.3611 - val_loss: 97.7647\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19803.9473 - val_loss: 97.0084\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 874.8254 - val_loss: 94.5613\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59463.6523 - val_loss: 94.8267\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 40552.9219 - val_loss: 96.9288\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26537.3281 - val_loss: 97.9301\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14491.9375 - val_loss: 95.5915\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36548.2812 - val_loss: 95.9823\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26491.4883 - val_loss: 97.5181\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6446.5640 - val_loss: 97.1601\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3173.2908 - val_loss: 98.8283\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55378.1992 - val_loss: 99.2178\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18276.4512 - val_loss: 96.7908\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14943.3965 - val_loss: 96.2348\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36627.1562 - val_loss: 96.4789\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4060.0696 - val_loss: 99.4715\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 71505.3203 - val_loss: 100.6484\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 75030.3516 - val_loss: 100.0340\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 32920.6992 - val_loss: 98.3930\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23363.0742 - val_loss: 96.6989\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 28207.1094 - val_loss: 97.6781\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3552.3787 - val_loss: 99.7973\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 71099.0938 - val_loss: 100.4316\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 59233.3633 - val_loss: 99.3051\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30891.5098 - val_loss: 97.0333\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 42730.1641 - val_loss: 97.0764\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 35180.3750 - val_loss: 98.2324\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3062.8704 - val_loss: 100.9484\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 65651.5703 - val_loss: 100.4439\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 48830.0586 - val_loss: 98.1398\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16477.6855 - val_loss: 97.5013\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8262.3984 - val_loss: 98.2628\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2466.2021 - val_loss: 98.6055\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28768.7793 - val_loss: 99.5803\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 23082.3184 - val_loss: 98.7629\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe0036459d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 27 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 203176.2031 - val_loss: 105.1790\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 124815.3125 - val_loss: 105.4523\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31693.7969 - val_loss: 101.7046\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 137061.0938 - val_loss: 96.0083\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 112640.6016 - val_loss: 101.0155\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13996.4766 - val_loss: 107.2145\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 184421.4531 - val_loss: 109.5689\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 151733.7344 - val_loss: 105.6442\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 39459.3711 - val_loss: 101.2502\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 75356.9844 - val_loss: 98.6522\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 69462.3281 - val_loss: 100.3393\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18086.1406 - val_loss: 103.2962\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 51670.5195 - val_loss: 103.5031\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 54132.9844 - val_loss: 103.0782\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12380.8047 - val_loss: 100.2945\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 112802.7344 - val_loss: 98.6157\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 104432.2031 - val_loss: 100.7862\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13094.3271 - val_loss: 102.4513\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42274.0117 - val_loss: 102.5877\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 42117.5820 - val_loss: 101.1745\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 2119.8240 - val_loss: 101.3725\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 21680.8945 - val_loss: 101.0487\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7895.7539 - val_loss: 101.0853\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20545.2266 - val_loss: 101.1667\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18347.5781 - val_loss: 100.4663\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11925.5254 - val_loss: 102.2009\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 46898.0039 - val_loss: 102.1500\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 29941.4609 - val_loss: 101.5654\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5960.1992 - val_loss: 100.8367\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7766.5923 - val_loss: 101.8318\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31027.6094 - val_loss: 101.5410\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16175.1250 - val_loss: 100.1888\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 43486.6914 - val_loss: 100.0546\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 30480.6719 - val_loss: 100.9627\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5200.4526 - val_loss: 101.0071\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 681.4209 - val_loss: 101.8346\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43885.3477 - val_loss: 102.0092\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28095.9746 - val_loss: 100.3501\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 41582.9141 - val_loss: 99.8358\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 40687.5312 - val_loss: 100.7385\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7038.9702 - val_loss: 102.1443\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 44787.2188 - val_loss: 102.0703\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 42555.5742 - val_loss: 101.4455\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15446.6104 - val_loss: 100.0695\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 28290.7461 - val_loss: 99.9652\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 32788.2578 - val_loss: 100.1705\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14600.5957 - val_loss: 101.7880\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 37065.4766 - val_loss: 102.0401\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 52149.0742 - val_loss: 101.9239\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 28915.1484 - val_loss: 100.5313\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb59445e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 28 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 317491.8125 - val_loss: 77.7154\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 97033.6406 - val_loss: 108.1195\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 370003.6250 - val_loss: 111.6991\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 303186.4688 - val_loss: 108.5547\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 146761.2344 - val_loss: 102.3684\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 102528.7734 - val_loss: 90.6836\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 174507.8906 - val_loss: 88.5126\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 188785.5156 - val_loss: 89.4232\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 106948.4609 - val_loss: 94.5559\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 51882.5117 - val_loss: 100.8040\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 141707.5312 - val_loss: 103.1507\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 141123.0938 - val_loss: 101.1191\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 65706.0234 - val_loss: 99.0126\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 31993.9414 - val_loss: 94.6415\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 93397.1719 - val_loss: 94.1385\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 94405.0625 - val_loss: 96.4479\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 37350.7109 - val_loss: 99.2092\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 49433.8945 - val_loss: 100.2268\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 44328.8633 - val_loss: 98.2650\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30769.2363 - val_loss: 97.6320\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7679.4780 - val_loss: 99.9344\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 66548.6562 - val_loss: 101.0945\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 61167.6758 - val_loss: 100.2410\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19090.3926 - val_loss: 98.2262\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10336.6953 - val_loss: 97.7571\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 24607.6621 - val_loss: 98.7489\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2002.0668 - val_loss: 98.0864\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 15390.6748 - val_loss: 99.1901\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 26272.2012 - val_loss: 99.3675\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7118.9233 - val_loss: 98.6727\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 6527.6479 - val_loss: 98.5835\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4276.6616 - val_loss: 98.5230\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 6399.8169 - val_loss: 99.7211\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 24186.3809 - val_loss: 99.2102\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8869.1758 - val_loss: 97.6780\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 42143.9648 - val_loss: 97.5286\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 24306.3145 - val_loss: 98.4290\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 31691.5527 - val_loss: 99.9691\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 15874.7617 - val_loss: 98.9884\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10639.8281 - val_loss: 98.1930\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20823.1855 - val_loss: 99.1211\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12839.3525 - val_loss: 98.9867\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 228.5397 - val_loss: 99.8099\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 30895.3027 - val_loss: 99.8595\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 21562.1172 - val_loss: 97.2032\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 66057.1094 - val_loss: 96.5621\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 64579.7812 - val_loss: 98.0209\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28853.0586 - val_loss: 100.1506\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 32488.6914 - val_loss: 100.3481\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 27598.7656 - val_loss: 99.4607\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff3938550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 29 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 92682.6250 - val_loss: 94.1051\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 101554.9766 - val_loss: 91.1414\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29123.4473 - val_loss: 86.6541\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 76019.1719 - val_loss: 85.3047\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 54014.0859 - val_loss: 91.0961\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86144.4297 - val_loss: 93.0591\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28226.8848 - val_loss: 89.9156\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 45377.4766 - val_loss: 87.3113\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59345.4922 - val_loss: 89.3622\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8571.3486 - val_loss: 92.4475\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61035.5391 - val_loss: 93.4989\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49807.0234 - val_loss: 92.6477\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19421.2617 - val_loss: 88.0960\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 107956.5156 - val_loss: 86.4711\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 102857.8281 - val_loss: 89.3494\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 60167.9492 - val_loss: 93.1238\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17735.0996 - val_loss: 93.7109\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11818.6074 - val_loss: 92.0282\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39911.9727 - val_loss: 92.6577\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21190.7793 - val_loss: 94.6696\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26713.0879 - val_loss: 94.8724\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18774.8066 - val_loss: 93.6519\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 20097.3145 - val_loss: 93.8703\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7172.3159 - val_loss: 95.0771\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32012.6641 - val_loss: 95.3902\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 19267.7695 - val_loss: 94.7463\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12415.1016 - val_loss: 93.9753\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14487.2090 - val_loss: 95.0394\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 23971.9883 - val_loss: 95.3149\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6825.6680 - val_loss: 94.2648\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12512.5840 - val_loss: 94.2544\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15252.2520 - val_loss: 95.0792\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10093.0312 - val_loss: 94.9830\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5686.1099 - val_loss: 95.1284\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3272.2312 - val_loss: 95.2425\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5790.4858 - val_loss: 94.7564\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14048.0049 - val_loss: 94.8640\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3895.8245 - val_loss: 95.9213\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36410.0625 - val_loss: 96.4304\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28615.0332 - val_loss: 95.1858\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24993.6387 - val_loss: 94.6686\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5634.2285 - val_loss: 96.1124\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14907.9375 - val_loss: 96.4639\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22365.8086 - val_loss: 95.7767\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6290.0977 - val_loss: 95.9320\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8840.4902 - val_loss: 95.6898\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7414.4629 - val_loss: 96.1022\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12271.4092 - val_loss: 96.0332\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1430.9844 - val_loss: 96.3279\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13373.0635 - val_loss: 95.9851\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb82a1af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 30 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 58775.1250 - val_loss: 107.6949\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 214739.1406 - val_loss: 113.8098\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 146819.8438 - val_loss: 104.0412\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14873.2305 - val_loss: 103.0026\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11287.4648 - val_loss: 100.6807\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 66276.1016 - val_loss: 99.6976\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38799.8555 - val_loss: 104.0336\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42926.3984 - val_loss: 103.5622\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32221.4609 - val_loss: 101.8971\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40560.7500 - val_loss: 100.2945\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 2934.8020 - val_loss: 101.3704\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8166.7402 - val_loss: 101.9301\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6249.2476 - val_loss: 100.6496\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38714.8242 - val_loss: 100.6949\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22947.5684 - val_loss: 103.9314\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 52423.2109 - val_loss: 103.8491\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33088.5938 - val_loss: 102.6915\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23638.4785 - val_loss: 100.7991\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21963.5137 - val_loss: 102.2817\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8304.7891 - val_loss: 101.7523\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2599.9902 - val_loss: 103.5002\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39346.3984 - val_loss: 102.7838\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15924.5020 - val_loss: 100.3430\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61701.3359 - val_loss: 99.2144\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46694.4258 - val_loss: 102.0565\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8505.9893 - val_loss: 102.1761\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13048.1738 - val_loss: 101.6867\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1134.4399 - val_loss: 98.0111\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79688.3984 - val_loss: 97.5755\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 89631.4375 - val_loss: 98.6594\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57741.2227 - val_loss: 100.7614\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1977.1221 - val_loss: 101.2193\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6442.5513 - val_loss: 101.4386\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3631.0674 - val_loss: 101.5761\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8969.4951 - val_loss: 101.0207\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21696.2109 - val_loss: 100.5838\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9467.7891 - val_loss: 101.9118\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42270.0312 - val_loss: 102.6729\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31730.0000 - val_loss: 100.6697\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25097.3887 - val_loss: 100.1640\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19315.2402 - val_loss: 101.1174\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13771.6016 - val_loss: 101.2809\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6846.5537 - val_loss: 99.8164\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35482.2500 - val_loss: 99.9252\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21463.1992 - val_loss: 100.5436\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20892.0273 - val_loss: 101.6521\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9796.8408 - val_loss: 100.5928\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7213.9316 - val_loss: 100.4901\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8686.2256 - val_loss: 101.5162\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 21965.4902 - val_loss: 101.2275\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb8914ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 31 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 79.0281 - val_loss: 59.4986\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56.4428 - val_loss: 44.9506\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44.7244 - val_loss: 50.2484\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.6552 - val_loss: 26.9468\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.4210 - val_loss: 20.9532\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26.9875 - val_loss: 10.1904\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23.2235 - val_loss: 9.4136\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21.2040 - val_loss: 7.3770\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20.1528 - val_loss: 9.2796\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19.3344 - val_loss: 8.7071\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.0615 - val_loss: 10.5892\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20.7947 - val_loss: 8.4369\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.8567 - val_loss: 8.3816\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.0370 - val_loss: 7.5977\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.7408 - val_loss: 7.3721\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.0239 - val_loss: 6.8129\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.9552 - val_loss: 7.6143\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.4977 - val_loss: 6.6091\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.7978 - val_loss: 6.9435\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.3239 - val_loss: 6.1268\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.5742 - val_loss: 7.2758\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.9537 - val_loss: 5.9805\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.0041 - val_loss: 7.1379\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.6759 - val_loss: 5.4167\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.1228 - val_loss: 4.9159\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.3353 - val_loss: 5.2809\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.0080 - val_loss: 5.2879\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.9211 - val_loss: 5.0745\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 11.6231 - val_loss: 4.6659\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.8136 - val_loss: 6.3750\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.1866 - val_loss: 4.8721\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.7031 - val_loss: 2.9653\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.1698 - val_loss: 6.5050\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.0757 - val_loss: 4.8558\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.9297 - val_loss: 4.3969\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.2916 - val_loss: 3.9238\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.4375 - val_loss: 2.8835\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.2692 - val_loss: 2.2619\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6786 - val_loss: 4.3175\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.4571 - val_loss: 3.6431\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.2322 - val_loss: 3.1695\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3169 - val_loss: 2.9171\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.4913 - val_loss: 4.8078\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.6153 - val_loss: 4.6052\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3794 - val_loss: 4.0132\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.9616 - val_loss: 1.5947\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9592 - val_loss: 3.5977\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0617 - val_loss: 2.7270\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5789 - val_loss: 1.6187\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.6206 - val_loss: 1.7594\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb82a1700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 32 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 77.6596 - val_loss: 49.2635\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47.0769 - val_loss: 34.2728\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.7740 - val_loss: 40.5489\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28.4619 - val_loss: 23.1902\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24.0345 - val_loss: 18.4223\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.8117 - val_loss: 4.8742\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20.7875 - val_loss: 12.3637\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.0083 - val_loss: 9.9581\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.8258 - val_loss: 6.4745\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.0193 - val_loss: 4.0036\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.7677 - val_loss: 6.3124\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.3345 - val_loss: 5.1521\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.3541 - val_loss: 4.9653\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.2543 - val_loss: 4.6396\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.5573 - val_loss: 5.4167\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.6799 - val_loss: 5.0532\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.6241 - val_loss: 6.2825\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.9982 - val_loss: 4.9123\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.1961 - val_loss: 4.6285\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.7943 - val_loss: 3.8711\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.9551 - val_loss: 3.9122\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.3541 - val_loss: 3.6180\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.2093 - val_loss: 4.1180\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.9432 - val_loss: 3.9725\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6912 - val_loss: 4.1169\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.4937 - val_loss: 4.6509\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.9923 - val_loss: 3.0603\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.4915 - val_loss: 4.7656\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.4837 - val_loss: 3.7057\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1622 - val_loss: 3.3845\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.5028 - val_loss: 4.0405\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.8495 - val_loss: 3.3467\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2432 - val_loss: 3.5387\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.9372 - val_loss: 2.9966\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6840 - val_loss: 7.8547\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.3028 - val_loss: 3.4519\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.9531 - val_loss: 4.8001\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6861 - val_loss: 2.2704\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.9607 - val_loss: 2.6573\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6262 - val_loss: 4.0952\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.4744 - val_loss: 5.0124\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7528 - val_loss: 4.0273\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.6931 - val_loss: 2.2807\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.4195 - val_loss: 3.8741\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3137 - val_loss: 3.1522\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.8865 - val_loss: 2.9032\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.8987 - val_loss: 3.0540\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9094 - val_loss: 2.4210\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.7007 - val_loss: 4.6255\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.8660 - val_loss: 2.3360\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfe74018b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 33 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 86.1434 - val_loss: 49.6516\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43.2299 - val_loss: 28.8155\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32.8956 - val_loss: 43.3077\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.1227 - val_loss: 39.1503\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25.6707 - val_loss: 23.1254\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21.3687 - val_loss: 20.5315\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.9286 - val_loss: 11.7583\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.5153 - val_loss: 7.1137\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.1534 - val_loss: 3.5486\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.3083 - val_loss: 2.9642\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.0662 - val_loss: 8.1990\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.9785 - val_loss: 5.2503\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1330 - val_loss: 4.0741\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.6320 - val_loss: 6.0658\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.8818 - val_loss: 4.0601\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.7998 - val_loss: 3.7554\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.0964 - val_loss: 4.3672\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4512 - val_loss: 5.9695\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4817 - val_loss: 4.1451\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.3566 - val_loss: 3.6291\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.7683 - val_loss: 4.3759\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.7006 - val_loss: 4.3334\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.0918 - val_loss: 4.6474\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.5078 - val_loss: 4.6609\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3464 - val_loss: 3.4363\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5776 - val_loss: 3.6043\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.4544 - val_loss: 4.5049\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.4509 - val_loss: 3.5565\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.1136 - val_loss: 3.5803\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.1192 - val_loss: 3.0802\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8544 - val_loss: 3.2288\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.6547 - val_loss: 3.4206\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.7637 - val_loss: 3.4207\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.5746 - val_loss: 2.9069\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.7780 - val_loss: 3.1256\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.4631 - val_loss: 3.0622\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0422 - val_loss: 3.3771\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.4604 - val_loss: 2.6705\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0731 - val_loss: 2.7322\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9800 - val_loss: 2.9356\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.3785 - val_loss: 2.6442\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.7424 - val_loss: 2.4383\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5814 - val_loss: 3.1215\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.4705 - val_loss: 2.3236\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7727 - val_loss: 2.1632\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.2047 - val_loss: 2.1727\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.1227 - val_loss: 2.1740\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.0078 - val_loss: 2.2272\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.9360 - val_loss: 2.0074\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.0023 - val_loss: 2.0006\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe0051bb3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 34 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 184135.7969 - val_loss: 87.6771\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 206447.2969 - val_loss: 95.8444\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30900.5469 - val_loss: 98.2417\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25797.2754 - val_loss: 97.6635\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16951.5234 - val_loss: 100.6910\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 90406.5078 - val_loss: 100.6517\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31552.9180 - val_loss: 98.7260\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 76273.2578 - val_loss: 98.4232\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44298.1484 - val_loss: 99.6041\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53997.9102 - val_loss: 100.4376\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43220.1250 - val_loss: 98.7955\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70844.8516 - val_loss: 98.5328\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30541.3125 - val_loss: 99.8848\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 35011.9766 - val_loss: 100.2127\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48866.8359 - val_loss: 98.8244\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25764.7051 - val_loss: 99.3175\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3142.3257 - val_loss: 100.9879\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83974.0938 - val_loss: 100.6478\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64771.0859 - val_loss: 99.3337\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14691.3291 - val_loss: 99.2521\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12966.0391 - val_loss: 99.6774\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25810.6426 - val_loss: 98.7539\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1913.4135 - val_loss: 98.2414\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33641.9102 - val_loss: 98.9538\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17535.3125 - val_loss: 99.6077\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28698.1387 - val_loss: 98.8489\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22265.2246 - val_loss: 97.6685\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57890.9492 - val_loss: 98.3370\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23282.4688 - val_loss: 99.5189\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42843.8984 - val_loss: 99.9404\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25068.2500 - val_loss: 99.2763\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37798.2188 - val_loss: 98.7642\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13357.9922 - val_loss: 99.8791\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 62842.3281 - val_loss: 100.4719\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47355.5078 - val_loss: 99.5373\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15340.1758 - val_loss: 99.1547\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46590.0508 - val_loss: 100.0774\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19662.8555 - val_loss: 100.8424\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23235.2383 - val_loss: 99.3891\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30040.6719 - val_loss: 99.2881\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12092.1758 - val_loss: 100.0350\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26678.4336 - val_loss: 100.1566\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8390.5537 - val_loss: 99.0583\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42482.4570 - val_loss: 98.9894\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16727.2832 - val_loss: 99.3849\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 56687.8008 - val_loss: 100.1231\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32765.5137 - val_loss: 99.2903\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14492.4248 - val_loss: 98.3081\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55466.6055 - val_loss: 98.4570\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21901.0332 - val_loss: 99.2840\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbcf9e160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 35 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 69.1394 - val_loss: 38.2458\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.6443 - val_loss: 19.7310\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26.0506 - val_loss: 40.1429\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25.9332 - val_loss: 34.8045\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20.4937 - val_loss: 20.5063\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20.3186 - val_loss: 21.1575\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.7007 - val_loss: 20.8855\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.3563 - val_loss: 12.1587\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.4936 - val_loss: 11.2899\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.6887 - val_loss: 8.2314\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7983 - val_loss: 4.4621\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7122 - val_loss: 5.6212\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7693 - val_loss: 10.8756\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6543 - val_loss: 3.2036\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5920 - val_loss: 5.5244\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6752 - val_loss: 4.4711\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4380 - val_loss: 2.6849\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.3899 - val_loss: 6.9737\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.8822 - val_loss: 3.0830\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0810 - val_loss: 8.8559\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.7754 - val_loss: 2.6614\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2751 - val_loss: 3.3722\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.3960 - val_loss: 4.1701\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.3795 - val_loss: 3.0399\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0611 - val_loss: 3.6770\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.9129 - val_loss: 3.9545\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.7631 - val_loss: 3.8980\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8635 - val_loss: 3.2581\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5943 - val_loss: 3.2361\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.5282 - val_loss: 4.1638\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8457 - val_loss: 2.7270\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.7003 - val_loss: 2.2722\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.4825 - val_loss: 5.4319\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2358 - val_loss: 3.3982\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8010 - val_loss: 5.3456\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.1817 - val_loss: 2.3290\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.4400 - val_loss: 2.2946\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.1073 - val_loss: 4.9073\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.1028 - val_loss: 2.2750\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5269 - val_loss: 2.4338\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.4870 - val_loss: 2.8728\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.8376 - val_loss: 4.7093\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7054 - val_loss: 3.4169\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.1490 - val_loss: 3.1455\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.2508 - val_loss: 2.7883\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5248 - val_loss: 2.6749\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.0080 - val_loss: 3.8234\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.2652 - val_loss: 2.1032\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.0433 - val_loss: 1.8970\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.7349 - val_loss: 2.3672\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfcdd341f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 36 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 98699.0234 - val_loss: 120.2307\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 162728.6250 - val_loss: 117.0442\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 99473.6719 - val_loss: 109.2841\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35095.1094 - val_loss: 108.1215\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8949.7422 - val_loss: 109.8181\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68474.2188 - val_loss: 109.3932\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40616.0078 - val_loss: 108.3147\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9367.0547 - val_loss: 107.1737\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12323.2529 - val_loss: 108.3401\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41407.8516 - val_loss: 108.0959\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9561.0635 - val_loss: 107.0598\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47282.6992 - val_loss: 105.7322\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48319.9570 - val_loss: 106.5556\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9332.6582 - val_loss: 108.2499\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 75593.4531 - val_loss: 108.9219\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49273.0000 - val_loss: 107.2422\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 33915.8789 - val_loss: 103.5546\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 68275.7109 - val_loss: 102.5883\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 75848.3438 - val_loss: 103.3179\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42182.5742 - val_loss: 104.3329\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7661.0347 - val_loss: 104.7098\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3799.5842 - val_loss: 104.7407\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13275.1143 - val_loss: 104.4234\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1797.4918 - val_loss: 104.6653\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18147.8594 - val_loss: 104.3347\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6195.6216 - val_loss: 103.1617\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31916.4570 - val_loss: 103.2549\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23556.4277 - val_loss: 103.9267\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12775.7207 - val_loss: 103.8627\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5361.3140 - val_loss: 102.7066\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30165.4746 - val_loss: 102.8364\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20273.1230 - val_loss: 103.1782\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18009.3477 - val_loss: 103.9097\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12000.4473 - val_loss: 102.7812\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24268.5918 - val_loss: 102.6155\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18984.6484 - val_loss: 103.1236\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 546.4103 - val_loss: 104.4369\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 63601.9805 - val_loss: 104.7804\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 60076.3008 - val_loss: 103.6547\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14863.0264 - val_loss: 102.7983\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5287.5557 - val_loss: 102.1677\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15587.5186 - val_loss: 102.6455\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10566.1123 - val_loss: 102.7531\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1818.2708 - val_loss: 102.5683\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3322.7100 - val_loss: 102.3392\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16455.2031 - val_loss: 101.8995\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14572.7744 - val_loss: 102.1892\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1037.5339 - val_loss: 102.1510\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5218.4634 - val_loss: 102.4530\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11266.5283 - val_loss: 102.2879\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdffa36b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 37 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 66.8313 - val_loss: 35.1705\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27.3380 - val_loss: 12.8203\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21.3810 - val_loss: 32.1430\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22.8937 - val_loss: 27.8031\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.5033 - val_loss: 12.0010\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.9922 - val_loss: 16.6098\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.8588 - val_loss: 18.8088\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.2983 - val_loss: 9.9735\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.9872 - val_loss: 6.0260\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0846 - val_loss: 4.8687\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.6570 - val_loss: 2.8146\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.0309 - val_loss: 3.7637\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.1198 - val_loss: 5.5955\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.7638 - val_loss: 6.3593\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8385 - val_loss: 2.8751\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6667 - val_loss: 3.0159\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3801 - val_loss: 3.7621\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0236 - val_loss: 2.7325\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.5162 - val_loss: 2.9043\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.1815 - val_loss: 3.0856\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.2630 - val_loss: 3.4583\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.0169 - val_loss: 3.1830\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.9953 - val_loss: 2.9234\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1733 - val_loss: 3.2001\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.0107 - val_loss: 3.7863\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.8493 - val_loss: 2.7782\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.7467 - val_loss: 2.9242\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.7485 - val_loss: 3.6389\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.3577 - val_loss: 3.6428\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.2079 - val_loss: 3.4772\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.6484 - val_loss: 3.6937\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.5354 - val_loss: 3.0622\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.0780 - val_loss: 5.0524\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.7843 - val_loss: 3.2829\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.7796 - val_loss: 3.1875\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.0544 - val_loss: 5.1813\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7490 - val_loss: 3.1898\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.2347 - val_loss: 3.1735\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.8229 - val_loss: 3.4505\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.8655 - val_loss: 3.9552\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3.5929 - val_loss: 4.9161\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.7702 - val_loss: 3.4712\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.6119 - val_loss: 3.5528\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.0773 - val_loss: 3.7799\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.8834 - val_loss: 4.5367\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.6758 - val_loss: 4.8895\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.3918 - val_loss: 3.6448\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.4684 - val_loss: 3.7892\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.2031 - val_loss: 5.1902\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.4296 - val_loss: 4.4188\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9f4290d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 38 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 90.3156 - val_loss: 70.5866\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46.3895 - val_loss: 35.0310\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46.2454 - val_loss: 41.7421\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.4775 - val_loss: 46.1310\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31.8883 - val_loss: 29.8560\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28.2238 - val_loss: 25.3221\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22.7908 - val_loss: 16.8721\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19.4353 - val_loss: 10.9647\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.6881 - val_loss: 4.1979\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.3199 - val_loss: 8.0708\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.6147 - val_loss: 5.8983\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.4224 - val_loss: 5.0551\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.9978 - val_loss: 5.3580\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.9225 - val_loss: 4.9125\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.5003 - val_loss: 3.9412\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.8589 - val_loss: 5.4955\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.0448 - val_loss: 6.1243\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.0973 - val_loss: 5.4336\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.5801 - val_loss: 11.3310\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.6952 - val_loss: 3.8262\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.5584 - val_loss: 5.3153\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.7724 - val_loss: 4.1788\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.5986 - val_loss: 2.6799\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6434 - val_loss: 3.4910\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1148 - val_loss: 6.7592\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.5597 - val_loss: 2.8935\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1674 - val_loss: 7.3370\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.9004 - val_loss: 2.8732\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.7536 - val_loss: 6.3729\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5941 - val_loss: 2.6982\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.3636 - val_loss: 4.0948\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.4974 - val_loss: 6.1523\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.1707 - val_loss: 3.8410\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.8940 - val_loss: 3.6315\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.6104 - val_loss: 6.2292\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.4885 - val_loss: 4.1956\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.4164 - val_loss: 4.4848\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0821 - val_loss: 5.6562\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.7163 - val_loss: 5.3939\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2013 - val_loss: 3.3497\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.2795 - val_loss: 2.5789\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7610 - val_loss: 7.7743\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3594 - val_loss: 3.5620\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.6599 - val_loss: 2.5708\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.0560 - val_loss: 5.9972\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6334 - val_loss: 5.2870\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.6382 - val_loss: 2.7202\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.8100 - val_loss: 3.1264\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2858 - val_loss: 5.1946\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6908 - val_loss: 5.2172\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa023a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 39 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 362007.8750 - val_loss: 112.6648\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 557579.5625 - val_loss: 99.0923\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38571.5977 - val_loss: 87.1855\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 413530.7500 - val_loss: 87.5666\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 331722.2500 - val_loss: 90.9745\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 109226.5156 - val_loss: 95.4940\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21351.3145 - val_loss: 92.2092\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 167490.4688 - val_loss: 91.7875\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 77182.5938 - val_loss: 95.0644\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 116624.1875 - val_loss: 96.6190\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83178.3750 - val_loss: 93.9326\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 83301.0391 - val_loss: 93.8752\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 54451.8477 - val_loss: 96.0558\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 67566.6172 - val_loss: 96.4153\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15189.5859 - val_loss: 94.8880\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81282.6094 - val_loss: 94.3874\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 68646.0234 - val_loss: 95.7690\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38010.8281 - val_loss: 97.3282\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27707.5918 - val_loss: 95.5256\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 35274.5547 - val_loss: 95.6286\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68906.2969 - val_loss: 98.5444\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 139565.1250 - val_loss: 98.0666\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47582.5352 - val_loss: 96.0819\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65259.9141 - val_loss: 95.9665\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 60085.2031 - val_loss: 97.2979\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30460.4941 - val_loss: 99.7387\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82874.8203 - val_loss: 99.3002\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18392.5566 - val_loss: 98.8804\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13932.6416 - val_loss: 100.1942\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27930.8789 - val_loss: 100.0748\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6567.2041 - val_loss: 99.6471\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12911.1670 - val_loss: 99.8546\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55006.4492 - val_loss: 99.7217\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27162.9473 - val_loss: 97.5040\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 112802.0391 - val_loss: 96.9104\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93412.2422 - val_loss: 98.7497\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12923.7891 - val_loss: 99.0150\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3036.0027 - val_loss: 98.8994\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24079.9805 - val_loss: 98.2757\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32123.7637 - val_loss: 97.4983\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 45629.3711 - val_loss: 99.4816\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18837.0312 - val_loss: 99.2553\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5387.6812 - val_loss: 100.6202\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 79415.3203 - val_loss: 100.3909\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22463.0996 - val_loss: 98.9506\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 60568.9492 - val_loss: 98.4248\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 49172.6250 - val_loss: 99.2999\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24504.8926 - val_loss: 100.1612\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93570.3516 - val_loss: 99.6582\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 58720.8359 - val_loss: 97.3370\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb89148b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 40 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 78.6547 - val_loss: 58.3885\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.6995 - val_loss: 52.3106\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.3191 - val_loss: 38.5634\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45.3214 - val_loss: 33.3843\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 41.7570 - val_loss: 25.1665\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37.6242 - val_loss: 18.1505\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.1269 - val_loss: 19.2990\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.9178 - val_loss: 15.8177\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.0157 - val_loss: 13.3427\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30.7037 - val_loss: 8.5746\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29.9494 - val_loss: 9.9161\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26.4778 - val_loss: 4.0126\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.9563 - val_loss: 12.6323\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34.2445 - val_loss: 31.5778\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 33.1563 - val_loss: 9.1562\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 30.9878 - val_loss: 4.5218\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20.4301 - val_loss: 12.8396\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21.9629 - val_loss: 2.1648\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.6554 - val_loss: 6.8974\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.9597 - val_loss: 9.4181\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.6765 - val_loss: 3.9463\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.2999 - val_loss: 8.5171\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.3596 - val_loss: 8.4590\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.3691 - val_loss: 3.3141\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.9041 - val_loss: 9.6052\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.3413 - val_loss: 3.1265\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.5476 - val_loss: 8.1053\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.7482 - val_loss: 5.8723\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.1975 - val_loss: 6.2954\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.2978 - val_loss: 5.4653\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.6620 - val_loss: 5.4398\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.2786 - val_loss: 6.2138\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.6317 - val_loss: 4.8418\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.0637 - val_loss: 5.6693\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 13.9331 - val_loss: 3.5046\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.0665 - val_loss: 7.2972\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5705 - val_loss: 2.9368\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.2219 - val_loss: 7.6915\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1971 - val_loss: 3.5169\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.8203 - val_loss: 4.0062\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4298 - val_loss: 4.7569\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1838 - val_loss: 3.1084\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.9409 - val_loss: 4.6293\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2248 - val_loss: 2.7114\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.9744 - val_loss: 5.5191\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.4100 - val_loss: 2.9697\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0499 - val_loss: 3.8215\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.0360 - val_loss: 3.1485\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.5231 - val_loss: 3.1970\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9497 - val_loss: 2.9802\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfddce3550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 41 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 343150.1562 - val_loss: 85.6397\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13651.5459 - val_loss: 104.6952\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 210187.7031 - val_loss: 105.9962\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 217718.7031 - val_loss: 103.9949\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 101453.7969 - val_loss: 98.1630\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57887.6445 - val_loss: 94.5617\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 51937.7227 - val_loss: 98.0528\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79471.2734 - val_loss: 99.0449\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18888.5996 - val_loss: 96.1821\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9662.8340 - val_loss: 94.5623\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71305.4297 - val_loss: 94.3399\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7628.4917 - val_loss: 97.1458\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84396.7812 - val_loss: 99.8359\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 91223.9141 - val_loss: 98.3353\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 38853.7812 - val_loss: 96.2607\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19224.1191 - val_loss: 95.9801\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14237.3516 - val_loss: 97.6132\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51930.5391 - val_loss: 98.0641\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27431.1680 - val_loss: 96.6190\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34656.3398 - val_loss: 95.6604\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 29496.1289 - val_loss: 97.6387\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25827.1504 - val_loss: 97.2168\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7140.5718 - val_loss: 96.2399\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16738.5371 - val_loss: 96.4023\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11704.7168 - val_loss: 97.5296\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19476.7793 - val_loss: 97.1861\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8705.5938 - val_loss: 95.4558\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 42357.4297 - val_loss: 95.9930\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25566.2363 - val_loss: 97.5795\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46638.4258 - val_loss: 98.2875\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22804.5781 - val_loss: 96.3176\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22664.4863 - val_loss: 96.1158\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 29832.9844 - val_loss: 97.3814\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22014.4531 - val_loss: 97.5136\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5475.6377 - val_loss: 95.7877\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 76132.8828 - val_loss: 95.0043\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 62508.1250 - val_loss: 97.0118\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8992.7783 - val_loss: 97.5828\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5345.1274 - val_loss: 96.3521\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35917.7383 - val_loss: 96.7953\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 23064.8184 - val_loss: 98.1784\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20847.2344 - val_loss: 97.9068\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6473.4360 - val_loss: 97.2495\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12267.6377 - val_loss: 97.3691\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8249.1533 - val_loss: 98.1462\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38887.5156 - val_loss: 98.6305\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19379.8594 - val_loss: 97.1946\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36703.5938 - val_loss: 96.7025\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 35563.7812 - val_loss: 97.7907\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13316.8018 - val_loss: 97.9780\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9e105670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 42 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 198260.7031 - val_loss: 89.1943\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89359.9766 - val_loss: 91.8561\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33673.8516 - val_loss: 84.9947\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75591.4375 - val_loss: 86.9857\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52281.1719 - val_loss: 92.9763\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 79793.7656 - val_loss: 95.1903\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64990.3945 - val_loss: 89.6212\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45863.4375 - val_loss: 90.1430\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48446.2891 - val_loss: 93.1981\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5312.7236 - val_loss: 93.0519\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25287.6602 - val_loss: 93.4039\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11230.2695 - val_loss: 99.0751\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 103403.6016 - val_loss: 100.3160\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 103252.5234 - val_loss: 98.5733\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 57017.9609 - val_loss: 95.8094\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18842.3984 - val_loss: 95.8688\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10207.7363 - val_loss: 97.5106\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28135.9766 - val_loss: 97.5429\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17636.9355 - val_loss: 95.5276\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 29881.8945 - val_loss: 96.1473\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 15732.4297 - val_loss: 97.6244\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27148.6973 - val_loss: 98.0209\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11594.0898 - val_loss: 97.2158\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 42427.6250 - val_loss: 95.7310\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28528.1836 - val_loss: 97.2819\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17046.5586 - val_loss: 98.3502\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9347.0391 - val_loss: 97.5223\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22737.5410 - val_loss: 97.2442\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12902.2246 - val_loss: 98.2406\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 11992.9121 - val_loss: 98.4353\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 5693.2354 - val_loss: 97.4277\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 17795.0605 - val_loss: 97.7683\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10174.0137 - val_loss: 99.1127\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 39396.2734 - val_loss: 99.7114\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12193.2695 - val_loss: 98.3668\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14394.9092 - val_loss: 97.4086\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 35212.6328 - val_loss: 97.4795\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 19504.7715 - val_loss: 99.8664\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 58802.1719 - val_loss: 101.0903\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 55081.2852 - val_loss: 99.6225\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2214.1672 - val_loss: 99.2798\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9144.7588 - val_loss: 99.3127\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5062.0073 - val_loss: 99.1545\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 2650.0938 - val_loss: 99.7047\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10016.7041 - val_loss: 99.5541\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3599.5757 - val_loss: 99.1381\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5328.4858 - val_loss: 98.8914\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 12837.9707 - val_loss: 99.5854\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5749.2974 - val_loss: 99.1733\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10845.2275 - val_loss: 99.2497\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff3b9f8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 43 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 73.2824 - val_loss: 48.2029\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 53.5821 - val_loss: 40.5696\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42.3395 - val_loss: 46.4172\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 36.4313 - val_loss: 43.9041\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32.1778 - val_loss: 28.8561\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29.2000 - val_loss: 22.8904\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23.5516 - val_loss: 25.2807\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.7508 - val_loss: 7.0757\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.8180 - val_loss: 13.1520\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.8329 - val_loss: 5.5241\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.2275 - val_loss: 7.1320\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.8004 - val_loss: 6.6145\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.8149 - val_loss: 7.7050\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.3836 - val_loss: 4.2553\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.1617 - val_loss: 4.8716\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.8673 - val_loss: 5.6088\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.6182 - val_loss: 3.7085\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.9120 - val_loss: 6.5516\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.6456 - val_loss: 5.5298\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.4695 - val_loss: 5.5204\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.4190 - val_loss: 4.5176\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.4160 - val_loss: 4.1849\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.3160 - val_loss: 3.0498\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.9507 - val_loss: 4.1200\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8716 - val_loss: 2.7064\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.7298 - val_loss: 3.4665\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5508 - val_loss: 3.2605\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.4469 - val_loss: 3.0659\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3529 - val_loss: 6.0341\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.8651 - val_loss: 2.5625\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4903 - val_loss: 2.8054\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6491 - val_loss: 2.3531\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2169 - val_loss: 3.0673\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5794 - val_loss: 2.2198\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.3096 - val_loss: 3.5933\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2111 - val_loss: 3.5682\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.6451 - val_loss: 1.7441\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8533 - val_loss: 2.5751\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.5320 - val_loss: 3.3146\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.4306 - val_loss: 1.6269\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.6210 - val_loss: 2.9192\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.5006 - val_loss: 1.4361\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.2731 - val_loss: 1.7624\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.1573 - val_loss: 1.6549\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1830 - val_loss: 3.7879\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.7167 - val_loss: 2.1407\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.9887 - val_loss: 1.5332\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.9268 - val_loss: 1.6577\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.8611 - val_loss: 1.6402\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.0206 - val_loss: 1.8727\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9d3b8e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 44 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 78.9134 - val_loss: 57.7275\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63.0722 - val_loss: 47.4641\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46.7503 - val_loss: 45.4683\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 40.2392 - val_loss: 35.2693\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 35.3577 - val_loss: 20.6969\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 28.3486 - val_loss: 17.6286\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24.9528 - val_loss: 8.5259\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20.5876 - val_loss: 7.3556\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 20.2851 - val_loss: 8.6880\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.9234 - val_loss: 8.4678\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.0173 - val_loss: 5.9098\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.8507 - val_loss: 7.3336\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.2432 - val_loss: 5.8712\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.8366 - val_loss: 8.5738\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 15.5217 - val_loss: 5.7413\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.1630 - val_loss: 5.9702\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.0710 - val_loss: 5.9550\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.7016 - val_loss: 5.1020\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.5938 - val_loss: 7.7766\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.9207 - val_loss: 5.3548\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.7767 - val_loss: 6.1794\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.0172 - val_loss: 7.2562\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.3267 - val_loss: 4.6859\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0962 - val_loss: 6.6499\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.6484 - val_loss: 6.1753\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.9117 - val_loss: 6.0489\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.6209 - val_loss: 7.8563\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.0568 - val_loss: 8.7072\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.4172 - val_loss: 7.8856\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.7299 - val_loss: 4.8628\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.8644 - val_loss: 7.6704\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.0368 - val_loss: 6.4313\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.3173 - val_loss: 6.9595\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.9744 - val_loss: 6.5501\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5457 - val_loss: 7.7263\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.7216 - val_loss: 7.7834\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.5854 - val_loss: 5.9842\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.3540 - val_loss: 5.6004\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5875 - val_loss: 4.7211\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.1916 - val_loss: 5.5785\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.5584 - val_loss: 7.7595\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0818 - val_loss: 6.6168\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.1521 - val_loss: 4.4140\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.1456 - val_loss: 5.0108\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4295 - val_loss: 7.9093\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.0472 - val_loss: 5.5691\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5717 - val_loss: 4.3159\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.4220 - val_loss: 4.4732\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.8423 - val_loss: 5.8049\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4219 - val_loss: 3.4572\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb96cb4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 45 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 11051.4629 - val_loss: 91.6102\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 192016.0000 - val_loss: 101.6784\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 165151.1562 - val_loss: 96.9209\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 34235.9062 - val_loss: 89.6825\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 149548.2656 - val_loss: 88.1883\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 128238.4062 - val_loss: 92.4665\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 33892.0469 - val_loss: 96.8823\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 108432.7734 - val_loss: 98.0711\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 94147.6484 - val_loss: 95.5370\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 23407.5293 - val_loss: 91.5804\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 87467.5312 - val_loss: 91.1736\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 77122.8359 - val_loss: 94.8007\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 776.0018 - val_loss: 95.3684\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15976.7812 - val_loss: 96.5546\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26045.2266 - val_loss: 96.9611\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15098.7734 - val_loss: 93.6897\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 65867.0234 - val_loss: 93.6446\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 71305.8047 - val_loss: 94.4543\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 45147.6797 - val_loss: 97.2350\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 31461.9375 - val_loss: 97.9815\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 27839.5859 - val_loss: 96.5306\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5820.1758 - val_loss: 96.9461\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8942.1133 - val_loss: 96.5403\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11825.2285 - val_loss: 96.7441\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4909.6963 - val_loss: 96.4594\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24516.7441 - val_loss: 96.2125\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9090.6748 - val_loss: 97.7296\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44866.2773 - val_loss: 98.4946\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36275.1445 - val_loss: 97.4417\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10753.0840 - val_loss: 97.0016\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 439.3604 - val_loss: 98.2726\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47204.5820 - val_loss: 98.8743\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37433.2930 - val_loss: 97.7608\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10680.1416 - val_loss: 95.5000\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 81269.5625 - val_loss: 94.5868\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 67824.7812 - val_loss: 96.1480\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10120.5127 - val_loss: 97.7855\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 29637.2871 - val_loss: 99.1191\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45476.4531 - val_loss: 99.0912\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 27762.9004 - val_loss: 97.8916\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 569.8786 - val_loss: 95.8292\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 84259.4453 - val_loss: 95.0087\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 71148.1562 - val_loss: 96.2810\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 40067.5781 - val_loss: 98.4221\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18375.8633 - val_loss: 99.4557\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16945.3438 - val_loss: 98.4046\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13410.9189 - val_loss: 98.2756\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 1694.8273 - val_loss: 99.0401\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 34521.5859 - val_loss: 99.4060\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 27606.2500 - val_loss: 98.6908\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa5f49700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 46 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 225185.4688 - val_loss: 78.4075\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5910.0952 - val_loss: 91.8753\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 230985.8906 - val_loss: 99.1281\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 187239.9531 - val_loss: 97.8397\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 138900.3438 - val_loss: 93.6798\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5413.3301 - val_loss: 94.6965\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4305.3271 - val_loss: 96.2298\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45143.8711 - val_loss: 96.9963\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26978.6387 - val_loss: 95.8932\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43094.1016 - val_loss: 95.4493\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27188.5918 - val_loss: 96.8787\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12065.4160 - val_loss: 96.8842\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8046.8486 - val_loss: 95.8928\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45392.1914 - val_loss: 95.9180\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19070.6191 - val_loss: 96.7104\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25395.0293 - val_loss: 97.5662\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 32101.9004 - val_loss: 97.2120\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12194.3223 - val_loss: 96.7812\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10724.5088 - val_loss: 96.9106\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7160.0659 - val_loss: 97.1135\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7855.0376 - val_loss: 96.7726\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13501.3271 - val_loss: 96.8991\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34336.9219 - val_loss: 97.6823\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9999.2090 - val_loss: 96.8469\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6045.3208 - val_loss: 96.3700\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31639.5195 - val_loss: 96.7471\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3257.8770 - val_loss: 97.9327\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 58420.0312 - val_loss: 98.5245\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 52599.8906 - val_loss: 97.6330\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10056.9902 - val_loss: 96.2132\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 50311.2305 - val_loss: 96.0522\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 49655.3398 - val_loss: 96.4178\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3741.8389 - val_loss: 97.8348\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 55195.7891 - val_loss: 99.1238\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 67768.6094 - val_loss: 99.0791\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51470.5234 - val_loss: 98.0086\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10773.4922 - val_loss: 96.5195\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 80679.1484 - val_loss: 95.9162\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 69376.5234 - val_loss: 96.8998\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22496.3066 - val_loss: 98.0570\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9957.9814 - val_loss: 98.5210\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16528.6543 - val_loss: 98.0043\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11212.5664 - val_loss: 98.1429\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5182.1768 - val_loss: 98.0202\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9111.4912 - val_loss: 98.2752\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10554.5791 - val_loss: 98.2344\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1753.1127 - val_loss: 97.2292\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51364.5938 - val_loss: 97.0822\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 44712.0508 - val_loss: 97.6660\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6465.1567 - val_loss: 98.4416\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa6eac040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 47 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2280\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf8bdf0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 48 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 310939.8438 - val_loss: 83.9231\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36458.1445 - val_loss: 94.7031\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 65105.8008 - val_loss: 92.1654\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 44344.4688 - val_loss: 100.8193\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 143673.1562 - val_loss: 102.7197\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 126685.2734 - val_loss: 99.9600\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34970.7383 - val_loss: 95.6562\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 15789.6729 - val_loss: 94.9557\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 35894.3516 - val_loss: 96.5463\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11250.5039 - val_loss: 96.1459\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12580.6602 - val_loss: 97.6550\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23896.6406 - val_loss: 96.4329\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11840.5732 - val_loss: 97.3462\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16204.1533 - val_loss: 96.2879\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11713.5352 - val_loss: 97.7021\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46726.1133 - val_loss: 98.1727\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11168.8311 - val_loss: 94.5353\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 94237.4062 - val_loss: 92.7431\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 88725.1484 - val_loss: 94.6231\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17465.4863 - val_loss: 97.1499\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 23964.6621 - val_loss: 98.9699\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 50842.5117 - val_loss: 98.4640\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28862.5684 - val_loss: 95.7291\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 72029.1406 - val_loss: 94.7961\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63702.1992 - val_loss: 98.2082\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 37856.4883 - val_loss: 99.2420\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 28957.5371 - val_loss: 97.2587\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 38480.9336 - val_loss: 96.4377\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9291.3252 - val_loss: 98.4597\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 44675.6992 - val_loss: 99.4540\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 41815.0430 - val_loss: 98.5439\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4637.9985 - val_loss: 98.2663\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10108.4141 - val_loss: 97.9662\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14946.1943 - val_loss: 98.2678\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10749.8623 - val_loss: 98.2575\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17674.6445 - val_loss: 97.9387\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1552.7798 - val_loss: 100.3503\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 70902.7266 - val_loss: 100.9856\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 68461.0391 - val_loss: 99.3972\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30870.1055 - val_loss: 97.0563\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 25252.5410 - val_loss: 97.2731\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 20662.9297 - val_loss: 98.6167\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27610.8594 - val_loss: 98.9833\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14515.0693 - val_loss: 97.4971\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32037.5391 - val_loss: 97.5144\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25637.4375 - val_loss: 98.7488\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25236.6387 - val_loss: 99.2770\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18150.5781 - val_loss: 97.1694\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 37631.9492 - val_loss: 97.2075\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36962.3672 - val_loss: 97.8562\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb89145e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 49 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 69.2007 - val_loss: 50.6297\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47.2031 - val_loss: 44.8373\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.8677 - val_loss: 47.2181\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 35.0368 - val_loss: 31.5110\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29.5907 - val_loss: 29.7270\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 26.5145 - val_loss: 22.1476\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22.2960 - val_loss: 13.7512\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 18.8442 - val_loss: 4.6293\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.2105 - val_loss: 9.9719\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.5258 - val_loss: 4.4480\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.0694 - val_loss: 3.9100\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.7194 - val_loss: 4.7713\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.4066 - val_loss: 3.9044\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.8366 - val_loss: 4.6210\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.5944 - val_loss: 4.5941\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.2047 - val_loss: 4.5721\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.1246 - val_loss: 5.2260\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.7178 - val_loss: 3.8496\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.5726 - val_loss: 3.6370\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.5363 - val_loss: 3.0862\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.7818 - val_loss: 3.7362\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.8249 - val_loss: 4.1747\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.6647 - val_loss: 3.6552\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.1505 - val_loss: 3.2899\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.8194 - val_loss: 4.5342\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.1534 - val_loss: 2.9633\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.6150 - val_loss: 3.6147\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.8533 - val_loss: 2.8341\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.3894 - val_loss: 2.5334\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.1235 - val_loss: 3.7131\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.5607 - val_loss: 2.8562\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.0308 - val_loss: 3.5836\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.5714 - val_loss: 6.1450\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3035 - val_loss: 4.0222\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6198 - val_loss: 2.4280\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1563 - val_loss: 3.9692\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.2889 - val_loss: 2.5056\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4458 - val_loss: 3.0861\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.6834 - val_loss: 4.1436\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.8858 - val_loss: 2.9661\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4885 - val_loss: 3.4014\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.5160 - val_loss: 6.4705\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2825 - val_loss: 3.6149\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7660 - val_loss: 4.1589\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.0141 - val_loss: 2.8262\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.9498 - val_loss: 3.4162\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3726 - val_loss: 2.7051\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.3658 - val_loss: 3.8907\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.7172 - val_loss: 3.5644\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.6583 - val_loss: 6.4337\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa38ad9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 50 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 66.2089 - val_loss: 36.3107\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47.4869 - val_loss: 34.0505\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34.7127 - val_loss: 42.6006\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 30.9616 - val_loss: 30.0610\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27.3334 - val_loss: 18.5700\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21.2868 - val_loss: 25.7700\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.7596 - val_loss: 7.0203\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.1801 - val_loss: 9.7074\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.1290 - val_loss: 4.9015\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.6447 - val_loss: 4.2715\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.3702 - val_loss: 6.0192\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.8321 - val_loss: 6.6205\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.2647 - val_loss: 4.2886\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.7473 - val_loss: 10.9146\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.8233 - val_loss: 3.7792\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.3635 - val_loss: 3.9918\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0881 - val_loss: 4.6141\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.7857 - val_loss: 3.8171\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.7658 - val_loss: 7.2035\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 8.6232 - val_loss: 3.1398\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.4428 - val_loss: 3.5224\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.5253 - val_loss: 4.7219\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.7853 - val_loss: 4.5074\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.7567 - val_loss: 3.2627\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.4042 - val_loss: 3.5811\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2087 - val_loss: 5.0509\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.1877 - val_loss: 3.0953\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.9499 - val_loss: 3.1537\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.4368 - val_loss: 3.7885\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.1417 - val_loss: 3.9801\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.5011 - val_loss: 3.3077\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.9704 - val_loss: 3.6990\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.7334 - val_loss: 3.4203\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.5851 - val_loss: 3.3443\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.5069 - val_loss: 3.2839\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.5803 - val_loss: 4.2463\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.5316 - val_loss: 3.1744\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.2021 - val_loss: 3.3205\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.5484 - val_loss: 3.0523\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.8194 - val_loss: 3.9842\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.3520 - val_loss: 3.5067\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.8482 - val_loss: 3.9003\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.3769 - val_loss: 4.5354\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.3518 - val_loss: 3.9127\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.4062 - val_loss: 3.4089\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.5708 - val_loss: 4.0962\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.2716 - val_loss: 3.7452\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.6322 - val_loss: 3.9743\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.9467 - val_loss: 4.3617\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.7460 - val_loss: 3.9914\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa1ca50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 51 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 400409.6875 - val_loss: 99.1849\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34735.6406 - val_loss: 114.4514\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 557798.0000 - val_loss: 116.1480\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 469660.9062 - val_loss: 110.2710\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 209274.1094 - val_loss: 104.9245\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41882.6953 - val_loss: 97.8999\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 159374.9531 - val_loss: 96.0859\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 179932.3594 - val_loss: 96.7009\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 147529.4688 - val_loss: 102.2529\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 70701.2500 - val_loss: 103.2206\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 82199.5312 - val_loss: 102.3623\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 50106.5703 - val_loss: 98.7597\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 89771.4844 - val_loss: 98.3730\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 85145.2891 - val_loss: 100.4097\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15926.8623 - val_loss: 103.4130\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 126211.3438 - val_loss: 104.3377\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 117271.9609 - val_loss: 102.1480\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12240.3311 - val_loss: 100.0804\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 78337.1953 - val_loss: 98.7479\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 75592.6250 - val_loss: 100.5558\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4771.7612 - val_loss: 102.9620\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 69110.6875 - val_loss: 103.0231\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71058.2188 - val_loss: 101.7394\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26140.8594 - val_loss: 99.1999\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 96795.8125 - val_loss: 98.4175\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 89182.4375 - val_loss: 100.2978\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5648.5776 - val_loss: 102.3470\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 98516.2266 - val_loss: 103.5736\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79168.2266 - val_loss: 101.9327\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20372.0195 - val_loss: 99.3906\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 72568.9375 - val_loss: 98.8268\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81236.5781 - val_loss: 99.1411\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22133.0938 - val_loss: 101.0452\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21586.1406 - val_loss: 102.3520\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 64074.2695 - val_loss: 102.5129\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18609.3320 - val_loss: 100.9851\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 50905.7109 - val_loss: 99.4572\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62152.6562 - val_loss: 99.7261\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 38839.8750 - val_loss: 101.4374\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37364.7422 - val_loss: 101.8879\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30262.3379 - val_loss: 101.2741\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6474.8452 - val_loss: 101.0487\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6811.5195 - val_loss: 100.7854\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21448.1914 - val_loss: 100.7653\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9841.8379 - val_loss: 102.1788\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42238.5117 - val_loss: 101.9479\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31224.0625 - val_loss: 101.1135\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11986.3496 - val_loss: 100.9590\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 801.4348 - val_loss: 102.1008\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 53517.8164 - val_loss: 102.2485\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf904fd790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 52 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 136579.7656 - val_loss: 88.0966\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79702.7344 - val_loss: 88.8846\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10823.1865 - val_loss: 96.5351\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 130578.5234 - val_loss: 98.9411\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 100392.6641 - val_loss: 94.5308\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2817.7278 - val_loss: 95.1535\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17760.6621 - val_loss: 92.9703\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39735.4062 - val_loss: 94.3590\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4980.9370 - val_loss: 98.7595\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 112039.0781 - val_loss: 100.8481\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 99235.7969 - val_loss: 95.9912\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14242.0625 - val_loss: 95.7217\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9319.1689 - val_loss: 98.6886\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71085.9219 - val_loss: 99.2989\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44203.8398 - val_loss: 96.8046\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1640.1637 - val_loss: 96.9616\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2532.1731 - val_loss: 97.7773\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12077.8369 - val_loss: 98.2930\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25282.6445 - val_loss: 97.9304\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10827.0918 - val_loss: 97.0178\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6280.3608 - val_loss: 97.8305\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 20423.0352 - val_loss: 98.6789\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 26857.7676 - val_loss: 98.2646\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17081.3223 - val_loss: 97.0318\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12881.1689 - val_loss: 98.8798\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 48505.2773 - val_loss: 99.7049\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26567.9121 - val_loss: 97.3629\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25207.8418 - val_loss: 96.8924\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28211.6719 - val_loss: 97.6716\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7167.5073 - val_loss: 98.2817\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3002.6865 - val_loss: 99.1101\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25005.7871 - val_loss: 98.8409\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6370.6699 - val_loss: 96.8896\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50129.2227 - val_loss: 96.5486\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41042.7891 - val_loss: 97.8943\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14941.2002 - val_loss: 100.6098\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55274.7227 - val_loss: 101.0674\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 54148.3203 - val_loss: 100.2773\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26966.1660 - val_loss: 98.3552\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 32151.1445 - val_loss: 97.8796\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28573.4375 - val_loss: 98.8426\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3360.8535 - val_loss: 99.0180\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5886.2539 - val_loss: 99.7069\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24848.0762 - val_loss: 99.9231\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17742.5977 - val_loss: 97.7413\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63357.6250 - val_loss: 96.8442\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 45165.6211 - val_loss: 97.8582\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22647.5879 - val_loss: 100.5684\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36141.9531 - val_loss: 101.0881\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 52667.9570 - val_loss: 101.0539\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf8f972700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 53 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 61.2198 - val_loss: 30.6228\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30.5978 - val_loss: 19.9055\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24.9475 - val_loss: 33.4510\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 22.0251 - val_loss: 23.0840\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19.4268 - val_loss: 15.3439\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.4306 - val_loss: 19.1191\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.1920 - val_loss: 8.5021\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.7330 - val_loss: 4.9264\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.8863 - val_loss: 8.7169\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.4415 - val_loss: 4.3977\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.6644 - val_loss: 6.6399\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.5202 - val_loss: 7.7338\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.9508 - val_loss: 4.6212\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.7615 - val_loss: 6.2771\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10.4077 - val_loss: 3.7717\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4745 - val_loss: 3.7341\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.2182 - val_loss: 5.5531\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.7178 - val_loss: 3.9559\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.3908 - val_loss: 4.3042\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.2532 - val_loss: 4.5374\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.9585 - val_loss: 3.3088\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.0405 - val_loss: 3.7203\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.5271 - val_loss: 4.2420\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.4675 - val_loss: 4.2066\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.5451 - val_loss: 4.1212\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.0094 - val_loss: 4.7268\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.9208 - val_loss: 3.5765\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.1041 - val_loss: 3.2323\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.6641 - val_loss: 4.6145\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.3245 - val_loss: 3.8060\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.2371 - val_loss: 3.8732\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.0089 - val_loss: 5.7808\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.7568 - val_loss: 5.8408\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4648 - val_loss: 2.9299\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.1342 - val_loss: 4.3501\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.1671 - val_loss: 5.7543\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.8886 - val_loss: 3.0145\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.0761 - val_loss: 2.9598\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.7099 - val_loss: 4.4418\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.9583 - val_loss: 3.3717\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.2119 - val_loss: 3.6307\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.2966 - val_loss: 5.5346\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.4580 - val_loss: 2.8706\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.6491 - val_loss: 3.6579\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.4147 - val_loss: 4.2940\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.7017 - val_loss: 2.3261\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.2271 - val_loss: 2.6305\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.7150 - val_loss: 2.9852\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.6839 - val_loss: 2.8438\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.4729 - val_loss: 2.3317\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb23878b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 54 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 113246.8672 - val_loss: 86.5244\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 87804.4766 - val_loss: 93.3960\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 195489.7500 - val_loss: 97.4900\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 99106.3672 - val_loss: 94.2644\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 61740.8008 - val_loss: 92.9196\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 46425.8320 - val_loss: 96.3524\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 88217.9375 - val_loss: 97.4579\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 51246.8828 - val_loss: 94.3761\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 92189.9766 - val_loss: 94.3156\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 72096.4688 - val_loss: 97.2812\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 60143.7695 - val_loss: 97.7252\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 20585.6758 - val_loss: 95.7802\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 90066.4297 - val_loss: 95.5225\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 64901.0586 - val_loss: 97.0668\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 14798.1855 - val_loss: 97.3655\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 7069.7251 - val_loss: 96.8283\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 23081.2129 - val_loss: 97.3009\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 17812.0977 - val_loss: 97.7798\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 17762.5566 - val_loss: 96.3083\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 89702.9531 - val_loss: 96.4471\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 43715.4375 - val_loss: 97.5362\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 38128.5742 - val_loss: 98.8494\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 41546.9141 - val_loss: 98.0723\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 21662.0684 - val_loss: 98.3234\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 13268.3857 - val_loss: 98.9305\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31727.6875 - val_loss: 98.0694\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23281.6094 - val_loss: 98.1410\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 18459.7090 - val_loss: 98.8744\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 28000.2207 - val_loss: 97.5941\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 46593.8906 - val_loss: 97.6198\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12993.4150 - val_loss: 98.5626\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 26237.9570 - val_loss: 99.0856\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 41930.5508 - val_loss: 98.4582\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 33185.5352 - val_loss: 97.4350\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 59727.0000 - val_loss: 98.2938\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9637.3125 - val_loss: 99.6567\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 24898.2344 - val_loss: 99.4226\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13261.5977 - val_loss: 98.6861\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 28053.8613 - val_loss: 99.0054\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 4539.1821 - val_loss: 99.0820\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5189.8320 - val_loss: 99.2321\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3178.8779 - val_loss: 100.1276\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 40488.8945 - val_loss: 99.8624\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 10793.6807 - val_loss: 98.7801\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 70299.2188 - val_loss: 98.4851\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 44693.8086 - val_loss: 99.4480\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21361.5469 - val_loss: 100.9112\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 76568.9297 - val_loss: 100.7234\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 40349.3242 - val_loss: 99.3401\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15542.2500 - val_loss: 99.5429\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9f4291f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 55 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 19016.0469 - val_loss: 81.8428\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 394178.1250 - val_loss: 86.5919\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 239506.5312 - val_loss: 95.8169\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 99638.4453 - val_loss: 105.2553\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 96843.9375 - val_loss: 106.4061\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 79919.0625 - val_loss: 103.1289\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4936.1255 - val_loss: 103.9880\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 20486.3066 - val_loss: 102.9372\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 29763.2656 - val_loss: 103.0341\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8523.5234 - val_loss: 103.1655\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18838.0195 - val_loss: 102.8347\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11090.4717 - val_loss: 104.3303\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35687.5117 - val_loss: 104.1284\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14310.3877 - val_loss: 103.0172\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 19422.6016 - val_loss: 102.0160\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30790.9414 - val_loss: 102.6319\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6400.8350 - val_loss: 102.7266\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15453.2236 - val_loss: 103.0056\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9285.6973 - val_loss: 102.5677\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10742.2471 - val_loss: 103.5956\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 37758.6211 - val_loss: 103.8742\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16140.8057 - val_loss: 100.5051\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 77436.3906 - val_loss: 99.4573\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 74603.5625 - val_loss: 100.0357\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 47902.0469 - val_loss: 103.5063\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23904.8242 - val_loss: 103.9647\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 40980.1211 - val_loss: 102.7469\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15663.4492 - val_loss: 100.0780\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 55689.1836 - val_loss: 99.6185\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 45789.1562 - val_loss: 100.9787\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11293.0361 - val_loss: 103.6470\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 40357.3164 - val_loss: 103.8454\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 45355.7773 - val_loss: 102.3971\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14460.4590 - val_loss: 100.0508\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 61538.6836 - val_loss: 99.1522\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 50231.1094 - val_loss: 101.3347\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8911.8047 - val_loss: 101.8433\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3216.5325 - val_loss: 100.9758\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12457.8193 - val_loss: 101.1114\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8119.1357 - val_loss: 102.3360\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 19122.0117 - val_loss: 101.9113\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6537.9580 - val_loss: 101.0354\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9365.2842 - val_loss: 101.1333\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5875.8418 - val_loss: 101.8081\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8676.5186 - val_loss: 101.5824\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1957.4180 - val_loss: 100.8296\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 25080.5586 - val_loss: 100.5440\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19183.7227 - val_loss: 102.1340\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17082.1230 - val_loss: 101.7419\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4630.9521 - val_loss: 101.0839\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9190a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 56 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 261233.2344 - val_loss: 83.5771\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 107024.3359 - val_loss: 104.4346\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 241064.5312 - val_loss: 111.1778\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 228955.5000 - val_loss: 107.1900\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 72360.4219 - val_loss: 104.0510\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 41315.9648 - val_loss: 96.3616\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 195600.6250 - val_loss: 94.5020\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 183666.3750 - val_loss: 96.8184\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 92755.5938 - val_loss: 99.4069\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 49051.9062 - val_loss: 103.7627\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 106245.7188 - val_loss: 105.7613\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 102489.8125 - val_loss: 103.7556\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41184.4258 - val_loss: 101.4120\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 41524.0586 - val_loss: 100.5640\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37022.5391 - val_loss: 102.5434\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9167.4336 - val_loss: 102.1180\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 6090.4155 - val_loss: 102.5728\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 26455.5332 - val_loss: 102.9413\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 5345.0439 - val_loss: 101.8242\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 43381.5000 - val_loss: 100.3608\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 44312.8438 - val_loss: 101.4843\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 5142.0083 - val_loss: 103.2563\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 54971.0039 - val_loss: 104.1262\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 50368.9062 - val_loss: 102.8046\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11376.6436 - val_loss: 100.7552\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 44984.8789 - val_loss: 100.4215\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 44159.0156 - val_loss: 101.0071\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28662.3320 - val_loss: 103.2074\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 53712.8828 - val_loss: 103.9317\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 46175.3438 - val_loss: 103.1440\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9403.9316 - val_loss: 101.4786\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 44907.1992 - val_loss: 100.4261\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 43513.8633 - val_loss: 101.2697\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2126.7151 - val_loss: 102.4960\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 44452.9297 - val_loss: 103.7937\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 50162.5391 - val_loss: 103.5272\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11285.6660 - val_loss: 101.7430\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4852.1968 - val_loss: 100.7061\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31163.6934 - val_loss: 101.4075\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5628.7358 - val_loss: 102.1279\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 39031.2539 - val_loss: 103.2377\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 30576.5781 - val_loss: 102.1443\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 7183.5684 - val_loss: 101.8260\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 2084.8945 - val_loss: 102.8144\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 24774.1406 - val_loss: 102.5593\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 15273.0029 - val_loss: 101.9493\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15319.4131 - val_loss: 101.5138\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4433.1367 - val_loss: 102.0991\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 30335.1738 - val_loss: 102.9662\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 30111.0918 - val_loss: 102.4932\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf8d6e3820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 57 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 180ms/step - loss: 68.2420 - val_loss: 42.7351\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 35.4018 - val_loss: 10.1545\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 29.9620 - val_loss: 31.3785\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 25.1517 - val_loss: 33.3562\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 20.5641 - val_loss: 15.4305\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 17.9403 - val_loss: 14.8283\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 14.5866 - val_loss: 14.9137\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.1808 - val_loss: 6.2607\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.9060 - val_loss: 4.7016\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.6465 - val_loss: 4.6774\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.7471 - val_loss: 3.5820\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.2822 - val_loss: 4.5946\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.2171 - val_loss: 4.5775\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.8489 - val_loss: 3.5167\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.5974 - val_loss: 5.4747\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.7976 - val_loss: 4.7484\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.3728 - val_loss: 4.3298\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.2163 - val_loss: 3.5142\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.2153 - val_loss: 5.7281\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.1913 - val_loss: 4.5873\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.6759 - val_loss: 3.7249\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.9833 - val_loss: 5.2277\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.7216 - val_loss: 3.3224\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.5803 - val_loss: 5.5598\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.1291 - val_loss: 3.5151\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.5113 - val_loss: 3.0995\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.2369 - val_loss: 3.5556\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.1497 - val_loss: 3.4379\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.0681 - val_loss: 3.8072\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.3858 - val_loss: 3.4025\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.9888 - val_loss: 3.6326\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.7310 - val_loss: 3.9172\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4.5176 - val_loss: 3.5781\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.6860 - val_loss: 2.9943\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.7076 - val_loss: 3.1291\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.4490 - val_loss: 3.0259\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.4773 - val_loss: 3.2796\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.5201 - val_loss: 3.0301\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.1454 - val_loss: 3.2412\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.2098 - val_loss: 3.2341\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.0680 - val_loss: 3.0469\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.8307 - val_loss: 3.6560\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 3.7598 - val_loss: 3.1661\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.6843 - val_loss: 3.0177\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 3.8507 - val_loss: 2.9676\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3.7037 - val_loss: 2.9280\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.8620 - val_loss: 2.9086\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3.8509 - val_loss: 3.5550\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 4.4348 - val_loss: 3.1619\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.1027 - val_loss: 3.7823\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb4810790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 58 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 6565484.0000 - val_loss: 102.1741\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3842901.5000 - val_loss: 101.2456\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 2169781.2500 - val_loss: 100.7426\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1200365.1250 - val_loss: 100.3314\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1414954.7500 - val_loss: 99.9004\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1162443.3750 - val_loss: 99.6367\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1006911.0625 - val_loss: 99.3848\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 921070.5000 - val_loss: 99.1884\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1032608.1250 - val_loss: 99.0540\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 978648.8125 - val_loss: 98.8599\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 679258.8125 - val_loss: 98.7134\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1038013.6875 - val_loss: 98.6055\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 827371.8750 - val_loss: 98.4816\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 775589.5000 - val_loss: 98.3860\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 967491.2500 - val_loss: 98.2902\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 516243.7500 - val_loss: 98.1585\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 948725.8750 - val_loss: 98.1151\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 716801.8125 - val_loss: 98.0140\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 846191.6875 - val_loss: 97.9186\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 525702.5000 - val_loss: 97.8560\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 849652.6250 - val_loss: 97.7742\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 728533.4375 - val_loss: 97.7339\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 643018.7500 - val_loss: 97.6998\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 630031.0000 - val_loss: 97.6500\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 719803.8125 - val_loss: 97.6524\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 723468.8125 - val_loss: 97.6071\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 527040.8125 - val_loss: 97.5933\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 693907.1875 - val_loss: 97.6049\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 649191.8125 - val_loss: 97.5726\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 683056.5000 - val_loss: 97.5781\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 498179.5938 - val_loss: 97.5755\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 690889.2500 - val_loss: 97.5561\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 584205.5625 - val_loss: 97.5740\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 599733.5000 - val_loss: 97.5726\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 605362.0625 - val_loss: 97.5777\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 464500.0938 - val_loss: 97.5979\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 638763.7500 - val_loss: 97.5890\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 611019.6875 - val_loss: 97.6087\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 451391.2500 - val_loss: 97.6150\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 618162.6875 - val_loss: 97.6068\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 543626.5000 - val_loss: 97.6345\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 541464.6250 - val_loss: 97.6311\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 555138.1250 - val_loss: 97.6450\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 435676.1562 - val_loss: 97.6656\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 575389.4375 - val_loss: 97.6548\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 539017.8125 - val_loss: 97.6750\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 491498.9375 - val_loss: 97.6859\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 413908.6250 - val_loss: 97.6741\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 573230.1875 - val_loss: 97.6962\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 546020.3125 - val_loss: 97.6889\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb958a820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 59 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 51.0943 - val_loss: 19.8524\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 39.6536 - val_loss: 29.6819\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 32.2896 - val_loss: 42.9582\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28.4362 - val_loss: 19.2571\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 25.8271 - val_loss: 19.9908\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 21.6006 - val_loss: 25.9986\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 17.9912 - val_loss: 11.1905\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 14.5335 - val_loss: 12.8143\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.4611 - val_loss: 8.6224\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.6297 - val_loss: 8.5220\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12.9274 - val_loss: 6.6791\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.5768 - val_loss: 9.2479\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 12.0311 - val_loss: 9.1779\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.5040 - val_loss: 4.9301\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.0001 - val_loss: 4.6943\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 10.7598 - val_loss: 8.6201\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.6296 - val_loss: 3.7807\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 10.6138 - val_loss: 8.3619\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.8918 - val_loss: 4.8887\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.8188 - val_loss: 4.5684\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 9.2767 - val_loss: 5.8825\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 9.2626 - val_loss: 6.8358\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.1004 - val_loss: 4.1427\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.6922 - val_loss: 7.5923\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.6757 - val_loss: 5.9791\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 8.8350 - val_loss: 4.7133\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.6970 - val_loss: 3.8318\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 8.4043 - val_loss: 8.8623\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8.2098 - val_loss: 4.7737\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.8633 - val_loss: 6.3180\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.4035 - val_loss: 4.5995\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 7.5501 - val_loss: 4.8976\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.1179 - val_loss: 6.1129\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 7.1808 - val_loss: 6.4932\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.2208 - val_loss: 7.0526\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.0253 - val_loss: 6.6101\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 7.0634 - val_loss: 7.6622\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.7416 - val_loss: 5.3305\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.4548 - val_loss: 3.7332\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.4457 - val_loss: 7.2888\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.3519 - val_loss: 5.5348\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.1103 - val_loss: 2.4127\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 5.7377 - val_loss: 6.3397\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.0672 - val_loss: 2.6504\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.5905 - val_loss: 2.0346\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.4047 - val_loss: 2.1140\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.6056 - val_loss: 6.9076\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.5582 - val_loss: 6.6683\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 5.5143 - val_loss: 2.8657\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.4338 - val_loss: 2.3919\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfcbca0940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 60 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 68.3987 - val_loss: 35.4878\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 39.2820 - val_loss: 26.5124\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.8398 - val_loss: 37.3293\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 28.2529 - val_loss: 35.1007\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 23.4409 - val_loss: 19.8928\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.2876 - val_loss: 9.0173\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.8581 - val_loss: 8.0547\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 14.8038 - val_loss: 10.1290\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.9953 - val_loss: 5.3892\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 13.7417 - val_loss: 12.6422\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.1737 - val_loss: 5.5991\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.4410 - val_loss: 3.8042\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.1515 - val_loss: 3.6433\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 11.0027 - val_loss: 3.8391\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.8922 - val_loss: 3.2963\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.4457 - val_loss: 4.2258\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.5552 - val_loss: 4.7000\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.8693 - val_loss: 3.4070\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.2275 - val_loss: 3.6661\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.2039 - val_loss: 4.4702\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.9234 - val_loss: 3.4516\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.0646 - val_loss: 4.0358\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.7516 - val_loss: 4.2019\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.3837 - val_loss: 5.2920\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.2266 - val_loss: 4.2103\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.0918 - val_loss: 4.8380\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9.7078 - val_loss: 3.7071\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.8901 - val_loss: 5.5482\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.6851 - val_loss: 4.7084\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.9297 - val_loss: 3.7092\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.9258 - val_loss: 4.7531\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.9906 - val_loss: 5.1394\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.5150 - val_loss: 3.3095\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.8699 - val_loss: 3.6658\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.4552 - val_loss: 3.9811\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.5097 - val_loss: 5.6921\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.7517 - val_loss: 3.8081\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.3403 - val_loss: 3.4881\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.4422 - val_loss: 4.2665\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.9904 - val_loss: 3.4194\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.5894 - val_loss: 3.6939\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.4937 - val_loss: 3.6125\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.6264 - val_loss: 3.8926\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.3846 - val_loss: 3.5023\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.1072 - val_loss: 3.4183\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.2752 - val_loss: 4.0097\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.2493 - val_loss: 2.9434\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.3892 - val_loss: 5.5100\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8.2378 - val_loss: 6.3577\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.1324 - val_loss: 5.1815\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf93baa4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 61 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 183962.7969 - val_loss: 120.2455\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 299918.2500 - val_loss: 124.3225\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 178221.8281 - val_loss: 115.4683\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 57951.3750 - val_loss: 102.7278\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 158442.7031 - val_loss: 100.1967\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 157478.6406 - val_loss: 103.4205\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 43689.8867 - val_loss: 106.8648\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 58456.0938 - val_loss: 110.4963\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 63066.8672 - val_loss: 108.3807\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 22706.3516 - val_loss: 103.1862\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 77818.0625 - val_loss: 103.2442\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 74248.9297 - val_loss: 105.9855\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 16800.5254 - val_loss: 110.1129\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 111651.9062 - val_loss: 111.6558\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 67936.9141 - val_loss: 108.9611\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 21999.5195 - val_loss: 105.8909\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 5841.6426 - val_loss: 107.0325\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 40637.1211 - val_loss: 108.2995\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 46087.9688 - val_loss: 107.6553\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 20048.1934 - val_loss: 103.7614\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 87487.1172 - val_loss: 102.0606\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 85521.4141 - val_loss: 103.1832\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 37073.0117 - val_loss: 105.2714\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4768.2881 - val_loss: 105.8821\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 10715.9180 - val_loss: 105.3533\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 22866.0449 - val_loss: 104.3867\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 21704.6387 - val_loss: 105.9655\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 35727.7266 - val_loss: 106.3602\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 6727.1938 - val_loss: 104.2318\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 50929.5273 - val_loss: 102.8722\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 49632.3633 - val_loss: 104.0456\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8161.0479 - val_loss: 105.8998\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 45528.7930 - val_loss: 106.4810\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 43369.4688 - val_loss: 104.8686\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 2094.9985 - val_loss: 102.7997\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 63689.2969 - val_loss: 101.9687\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 55103.2812 - val_loss: 102.7659\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 37724.3359 - val_loss: 105.1726\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 24240.9141 - val_loss: 105.2461\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 30694.7930 - val_loss: 104.8684\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12390.5703 - val_loss: 102.3417\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 58033.6172 - val_loss: 101.4469\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 59965.6641 - val_loss: 102.0639\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 31264.3945 - val_loss: 103.5577\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 15265.6533 - val_loss: 104.0204\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 13004.9775 - val_loss: 102.9185\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12864.8643 - val_loss: 103.1877\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 3149.3406 - val_loss: 104.2514\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 42180.9219 - val_loss: 104.6867\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 26663.1074 - val_loss: 103.0952\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfae8a8280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 62 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 61.8405 - val_loss: 18.8584\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 36.4535 - val_loss: 15.0785\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 25.0949 - val_loss: 38.3890\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 27.2451 - val_loss: 25.3694\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 21.2255 - val_loss: 15.5645\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20.5755 - val_loss: 24.3962\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 18.7481 - val_loss: 16.7125\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 16.7116 - val_loss: 18.8326\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.5392 - val_loss: 12.9925\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.2913 - val_loss: 11.4370\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 12.6383 - val_loss: 4.2654\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.1952 - val_loss: 7.3015\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.7844 - val_loss: 4.5853\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.6635 - val_loss: 4.9088\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.2377 - val_loss: 4.2241\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.0974 - val_loss: 4.7129\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.9947 - val_loss: 4.9327\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.5702 - val_loss: 5.6812\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 8.4190 - val_loss: 4.1807\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 7.8466 - val_loss: 5.0149\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.5730 - val_loss: 4.3819\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.4950 - val_loss: 5.4924\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4365 - val_loss: 3.9736\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.3180 - val_loss: 5.2721\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.0881 - val_loss: 3.7338\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.7500 - val_loss: 3.8854\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.7581 - val_loss: 5.3404\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.3524 - val_loss: 6.4670\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.9756 - val_loss: 3.7203\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 6.3399 - val_loss: 3.2325\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.8557 - val_loss: 4.5054\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.7046 - val_loss: 3.9298\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 6.2000 - val_loss: 4.6912\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.5912 - val_loss: 3.3661\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 6.1651 - val_loss: 2.7712\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.7981 - val_loss: 2.7717\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.3367 - val_loss: 3.1747\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.2846 - val_loss: 3.1158\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 5.3844 - val_loss: 2.6743\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.1125 - val_loss: 2.5456\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.0249 - val_loss: 2.4190\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 5.4843 - val_loss: 3.1769\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.6556 - val_loss: 5.1334\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 5.9471 - val_loss: 2.5611\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 4.8050 - val_loss: 2.3471\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.0593 - val_loss: 2.5304\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.3789 - val_loss: 2.4473\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.4664 - val_loss: 2.8216\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.1327 - val_loss: 2.4320\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.7147 - val_loss: 3.3677\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff3b9fd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 63 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 7223712.0000 - val_loss: 100.3536\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5843409.0000 - val_loss: 99.0523\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5463417.5000 - val_loss: 98.8661\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1792949.6250 - val_loss: 98.4997\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1422352.6250 - val_loss: 98.1607\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 336547.7188 - val_loss: 97.8913\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 432567.9688 - val_loss: 97.5874\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1055515.6250 - val_loss: 97.2821\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1105317.0000 - val_loss: 97.1939\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 931004.5000 - val_loss: 96.9654\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 870984.6875 - val_loss: 96.8243\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 648432.7500 - val_loss: 96.7251\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 971604.5000 - val_loss: 96.5438\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 255533.4219 - val_loss: 96.4363\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 418662.3438 - val_loss: 96.2792\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 483214.7500 - val_loss: 96.1464\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 591804.8125 - val_loss: 96.0426\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1196458.5000 - val_loss: 95.8542\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1621669.5000 - val_loss: 95.8267\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 574115.3750 - val_loss: 95.7668\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 357452.1562 - val_loss: 95.7115\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 374283.9062 - val_loss: 95.6335\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 804108.1875 - val_loss: 95.6134\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 651455.3750 - val_loss: 95.5462\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 210937.7031 - val_loss: 95.4883\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 272442.6562 - val_loss: 95.3856\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 656654.1875 - val_loss: 95.3198\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 691434.6250 - val_loss: 95.2262\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 678519.1875 - val_loss: 95.2158\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 625177.1250 - val_loss: 95.1563\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 171766.5625 - val_loss: 95.1068\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 259370.8125 - val_loss: 95.0380\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 480205.9375 - val_loss: 94.9967\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1085376.3750 - val_loss: 94.9515\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1142423.6250 - val_loss: 95.0065\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 627126.3750 - val_loss: 95.0283\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 336892.5938 - val_loss: 95.0374\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 379698.5312 - val_loss: 95.0317\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 432310.2500 - val_loss: 95.0284\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 108253.2109 - val_loss: 94.9823\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 327629.8125 - val_loss: 94.9438\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 374335.4062 - val_loss: 94.9246\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 331468.7500 - val_loss: 94.8861\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 366619.3750 - val_loss: 94.8479\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 383923.0000 - val_loss: 94.8138\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 306967.4688 - val_loss: 94.7912\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 325157.0938 - val_loss: 94.7598\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 402407.0938 - val_loss: 94.7447\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 93563.1484 - val_loss: 94.7119\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 318147.4688 - val_loss: 94.6668\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa74fa0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 64 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 18021.2129 - val_loss: 80.9874\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 152877.1875 - val_loss: 76.1205\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 134046.5938 - val_loss: 84.0821\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7322.5874 - val_loss: 89.3000\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 52792.1484 - val_loss: 90.9878\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 58898.7227 - val_loss: 90.5620\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3540.5115 - val_loss: 90.9386\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 19882.1074 - val_loss: 91.1137\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2770.8079 - val_loss: 89.5630\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 59023.0117 - val_loss: 90.2126\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 48363.4922 - val_loss: 91.6594\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2837.7761 - val_loss: 91.9960\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16401.7305 - val_loss: 92.1783\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6403.0815 - val_loss: 94.2034\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 64630.9141 - val_loss: 94.6517\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 70136.3594 - val_loss: 94.2228\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 39162.9023 - val_loss: 93.1563\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 36891.8242 - val_loss: 92.9382\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11308.4531 - val_loss: 94.2877\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12770.9629 - val_loss: 95.1508\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 26396.7305 - val_loss: 95.0543\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 3057.3574 - val_loss: 93.4370\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 59505.1719 - val_loss: 93.4630\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 45439.0156 - val_loss: 95.2851\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12425.8193 - val_loss: 95.6219\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6054.0762 - val_loss: 94.2324\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 63055.6836 - val_loss: 94.1331\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 53796.4375 - val_loss: 94.9242\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17300.2871 - val_loss: 96.0058\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 30054.7734 - val_loss: 97.0328\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28590.3379 - val_loss: 96.5694\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 615.9196 - val_loss: 96.8779\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9654.2344 - val_loss: 96.8805\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 2725.6497 - val_loss: 95.6569\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 72386.5625 - val_loss: 95.2038\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 57451.6367 - val_loss: 96.2133\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24189.3164 - val_loss: 97.3058\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9912.9707 - val_loss: 97.7824\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11266.5039 - val_loss: 97.4719\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 7807.1035 - val_loss: 97.5899\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 4423.4492 - val_loss: 97.5880\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 21416.2793 - val_loss: 97.2586\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13952.9502 - val_loss: 98.1064\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 14303.4902 - val_loss: 98.1740\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 14896.9492 - val_loss: 97.9845\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 5815.6885 - val_loss: 97.1304\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 29878.1816 - val_loss: 97.1879\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 30738.0098 - val_loss: 97.6701\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 6434.1475 - val_loss: 98.2403\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6698.0781 - val_loss: 98.3748\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf92a22ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 65 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 81.0397 - val_loss: 50.9201\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 40.9484 - val_loss: 9.0943\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 31.5270 - val_loss: 33.8565\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28.1925 - val_loss: 36.1597\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 24.3287 - val_loss: 16.0373\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 22.8444 - val_loss: 16.9669\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19.8961 - val_loss: 23.6959\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.2526 - val_loss: 13.4758\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.0713 - val_loss: 12.5394\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.1628 - val_loss: 9.6852\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.7122 - val_loss: 9.0516\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.5175 - val_loss: 7.5397\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.0419 - val_loss: 7.0206\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.3197 - val_loss: 7.0140\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.7322 - val_loss: 3.1419\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.1420 - val_loss: 11.3199\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.1865 - val_loss: 4.4518\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.8849 - val_loss: 3.2674\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.4987 - val_loss: 7.2788\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.9398 - val_loss: 2.4365\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.8285 - val_loss: 7.2499\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.2936 - val_loss: 2.6198\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.8412 - val_loss: 4.1752\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.5541 - val_loss: 5.7797\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.5554 - val_loss: 2.2804\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.9705 - val_loss: 5.4760\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.5212 - val_loss: 2.8342\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4331 - val_loss: 5.1894\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.6340 - val_loss: 2.1710\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.8351 - val_loss: 4.9935\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.0430 - val_loss: 3.0701\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.6922 - val_loss: 4.3906\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.0033 - val_loss: 4.9635\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.4113 - val_loss: 3.9324\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.2362 - val_loss: 4.1069\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.0211 - val_loss: 3.3634\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.0864 - val_loss: 2.6673\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.9412 - val_loss: 5.9633\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 5.9908 - val_loss: 2.7105\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.7788 - val_loss: 3.5169\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.0111 - val_loss: 4.8914\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.7634 - val_loss: 2.4432\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 5.8529 - val_loss: 2.8213\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.3300 - val_loss: 2.3564\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.1401 - val_loss: 3.2429\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4.9675 - val_loss: 4.2161\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.9569 - val_loss: 5.2238\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.2061 - val_loss: 4.5703\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.6560 - val_loss: 3.3444\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.3213 - val_loss: 3.1917\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9994adc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 66 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 64.9039 - val_loss: 33.2656\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 36.8525 - val_loss: 18.6477\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 27.6136 - val_loss: 37.5379\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25.2565 - val_loss: 29.0462\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21.3839 - val_loss: 12.1829\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.8166 - val_loss: 20.0529\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 17.0436 - val_loss: 13.8220\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.5469 - val_loss: 7.6575\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.4657 - val_loss: 14.5518\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.0399 - val_loss: 3.6800\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.7733 - val_loss: 12.0191\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.4432 - val_loss: 4.3821\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.9064 - val_loss: 10.0151\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.8802 - val_loss: 4.0201\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.7866 - val_loss: 8.9956\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.5456 - val_loss: 6.0627\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.1092 - val_loss: 6.7112\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 9.6708 - val_loss: 6.1850\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.5050 - val_loss: 4.9150\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.4050 - val_loss: 6.0103\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.2261 - val_loss: 6.0173\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.1292 - val_loss: 5.3000\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.9946 - val_loss: 4.5228\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.7474 - val_loss: 5.8029\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 8.6430 - val_loss: 6.3597\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 8.4809 - val_loss: 4.8630\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 8.5056 - val_loss: 4.5254\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.2467 - val_loss: 3.3181\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.2094 - val_loss: 3.8224\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.9630 - val_loss: 5.2420\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.2044 - val_loss: 3.2334\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.6104 - val_loss: 3.6685\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.4837 - val_loss: 5.4533\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.2741 - val_loss: 4.1957\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.1961 - val_loss: 2.1896\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.1073 - val_loss: 3.8236\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.0258 - val_loss: 3.1373\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.7460 - val_loss: 4.3544\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.0941 - val_loss: 1.9775\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.8923 - val_loss: 4.8471\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 5.9232 - val_loss: 3.2026\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.0487 - val_loss: 1.9998\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.9705 - val_loss: 2.1751\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.5607 - val_loss: 2.6167\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.2763 - val_loss: 2.1370\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.3154 - val_loss: 3.5635\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.2484 - val_loss: 3.0177\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.0200 - val_loss: 2.2176\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.2142 - val_loss: 3.2527\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.2199 - val_loss: 2.2604\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9e105700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 67 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 75.2270 - val_loss: 41.1077\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 31.0056 - val_loss: 9.1458\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 26.9566 - val_loss: 25.6259\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 22.2369 - val_loss: 31.1325\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19.3059 - val_loss: 14.4090\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.8930 - val_loss: 11.2801\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.1219 - val_loss: 20.8108\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.4209 - val_loss: 10.3523\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.3387 - val_loss: 9.2530\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.0334 - val_loss: 8.6689\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.8602 - val_loss: 8.6976\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6378 - val_loss: 6.6031\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1336 - val_loss: 6.4187\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.8656 - val_loss: 6.0230\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.8083 - val_loss: 6.9018\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.4277 - val_loss: 6.1265\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.3073 - val_loss: 6.1894\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.0931 - val_loss: 6.4169\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.0580 - val_loss: 6.1099\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.2729 - val_loss: 8.1356\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.8421 - val_loss: 8.6818\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.6408 - val_loss: 7.3441\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.5677 - val_loss: 6.1443\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 6.2706 - val_loss: 6.7211\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.8631 - val_loss: 6.1817\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.9069 - val_loss: 6.7039\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.9117 - val_loss: 5.8179\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.8991 - val_loss: 6.7773\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.8824 - val_loss: 6.0102\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.4329 - val_loss: 5.8983\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.1044 - val_loss: 5.8699\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.1303 - val_loss: 6.8614\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.7879 - val_loss: 5.9122\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.0816 - val_loss: 6.3488\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.1186 - val_loss: 6.5567\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.1922 - val_loss: 5.7737\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.9505 - val_loss: 5.7430\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.9575 - val_loss: 5.6830\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.7173 - val_loss: 5.6828\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.5540 - val_loss: 5.6844\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.5328 - val_loss: 6.1488\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.1015 - val_loss: 5.2787\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.6858 - val_loss: 5.2344\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.4784 - val_loss: 5.3535\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.3279 - val_loss: 5.6175\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.3604 - val_loss: 5.3265\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.3683 - val_loss: 5.3433\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.2340 - val_loss: 5.2415\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.3666 - val_loss: 6.4852\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.6328 - val_loss: 5.8832\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfeb32ce50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 68 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 75.4096 - val_loss: 51.5916\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30.8831 - val_loss: 2.7924\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 27.3764 - val_loss: 23.9641\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20.4748 - val_loss: 28.9971\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.9327 - val_loss: 13.9798\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.3326 - val_loss: 12.4101\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.1777 - val_loss: 16.7012\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.2043 - val_loss: 2.7830\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.8375 - val_loss: 5.2383\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4409 - val_loss: 3.8275\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.8318 - val_loss: 6.4928\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.0018 - val_loss: 4.8677\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.2124 - val_loss: 4.6343\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.0650 - val_loss: 3.9368\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.6565 - val_loss: 4.6726\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.5372 - val_loss: 4.1581\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.3538 - val_loss: 5.2200\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.6690 - val_loss: 4.4846\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.5854 - val_loss: 4.6210\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.3400 - val_loss: 6.1187\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.4786 - val_loss: 4.5544\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.6109 - val_loss: 5.1056\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.1081 - val_loss: 4.9968\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.0958 - val_loss: 4.2906\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.5432 - val_loss: 4.5676\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.9007 - val_loss: 5.3217\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.4230 - val_loss: 4.6938\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.0656 - val_loss: 5.6998\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.3120 - val_loss: 4.0336\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.2890 - val_loss: 4.1178\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.1553 - val_loss: 4.9366\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.9318 - val_loss: 3.7099\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.7435 - val_loss: 4.9801\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.8163 - val_loss: 5.7287\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.6854 - val_loss: 5.3793\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.6051 - val_loss: 5.9611\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.9340 - val_loss: 4.1242\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.6917 - val_loss: 3.8223\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.7331 - val_loss: 4.3655\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.1672 - val_loss: 7.2525\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.0070 - val_loss: 3.8858\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.7779 - val_loss: 4.1819\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.0826 - val_loss: 5.7010\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.5700 - val_loss: 4.5228\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.6164 - val_loss: 3.9677\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.0829 - val_loss: 5.0568\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.2799 - val_loss: 5.6859\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.0754 - val_loss: 4.2568\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.0339 - val_loss: 4.3497\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.9748 - val_loss: 4.0113\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc8e1a310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 69 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 74.1140 - val_loss: 41.1914\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28.2716 - val_loss: 6.6166\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 26.2238 - val_loss: 24.1959\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.2974 - val_loss: 29.5890\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 19.5141 - val_loss: 15.5889\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.0481 - val_loss: 16.8965\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.3885 - val_loss: 15.9892\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.9090 - val_loss: 9.3465\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.0685 - val_loss: 4.1645\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.4186 - val_loss: 9.0770\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.4311 - val_loss: 4.7719\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.9297 - val_loss: 6.3861\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.0419 - val_loss: 5.8457\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.9500 - val_loss: 6.2978\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.7866 - val_loss: 4.5641\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.0214 - val_loss: 4.9144\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.7248 - val_loss: 4.6901\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.6996 - val_loss: 4.6044\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.6473 - val_loss: 4.6346\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.9565 - val_loss: 5.1635\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.1138 - val_loss: 5.3782\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.3660 - val_loss: 6.0108\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.6459 - val_loss: 5.4413\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.5491 - val_loss: 4.7551\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.0886 - val_loss: 4.8543\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.1601 - val_loss: 4.8864\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.2000 - val_loss: 5.2801\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.0012 - val_loss: 4.7343\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.4359 - val_loss: 4.7574\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.8653 - val_loss: 4.7617\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.8462 - val_loss: 5.0798\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.7134 - val_loss: 4.7759\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.2439 - val_loss: 5.7190\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.9462 - val_loss: 5.2356\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.8689 - val_loss: 4.2186\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.0889 - val_loss: 4.8954\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.6307 - val_loss: 5.6594\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.9554 - val_loss: 4.9536\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.2119 - val_loss: 4.2216\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.6831 - val_loss: 4.3088\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.4563 - val_loss: 4.6146\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.7891 - val_loss: 4.5710\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.5331 - val_loss: 4.3688\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.1794 - val_loss: 5.3421\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.6264 - val_loss: 4.2018\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.1120 - val_loss: 4.1796\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 4.0406 - val_loss: 4.3144\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.0155 - val_loss: 4.4059\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3.9336 - val_loss: 4.9798\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.2012 - val_loss: 4.0160\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7fd9820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 70 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 441167.6562 - val_loss: 96.1057\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 204077.0469 - val_loss: 104.9424\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 770895.1875 - val_loss: 109.8117\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 359564.8125 - val_loss: 102.0535\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 134159.7812 - val_loss: 84.6625\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1187433.0000 - val_loss: 81.8552\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1231747.6250 - val_loss: 86.6859\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 662786.1875 - val_loss: 93.8773\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 238521.1875 - val_loss: 104.3539\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 763343.1875 - val_loss: 108.8010\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 589555.5000 - val_loss: 104.8632\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 218676.0000 - val_loss: 98.9712\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 137613.2500 - val_loss: 96.4019\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 190819.8438 - val_loss: 97.6609\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 53112.8906 - val_loss: 101.9524\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 182235.9531 - val_loss: 102.3971\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 202129.7344 - val_loss: 101.3698\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 67118.1875 - val_loss: 97.1070\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 177996.8594 - val_loss: 96.3164\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 197244.3281 - val_loss: 97.7424\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 54773.0312 - val_loss: 99.7730\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18813.9434 - val_loss: 99.6196\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 32132.3652 - val_loss: 98.4221\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 71829.6875 - val_loss: 98.6696\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25720.9902 - val_loss: 100.9189\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 118639.4844 - val_loss: 100.9118\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 77137.5625 - val_loss: 98.9725\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 35460.6641 - val_loss: 99.1987\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 29187.6152 - val_loss: 100.2406\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32716.0684 - val_loss: 98.7426\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 59008.2383 - val_loss: 99.2382\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13538.2090 - val_loss: 99.9709\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 34472.4492 - val_loss: 99.2430\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 67146.0156 - val_loss: 98.5242\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44409.4023 - val_loss: 100.6184\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 106156.8047 - val_loss: 100.8458\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 56795.8633 - val_loss: 98.2515\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 182869.4844 - val_loss: 97.1318\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 111605.2656 - val_loss: 99.0802\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 83361.0000 - val_loss: 102.1739\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 209089.3438 - val_loss: 102.0263\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 124099.2891 - val_loss: 99.7761\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 52922.9492 - val_loss: 97.4810\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 192571.0938 - val_loss: 97.7162\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 132183.7812 - val_loss: 100.6091\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 141309.1250 - val_loss: 101.6636\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 67952.9375 - val_loss: 99.9967\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 56485.7812 - val_loss: 97.2857\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 215885.0469 - val_loss: 97.4880\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 161842.9219 - val_loss: 99.3325\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf80b811f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 71 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 439ms/step - loss: 46893.2461 - val_loss: 83.8261\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 199244.1562 - val_loss: 78.8154\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 120127.3125 - val_loss: 91.1611\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 55387.8828 - val_loss: 98.1693\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 26761.6113 - val_loss: 87.9900\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 97612.2734 - val_loss: 86.1166\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 77592.0938 - val_loss: 89.3145\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 39787.9805 - val_loss: 100.9421\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 120805.4062 - val_loss: 106.6304\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 93329.3047 - val_loss: 101.9308\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 62678.5078 - val_loss: 93.2808\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 61497.6758 - val_loss: 90.6752\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 46161.6914 - val_loss: 93.7404\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9556.1992 - val_loss: 101.4055\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 65439.1719 - val_loss: 101.6597\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 62442.6914 - val_loss: 98.5078\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 22150.0039 - val_loss: 93.1628\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 51215.6836 - val_loss: 93.3092\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 41590.0586 - val_loss: 96.3321\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 6394.7539 - val_loss: 97.6675\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3900.0498 - val_loss: 99.3828\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 27928.4316 - val_loss: 99.3154\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6524.6284 - val_loss: 95.4166\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 55309.9258 - val_loss: 93.1889\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 38097.2891 - val_loss: 96.0921\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 17735.3086 - val_loss: 101.8681\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 79647.5703 - val_loss: 104.4031\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 63251.0977 - val_loss: 102.3867\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 41121.3242 - val_loss: 96.7463\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 49179.8203 - val_loss: 93.9855\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46419.3594 - val_loss: 97.5780\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9069.0898 - val_loss: 98.8031\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6389.7954 - val_loss: 98.5675\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 300.7349 - val_loss: 96.8719\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 28403.6973 - val_loss: 96.6253\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5875.2397 - val_loss: 99.8121\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 42874.4688 - val_loss: 102.1344\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 37471.1211 - val_loss: 99.4054\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9322.4482 - val_loss: 95.4629\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 35412.1992 - val_loss: 95.2911\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 37587.5508 - val_loss: 97.3001\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8867.7461 - val_loss: 99.8949\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 26488.5430 - val_loss: 100.7244\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 20910.1602 - val_loss: 99.8072\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12607.2432 - val_loss: 95.3417\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 39637.2617 - val_loss: 94.8302\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 48830.8633 - val_loss: 95.5329\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 35272.1602 - val_loss: 98.8855\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9441.9785 - val_loss: 99.7128\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6512.1958 - val_loss: 97.2744\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfdad32940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 72 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 602159.5000 - val_loss: 102.1004\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 822835.0000 - val_loss: 105.2030\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 584192.6875 - val_loss: 101.2753\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 248691.2656 - val_loss: 96.5670\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 464384.0000 - val_loss: 99.0233\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 128867.7266 - val_loss: 101.1466\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 120526.2500 - val_loss: 99.9247\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 35680.1211 - val_loss: 100.1546\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 21778.5781 - val_loss: 99.2857\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 165983.8125 - val_loss: 99.1075\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 108677.9609 - val_loss: 101.3613\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 149224.7969 - val_loss: 100.6652\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 21744.6309 - val_loss: 100.4702\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16459.5645 - val_loss: 100.7250\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 17125.4902 - val_loss: 99.3687\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 205567.3906 - val_loss: 99.6965\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 102607.1016 - val_loss: 102.2513\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 236775.7656 - val_loss: 102.4503\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 206822.8281 - val_loss: 101.6070\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 70432.2109 - val_loss: 97.6877\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 622162.4375 - val_loss: 95.9509\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 579058.0625 - val_loss: 97.4991\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 303948.0000 - val_loss: 99.7113\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 71022.7188 - val_loss: 101.3533\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 252715.7656 - val_loss: 101.3935\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 178620.0312 - val_loss: 100.1825\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50833.5859 - val_loss: 99.8487\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 37528.6367 - val_loss: 100.2627\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21505.1973 - val_loss: 99.8714\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12923.0322 - val_loss: 100.0285\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15304.5693 - val_loss: 99.9849\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6402.8838 - val_loss: 100.2302\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17633.7676 - val_loss: 100.2150\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15104.1270 - val_loss: 100.0738\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4651.9092 - val_loss: 99.4970\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 54090.1445 - val_loss: 99.8891\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 33652.7930 - val_loss: 99.4584\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 50841.2617 - val_loss: 99.6887\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8793.9414 - val_loss: 99.0808\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 76900.0625 - val_loss: 99.6420\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5855.4805 - val_loss: 99.2703\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 49322.3203 - val_loss: 99.5367\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 12007.8379 - val_loss: 99.1822\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 96298.9219 - val_loss: 99.1924\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 23880.8281 - val_loss: 100.2184\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 112685.1328 - val_loss: 100.3962\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 79496.8125 - val_loss: 98.8926\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 182966.2969 - val_loss: 98.8498\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 177209.8281 - val_loss: 99.3597\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 17007.1855 - val_loss: 100.1735\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf93baa040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 73 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 127406.7734 - val_loss: 70.1790\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 88671.6328 - val_loss: 81.0356\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 81037.9141 - val_loss: 79.0015\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16499.6895 - val_loss: 81.6539\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 21661.6895 - val_loss: 82.0011\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 3096.6536 - val_loss: 83.4149\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 24487.9805 - val_loss: 83.2229\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9042.3467 - val_loss: 83.8975\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20271.4238 - val_loss: 84.0156\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4938.7832 - val_loss: 79.9063\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 133090.1406 - val_loss: 79.6710\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 123998.4766 - val_loss: 83.1694\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 71286.0859 - val_loss: 88.0726\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 64163.1172 - val_loss: 90.1445\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20921.8965 - val_loss: 88.7410\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12002.1553 - val_loss: 88.0988\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24363.7461 - val_loss: 89.3922\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8044.7476 - val_loss: 89.2955\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9399.8701 - val_loss: 90.1841\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12514.2949 - val_loss: 89.7249\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16382.2207 - val_loss: 90.1723\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7043.5996 - val_loss: 90.1762\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18759.7520 - val_loss: 90.2029\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10150.3691 - val_loss: 90.8518\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 338.8930 - val_loss: 91.1855\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11921.6523 - val_loss: 91.0152\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 785.9973 - val_loss: 91.6786\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25251.1680 - val_loss: 91.5501\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11367.4062 - val_loss: 90.5119\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 36668.5820 - val_loss: 90.8055\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28998.2891 - val_loss: 92.1673\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 21560.4902 - val_loss: 92.5876\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9499.0215 - val_loss: 91.8470\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 23145.2070 - val_loss: 91.9372\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18472.1309 - val_loss: 92.7608\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7682.7090 - val_loss: 92.8568\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 685.1898 - val_loss: 91.9327\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 38020.6172 - val_loss: 92.2131\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 27396.1211 - val_loss: 93.3089\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1383.3036 - val_loss: 93.2838\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6214.4458 - val_loss: 93.6502\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10456.6973 - val_loss: 93.6634\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2913.9656 - val_loss: 92.7675\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 42877.0039 - val_loss: 92.6748\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 36749.2891 - val_loss: 94.0277\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 18999.8516 - val_loss: 94.5784\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9418.2832 - val_loss: 93.5830\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 25686.3633 - val_loss: 93.7217\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 27019.2266 - val_loss: 94.5513\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5062.0273 - val_loss: 96.3072\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe007026550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 74 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 56.8701 - val_loss: 36.1013\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 35.9476 - val_loss: 29.6722\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 30.7492 - val_loss: 35.4447\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24.8862 - val_loss: 21.1828\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 19.0599 - val_loss: 18.9760\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.9138 - val_loss: 3.0548\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.4115 - val_loss: 8.5476\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.8841 - val_loss: 3.8969\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.5028 - val_loss: 7.3054\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.9883 - val_loss: 6.2581\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.6938 - val_loss: 5.8001\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.5238 - val_loss: 5.0119\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.4825 - val_loss: 3.8051\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.8703 - val_loss: 4.9052\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.4464 - val_loss: 3.7942\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.6796 - val_loss: 3.0927\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.0479 - val_loss: 7.4281\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.4073 - val_loss: 3.5697\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.2370 - val_loss: 4.0541\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.5790 - val_loss: 4.2502\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.1930 - val_loss: 4.6412\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.1924 - val_loss: 3.1804\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.6174 - val_loss: 3.4832\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.4589 - val_loss: 3.9393\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.2661 - val_loss: 3.0784\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.0754 - val_loss: 3.6268\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.8488 - val_loss: 4.6416\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.9109 - val_loss: 4.3023\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.7892 - val_loss: 3.2407\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.1036 - val_loss: 5.8463\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.2157 - val_loss: 5.7983\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.2910 - val_loss: 3.4031\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.9398 - val_loss: 2.8926\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.3227 - val_loss: 3.6875\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.0328 - val_loss: 3.4143\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.4692 - val_loss: 3.6043\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.7891 - val_loss: 3.6431\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.9211 - val_loss: 3.1041\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.5935 - val_loss: 4.9242\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.9169 - val_loss: 3.4440\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 4.7764 - val_loss: 3.3531\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.4328 - val_loss: 4.1432\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.5835 - val_loss: 3.6544\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.9869 - val_loss: 5.3415\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.5577 - val_loss: 3.5832\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.4049 - val_loss: 3.7033\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.6026 - val_loss: 3.6720\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.0210 - val_loss: 3.5138\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.2720 - val_loss: 4.0259\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.2611 - val_loss: 3.9676\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf92a22af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 75 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 68.8217 - val_loss: 43.7100\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 41.2293 - val_loss: 28.2788\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 29.3936 - val_loss: 45.7615\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 31.3633 - val_loss: 37.9753\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 25.4478 - val_loss: 18.7885\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 25.7569 - val_loss: 23.2015\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 22.2788 - val_loss: 29.4639\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20.6863 - val_loss: 12.1896\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 17.5811 - val_loss: 18.7456\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 15.3386 - val_loss: 4.4553\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.5784 - val_loss: 9.9963\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.1441 - val_loss: 3.4645\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 14.6288 - val_loss: 9.3449\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.7384 - val_loss: 3.9461\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.5432 - val_loss: 6.6422\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.9929 - val_loss: 4.9999\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.3046 - val_loss: 5.0288\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.0737 - val_loss: 4.7167\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.5978 - val_loss: 5.7557\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.5414 - val_loss: 6.1715\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 10.7497 - val_loss: 4.8692\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.8742 - val_loss: 6.7181\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.6032 - val_loss: 5.4810\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.9618 - val_loss: 5.2529\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.7926 - val_loss: 6.2442\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.8400 - val_loss: 5.0604\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.9534 - val_loss: 5.3389\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 9.2001 - val_loss: 5.9865\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.0922 - val_loss: 4.7978\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.9312 - val_loss: 5.4613\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.1093 - val_loss: 5.4800\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.9566 - val_loss: 4.8576\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.0782 - val_loss: 6.4142\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.0153 - val_loss: 6.1488\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.5446 - val_loss: 4.3331\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 8.1424 - val_loss: 5.3313\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8.1470 - val_loss: 4.4811\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.6691 - val_loss: 4.1899\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 7.1135 - val_loss: 4.2297\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.0037 - val_loss: 4.9888\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.3572 - val_loss: 4.1679\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.9443 - val_loss: 4.5474\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.5936 - val_loss: 3.8486\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.8491 - val_loss: 5.0617\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 6.7118 - val_loss: 4.1629\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.2981 - val_loss: 3.5589\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.6593 - val_loss: 3.7255\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.9100 - val_loss: 3.3625\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 6.2593 - val_loss: 3.5612\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 6.0965 - val_loss: 4.3976\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7e954d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 76 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 28827.4375 - val_loss: 121.7191\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 395727.6875 - val_loss: 118.8319\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 279576.3750 - val_loss: 109.8978\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 45399.2266 - val_loss: 103.6993\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 76216.3594 - val_loss: 100.7961\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 71201.1641 - val_loss: 102.2926\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 21814.6641 - val_loss: 106.1452\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 87888.6875 - val_loss: 105.6136\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 84941.7109 - val_loss: 103.7149\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 35828.1992 - val_loss: 99.9714\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 42213.8594 - val_loss: 99.7867\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 43984.5977 - val_loss: 100.3257\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12932.5996 - val_loss: 101.6813\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 6340.7954 - val_loss: 100.9336\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9474.2480 - val_loss: 100.4844\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 27170.0664 - val_loss: 100.7456\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 9262.0889 - val_loss: 101.4663\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5691.0737 - val_loss: 100.0065\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 40501.1523 - val_loss: 100.2349\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 21743.9062 - val_loss: 101.6629\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 21350.7422 - val_loss: 101.7056\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 14026.2354 - val_loss: 99.9328\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 40062.9492 - val_loss: 100.1806\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 18866.2402 - val_loss: 101.2778\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 37027.1367 - val_loss: 102.2323\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 24072.4316 - val_loss: 100.0238\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 37532.9805 - val_loss: 99.7101\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 33235.6602 - val_loss: 100.2127\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1006.7534 - val_loss: 100.9765\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1132.3988 - val_loss: 100.5107\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 31035.1875 - val_loss: 99.7577\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 30231.4238 - val_loss: 101.0917\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6472.0938 - val_loss: 100.5467\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14376.1279 - val_loss: 100.6467\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 20339.2520 - val_loss: 101.4055\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11426.6650 - val_loss: 100.7291\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11724.4854 - val_loss: 100.1078\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 18563.4629 - val_loss: 100.7766\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 20427.6582 - val_loss: 101.1834\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 6573.8794 - val_loss: 99.1158\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 72691.3359 - val_loss: 98.0923\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 59442.2773 - val_loss: 99.5034\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13450.8252 - val_loss: 101.4438\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 34501.4531 - val_loss: 101.9734\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 39975.7500 - val_loss: 100.9759\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7846.1431 - val_loss: 99.6750\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 32855.5078 - val_loss: 99.2558\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 29704.7637 - val_loss: 100.4250\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 6495.1499 - val_loss: 100.2262\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7894.8677 - val_loss: 100.4220\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf86e9c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 77 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 74.0605 - val_loss: 56.7940\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 59.6777 - val_loss: 56.1310\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 44.2981 - val_loss: 42.3852\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 37.8283 - val_loss: 26.7484\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 32.2309 - val_loss: 27.5534\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 27.9240 - val_loss: 11.6795\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 26.1831 - val_loss: 10.7092\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 24.6712 - val_loss: 6.9757\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 22.2272 - val_loss: 6.2985\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 21.3458 - val_loss: 6.2436\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19.6165 - val_loss: 6.5439\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 18.3490 - val_loss: 7.1787\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18.0864 - val_loss: 6.4566\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 17.5988 - val_loss: 5.8079\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.6047 - val_loss: 5.7757\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 15.7713 - val_loss: 5.7221\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 15.0725 - val_loss: 5.2655\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 15.6351 - val_loss: 4.9085\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 15.2527 - val_loss: 6.5698\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 14.7962 - val_loss: 5.0098\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.0702 - val_loss: 4.8305\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.9180 - val_loss: 6.4075\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.8541 - val_loss: 4.2448\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.5245 - val_loss: 5.1472\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.1326 - val_loss: 4.4763\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 11.0518 - val_loss: 4.4194\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12.5760 - val_loss: 3.9980\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.2020 - val_loss: 6.4628\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.4555 - val_loss: 5.7779\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 11.8926 - val_loss: 3.7003\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 10.9502 - val_loss: 5.1486\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.1342 - val_loss: 4.1905\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 12.9094 - val_loss: 4.8905\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.4761 - val_loss: 3.5256\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.2274 - val_loss: 6.9267\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.5495 - val_loss: 3.3734\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 8.9953 - val_loss: 7.0031\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.5213 - val_loss: 4.8182\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.9363 - val_loss: 7.3035\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.8945 - val_loss: 3.0600\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 15.0736 - val_loss: 5.7088\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.7362 - val_loss: 4.7144\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.9030 - val_loss: 5.1177\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 9.5677 - val_loss: 6.5856\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9.4679 - val_loss: 4.6693\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.7325 - val_loss: 3.6592\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.3627 - val_loss: 4.9061\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.3158 - val_loss: 4.2576\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.4989 - val_loss: 4.7293\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8.6314 - val_loss: 4.3085\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff3adb040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 78 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 74.4364 - val_loss: 48.2999\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 36.4493 - val_loss: 22.0059\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 31.8348 - val_loss: 35.4620\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 28.3552 - val_loss: 37.7825\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 26.0713 - val_loss: 22.7858\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 23.0344 - val_loss: 17.3355\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 20.1217 - val_loss: 19.9221\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16.7692 - val_loss: 9.1515\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 14.6909 - val_loss: 4.7830\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 13.2085 - val_loss: 3.0627\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 12.6378 - val_loss: 3.4942\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 12.0598 - val_loss: 3.3917\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.3799 - val_loss: 3.3992\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.3928 - val_loss: 4.1891\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.7603 - val_loss: 5.4738\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.1787 - val_loss: 3.5158\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 9.4537 - val_loss: 5.7361\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.7013 - val_loss: 7.4712\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.6257 - val_loss: 5.2907\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.4789 - val_loss: 3.5831\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.9377 - val_loss: 4.1296\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.0185 - val_loss: 3.4298\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.6388 - val_loss: 5.7465\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.6343 - val_loss: 4.8452\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.0658 - val_loss: 4.7838\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.8171 - val_loss: 3.3650\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.1472 - val_loss: 3.5773\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.7541 - val_loss: 3.4306\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.7345 - val_loss: 3.5907\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 5.3092 - val_loss: 4.3425\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.2416 - val_loss: 3.5892\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.0270 - val_loss: 3.5834\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.7769 - val_loss: 4.6120\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.0661 - val_loss: 3.5206\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.5058 - val_loss: 4.6576\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.4510 - val_loss: 3.8993\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.9987 - val_loss: 4.3835\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.9234 - val_loss: 3.5010\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.0608 - val_loss: 3.8914\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.4359 - val_loss: 3.4877\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.4084 - val_loss: 3.6714\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.8244 - val_loss: 3.6735\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 4.5852 - val_loss: 3.9266\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.6092 - val_loss: 5.0898\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.6802 - val_loss: 4.7515\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.8422 - val_loss: 4.2081\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.7816 - val_loss: 3.3732\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.2321 - val_loss: 3.4018\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.1347 - val_loss: 3.3033\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.0853 - val_loss: 4.3467\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe0070261f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 79 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 4541216.5000 - val_loss: 102.7123\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8029594.0000 - val_loss: 102.0309\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6645910.5000 - val_loss: 100.9473\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3670085.5000 - val_loss: 100.0410\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 3161003.2500 - val_loss: 99.5846\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 2275409.0000 - val_loss: 99.5451\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1898452.8750 - val_loss: 98.8781\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 1681065.8750 - val_loss: 98.5491\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1969379.3750 - val_loss: 98.2661\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 2114595.7500 - val_loss: 98.1844\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1517151.1250 - val_loss: 98.0807\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 1456444.5000 - val_loss: 97.8135\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1404587.0000 - val_loss: 97.7849\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1294563.6250 - val_loss: 97.5095\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1717000.0000 - val_loss: 97.4296\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1667342.2500 - val_loss: 97.2880\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1400606.3750 - val_loss: 97.1519\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1201047.7500 - val_loss: 97.1297\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1168158.1250 - val_loss: 96.9400\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1376689.6250 - val_loss: 96.9569\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1188353.7500 - val_loss: 96.7893\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1692008.1250 - val_loss: 96.7378\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1071285.0000 - val_loss: 96.7095\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 402365.6562 - val_loss: 96.6384\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 630435.5000 - val_loss: 96.5088\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 599189.1250 - val_loss: 96.4590\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 686701.1875 - val_loss: 96.3520\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 303974.6562 - val_loss: 96.2794\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 468252.3125 - val_loss: 96.1763\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 742733.6875 - val_loss: 96.0804\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1054952.0000 - val_loss: 96.0316\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 507434.6250 - val_loss: 95.9622\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 299418.5938 - val_loss: 95.8803\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 139301.3125 - val_loss: 95.8045\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 475686.5938 - val_loss: 95.7346\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 638792.3125 - val_loss: 95.6525\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 348993.1562 - val_loss: 95.5459\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 641278.4375 - val_loss: 95.5426\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 565495.3750 - val_loss: 95.4732\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 423192.0938 - val_loss: 95.4343\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 535445.3750 - val_loss: 95.4299\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 554557.4375 - val_loss: 95.3560\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 564715.0625 - val_loss: 95.3374\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 320691.2812 - val_loss: 95.2706\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 176967.3438 - val_loss: 95.2081\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 161644.9531 - val_loss: 95.1507\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 165716.4531 - val_loss: 95.0888\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 172143.6094 - val_loss: 95.0212\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 236365.8906 - val_loss: 94.9382\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 597667.1875 - val_loss: 94.9428\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf961c9ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 80 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 53.7067 - val_loss: 17.0848\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 34.6602 - val_loss: 22.8294\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 25.3668 - val_loss: 35.3692\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 24.1534 - val_loss: 22.1484\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 20.7458 - val_loss: 16.7970\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 17.5026 - val_loss: 18.3618\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.7676 - val_loss: 5.6866\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.8483 - val_loss: 3.8820\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.8838 - val_loss: 6.4181\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.1154 - val_loss: 3.5756\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.2516 - val_loss: 3.3423\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.5943 - val_loss: 3.6042\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.8969 - val_loss: 4.9304\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.6098 - val_loss: 5.7174\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.8343 - val_loss: 4.3436\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 9.1701 - val_loss: 4.4711\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.7693 - val_loss: 7.7612\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8.3452 - val_loss: 4.5192\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1190 - val_loss: 5.1580\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.8395 - val_loss: 6.2996\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.6978 - val_loss: 5.4739\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.7279 - val_loss: 4.2068\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4124 - val_loss: 5.3267\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.4887 - val_loss: 8.0846\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8.2120 - val_loss: 4.2546\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.4190 - val_loss: 4.8086\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.1909 - val_loss: 5.6067\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 6.9357 - val_loss: 4.2263\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.2196 - val_loss: 5.5212\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.3706 - val_loss: 7.6171\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.7430 - val_loss: 3.6323\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.3270 - val_loss: 3.3552\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.6518 - val_loss: 6.0634\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.2119 - val_loss: 3.7357\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.5052 - val_loss: 3.5911\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 6.7363 - val_loss: 6.6868\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.5210 - val_loss: 3.5762\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 5.9252 - val_loss: 4.0153\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.8921 - val_loss: 3.0865\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.9519 - val_loss: 4.1554\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.6299 - val_loss: 3.1585\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.5795 - val_loss: 4.1108\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.4821 - val_loss: 3.3942\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.2779 - val_loss: 4.0997\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.4723 - val_loss: 5.7841\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.2141 - val_loss: 3.5543\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.0482 - val_loss: 9.6182\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.5694 - val_loss: 2.4826\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 6.3218 - val_loss: 5.2983\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 5.9143 - val_loss: 6.0931\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9948a8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 81 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 5371723.0000 - val_loss: 99.7469\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8624725.0000 - val_loss: 99.4625\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 7757694.5000 - val_loss: 99.6244\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4115596.7500 - val_loss: 99.1428\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3631852.7500 - val_loss: 98.5411\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 2649779.7500 - val_loss: 98.3292\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 2211390.0000 - val_loss: 98.0821\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2401848.7500 - val_loss: 98.0841\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1776381.5000 - val_loss: 98.0029\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 363689.6875 - val_loss: 97.9557\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 304458.5000 - val_loss: 97.8318\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 301788.5625 - val_loss: 97.7017\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 342082.4688 - val_loss: 97.5795\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 259191.7969 - val_loss: 97.4502\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 290066.3438 - val_loss: 97.2834\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 309137.4375 - val_loss: 97.1039\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 265045.7188 - val_loss: 96.9591\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 336186.6250 - val_loss: 96.7793\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 318087.4688 - val_loss: 96.6269\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 278247.8750 - val_loss: 96.4843\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 258900.1250 - val_loss: 96.3231\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 344306.8438 - val_loss: 96.2044\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 282462.7812 - val_loss: 96.0482\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 273324.7812 - val_loss: 95.9073\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 802391.5000 - val_loss: 95.7998\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 924168.3125 - val_loss: 95.7373\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 590124.6875 - val_loss: 95.6944\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 969835.5000 - val_loss: 95.6353\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 249470.6250 - val_loss: 95.6097\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 635195.8750 - val_loss: 95.5384\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 964654.9375 - val_loss: 95.5365\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 509586.1562 - val_loss: 95.5304\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1021104.7500 - val_loss: 95.5233\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 724978.9375 - val_loss: 95.5514\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 731187.0625 - val_loss: 95.5528\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 895839.2500 - val_loss: 95.5576\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 303006.9688 - val_loss: 95.5686\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 280299.3125 - val_loss: 95.5690\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 217164.6875 - val_loss: 95.5364\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 273330.5000 - val_loss: 95.5019\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 252026.2344 - val_loss: 95.4490\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 221051.9531 - val_loss: 95.4011\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 226176.4688 - val_loss: 95.3767\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 247227.4688 - val_loss: 95.3248\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 249535.3906 - val_loss: 95.2674\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 218999.2812 - val_loss: 95.2258\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 216272.2500 - val_loss: 95.1933\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 249301.1094 - val_loss: 95.1460\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 665014.1875 - val_loss: 95.1091\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 628843.5000 - val_loss: 95.1032\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf6dbdaf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 82 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 267281.3438 - val_loss: 79.1779\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 75862.8516 - val_loss: 102.9204\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 335612.2188 - val_loss: 108.9844\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 286247.7500 - val_loss: 107.7991\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 169799.6875 - val_loss: 102.4119\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 97372.5781 - val_loss: 95.8260\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 140521.7969 - val_loss: 93.9953\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 134369.0469 - val_loss: 94.6659\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 92887.2188 - val_loss: 98.1489\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 70480.4922 - val_loss: 99.7219\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 54653.6836 - val_loss: 98.4081\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 27779.7559 - val_loss: 97.6080\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 3117.0283 - val_loss: 97.9656\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15533.9443 - val_loss: 97.9809\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3164.9304 - val_loss: 98.8858\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 45162.0742 - val_loss: 99.0642\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 35923.3242 - val_loss: 97.7290\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 23685.7656 - val_loss: 97.8644\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3771.7625 - val_loss: 98.4748\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 11315.5674 - val_loss: 98.8350\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 24928.6172 - val_loss: 97.9706\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 21190.6758 - val_loss: 97.9672\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3280.1746 - val_loss: 99.4704\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 74443.6562 - val_loss: 100.0210\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 61897.7578 - val_loss: 99.2531\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 21357.6094 - val_loss: 97.5008\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 60555.6250 - val_loss: 96.6289\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 58366.4492 - val_loss: 97.4811\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 31126.3320 - val_loss: 99.4359\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 36974.2891 - val_loss: 99.4931\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 39246.0742 - val_loss: 99.0292\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 14887.0869 - val_loss: 97.2879\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 74028.2500 - val_loss: 96.4419\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 59136.8555 - val_loss: 97.7663\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6812.4912 - val_loss: 99.5710\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 36839.4727 - val_loss: 99.9365\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 53937.1836 - val_loss: 99.6770\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 24438.0039 - val_loss: 98.5067\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 9855.6846 - val_loss: 98.1387\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 13143.2559 - val_loss: 98.9407\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18902.5527 - val_loss: 98.7334\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 319.9317 - val_loss: 98.9137\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 26384.5781 - val_loss: 99.0964\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 18017.8438 - val_loss: 97.6766\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 43341.0234 - val_loss: 97.5049\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 34410.8242 - val_loss: 98.5829\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21552.2344 - val_loss: 99.0585\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3974.7874 - val_loss: 97.7156\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 47993.0156 - val_loss: 97.2462\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 45539.8672 - val_loss: 97.7559\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7fb0eaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 83 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 86.4798 - val_loss: 52.5865\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 24.8983 - val_loss: 10.2040\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 20.4942 - val_loss: 14.0887\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.0747 - val_loss: 25.5000\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.7422 - val_loss: 11.3354\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 11.7468 - val_loss: 8.8529\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10.6371 - val_loss: 17.8102\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10.8875 - val_loss: 13.1364\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9.2586 - val_loss: 8.6629\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 8.8318 - val_loss: 11.4250\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.3277 - val_loss: 9.0340\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.8309 - val_loss: 8.4440\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.4670 - val_loss: 8.8604\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 6.3364 - val_loss: 8.6825\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.8896 - val_loss: 4.9143\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.8971 - val_loss: 9.5103\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.4450 - val_loss: 4.4793\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4.3775 - val_loss: 3.6313\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 4.6431 - val_loss: 4.7809\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.0428 - val_loss: 4.6336\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3.9499 - val_loss: 5.3608\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3.7637 - val_loss: 3.5653\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.9722 - val_loss: 4.4124\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3.7993 - val_loss: 3.5118\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3.5453 - val_loss: 5.1725\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3.9074 - val_loss: 3.5068\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3.8066 - val_loss: 3.5760\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.6246 - val_loss: 4.4107\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3.5845 - val_loss: 4.4374\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.5730 - val_loss: 5.2905\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.1739 - val_loss: 3.8368\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.9309 - val_loss: 3.3883\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 3.8498 - val_loss: 6.2548\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.0924 - val_loss: 4.5164\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3.7779 - val_loss: 3.7044\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3.8085 - val_loss: 5.1762\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.7886 - val_loss: 3.4659\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3.5321 - val_loss: 3.4800\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3.6287 - val_loss: 3.3621\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.6493 - val_loss: 4.0943\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.0576 - val_loss: 3.7503\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.5402 - val_loss: 4.1606\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 3.1446 - val_loss: 3.5795\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3.3017 - val_loss: 3.4625\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 3.2052 - val_loss: 4.7124\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.4507 - val_loss: 3.7765\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3.2499 - val_loss: 3.4228\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3.6272 - val_loss: 3.7937\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3.1885 - val_loss: 4.6998\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 3.2369 - val_loss: 3.9632\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfb96cbf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 84 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 60.0433 - val_loss: 36.5076\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 43.2118 - val_loss: 36.1106\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 34.6857 - val_loss: 32.2717\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28.3287 - val_loss: 20.1298\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 21.9974 - val_loss: 15.0283\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 18.7572 - val_loss: 11.2964\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.6036 - val_loss: 9.4320\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 16.8771 - val_loss: 12.9762\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 16.7368 - val_loss: 9.2465\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 16.1593 - val_loss: 11.3679\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 15.7001 - val_loss: 10.0237\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 16.0873 - val_loss: 10.4459\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.0939 - val_loss: 9.8790\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.8909 - val_loss: 10.7550\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.9686 - val_loss: 10.4106\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 16.1854 - val_loss: 11.0016\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15.1019 - val_loss: 9.9759\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15.3938 - val_loss: 10.1117\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 14.5858 - val_loss: 10.2575\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 14.5952 - val_loss: 10.2883\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.3252 - val_loss: 10.3997\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.3104 - val_loss: 10.1164\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.1433 - val_loss: 10.7839\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 14.2458 - val_loss: 9.9583\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 13.8993 - val_loss: 10.2353\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.7481 - val_loss: 10.3390\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.6073 - val_loss: 9.9942\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.2311 - val_loss: 10.8726\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.4837 - val_loss: 10.8390\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 14.3008 - val_loss: 10.7285\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 13.8545 - val_loss: 9.9735\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 14.5733 - val_loss: 9.9817\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 13.8103 - val_loss: 10.2994\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 13.8304 - val_loss: 10.4129\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 14.8620 - val_loss: 9.5002\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.8917 - val_loss: 9.7576\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.2564 - val_loss: 10.1985\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.7120 - val_loss: 9.7469\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.3317 - val_loss: 9.7065\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 12.9277 - val_loss: 9.4432\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.8508 - val_loss: 9.5668\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.6651 - val_loss: 9.4326\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 12.5827 - val_loss: 9.2736\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.5602 - val_loss: 9.2637\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 13.0412 - val_loss: 9.5949\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.7585 - val_loss: 9.6584\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.6817 - val_loss: 9.5075\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.5061 - val_loss: 9.2172\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.2873 - val_loss: 9.1285\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.8030 - val_loss: 8.6235\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa5f49a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 85 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 88.8012 - val_loss: 58.9858\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 34.9161 - val_loss: 9.9381\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 32.9601 - val_loss: 23.1410\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 24.0205 - val_loss: 33.7164\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 23.0484 - val_loss: 23.5610\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 18.9297 - val_loss: 14.4364\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17.2596 - val_loss: 17.7240\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.4909 - val_loss: 14.2538\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 11.8348 - val_loss: 11.2827\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10.7293 - val_loss: 7.6131\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.2524 - val_loss: 7.0903\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.6845 - val_loss: 6.6443\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.4621 - val_loss: 7.6076\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 7.9812 - val_loss: 7.3374\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.8766 - val_loss: 7.9389\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.0151 - val_loss: 8.0086\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.9870 - val_loss: 8.2165\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 5.6725 - val_loss: 11.1164\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.0510 - val_loss: 8.4413\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 5.4673 - val_loss: 7.7876\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.9348 - val_loss: 9.4032\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.0424 - val_loss: 8.5261\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.5611 - val_loss: 7.6295\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.1397 - val_loss: 8.5840\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 4.9560 - val_loss: 8.6371\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.6705 - val_loss: 7.8367\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 4.8984 - val_loss: 8.4359\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.8569 - val_loss: 9.5306\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.5919 - val_loss: 8.1079\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.4648 - val_loss: 7.4138\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.2969 - val_loss: 9.0245\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.3900 - val_loss: 7.9561\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.0779 - val_loss: 7.5332\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.0797 - val_loss: 8.2016\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.9907 - val_loss: 8.6817\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 3.9689 - val_loss: 8.0205\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 3.8568 - val_loss: 7.4716\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.9415 - val_loss: 7.1842\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.3341 - val_loss: 6.5609\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.7645 - val_loss: 8.7007\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.4374 - val_loss: 11.1628\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.6429 - val_loss: 9.8241\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 4.2513 - val_loss: 6.3743\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.5062 - val_loss: 6.8275\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.3766 - val_loss: 10.2338\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 4.3432 - val_loss: 8.3443\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.8643 - val_loss: 6.7039\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3.9390 - val_loss: 11.1056\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 5.4704 - val_loss: 6.2344\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.4265 - val_loss: 6.4708\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa023a280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 86 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 175ms/step - loss: 88.3130 - val_loss: 62.3690\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 34.8136 - val_loss: 15.0775\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 31.9694 - val_loss: 30.7875\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 25.4948 - val_loss: 34.7663\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 23.1824 - val_loss: 19.4362\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 20.2258 - val_loss: 19.8701\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.4397 - val_loss: 15.0427\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 13.7092 - val_loss: 9.2378\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 13.0310 - val_loss: 8.1957\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 12.1515 - val_loss: 8.0688\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 11.0886 - val_loss: 7.6015\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 10.1930 - val_loss: 8.3878\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.5717 - val_loss: 8.2305\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.2023 - val_loss: 8.5527\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.9966 - val_loss: 8.1575\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.8952 - val_loss: 8.9301\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.6631 - val_loss: 8.9049\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.2764 - val_loss: 10.2281\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.2542 - val_loss: 8.2120\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 8.3587 - val_loss: 8.2221\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8.1163 - val_loss: 8.8633\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.3750 - val_loss: 8.3445\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.2246 - val_loss: 10.8683\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.2343 - val_loss: 8.5282\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 9.2236 - val_loss: 10.0592\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 9.4216 - val_loss: 8.4071\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 9.2293 - val_loss: 9.4527\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.3875 - val_loss: 7.7313\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.5474 - val_loss: 8.9424\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.0754 - val_loss: 7.6337\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.6116 - val_loss: 7.3818\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.2662 - val_loss: 7.4507\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 7.2541 - val_loss: 7.4823\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 7.0933 - val_loss: 8.0894\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.2448 - val_loss: 7.5975\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.2969 - val_loss: 7.2709\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.1562 - val_loss: 7.9642\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 7.1024 - val_loss: 7.2792\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.8330 - val_loss: 8.1124\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 6.9345 - val_loss: 7.0958\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.0139 - val_loss: 7.2714\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 6.8360 - val_loss: 6.8944\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.7434 - val_loss: 7.4669\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 6.8600 - val_loss: 7.1276\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.7519 - val_loss: 6.8004\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.9973 - val_loss: 7.4601\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 6.5287 - val_loss: 6.8911\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.6770 - val_loss: 6.9137\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.5229 - val_loss: 6.9772\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 6.4131 - val_loss: 6.2846\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf887560d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 87 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 29632.9434 - val_loss: 94.1352\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 52473.7227 - val_loss: 91.0563\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 51426.5859 - val_loss: 94.2935\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 3743.3713 - val_loss: 94.5262\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 17049.8809 - val_loss: 96.0740\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15686.1777 - val_loss: 95.7432\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12819.3467 - val_loss: 95.9417\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1564.7878 - val_loss: 100.8853\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 88420.9141 - val_loss: 101.7632\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 86899.4453 - val_loss: 100.8966\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 49752.7812 - val_loss: 98.3899\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12188.6738 - val_loss: 96.6287\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 2466.8557 - val_loss: 97.0317\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6430.8140 - val_loss: 97.9997\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 12922.5322 - val_loss: 98.0757\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 5456.0840 - val_loss: 95.2474\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 74902.1641 - val_loss: 94.0776\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 70415.1172 - val_loss: 96.4071\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14657.7910 - val_loss: 98.2054\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4818.7788 - val_loss: 98.6229\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14088.4902 - val_loss: 98.4644\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7413.1465 - val_loss: 98.0632\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4843.1392 - val_loss: 99.4048\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 21495.5977 - val_loss: 99.2071\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14367.5654 - val_loss: 98.2131\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10819.1133 - val_loss: 98.5191\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3187.7153 - val_loss: 99.2873\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 20275.3926 - val_loss: 99.4500\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 13539.1826 - val_loss: 98.6506\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10796.7383 - val_loss: 98.4795\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4881.0400 - val_loss: 99.2792\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22114.0684 - val_loss: 99.6473\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 13468.1777 - val_loss: 99.1120\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 679.9784 - val_loss: 98.6615\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7314.2671 - val_loss: 98.8153\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1557.1631 - val_loss: 100.6166\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 49852.5352 - val_loss: 101.1368\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 49441.2031 - val_loss: 100.8007\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 36732.1133 - val_loss: 99.5614\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4696.1953 - val_loss: 98.1062\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46246.6641 - val_loss: 97.3801\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 38593.9883 - val_loss: 98.0490\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16009.1416 - val_loss: 99.1448\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13512.3408 - val_loss: 99.8119\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 13763.7949 - val_loss: 99.2374\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5815.0454 - val_loss: 99.0536\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 363.4854 - val_loss: 98.7206\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10700.4521 - val_loss: 99.1553\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4914.9458 - val_loss: 99.2989\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 750.0030 - val_loss: 97.9240\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7148a790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 88 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 17084.4941 - val_loss: 50.6781\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 283603.7500 - val_loss: 52.3384\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 141036.1250 - val_loss: 61.4210\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 94478.4062 - val_loss: 75.8343\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 167312.2500 - val_loss: 80.8990\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 174291.3750 - val_loss: 81.2475\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 80024.6562 - val_loss: 80.6963\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20646.2051 - val_loss: 77.8480\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 87289.8047 - val_loss: 78.4227\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 98448.0703 - val_loss: 80.0967\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 50893.7578 - val_loss: 82.8485\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 64676.6328 - val_loss: 84.1817\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 49520.6094 - val_loss: 82.8900\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10118.2578 - val_loss: 83.3796\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10581.0752 - val_loss: 84.9469\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 31925.9531 - val_loss: 84.8162\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10416.0420 - val_loss: 84.0230\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 31200.8984 - val_loss: 84.2302\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 23565.3398 - val_loss: 85.7042\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 29724.2637 - val_loss: 85.7813\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13932.7734 - val_loss: 84.8854\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 48870.5938 - val_loss: 84.7309\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 41159.2930 - val_loss: 86.3300\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 31852.5684 - val_loss: 86.8828\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18135.4531 - val_loss: 86.1970\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 37689.7812 - val_loss: 85.9922\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 27451.6094 - val_loss: 87.0959\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 17831.7363 - val_loss: 87.5302\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7393.1396 - val_loss: 86.9405\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20927.7207 - val_loss: 87.2555\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12839.6797 - val_loss: 87.7366\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 29197.4941 - val_loss: 88.5811\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 26492.8066 - val_loss: 88.1674\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1734.2469 - val_loss: 86.8386\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 84548.7734 - val_loss: 86.5956\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 78558.7734 - val_loss: 88.0099\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 26680.2637 - val_loss: 89.4189\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16888.5156 - val_loss: 90.2174\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17660.7910 - val_loss: 89.7024\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 13401.8877 - val_loss: 90.2156\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3683.5151 - val_loss: 90.0178\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17345.0645 - val_loss: 90.3311\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 426.4853 - val_loss: 91.1489\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 25404.7285 - val_loss: 91.2064\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 21556.7070 - val_loss: 90.9210\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 15233.1328 - val_loss: 90.6421\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8648.7627 - val_loss: 91.0470\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3696.1140 - val_loss: 91.1935\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6464.9429 - val_loss: 90.9293\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14856.6514 - val_loss: 91.1833\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7d1f1430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 89 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 76.2314 - val_loss: 48.9542\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 41.8867 - val_loss: 22.1855\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 35.1871 - val_loss: 39.9953\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 31.5587 - val_loss: 39.1551\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 25.7339 - val_loss: 20.1569\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 22.8491 - val_loss: 18.4597\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 19.0677 - val_loss: 21.0487\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 15.6869 - val_loss: 7.9289\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 14.1962 - val_loss: 11.1002\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 14.0929 - val_loss: 9.5897\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 13.5551 - val_loss: 6.2958\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 13.4612 - val_loss: 10.7112\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.9744 - val_loss: 6.6440\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.7896 - val_loss: 8.3986\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.2788 - val_loss: 6.1312\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.9801 - val_loss: 7.9202\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.6901 - val_loss: 6.2315\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.2473 - val_loss: 8.8213\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 10.8944 - val_loss: 6.8838\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10.3584 - val_loss: 7.0993\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.9579 - val_loss: 6.6401\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.1638 - val_loss: 6.2479\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 10.0376 - val_loss: 6.8587\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 9.7259 - val_loss: 6.7166\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.5221 - val_loss: 6.2629\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.3314 - val_loss: 6.8260\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.1897 - val_loss: 5.9672\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.7766 - val_loss: 6.1947\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.8574 - val_loss: 7.0647\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.6815 - val_loss: 5.6760\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 8.4475 - val_loss: 5.9431\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.0390 - val_loss: 6.5743\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.1036 - val_loss: 5.8161\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.4552 - val_loss: 5.5262\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.8796 - val_loss: 5.3204\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.7202 - val_loss: 6.1971\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.4463 - val_loss: 5.4588\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 7.0657 - val_loss: 6.3223\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.2959 - val_loss: 5.7388\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.0158 - val_loss: 5.0772\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 6.7437 - val_loss: 4.9566\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.6058 - val_loss: 5.4752\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.1871 - val_loss: 6.1297\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.0777 - val_loss: 6.3862\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.6464 - val_loss: 5.7887\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.6937 - val_loss: 4.6473\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 5.9367 - val_loss: 5.0773\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 5.6796 - val_loss: 4.8362\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.6915 - val_loss: 4.6869\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 6.4251 - val_loss: 5.1634\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9e711f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 90 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 200ms/step - loss: 49467.2070 - val_loss: 116.8205\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 175458.9062 - val_loss: 111.3920\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 95496.9375 - val_loss: 103.3583\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 39916.7656 - val_loss: 103.0202\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 16982.6699 - val_loss: 106.9530\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 60574.0391 - val_loss: 105.3930\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 32921.4062 - val_loss: 103.5058\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 14801.2021 - val_loss: 96.7728\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 97259.2188 - val_loss: 95.9761\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 107394.7500 - val_loss: 98.0389\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 54597.6758 - val_loss: 100.7678\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1510.8973 - val_loss: 101.0005\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10383.0889 - val_loss: 101.7603\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 25080.0859 - val_loss: 101.8761\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 431.2491 - val_loss: 101.8335\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 30532.5293 - val_loss: 102.4839\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 24788.3438 - val_loss: 100.3538\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 31431.9316 - val_loss: 100.2860\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17854.2734 - val_loss: 102.1387\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 34350.2188 - val_loss: 102.4114\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 21649.9492 - val_loss: 101.2847\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3042.8726 - val_loss: 98.2458\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 72051.1797 - val_loss: 97.7763\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 72450.8438 - val_loss: 99.0022\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 40118.6055 - val_loss: 101.1229\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 23495.2812 - val_loss: 101.9110\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16917.4902 - val_loss: 100.6671\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 28880.5879 - val_loss: 99.9168\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 13058.1816 - val_loss: 101.7785\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 25832.4590 - val_loss: 102.1322\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 26102.2656 - val_loss: 100.9418\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 15035.0693 - val_loss: 100.4616\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3056.7537 - val_loss: 100.7081\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 6393.7617 - val_loss: 101.2515\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 19544.7090 - val_loss: 101.4134\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3617.9519 - val_loss: 100.2544\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13602.2090 - val_loss: 100.1397\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17193.0801 - val_loss: 100.4651\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6186.4033 - val_loss: 101.0706\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4507.3867 - val_loss: 100.4533\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 18829.5391 - val_loss: 100.2306\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7838.8403 - val_loss: 100.8882\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 25410.6777 - val_loss: 101.9130\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 24607.4727 - val_loss: 101.3226\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 2323.2703 - val_loss: 100.8810\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 2616.6892 - val_loss: 100.0883\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 21919.8633 - val_loss: 100.1504\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6687.5127 - val_loss: 101.5566\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 30966.2734 - val_loss: 102.0092\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28527.8516 - val_loss: 100.7509\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9948af70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 91 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 69.3566 - val_loss: 57.4353\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 50.1518 - val_loss: 49.9556\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 34.3885 - val_loss: 18.8947\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 28.1351 - val_loss: 15.7013\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18.4104 - val_loss: 8.4622\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 32.4589 - val_loss: 13.5541\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 19.4903 - val_loss: 8.0895\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.3085 - val_loss: 7.0516\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 15.0204 - val_loss: 11.4730\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 14.8579 - val_loss: 7.6262\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 13.7902 - val_loss: 7.2614\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.6461 - val_loss: 7.5019\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.1879 - val_loss: 7.0455\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.0314 - val_loss: 7.7081\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12.4615 - val_loss: 7.1372\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 11.2847 - val_loss: 7.3152\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.9146 - val_loss: 7.0673\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.7105 - val_loss: 6.8502\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.0289 - val_loss: 6.6284\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 11.7845 - val_loss: 6.5624\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.0931 - val_loss: 6.9851\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.1650 - val_loss: 6.3221\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.0515 - val_loss: 6.1540\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.2425 - val_loss: 6.2612\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.9893 - val_loss: 6.0453\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10.8978 - val_loss: 6.0832\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.2537 - val_loss: 6.1581\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.5153 - val_loss: 6.0414\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 10.9120 - val_loss: 6.3300\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10.9282 - val_loss: 6.7898\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 11.2488 - val_loss: 5.5200\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.2932 - val_loss: 5.6488\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.4740 - val_loss: 7.3704\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.0442 - val_loss: 7.3819\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.8778 - val_loss: 5.9899\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.9647 - val_loss: 5.6934\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.4305 - val_loss: 5.9285\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.9202 - val_loss: 6.7979\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 12.5334 - val_loss: 8.7839\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 11.6776 - val_loss: 6.4904\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.9999 - val_loss: 7.0237\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.2110 - val_loss: 7.3722\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.3682 - val_loss: 7.8271\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.7352 - val_loss: 5.8688\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.6441 - val_loss: 6.0108\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.7875 - val_loss: 5.8400\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.1055 - val_loss: 5.7053\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.7830 - val_loss: 5.4515\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 10.2172 - val_loss: 5.6059\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.5791 - val_loss: 6.9089\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf88767040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 92 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 79.5181 - val_loss: 44.9183\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 33.8317 - val_loss: 5.5548\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 31.5665 - val_loss: 18.6898\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 23.3228 - val_loss: 30.0312\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 21.0422 - val_loss: 11.1333\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 19.7836 - val_loss: 5.1372\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.3236 - val_loss: 16.4476\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 15.9353 - val_loss: 5.4475\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 15.0420 - val_loss: 4.2177\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 13.3821 - val_loss: 6.4648\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 13.0408 - val_loss: 5.6391\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 12.4242 - val_loss: 4.8904\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 11.5073 - val_loss: 5.2590\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10.8807 - val_loss: 4.8946\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10.1067 - val_loss: 5.1865\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5963 - val_loss: 5.0313\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.1742 - val_loss: 4.8573\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.9261 - val_loss: 5.0433\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.3818 - val_loss: 4.8903\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 8.3698 - val_loss: 5.2155\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 7.9483 - val_loss: 4.8935\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 7.9237 - val_loss: 5.2635\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 7.3252 - val_loss: 4.7606\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.2388 - val_loss: 7.8408\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.8711 - val_loss: 5.1177\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.1168 - val_loss: 5.5666\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.5769 - val_loss: 4.6514\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.7424 - val_loss: 5.8635\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.5320 - val_loss: 5.4941\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.3915 - val_loss: 4.3155\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.8880 - val_loss: 4.9510\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.8548 - val_loss: 4.1522\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.7293 - val_loss: 4.6990\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.8770 - val_loss: 6.5020\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.3098 - val_loss: 4.0359\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.6688 - val_loss: 4.6312\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 6.4285 - val_loss: 6.4255\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.6063 - val_loss: 4.9595\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.6430 - val_loss: 5.4787\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.9668 - val_loss: 4.5537\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 5.9050 - val_loss: 4.2625\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.0663 - val_loss: 5.3656\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.3098 - val_loss: 3.5189\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.0825 - val_loss: 3.4459\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.7956 - val_loss: 4.1889\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.7993 - val_loss: 3.5639\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.5004 - val_loss: 3.8846\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.5901 - val_loss: 4.3112\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.8714 - val_loss: 3.2414\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.5781 - val_loss: 3.3344\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf75205a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 93 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 69.2320 - val_loss: 41.9024\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 54.0749 - val_loss: 49.8271\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 42.0413 - val_loss: 55.9364\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 40.7823 - val_loss: 39.7398\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 33.9704 - val_loss: 29.5832\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 28.4507 - val_loss: 27.2882\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 25.4204 - val_loss: 9.4942\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 24.5780 - val_loss: 18.1516\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 20.9702 - val_loss: 7.4028\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 23.0189 - val_loss: 20.0232\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 21.9844 - val_loss: 8.4029\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19.2120 - val_loss: 13.2948\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 19.8671 - val_loss: 4.1930\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 19.1727 - val_loss: 6.4070\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 18.5229 - val_loss: 6.8850\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.3213 - val_loss: 7.3527\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 16.3907 - val_loss: 4.0772\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 15.6813 - val_loss: 4.5828\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 15.2751 - val_loss: 4.8272\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 15.2081 - val_loss: 4.3035\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.9759 - val_loss: 4.7352\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.8780 - val_loss: 6.0790\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.5182 - val_loss: 5.8445\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.1506 - val_loss: 3.9402\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 14.7174 - val_loss: 4.6401\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 13.7597 - val_loss: 3.5308\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.8239 - val_loss: 4.3339\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 13.8737 - val_loss: 3.9405\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 12.7059 - val_loss: 4.0432\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 12.9619 - val_loss: 3.8555\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.2058 - val_loss: 3.7465\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.0171 - val_loss: 3.2354\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.7380 - val_loss: 3.1614\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.8847 - val_loss: 3.4716\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 10.7987 - val_loss: 2.7401\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 11.0358 - val_loss: 4.2112\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 11.3403 - val_loss: 6.2550\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.3624 - val_loss: 3.3004\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 10.4093 - val_loss: 2.4361\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.6958 - val_loss: 2.4393\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.5281 - val_loss: 3.0101\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.6926 - val_loss: 3.2297\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.5951 - val_loss: 3.2635\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.9674 - val_loss: 2.7845\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.2780 - val_loss: 2.7065\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.8537 - val_loss: 4.3474\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.1991 - val_loss: 5.1988\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.9698 - val_loss: 3.7977\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.2270 - val_loss: 2.6021\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.6182 - val_loss: 3.4810\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf80b815e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 94 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 82.3313 - val_loss: 47.3346\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 40.2549 - val_loss: 10.8979\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 32.6029 - val_loss: 23.6802\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 28.9760 - val_loss: 34.0586\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 26.8726 - val_loss: 17.7873\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 21.7662 - val_loss: 7.5762\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 21.8150 - val_loss: 7.2848\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.0048 - val_loss: 10.0162\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.6090 - val_loss: 7.2968\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 14.2393 - val_loss: 6.5280\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 12.7274 - val_loss: 7.3683\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.8978 - val_loss: 7.0232\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9.9379 - val_loss: 7.0784\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.5072 - val_loss: 6.8501\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.6422 - val_loss: 6.5229\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.6151 - val_loss: 6.0256\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.4477 - val_loss: 5.7570\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.2067 - val_loss: 5.6913\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 8.4336 - val_loss: 5.4132\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.6707 - val_loss: 5.2960\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.4519 - val_loss: 5.1783\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.8489 - val_loss: 5.3584\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.4554 - val_loss: 4.9488\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.3921 - val_loss: 4.9261\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.4453 - val_loss: 6.5332\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.7006 - val_loss: 6.3204\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.5709 - val_loss: 5.4146\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.0037 - val_loss: 4.7576\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.4636 - val_loss: 4.6052\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.3564 - val_loss: 5.9076\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.4424 - val_loss: 4.4301\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.4793 - val_loss: 4.3836\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 6.9540 - val_loss: 4.8110\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 7.0632 - val_loss: 4.7009\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.4716 - val_loss: 5.3607\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.6225 - val_loss: 4.1771\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 6.4110 - val_loss: 4.1278\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.6666 - val_loss: 4.2693\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.2348 - val_loss: 5.1825\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.8850 - val_loss: 4.4156\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.3301 - val_loss: 3.9195\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.0667 - val_loss: 3.8578\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.4260 - val_loss: 3.8355\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.4015 - val_loss: 3.7691\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.2237 - val_loss: 3.8615\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.3361 - val_loss: 4.3145\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 6.0395 - val_loss: 3.6963\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 6.1778 - val_loss: 3.6419\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.7567 - val_loss: 3.5154\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.7801 - val_loss: 3.5181\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9994af70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 95 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 90.6845 - val_loss: 62.1601\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 47.8663 - val_loss: 35.7985\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 40.5216 - val_loss: 36.6994\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 32.2629 - val_loss: 36.5844\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 27.6453 - val_loss: 18.4259\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 22.2004 - val_loss: 15.1593\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 20.2317 - val_loss: 7.1411\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 21.0499 - val_loss: 9.1896\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18.5946 - val_loss: 10.2497\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.5608 - val_loss: 8.7825\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.9289 - val_loss: 9.1750\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.4856 - val_loss: 6.1946\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.1635 - val_loss: 5.9295\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 15.5826 - val_loss: 5.9406\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 15.3728 - val_loss: 5.5808\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 14.7131 - val_loss: 5.5735\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 14.8402 - val_loss: 5.8685\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 14.8263 - val_loss: 6.1470\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.6530 - val_loss: 5.0783\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15.1278 - val_loss: 6.5473\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.7562 - val_loss: 6.0908\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 14.8925 - val_loss: 6.2283\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.7213 - val_loss: 7.5384\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.0324 - val_loss: 5.0956\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.0879 - val_loss: 7.8727\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 13.9592 - val_loss: 5.4646\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 13.7329 - val_loss: 5.5666\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 13.5491 - val_loss: 5.8569\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 13.1919 - val_loss: 5.6684\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 12.7461 - val_loss: 6.0862\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12.6151 - val_loss: 5.1227\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.5760 - val_loss: 6.0669\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.4351 - val_loss: 5.4326\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.2895 - val_loss: 5.2392\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.0851 - val_loss: 5.2443\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.9422 - val_loss: 7.4630\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 12.2968 - val_loss: 5.4267\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.2773 - val_loss: 5.3755\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 11.7725 - val_loss: 5.8093\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.4082 - val_loss: 6.8929\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.0021 - val_loss: 5.4261\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.1199 - val_loss: 5.5728\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.7545 - val_loss: 6.3597\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.5505 - val_loss: 5.2272\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.7367 - val_loss: 5.6040\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 10.2775 - val_loss: 5.8537\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10.4826 - val_loss: 5.6142\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.8913 - val_loss: 5.1435\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.4053 - val_loss: 6.1714\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.0901 - val_loss: 5.8720\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa9d27e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 96 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 189ms/step - loss: 54.3463 - val_loss: 20.0370\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 24.0118 - val_loss: 14.6302\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17.3870 - val_loss: 33.0579\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17.5319 - val_loss: 17.2655\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.3810 - val_loss: 19.1320\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.3015 - val_loss: 22.3772\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.8937 - val_loss: 13.1746\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.0682 - val_loss: 15.5033\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1616 - val_loss: 10.1485\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.1264 - val_loss: 5.0134\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 7.3989 - val_loss: 9.8989\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.9234 - val_loss: 10.2248\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.0407 - val_loss: 7.3455\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 6.6554 - val_loss: 3.0051\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.6899 - val_loss: 11.0130\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.4564 - val_loss: 3.1255\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.4215 - val_loss: 4.8285\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.2521 - val_loss: 6.2657\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 6.2253 - val_loss: 6.1383\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.8312 - val_loss: 4.2992\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.7320 - val_loss: 3.7636\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.5905 - val_loss: 3.1017\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.7995 - val_loss: 3.1462\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.7875 - val_loss: 3.4412\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.3862 - val_loss: 3.5083\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 5.2993 - val_loss: 3.3116\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.4838 - val_loss: 3.3503\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.0031 - val_loss: 3.4219\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.8989 - val_loss: 3.5247\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 4.7958 - val_loss: 3.5388\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.7563 - val_loss: 3.9846\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 4.7664 - val_loss: 3.5113\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4.7605 - val_loss: 3.5573\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.9181 - val_loss: 3.6856\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.5224 - val_loss: 3.5031\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.0820 - val_loss: 5.9599\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.2401 - val_loss: 4.3929\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.6905 - val_loss: 3.2753\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.7100 - val_loss: 3.6742\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 4.6157 - val_loss: 3.9554\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.5514 - val_loss: 4.4664\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.0171 - val_loss: 3.4871\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.1945 - val_loss: 3.1102\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.6387 - val_loss: 3.6874\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.4560 - val_loss: 4.2095\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.3972 - val_loss: 4.0006\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.4077 - val_loss: 3.4888\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.4741 - val_loss: 3.5052\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 4.1648 - val_loss: 3.1602\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4.2731 - val_loss: 3.1760\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7d1f1d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 97 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 71.9564 - val_loss: 32.9045\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 29.9346 - val_loss: 6.1488\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 24.3758 - val_loss: 16.0398\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 19.8990 - val_loss: 24.4466\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 18.5806 - val_loss: 13.8070\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.3666 - val_loss: 4.9553\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 14.4288 - val_loss: 6.7373\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.9637 - val_loss: 7.2811\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.4775 - val_loss: 4.6743\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.9921 - val_loss: 2.7788\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 6.6652 - val_loss: 10.1361\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.7134 - val_loss: 4.3319\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.1760 - val_loss: 3.3095\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.6599 - val_loss: 2.6438\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.3195 - val_loss: 2.7016\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 4.8072 - val_loss: 3.9048\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.9626 - val_loss: 3.1202\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 4.6228 - val_loss: 3.0640\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.7526 - val_loss: 3.3482\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.4622 - val_loss: 3.6579\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.3569 - val_loss: 3.1585\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.8562 - val_loss: 3.5314\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 4.4747 - val_loss: 4.9790\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.6909 - val_loss: 3.2422\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.8732 - val_loss: 4.4741\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.1634 - val_loss: 3.9341\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.1249 - val_loss: 2.7098\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.3209 - val_loss: 3.5187\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.1455 - val_loss: 3.2765\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.0003 - val_loss: 3.5850\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.3297 - val_loss: 5.5831\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.1560 - val_loss: 3.2429\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.0610 - val_loss: 2.8991\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 3.9856 - val_loss: 4.1492\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 4.2091 - val_loss: 5.4829\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.1412 - val_loss: 3.0986\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.1768 - val_loss: 3.3268\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.5065 - val_loss: 2.7517\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.9239 - val_loss: 4.1105\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.0825 - val_loss: 4.6624\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.9976 - val_loss: 2.8503\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.2918 - val_loss: 3.1210\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.9183 - val_loss: 7.9462\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 4.8238 - val_loss: 2.6904\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 4.3517 - val_loss: 2.6415\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3.8843 - val_loss: 4.5815\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3.7024 - val_loss: 4.8278\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3.7616 - val_loss: 3.1921\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.8310 - val_loss: 3.0354\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.5746 - val_loss: 3.7359\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf73003040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 98 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 74.5323 - val_loss: 45.0585\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 44.9298 - val_loss: 20.7748\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 39.1112 - val_loss: 33.4448\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.8631 - val_loss: 34.0255\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 25.0053 - val_loss: 17.2144\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 23.2631 - val_loss: 21.1962\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 19.6830 - val_loss: 18.7105\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 16.2582 - val_loss: 13.7478\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 15.7851 - val_loss: 12.0700\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 15.3823 - val_loss: 11.9480\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 14.6323 - val_loss: 12.2567\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.2761 - val_loss: 11.0566\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.8551 - val_loss: 11.7822\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.2502 - val_loss: 11.0280\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.2950 - val_loss: 10.7680\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 13.1141 - val_loss: 11.6411\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 13.0995 - val_loss: 10.5470\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 13.6355 - val_loss: 10.8377\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.1843 - val_loss: 10.6304\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.1301 - val_loss: 12.1732\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.5635 - val_loss: 10.5355\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.0453 - val_loss: 10.4660\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 11.6878 - val_loss: 10.2731\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.9394 - val_loss: 10.5894\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.8504 - val_loss: 11.4423\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.1716 - val_loss: 10.1784\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.4728 - val_loss: 11.2472\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.3727 - val_loss: 10.0491\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.4447 - val_loss: 10.2743\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.4256 - val_loss: 9.8035\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.5800 - val_loss: 10.4519\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.1093 - val_loss: 9.6403\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.7959 - val_loss: 9.7503\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.9202 - val_loss: 10.4230\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.1445 - val_loss: 9.4152\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.8236 - val_loss: 9.3610\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.8377 - val_loss: 9.7000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.2062 - val_loss: 9.4493\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.3297 - val_loss: 9.9704\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.1728 - val_loss: 9.9110\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.1243 - val_loss: 9.6897\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.0873 - val_loss: 10.6211\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.8266 - val_loss: 9.8332\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.0531 - val_loss: 10.0205\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.4389 - val_loss: 11.1476\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.0667 - val_loss: 8.7761\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.7508 - val_loss: 9.1988\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.9116 - val_loss: 9.1331\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.0582 - val_loss: 8.8579\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.8015 - val_loss: 9.0258\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf71079af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 99 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 71061.6016 - val_loss: 78.4013\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 201153.8438 - val_loss: 69.4926\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 157248.5469 - val_loss: 78.7362\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6120.9126 - val_loss: 81.6256\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 17543.7559 - val_loss: 86.9966\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 58716.9414 - val_loss: 84.5935\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7724.0928 - val_loss: 78.1017\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 170080.8594 - val_loss: 76.0902\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 89696.1875 - val_loss: 82.1229\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 52204.6562 - val_loss: 88.4510\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 42449.4062 - val_loss: 86.0485\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 20660.9824 - val_loss: 86.3475\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2586.5513 - val_loss: 89.1167\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 76049.1250 - val_loss: 90.4315\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 60646.4922 - val_loss: 87.3102\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 23832.4961 - val_loss: 86.9803\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8781.4443 - val_loss: 90.1190\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 57571.0859 - val_loss: 90.1933\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 40084.4062 - val_loss: 88.0950\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 21044.7559 - val_loss: 87.7758\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1528.0496 - val_loss: 89.7150\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 68064.6016 - val_loss: 91.4650\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 44278.7266 - val_loss: 88.5047\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 42013.0625 - val_loss: 87.1508\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 31931.5723 - val_loss: 88.8355\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13297.0400 - val_loss: 89.6092\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5426.9785 - val_loss: 87.0775\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 49449.9609 - val_loss: 87.9520\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 32864.1836 - val_loss: 90.3448\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 27504.5996 - val_loss: 90.7416\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8837.1357 - val_loss: 89.3242\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15547.3096 - val_loss: 89.5023\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 13651.7295 - val_loss: 90.9826\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 15511.3418 - val_loss: 90.5592\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 374.0171 - val_loss: 89.3684\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 47423.7773 - val_loss: 88.5727\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 31973.8984 - val_loss: 90.2234\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 26895.3867 - val_loss: 91.6769\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1187.3099 - val_loss: 91.2562\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 30422.5137 - val_loss: 92.0766\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 20219.2754 - val_loss: 90.0921\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 37819.5742 - val_loss: 89.9074\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 24864.3320 - val_loss: 91.6619\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 33906.0547 - val_loss: 92.7621\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 15184.0693 - val_loss: 90.6428\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 50767.1797 - val_loss: 89.6765\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 46032.2148 - val_loss: 91.5468\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4610.7339 - val_loss: 94.2262\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 54170.1016 - val_loss: 94.8238\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 53842.9648 - val_loss: 93.7719\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfacebb430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 100 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 228ms/step - loss: 80.0522 - val_loss: 51.0353\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 25.6279 - val_loss: 9.4899\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 23.6280 - val_loss: 17.6155\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.6893 - val_loss: 31.4091\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.3081 - val_loss: 16.6098\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.6780 - val_loss: 8.7464\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.8115 - val_loss: 15.0495\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 11.2679 - val_loss: 19.7272\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.2228 - val_loss: 14.0358\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.3958 - val_loss: 7.8457\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.5760 - val_loss: 12.6598\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.0376 - val_loss: 12.6000\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.0219 - val_loss: 6.9092\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.0149 - val_loss: 9.4219\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.7587 - val_loss: 6.4386\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.4348 - val_loss: 3.8911\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.5901 - val_loss: 4.9125\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.3077 - val_loss: 3.9283\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.2022 - val_loss: 4.1175\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.9715 - val_loss: 4.1029\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 3.7307 - val_loss: 3.7899\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 3.6709 - val_loss: 3.9351\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.2884 - val_loss: 4.6098\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 3.9590 - val_loss: 3.7283\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.5119 - val_loss: 3.7353\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.4662 - val_loss: 3.7602\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.5040 - val_loss: 3.7246\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.3962 - val_loss: 3.6716\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 3.4612 - val_loss: 3.6726\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 3.5091 - val_loss: 4.1076\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3.7277 - val_loss: 3.8077\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3.3452 - val_loss: 3.9492\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.3466 - val_loss: 3.7568\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.5353 - val_loss: 3.7777\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3.5072 - val_loss: 3.7958\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3.3894 - val_loss: 3.7635\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3.1640 - val_loss: 3.5985\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3.1652 - val_loss: 3.5879\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.2146 - val_loss: 3.9105\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3.4331 - val_loss: 3.9525\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.1410 - val_loss: 3.5670\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 3.0471 - val_loss: 3.5210\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 3.0847 - val_loss: 3.5023\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 3.1009 - val_loss: 3.4879\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.3550 - val_loss: 3.7592\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.3769 - val_loss: 4.5006\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.8770 - val_loss: 4.3345\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.3221 - val_loss: 3.5678\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.2606 - val_loss: 3.4359\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.5544 - val_loss: 3.3911\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7ffddca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 101 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 194ms/step - loss: 80.2069 - val_loss: 44.1956\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 43.8532 - val_loss: 28.4183\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 32.9969 - val_loss: 44.3306\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 30.9473 - val_loss: 35.7872\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 24.6315 - val_loss: 14.1930\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 22.1493 - val_loss: 19.4363\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 17.2003 - val_loss: 9.7497\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.1660 - val_loss: 12.3928\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.2635 - val_loss: 3.5554\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.1772 - val_loss: 12.9719\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.7086 - val_loss: 4.8842\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.7324 - val_loss: 9.2209\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 12.9573 - val_loss: 3.6138\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 11.6995 - val_loss: 4.8693\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.3475 - val_loss: 3.5178\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.7407 - val_loss: 3.0218\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.5018 - val_loss: 3.1586\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.6436 - val_loss: 3.7872\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.3500 - val_loss: 5.7217\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.3080 - val_loss: 2.8367\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.2521 - val_loss: 3.7287\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.7847 - val_loss: 2.6885\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.5950 - val_loss: 2.9236\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.2302 - val_loss: 2.4798\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8.9292 - val_loss: 2.8487\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8.9509 - val_loss: 4.7899\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.2437 - val_loss: 3.0477\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.6812 - val_loss: 4.8959\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.3809 - val_loss: 2.7724\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.8735 - val_loss: 2.7739\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.3678 - val_loss: 4.2968\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.3004 - val_loss: 3.4836\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.7788 - val_loss: 2.4267\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.8470 - val_loss: 2.1528\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.2502 - val_loss: 1.7973\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.8282 - val_loss: 1.8950\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.0263 - val_loss: 2.3536\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.6610 - val_loss: 2.8371\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.6098 - val_loss: 3.1460\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.0938 - val_loss: 1.5539\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.0495 - val_loss: 1.4556\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.9647 - val_loss: 1.7534\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.9225 - val_loss: 2.6047\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.8356 - val_loss: 2.0633\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.2040 - val_loss: 1.7860\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.0808 - val_loss: 1.8729\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 5.7498 - val_loss: 4.5832\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.3376 - val_loss: 2.4974\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.1223 - val_loss: 1.9593\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.2544 - val_loss: 2.1742\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa38ad550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 102 finished\n"
     ]
    }
   ],
   "source": [
    "zipcodes = nv_zipcodes\n",
    "dict_mape2 = {}\n",
    "dict_pred2 = {}\n",
    "\n",
    "for zipcode in range(len(zipcodes)):\n",
    "\n",
    "    # init a RMM model\n",
    "    rnn_model2 = Sequential()\n",
    "    # add 4 layers of RNN and a last layer\n",
    "\n",
    "    # we define shape on first layer, (60,1) because we use 60 inputs per prediction\n",
    "    rnn_model2.add(LSTM(units= 60, return_sequences = True, input_shape=((60,1))))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # another layer\n",
    "    rnn_model2.add(LSTM(units= 30, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # return_sequence is False because we want only 1 output after this layer\n",
    "    #rnn_model.add(LSTM(units= 60, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # last layer \n",
    "\n",
    "    rnn_model2.add(Dense(units=1))\n",
    "\n",
    "    # compile - because this is a regression model we want to minimize MSE\n",
    "\n",
    "    rnn_model2.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "\n",
    "    # We get only the specific column(Zipcode from our train and test datas)\n",
    "    train_data = train.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    test_data = test.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # We are using normalizaion rather than standascaler. \n",
    "    # In a upward trending timeseries it is better to not start from negative\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Because we are using 60 previous values to model and predict the next value, \n",
    "    # We set X_train from arrays of 60 for each y_train value\n",
    "    # Same idea for test data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(train_data_scaled)):\n",
    "        X_train.append(train_data_scaled[i-60:i])\n",
    "        y_train.append(train_data_scaled[i])\n",
    "\n",
    "    data_total = pd.concat((train.iloc[:,zipcode:zipcode+1], test.iloc[:,zipcode:zipcode+1]),axis=0)\n",
    "    inputs = data_total[len(train)-60:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(60,len(inputs)):\n",
    "        X_test.append(inputs[i-60:i])\n",
    "        y_test.append(inputs[i])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(test_data)\n",
    "\n",
    "    # We need numpy arrays for our model\n",
    "    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # We fit our data to our zipcode specific data\n",
    "    rnn_model2.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, scaler.transform(y_test)))\n",
    "\n",
    "    # Make predictions on the data\n",
    "\n",
    "    y_hat_raw = rnn_model2.predict(X_test)\n",
    "    y_hat = scaler.inverse_transform(y_hat_raw)\n",
    "\n",
    "    # Use the score on unseen test data to calculate the MAPE\n",
    "\n",
    "    dict_mape2[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_test)/y_test))      \n",
    "\n",
    "    # We get the last 60 values from our test data which is basically last 60 values in the data set\n",
    "    last_60 = df_time_series.iloc[-60:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # Before we use our data we scale it\n",
    "    last_60 = scaler.transform(last_60)\n",
    "    \n",
    "    # Our input should be in (x,60,1) format\n",
    "    x_new_pred = last_60[-60:].reshape(1,60,1)\n",
    "\n",
    "    # make a prediction, add to the last_60 for the next prediction and \n",
    "    y_pred = rnn_model2.predict(x_new_pred)\n",
    "\n",
    "    # We add our predition to our list of predictions for zipcode specific predictions list\n",
    "    dict_pred2[zipcodes[zipcode]]=scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(f'Iteration number {zipcode} finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_keys2 = list(dict_mape2.keys())\n",
    "rnn_mape2 = list(dict_mape2.values())\n",
    "rnn_pred2 = []\n",
    "rnn_dict2 = {}\n",
    "for zipcode in dict_pred.keys():\n",
    "    rnn_pred2.append(dict_pred2[zipcode].astype(int)[0][0])\n",
    "for zc in rnn_keys2:\n",
    "    a = []\n",
    "    a.append(dict_mape2[zc])\n",
    "    a.append(dict_pred2[zc].astype(float)[0][0])\n",
    "    a.append('RNN_2_Layers')\n",
    "    rnn_dict2[zc] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2113528638887323"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_mape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 20860.5410 - val_loss: 124.1890\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 222539.3438 - val_loss: 123.3592\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 131274.8125 - val_loss: 117.9516\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 62323.0977 - val_loss: 109.5338\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 87688.2422 - val_loss: 106.0233\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 76597.2266 - val_loss: 108.2965\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20096.6660 - val_loss: 111.3690\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16254.6494 - val_loss: 113.1617\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15240.6064 - val_loss: 112.0844\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2609.4368 - val_loss: 113.7924\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50556.3906 - val_loss: 113.0186\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22596.2344 - val_loss: 110.1515\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 78404.5625 - val_loss: 108.8017\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45209.2812 - val_loss: 110.3075\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22134.4160 - val_loss: 110.9827\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5435.9536 - val_loss: 109.4091\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47438.4180 - val_loss: 109.4883\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31290.0762 - val_loss: 110.6694\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15439.8994 - val_loss: 111.1796\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 810.7280 - val_loss: 112.4894\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56326.0742 - val_loss: 113.0184\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38758.2852 - val_loss: 110.4301\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 33218.4688 - val_loss: 109.1641\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 47700.1094 - val_loss: 110.8415\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9298.1797 - val_loss: 113.1375\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45045.2305 - val_loss: 113.0739\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 58620.4219 - val_loss: 111.3215\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4534.9146 - val_loss: 111.5507\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40521.8867 - val_loss: 111.4561\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15802.4229 - val_loss: 110.4888\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15399.8672 - val_loss: 111.6768\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19660.8789 - val_loss: 111.5883\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19776.1836 - val_loss: 109.7638\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12123.0967 - val_loss: 110.4176\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6091.2505 - val_loss: 113.0574\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 101993.4766 - val_loss: 114.1886\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22650.4609 - val_loss: 111.4418\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24102.8223 - val_loss: 109.5111\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10351.9395 - val_loss: 109.3770\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39253.5312 - val_loss: 109.3787\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14758.6250 - val_loss: 108.4010\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29541.7461 - val_loss: 109.1344\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8185.2129 - val_loss: 110.3636\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43225.9570 - val_loss: 111.6755\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 71289.7656 - val_loss: 110.4549\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10435.9883 - val_loss: 110.1319\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46115.4453 - val_loss: 109.5413\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10182.4717 - val_loss: 108.0246\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14583.2959 - val_loss: 108.1627\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41778.9062 - val_loss: 109.6299\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9948ac10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 0 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 74048.0000 - val_loss: 95.9198\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34295.7852 - val_loss: 95.4999\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 21044.5703 - val_loss: 97.9118\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 96345.4766 - val_loss: 94.0387\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 133817.6875 - val_loss: 95.2470\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 96915.5938 - val_loss: 98.4174\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 56128.6992 - val_loss: 97.5685\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 84193.1406 - val_loss: 95.7166\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 95705.2969 - val_loss: 95.9640\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76991.7578 - val_loss: 100.4135\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 151540.0156 - val_loss: 99.7476\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63024.7812 - val_loss: 97.0734\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 67528.5547 - val_loss: 99.3094\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 76508.8984 - val_loss: 98.9777\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21871.3418 - val_loss: 98.0578\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20405.3184 - val_loss: 99.5042\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 119581.8125 - val_loss: 99.3386\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57902.2773 - val_loss: 95.7155\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 211432.2656 - val_loss: 95.7478\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 81756.4141 - val_loss: 98.7776\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12977.4883 - val_loss: 100.9105\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 105018.2031 - val_loss: 99.8755\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12155.5771 - val_loss: 98.9536\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 91766.5469 - val_loss: 98.6979\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 74010.8438 - val_loss: 101.5749\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 125445.3047 - val_loss: 101.6176\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 96061.6328 - val_loss: 97.4291\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 136141.5312 - val_loss: 96.6507\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 113308.7734 - val_loss: 98.1632\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37201.0273 - val_loss: 100.4447\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 173215.0312 - val_loss: 101.2237\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 93266.9688 - val_loss: 99.5673\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 85161.9609 - val_loss: 97.6812\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 119796.5000 - val_loss: 99.7191\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 66403.9453 - val_loss: 100.1606\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44920.7305 - val_loss: 99.3858\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34714.3945 - val_loss: 100.0749\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28322.5957 - val_loss: 101.5202\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 96240.6719 - val_loss: 100.9439\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10076.7832 - val_loss: 99.2441\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 101281.9844 - val_loss: 99.1022\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27753.2109 - val_loss: 99.9404\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40596.1445 - val_loss: 98.4042\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 98381.0156 - val_loss: 98.6014\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 71605.5938 - val_loss: 101.1605\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 126291.2266 - val_loss: 100.6258\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49141.7773 - val_loss: 99.0604\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 57992.9609 - val_loss: 98.1722\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44793.5312 - val_loss: 99.6134\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 60750.5117 - val_loss: 100.0846\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7fb0e820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 1 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 72.1964 - val_loss: 53.9183\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46.6405 - val_loss: 29.5365\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37.5645 - val_loss: 31.3166\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31.1447 - val_loss: 32.9997\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.7530 - val_loss: 25.0060\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 24.2656 - val_loss: 12.5979\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22.6278 - val_loss: 14.4860\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.3954 - val_loss: 11.2622\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.9257 - val_loss: 6.5972\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.5353 - val_loss: 5.4390\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.6590 - val_loss: 2.4041\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.9467 - val_loss: 4.4295\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.5408 - val_loss: 10.2523\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.3036 - val_loss: 3.9594\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.0285 - val_loss: 5.2713\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.8521 - val_loss: 6.0791\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.6241 - val_loss: 4.4479\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.1270 - val_loss: 3.3283\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.9103 - val_loss: 4.5417\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3664 - val_loss: 3.6102\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4094 - val_loss: 6.5677\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9672 - val_loss: 3.1972\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7520 - val_loss: 5.2407\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0969 - val_loss: 4.4187\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2127 - val_loss: 5.0124\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.1308 - val_loss: 4.0679\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7538 - val_loss: 4.3291\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5381 - val_loss: 6.2648\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.8686 - val_loss: 3.4938\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3661 - val_loss: 3.6799\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.3669 - val_loss: 5.1547\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9414 - val_loss: 4.0090\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.9917 - val_loss: 3.1544\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.1581 - val_loss: 5.9035\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4320 - val_loss: 2.5503\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.5241 - val_loss: 3.3180\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6343 - val_loss: 2.8047\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1849 - val_loss: 2.1738\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2518 - val_loss: 5.2774\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6348 - val_loss: 3.1371\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.9463 - val_loss: 2.5008\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5931 - val_loss: 4.3308\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8119 - val_loss: 2.9824\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8404 - val_loss: 5.2181\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.0620 - val_loss: 3.9282\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8275 - val_loss: 3.1886\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.5631 - val_loss: 4.8532\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.4951 - val_loss: 3.6475\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4467 - val_loss: 2.5809\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5343 - val_loss: 3.3771\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf6f52cca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 2 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 74.4454 - val_loss: 48.7419\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27.2286 - val_loss: 3.9472\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23.5332 - val_loss: 16.6053\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.1658 - val_loss: 25.7003\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.8186 - val_loss: 20.6968\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.5697 - val_loss: 12.7212\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.7892 - val_loss: 8.3146\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.1158 - val_loss: 12.8962\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9506 - val_loss: 5.0440\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.2305 - val_loss: 8.0484\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4902 - val_loss: 2.5720\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3131 - val_loss: 4.1950\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6934 - val_loss: 7.4123\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.7589 - val_loss: 2.3259\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4851 - val_loss: 10.0657\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4423 - val_loss: 2.0814\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2138 - val_loss: 6.4688\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4440 - val_loss: 3.9187\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1497 - val_loss: 2.3095\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4999 - val_loss: 6.6325\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0118 - val_loss: 2.4114\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3785 - val_loss: 3.6483\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7178 - val_loss: 6.2004\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9277 - val_loss: 2.4935\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.2078 - val_loss: 4.3870\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9591 - val_loss: 2.6217\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.5845 - val_loss: 2.5032\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2962 - val_loss: 4.5453\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.0608 - val_loss: 2.3264\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2124 - val_loss: 2.9032\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3239 - val_loss: 2.6289\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7544 - val_loss: 3.6438\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8996 - val_loss: 2.6199\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7304 - val_loss: 2.0525\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6123 - val_loss: 2.6328\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.0034 - val_loss: 2.2798\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4676 - val_loss: 3.1381\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9219 - val_loss: 3.4947\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9021 - val_loss: 2.1791\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2319 - val_loss: 5.4370\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1736 - val_loss: 3.4771\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6279 - val_loss: 3.8345\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5631 - val_loss: 2.0735\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7173 - val_loss: 2.1116\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9708 - val_loss: 3.5275\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5699 - val_loss: 2.2912\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6374 - val_loss: 2.8134\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6691 - val_loss: 2.1062\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7235 - val_loss: 2.5505\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8164 - val_loss: 2.0996\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf76c50670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 3 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 91.2921 - val_loss: 76.3753\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 56.9480 - val_loss: 48.4128\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47.1066 - val_loss: 42.1182\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37.9408 - val_loss: 38.4508\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30.1018 - val_loss: 21.9505\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27.4267 - val_loss: 22.2408\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23.6871 - val_loss: 14.9156\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21.5090 - val_loss: 7.8659\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.0885 - val_loss: 8.4231\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.7571 - val_loss: 4.2322\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.3028 - val_loss: 6.6776\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.1374 - val_loss: 5.0031\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.0005 - val_loss: 4.3682\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.0079 - val_loss: 6.4280\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.3243 - val_loss: 4.5992\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.8160 - val_loss: 7.5874\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.9820 - val_loss: 5.4735\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.0965 - val_loss: 3.8551\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.3010 - val_loss: 5.2075\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.8677 - val_loss: 4.1051\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.8596 - val_loss: 5.3225\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.6824 - val_loss: 5.3922\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6900 - val_loss: 4.1018\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.6294 - val_loss: 5.0045\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.9541 - val_loss: 4.0347\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7675 - val_loss: 3.5327\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4290 - val_loss: 6.7036\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6676 - val_loss: 3.7313\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4761 - val_loss: 4.7192\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9870 - val_loss: 3.4708\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1980 - val_loss: 3.5767\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7247 - val_loss: 4.1527\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2087 - val_loss: 4.0494\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5576 - val_loss: 5.4172\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7479 - val_loss: 2.2775\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3753 - val_loss: 3.2998\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.8832 - val_loss: 4.3938\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5107 - val_loss: 5.2131\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9335 - val_loss: 2.8065\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2059 - val_loss: 6.2126\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4767 - val_loss: 3.6090\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9274 - val_loss: 3.3867\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4561 - val_loss: 2.6875\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5694 - val_loss: 4.2178\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3889 - val_loss: 5.6601\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5574 - val_loss: 3.1821\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.9528 - val_loss: 2.4155\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5719 - val_loss: 3.2818\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1637 - val_loss: 4.2209\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3078 - val_loss: 2.6502\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf6e7a3e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 4 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 59838.4336 - val_loss: 100.5333\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 91508.7344 - val_loss: 96.2648\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 26985.4746 - val_loss: 89.4770\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87712.8594 - val_loss: 89.0854\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 41120.7031 - val_loss: 92.3260\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52336.0000 - val_loss: 95.0552\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41564.5312 - val_loss: 91.1721\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 55606.1250 - val_loss: 89.5838\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42652.6758 - val_loss: 91.3647\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3038.8149 - val_loss: 94.6826\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 108132.9688 - val_loss: 96.3118\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52455.0781 - val_loss: 93.4020\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2820.8496 - val_loss: 91.0052\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64543.2891 - val_loss: 89.3222\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52194.2930 - val_loss: 91.4531\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5493.4341 - val_loss: 94.8750\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50843.5508 - val_loss: 95.1239\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 61509.2812 - val_loss: 94.4163\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 19073.3320 - val_loss: 92.0575\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13887.5068 - val_loss: 91.3831\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8971.1514 - val_loss: 91.7431\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 20640.9238 - val_loss: 94.1640\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 48940.8242 - val_loss: 94.9052\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 91031.8047 - val_loss: 94.0669\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 41380.4531 - val_loss: 92.4284\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12683.6436 - val_loss: 89.7137\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44644.5312 - val_loss: 89.3047\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45898.7344 - val_loss: 89.8395\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33315.4258 - val_loss: 91.7769\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17698.7305 - val_loss: 92.6308\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16120.2480 - val_loss: 93.1820\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 34482.4609 - val_loss: 93.5992\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36254.6836 - val_loss: 92.6402\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 30171.0664 - val_loss: 89.2484\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82017.8594 - val_loss: 88.3884\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 71451.3281 - val_loss: 89.3663\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35439.9648 - val_loss: 90.8906\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17451.0879 - val_loss: 93.4591\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28602.1152 - val_loss: 94.1010\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26604.6055 - val_loss: 93.8590\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61754.4141 - val_loss: 92.1819\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12096.5391 - val_loss: 91.7843\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18682.9062 - val_loss: 93.1910\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26797.0898 - val_loss: 93.8346\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38866.3203 - val_loss: 92.7153\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7120.1250 - val_loss: 90.4507\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91858.7266 - val_loss: 89.1241\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75322.2422 - val_loss: 90.1146\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46229.7852 - val_loss: 92.7627\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4847.5996 - val_loss: 93.4151\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5bf34a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 5 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 18178.4902 - val_loss: 105.4468\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 329757.7500 - val_loss: 109.9953\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 235928.3438 - val_loss: 99.7476\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 131005.5547 - val_loss: 89.4152\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 95980.6562 - val_loss: 86.8711\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 87571.5469 - val_loss: 89.3744\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43341.7109 - val_loss: 94.7864\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 85627.1875 - val_loss: 96.6204\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 81758.6328 - val_loss: 94.9831\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42113.7109 - val_loss: 90.7082\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 69556.3203 - val_loss: 90.3937\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 56632.8242 - val_loss: 92.5487\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2778.0393 - val_loss: 91.9033\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 57372.1250 - val_loss: 92.8525\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22518.7031 - val_loss: 95.9393\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 89959.6172 - val_loss: 96.9561\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 65347.5391 - val_loss: 95.0553\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21154.2695 - val_loss: 92.2934\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41488.9883 - val_loss: 92.3859\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35657.1992 - val_loss: 93.6105\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6021.5938 - val_loss: 93.9622\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7732.2197 - val_loss: 95.1160\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16868.2148 - val_loss: 94.9076\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2233.0300 - val_loss: 92.3152\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67249.7031 - val_loss: 91.5170\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46381.0352 - val_loss: 93.8146\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28962.6875 - val_loss: 94.4506\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35989.6562 - val_loss: 93.8613\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18009.1094 - val_loss: 92.2655\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27185.3164 - val_loss: 93.0549\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2588.5469 - val_loss: 92.8199\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38158.0625 - val_loss: 93.3186\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25874.5176 - val_loss: 95.1182\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55111.2539 - val_loss: 95.7200\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39586.4062 - val_loss: 94.2232\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21922.3281 - val_loss: 91.3423\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 115165.9609 - val_loss: 90.1603\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 88953.3203 - val_loss: 91.1932\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 65527.7617 - val_loss: 94.1766\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4476.2412 - val_loss: 97.2285\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 146283.2031 - val_loss: 98.2717\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 136784.1094 - val_loss: 97.4029\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76887.5391 - val_loss: 95.1921\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41104.5820 - val_loss: 92.7668\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10169.7158 - val_loss: 92.3097\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39441.1914 - val_loss: 93.1415\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 30968.5859 - val_loss: 94.4188\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61831.9805 - val_loss: 95.3701\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30443.8184 - val_loss: 92.9985\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37158.4883 - val_loss: 92.6890\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf710798b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 6 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 89.8306 - val_loss: 77.5614\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 59.1948 - val_loss: 47.3175\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53.2458 - val_loss: 36.9311\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44.1220 - val_loss: 40.3218\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35.3186 - val_loss: 34.3993\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30.5645 - val_loss: 23.9782\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27.3315 - val_loss: 22.5614\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 24.8655 - val_loss: 19.1440\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22.8599 - val_loss: 11.1068\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21.2932 - val_loss: 14.2440\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.8708 - val_loss: 4.6116\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.7120 - val_loss: 4.1623\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.2828 - val_loss: 2.8773\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.8443 - val_loss: 4.5582\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.8602 - val_loss: 2.2814\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.7006 - val_loss: 6.2882\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.0532 - val_loss: 2.3246\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.4762 - val_loss: 5.9847\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.5364 - val_loss: 4.6741\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.5689 - val_loss: 4.0789\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1766 - val_loss: 4.7993\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.3051 - val_loss: 2.9507\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.5919 - val_loss: 3.9483\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.9235 - val_loss: 3.5144\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0456 - val_loss: 6.5113\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.3483 - val_loss: 4.0868\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.1110 - val_loss: 2.9547\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1877 - val_loss: 4.5130\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.6914 - val_loss: 4.1480\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3513 - val_loss: 5.9856\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4675 - val_loss: 1.8501\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0486 - val_loss: 4.1272\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5726 - val_loss: 4.7924\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5939 - val_loss: 2.8576\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8792 - val_loss: 3.7709\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.7508 - val_loss: 5.7621\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4960 - val_loss: 4.5220\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.8179 - val_loss: 2.2115\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1024 - val_loss: 5.6740\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5828 - val_loss: 3.7311\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6742 - val_loss: 1.6449\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.5532 - val_loss: 3.8817\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.1852 - val_loss: 3.6498\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5404 - val_loss: 4.0487\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7733 - val_loss: 1.6964\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9565 - val_loss: 3.1490\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0599 - val_loss: 4.8774\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8708 - val_loss: 2.7974\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6295 - val_loss: 4.8083\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.0956 - val_loss: 2.7064\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf6db2e160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 7 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 199952.5469 - val_loss: 90.5164\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22388.9531 - val_loss: 106.1453\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 210775.4062 - val_loss: 108.7218\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 154459.5625 - val_loss: 106.0776\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 139906.7188 - val_loss: 97.3879\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16449.9746 - val_loss: 95.7525\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18507.3145 - val_loss: 97.9444\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28106.8516 - val_loss: 98.3926\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2356.4670 - val_loss: 98.3540\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 59984.8438 - val_loss: 98.6255\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4225.8452 - val_loss: 95.5734\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42220.6680 - val_loss: 95.2581\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31241.1016 - val_loss: 96.8347\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6186.9375 - val_loss: 101.8611\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 98061.7578 - val_loss: 102.3335\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 88723.2188 - val_loss: 101.3322\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45477.5938 - val_loss: 97.2990\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3704.9436 - val_loss: 95.9175\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31360.6348 - val_loss: 97.0659\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10340.4775 - val_loss: 100.5774\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 95594.8516 - val_loss: 101.8061\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 58856.4062 - val_loss: 98.0774\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8212.9883 - val_loss: 97.0765\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23009.1816 - val_loss: 94.8933\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47890.2148 - val_loss: 95.6141\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43665.7031 - val_loss: 97.0967\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8564.6982 - val_loss: 97.8053\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 236.6769 - val_loss: 99.8559\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 79448.1484 - val_loss: 100.0016\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 32634.7461 - val_loss: 97.7852\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7874.1948 - val_loss: 93.1105\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 92055.6719 - val_loss: 92.7305\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 95314.7891 - val_loss: 94.2566\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55931.7305 - val_loss: 97.1513\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29955.1152 - val_loss: 98.3568\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14944.3818 - val_loss: 96.1074\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 54196.5938 - val_loss: 96.0025\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 53045.8242 - val_loss: 97.5159\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10145.7070 - val_loss: 99.6440\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 69899.7734 - val_loss: 100.8736\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 56580.2969 - val_loss: 98.9308\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16791.0078 - val_loss: 96.2720\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 43347.8164 - val_loss: 95.7583\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50257.9922 - val_loss: 95.9882\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38140.8438 - val_loss: 99.1483\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44159.8750 - val_loss: 99.9997\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39791.3398 - val_loss: 99.0256\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3134.0718 - val_loss: 98.4639\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20142.9336 - val_loss: 98.7455\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16516.9355 - val_loss: 97.3458\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9994a430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 8 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 88.7998 - val_loss: 75.1484\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 60.5624 - val_loss: 53.4853\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51.0293 - val_loss: 47.9242\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41.1296 - val_loss: 38.9874\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33.2918 - val_loss: 22.2285\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30.6465 - val_loss: 23.5694\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27.1700 - val_loss: 11.6413\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26.8621 - val_loss: 10.9912\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23.0942 - val_loss: 10.8674\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22.0784 - val_loss: 5.4951\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20.0451 - val_loss: 7.9403\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.3234 - val_loss: 4.0064\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20.3128 - val_loss: 4.0840\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.5776 - val_loss: 7.2547\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.5085 - val_loss: 3.6742\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.9453 - val_loss: 5.1678\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.4084 - val_loss: 5.1756\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.2535 - val_loss: 4.1061\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.0759 - val_loss: 4.6162\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.0618 - val_loss: 4.1553\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.8674 - val_loss: 3.8277\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.8787 - val_loss: 4.8859\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.9544 - val_loss: 4.1971\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.4604 - val_loss: 4.0373\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.4729 - val_loss: 2.9318\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.0484 - val_loss: 3.5935\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.5514 - val_loss: 3.9679\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.9043 - val_loss: 3.8163\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.9063 - val_loss: 4.2622\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4472 - val_loss: 3.5457\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2021 - val_loss: 3.7260\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.4003 - val_loss: 3.3155\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1696 - val_loss: 3.1905\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.3211 - val_loss: 2.9807\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.8347 - val_loss: 2.9643\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.4261 - val_loss: 2.8841\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.9058 - val_loss: 3.8033\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.4305 - val_loss: 3.3282\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3405 - val_loss: 3.8566\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.1039 - val_loss: 3.3636\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.1015 - val_loss: 3.2890\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.1405 - val_loss: 2.7773\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8884 - val_loss: 2.6140\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8464 - val_loss: 2.9756\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7495 - val_loss: 2.7261\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0491 - val_loss: 2.7994\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.3260 - val_loss: 4.1684\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2937 - val_loss: 2.5087\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.0153 - val_loss: 2.7572\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.0262 - val_loss: 2.6931\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf964604c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 9 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 63282.5195 - val_loss: 111.7682\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34518.6094 - val_loss: 108.2220\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12976.0918 - val_loss: 111.8783\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 67031.8047 - val_loss: 111.8626\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61245.8750 - val_loss: 106.2792\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 84577.5703 - val_loss: 104.1969\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16254.2695 - val_loss: 105.7841\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5410.7817 - val_loss: 110.7306\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 80468.8281 - val_loss: 111.5179\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 105421.6953 - val_loss: 108.3285\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69949.9141 - val_loss: 104.3205\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13728.5703 - val_loss: 103.8727\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3624.1204 - val_loss: 105.1962\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29161.1543 - val_loss: 106.3894\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7045.0796 - val_loss: 105.0837\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31652.4316 - val_loss: 105.3074\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29810.8418 - val_loss: 102.1496\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16471.9961 - val_loss: 101.7084\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27823.7734 - val_loss: 102.8743\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33668.1367 - val_loss: 105.0429\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31311.6113 - val_loss: 101.9663\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32117.3320 - val_loss: 100.8959\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 65290.0117 - val_loss: 104.0130\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43795.4609 - val_loss: 105.3514\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35562.2148 - val_loss: 102.4045\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 53543.8750 - val_loss: 101.9412\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43637.7344 - val_loss: 103.9951\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 26148.9121 - val_loss: 104.3078\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1057.6086 - val_loss: 104.6439\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19172.0449 - val_loss: 103.6914\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18423.6582 - val_loss: 104.3748\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9429.9238 - val_loss: 104.5286\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12591.2168 - val_loss: 101.5957\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 66737.1641 - val_loss: 100.8045\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50871.9648 - val_loss: 102.1343\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28415.0137 - val_loss: 106.2072\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21232.7324 - val_loss: 107.2999\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 53860.4766 - val_loss: 106.3042\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21228.8379 - val_loss: 103.7830\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23741.5273 - val_loss: 102.9309\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6590.3345 - val_loss: 104.5403\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25923.4277 - val_loss: 105.1101\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 50333.5664 - val_loss: 105.5347\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35884.4336 - val_loss: 105.1834\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5657.0327 - val_loss: 103.3663\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37913.5508 - val_loss: 102.7174\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26430.7910 - val_loss: 104.4204\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15144.5117 - val_loss: 104.4452\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17936.5195 - val_loss: 103.5497\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15447.4131 - val_loss: 102.1066\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf85206af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 10 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 153171.3906 - val_loss: 116.1931\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16267.9092 - val_loss: 111.9704\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41645.3086 - val_loss: 114.3941\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 72803.4375 - val_loss: 115.8933\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38491.7969 - val_loss: 112.7662\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9609.2158 - val_loss: 113.7935\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 104235.9062 - val_loss: 115.9312\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 73683.3516 - val_loss: 114.0539\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 123717.6953 - val_loss: 110.9909\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 148952.3750 - val_loss: 115.9086\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 135149.1719 - val_loss: 116.4981\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55916.9141 - val_loss: 113.8564\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 51306.1758 - val_loss: 111.7999\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35842.9648 - val_loss: 113.0347\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11501.8916 - val_loss: 114.0089\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6882.5693 - val_loss: 113.4690\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18434.1543 - val_loss: 114.7274\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42398.2891 - val_loss: 114.9525\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 64061.6719 - val_loss: 114.8949\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25249.3418 - val_loss: 115.2421\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 105703.6016 - val_loss: 116.3866\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19911.1230 - val_loss: 112.2282\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 123154.6719 - val_loss: 110.6662\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 131033.4453 - val_loss: 113.0636\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34207.3477 - val_loss: 115.7399\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 60756.3164 - val_loss: 115.2775\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 57264.5273 - val_loss: 111.2064\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 124641.1562 - val_loss: 110.0694\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 142648.5000 - val_loss: 111.5751\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 36626.4062 - val_loss: 113.1064\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12114.7842 - val_loss: 115.6646\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 105797.2188 - val_loss: 115.6882\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 105815.7109 - val_loss: 114.0885\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32089.1289 - val_loss: 110.3528\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 143840.7344 - val_loss: 109.0789\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 121705.2891 - val_loss: 109.8331\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69313.2500 - val_loss: 112.9051\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 60829.7422 - val_loss: 114.1207\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 50831.8945 - val_loss: 112.0281\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17818.8438 - val_loss: 112.7700\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53574.0391 - val_loss: 113.6481\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 68352.1328 - val_loss: 112.1156\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40428.0508 - val_loss: 108.8096\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 118372.0547 - val_loss: 109.2542\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45165.4141 - val_loss: 111.3675\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52096.1523 - val_loss: 112.3327\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46580.6992 - val_loss: 109.9039\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 75531.9219 - val_loss: 110.1487\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36740.1523 - val_loss: 111.0315\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30304.0332 - val_loss: 110.4284\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf80fe4940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 11 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 220408.8438 - val_loss: 100.6261\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 59998.1992 - val_loss: 101.6751\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26593.6367 - val_loss: 98.4411\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40874.7773 - val_loss: 97.0449\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 88584.4141 - val_loss: 100.6661\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 96251.3594 - val_loss: 101.8051\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3186.8433 - val_loss: 98.3413\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 127062.8125 - val_loss: 96.3896\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 82731.4609 - val_loss: 98.6803\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12765.4346 - val_loss: 101.6593\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 83609.4375 - val_loss: 100.8313\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 62207.6992 - val_loss: 99.0626\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 70543.5625 - val_loss: 102.1360\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73585.9141 - val_loss: 101.5703\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34300.3438 - val_loss: 100.1935\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10921.8252 - val_loss: 98.8348\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53780.7734 - val_loss: 98.5250\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48361.7539 - val_loss: 102.3597\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 104874.3750 - val_loss: 102.3782\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42117.7695 - val_loss: 101.3926\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35190.2734 - val_loss: 99.8877\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40286.4531 - val_loss: 100.7227\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37506.1133 - val_loss: 101.9241\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7318.3774 - val_loss: 100.1151\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41383.4297 - val_loss: 100.2646\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40870.4258 - val_loss: 100.9768\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21960.1680 - val_loss: 101.3424\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17744.4004 - val_loss: 99.6755\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16178.4443 - val_loss: 99.8384\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4137.1025 - val_loss: 98.6549\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73478.8438 - val_loss: 99.5737\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15686.1221 - val_loss: 100.2688\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49939.2852 - val_loss: 103.6599\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 163479.3438 - val_loss: 103.8555\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 75887.5234 - val_loss: 100.7324\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29019.2637 - val_loss: 99.4386\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38537.5312 - val_loss: 99.9324\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37505.9258 - val_loss: 102.8586\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50967.5000 - val_loss: 102.8877\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31178.3555 - val_loss: 101.9164\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 53329.9336 - val_loss: 103.4607\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49627.3398 - val_loss: 103.5252\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 89083.6328 - val_loss: 102.4409\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43402.1602 - val_loss: 102.2925\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43402.5273 - val_loss: 102.2455\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7705.2681 - val_loss: 100.5783\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 86092.7188 - val_loss: 100.8717\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31966.9512 - val_loss: 102.9507\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27080.8398 - val_loss: 103.3830\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14136.9443 - val_loss: 102.1346\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff06150d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 12 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 157940.6094 - val_loss: 97.2552\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 151412.4375 - val_loss: 107.6058\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 183204.1250 - val_loss: 108.3904\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17299.7637 - val_loss: 102.7809\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 180995.7188 - val_loss: 98.8303\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 143804.3281 - val_loss: 100.9727\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 78320.1016 - val_loss: 108.7734\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 269352.7188 - val_loss: 112.2088\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 197510.1094 - val_loss: 108.1888\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73230.8438 - val_loss: 102.8739\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 176599.2812 - val_loss: 101.5514\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 159714.7031 - val_loss: 103.8266\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22790.5918 - val_loss: 105.6368\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28588.9805 - val_loss: 104.5125\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 59565.1758 - val_loss: 102.9032\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 116458.6875 - val_loss: 103.4396\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19905.1895 - val_loss: 104.4759\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44419.7930 - val_loss: 105.3175\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 69648.6328 - val_loss: 103.6046\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34529.1211 - val_loss: 103.4154\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29770.8613 - val_loss: 103.3292\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4936.4282 - val_loss: 103.9647\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7716.0625 - val_loss: 103.4121\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 63980.8867 - val_loss: 103.5568\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12156.8027 - val_loss: 105.4538\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34217.7305 - val_loss: 104.6978\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 72235.4766 - val_loss: 102.3419\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 121625.2891 - val_loss: 102.7793\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 55449.7383 - val_loss: 104.6926\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13108.2129 - val_loss: 105.0619\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17744.2441 - val_loss: 105.9753\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27036.3672 - val_loss: 104.7443\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 68815.3516 - val_loss: 104.3128\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42625.8320 - val_loss: 106.0116\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 68306.5703 - val_loss: 106.9012\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44806.1680 - val_loss: 106.5166\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20886.0176 - val_loss: 106.8837\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37389.3086 - val_loss: 106.0725\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 67184.2344 - val_loss: 103.9211\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 111524.3828 - val_loss: 103.9407\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73083.9062 - val_loss: 105.8072\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 56852.1445 - val_loss: 106.0130\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21818.0918 - val_loss: 105.5443\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11016.8936 - val_loss: 105.5285\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28222.5781 - val_loss: 105.2161\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20034.3301 - val_loss: 105.8014\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52004.6094 - val_loss: 106.1886\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54171.9375 - val_loss: 104.7109\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16275.4854 - val_loss: 104.0584\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 62802.0273 - val_loss: 104.4742\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5d3b6d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 13 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 128139.2734 - val_loss: 100.5822\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 122987.7500 - val_loss: 104.2736\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 115192.4453 - val_loss: 99.3532\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28719.3496 - val_loss: 92.4456\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 116457.6484 - val_loss: 89.8929\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 85086.5859 - val_loss: 92.8387\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51536.5117 - val_loss: 96.8785\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34137.8867 - val_loss: 97.9422\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22733.6836 - val_loss: 94.6801\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 63324.8828 - val_loss: 93.0809\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34465.3398 - val_loss: 95.9610\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8702.2920 - val_loss: 97.2804\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14805.5908 - val_loss: 95.1625\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30408.5098 - val_loss: 95.5496\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8412.1982 - val_loss: 98.8265\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63449.5742 - val_loss: 100.3794\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40884.0117 - val_loss: 97.6238\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30717.8887 - val_loss: 95.2513\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17849.3691 - val_loss: 95.6142\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14846.8174 - val_loss: 100.9999\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 101242.4375 - val_loss: 102.5636\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 106803.9141 - val_loss: 101.4871\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73021.2578 - val_loss: 97.7191\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10004.2031 - val_loss: 96.5095\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11275.0342 - val_loss: 97.5576\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28746.3750 - val_loss: 97.6132\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2816.1589 - val_loss: 95.4781\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35406.2383 - val_loss: 96.3219\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16958.3047 - val_loss: 98.3495\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52138.6094 - val_loss: 99.3181\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23677.6289 - val_loss: 96.6952\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4085.6479 - val_loss: 95.8353\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17422.1152 - val_loss: 98.2503\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36717.4062 - val_loss: 99.8683\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55994.9258 - val_loss: 97.1341\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1195.2549 - val_loss: 93.8146\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61159.0742 - val_loss: 93.3952\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 96535.3828 - val_loss: 94.9546\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33717.7227 - val_loss: 97.8099\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12995.3486 - val_loss: 98.2706\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7315.2031 - val_loss: 96.4998\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36692.0742 - val_loss: 96.2707\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24161.0176 - val_loss: 98.2384\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2140.2747 - val_loss: 101.5873\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 60784.1562 - val_loss: 101.9928\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 112718.6484 - val_loss: 101.1396\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 83505.0078 - val_loss: 97.5757\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16967.7520 - val_loss: 96.9480\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9255.8877 - val_loss: 95.4186\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45318.3242 - val_loss: 96.1363\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf8625ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 14 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 229387.6094 - val_loss: 71.5623\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 97067.0625 - val_loss: 83.2581\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 53076.4258 - val_loss: 86.6904\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 68651.5234 - val_loss: 85.1694\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 59385.7227 - val_loss: 81.6771\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 79472.2969 - val_loss: 80.6364\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39365.2383 - val_loss: 82.4779\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9769.7734 - val_loss: 87.6618\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 80546.9922 - val_loss: 89.8478\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 111730.7656 - val_loss: 88.4357\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49482.0898 - val_loss: 86.8162\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24049.5273 - val_loss: 85.6313\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31810.6914 - val_loss: 86.6328\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 51551.4609 - val_loss: 86.4834\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8493.2607 - val_loss: 85.6333\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 921.8227 - val_loss: 83.8296\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 101301.9844 - val_loss: 83.0929\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 98377.2812 - val_loss: 86.4642\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11360.5488 - val_loss: 87.4987\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7343.2104 - val_loss: 89.2498\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35034.5117 - val_loss: 88.5558\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19512.0879 - val_loss: 86.0849\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46157.7539 - val_loss: 86.3073\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47295.7227 - val_loss: 87.4523\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30612.4609 - val_loss: 89.4350\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15861.0000 - val_loss: 88.6713\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3378.9597 - val_loss: 86.4640\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46981.1016 - val_loss: 86.2848\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69243.9688 - val_loss: 87.4303\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44011.0742 - val_loss: 91.3547\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 67000.4531 - val_loss: 93.1514\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 57013.9727 - val_loss: 92.2995\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18200.8223 - val_loss: 90.5921\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39704.5312 - val_loss: 89.4213\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10900.9004 - val_loss: 92.5658\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73127.9766 - val_loss: 93.7702\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52560.0547 - val_loss: 90.4275\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10170.6016 - val_loss: 89.8840\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6930.5698 - val_loss: 90.8540\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 236.3053 - val_loss: 94.8993\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 71962.2734 - val_loss: 95.6284\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 118908.1562 - val_loss: 94.5410\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 63059.6992 - val_loss: 92.5977\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1700.3590 - val_loss: 90.3241\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1214.1639 - val_loss: 91.7058\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49478.2305 - val_loss: 92.3684\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28293.9043 - val_loss: 91.0805\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11139.6484 - val_loss: 90.9229\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7545.9951 - val_loss: 89.3309\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17012.8281 - val_loss: 90.0142\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5ebb33a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 15 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 164826.5938 - val_loss: 87.8950\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 335235.7500 - val_loss: 96.3636\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 173867.0312 - val_loss: 104.7328\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 177792.9531 - val_loss: 101.4417\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59055.0117 - val_loss: 95.3394\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 208547.8125 - val_loss: 95.1552\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 118129.7344 - val_loss: 98.2005\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 62168.5859 - val_loss: 103.3625\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 165861.0312 - val_loss: 103.2339\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 108398.3203 - val_loss: 97.6348\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 143261.7656 - val_loss: 97.5784\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 114829.5000 - val_loss: 99.0958\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40457.7812 - val_loss: 102.8423\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 127882.9766 - val_loss: 103.0745\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55959.3945 - val_loss: 99.9038\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6852.5215 - val_loss: 98.8529\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 75356.6016 - val_loss: 100.3925\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18563.9785 - val_loss: 102.5200\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 58391.1250 - val_loss: 101.4862\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 58088.1562 - val_loss: 97.6967\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 103159.8672 - val_loss: 97.6016\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 148564.1094 - val_loss: 99.9536\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8603.0732 - val_loss: 101.6984\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 66323.5469 - val_loss: 101.4898\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33870.7227 - val_loss: 100.4016\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14806.2695 - val_loss: 99.9268\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19076.9688 - val_loss: 101.9276\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40784.6133 - val_loss: 100.1532\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15674.0498 - val_loss: 101.3077\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 69864.8125 - val_loss: 100.7623\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28305.8418 - val_loss: 101.5583\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33907.5117 - val_loss: 101.0882\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51750.3555 - val_loss: 101.0367\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49872.7617 - val_loss: 100.8568\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 84632.4766 - val_loss: 96.9713\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 118248.2656 - val_loss: 97.5518\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20799.1035 - val_loss: 99.7076\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37822.8867 - val_loss: 100.4283\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6607.2637 - val_loss: 101.2080\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 73469.3828 - val_loss: 100.8918\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 68259.9766 - val_loss: 98.2509\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 99159.1406 - val_loss: 98.3057\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 71798.3984 - val_loss: 99.5890\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42036.7812 - val_loss: 101.9382\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 124147.2656 - val_loss: 102.2628\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 66256.5859 - val_loss: 99.1998\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 79419.0312 - val_loss: 98.9493\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50597.5586 - val_loss: 101.0173\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21205.6309 - val_loss: 101.0895\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35803.7305 - val_loss: 100.0274\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf60e5d1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 16 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 68.5954 - val_loss: 48.6944\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48.0386 - val_loss: 27.8243\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37.8085 - val_loss: 38.1458\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31.4238 - val_loss: 38.5592\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28.6939 - val_loss: 23.8974\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23.4208 - val_loss: 12.7492\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22.0454 - val_loss: 17.2109\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.0034 - val_loss: 14.4107\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.2918 - val_loss: 8.9457\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.8245 - val_loss: 8.3358\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.6740 - val_loss: 5.2960\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.5489 - val_loss: 9.2593\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.0746 - val_loss: 2.2173\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.7021 - val_loss: 4.7713\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.7744 - val_loss: 5.0164\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.6204 - val_loss: 4.3779\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.5338 - val_loss: 1.8245\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3065 - val_loss: 2.0055\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.4365 - val_loss: 3.7367\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.7761 - val_loss: 2.6049\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.6662 - val_loss: 4.5200\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.4921 - val_loss: 3.9425\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.2415 - val_loss: 2.4504\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.0664 - val_loss: 2.7752\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.5662 - val_loss: 2.1506\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1085 - val_loss: 7.3446\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.0525 - val_loss: 1.9310\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0891 - val_loss: 4.0713\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.8842 - val_loss: 2.9598\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1226 - val_loss: 2.5534\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.6150 - val_loss: 3.0295\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5713 - val_loss: 1.9131\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.3467 - val_loss: 3.2884\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.5292 - val_loss: 5.3658\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7153 - val_loss: 2.4176\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.1866 - val_loss: 3.0833\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.8590 - val_loss: 2.0508\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6706 - val_loss: 2.8613\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.8073 - val_loss: 3.1135\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4051 - val_loss: 1.8193\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.0739 - val_loss: 4.8974\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8406 - val_loss: 2.7054\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.9145 - val_loss: 3.4393\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.0664 - val_loss: 4.2860\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4048 - val_loss: 1.7418\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 7.8621 - val_loss: 3.2517\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.2524 - val_loss: 1.7878\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.9750 - val_loss: 4.3236\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.9781 - val_loss: 3.3959\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.6508 - val_loss: 1.9173\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf915419d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 17 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 81.3229 - val_loss: 67.7941\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39.5650 - val_loss: 28.9053\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31.3241 - val_loss: 16.2302\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26.0406 - val_loss: 31.4349\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 21.1016 - val_loss: 33.1004\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.0630 - val_loss: 24.0424\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.6868 - val_loss: 16.9947\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.5145 - val_loss: 19.6040\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.7377 - val_loss: 20.1330\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.6728 - val_loss: 13.9572\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.8875 - val_loss: 9.9092\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.7541 - val_loss: 11.5680\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.8225 - val_loss: 3.4357\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.1542 - val_loss: 7.9209\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.9684 - val_loss: 3.9623\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6374 - val_loss: 4.4767\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2940 - val_loss: 4.6911\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.5227 - val_loss: 1.8190\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5057 - val_loss: 4.6293\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.4319 - val_loss: 2.1605\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.4300 - val_loss: 3.7035\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9755 - val_loss: 2.8115\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6104 - val_loss: 7.5818\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.3199 - val_loss: 4.2674\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1451 - val_loss: 8.1075\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.8143 - val_loss: 3.3660\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6514 - val_loss: 3.7410\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4850 - val_loss: 4.0758\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5027 - val_loss: 1.7758\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0176 - val_loss: 6.5700\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0764 - val_loss: 1.9189\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4429 - val_loss: 5.4778\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5056 - val_loss: 1.8047\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1165 - val_loss: 2.1084\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1495 - val_loss: 2.7908\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6311 - val_loss: 2.3172\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9676 - val_loss: 5.2592\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.1468 - val_loss: 2.1037\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9340 - val_loss: 4.1948\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8607 - val_loss: 2.1115\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9045 - val_loss: 2.0864\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7826 - val_loss: 3.1258\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9223 - val_loss: 3.0979\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5220 - val_loss: 2.9033\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0036 - val_loss: 2.3845\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8992 - val_loss: 1.9889\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3042 - val_loss: 1.9187\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9004 - val_loss: 1.7537\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3737 - val_loss: 1.8167\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1016 - val_loss: 2.4324\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf82ed9c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 18 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 6762.6064 - val_loss: 96.3913\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 298881.8125 - val_loss: 93.8878\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 241298.7656 - val_loss: 100.5546\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37560.0391 - val_loss: 105.4737\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 94452.3438 - val_loss: 109.1068\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44813.6211 - val_loss: 106.2034\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 32835.6836 - val_loss: 105.4846\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5514.4395 - val_loss: 104.9199\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44800.7383 - val_loss: 104.4105\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31446.9434 - val_loss: 105.3629\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52455.6719 - val_loss: 107.0106\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31414.5762 - val_loss: 105.5027\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41421.2266 - val_loss: 105.0321\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16688.0078 - val_loss: 106.8633\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 58222.7305 - val_loss: 107.7669\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 54127.1289 - val_loss: 106.2709\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10521.1025 - val_loss: 104.9054\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 60269.7812 - val_loss: 103.3253\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46762.7852 - val_loss: 103.8285\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28950.9043 - val_loss: 105.2793\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23835.5859 - val_loss: 108.5326\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 111598.5156 - val_loss: 109.1026\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 112272.7734 - val_loss: 108.0036\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 111741.8438 - val_loss: 106.0685\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40296.9883 - val_loss: 104.4657\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39501.9102 - val_loss: 104.0817\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49088.2773 - val_loss: 104.8338\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10863.3193 - val_loss: 106.4382\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66712.7031 - val_loss: 107.3825\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16626.5430 - val_loss: 106.0784\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1024.8011 - val_loss: 104.9492\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27801.4043 - val_loss: 104.3331\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 36546.9570 - val_loss: 105.0489\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17497.8359 - val_loss: 106.9674\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49107.6680 - val_loss: 107.2285\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16432.4512 - val_loss: 105.8213\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14672.5771 - val_loss: 104.4009\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39912.7031 - val_loss: 103.6359\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 55485.0859 - val_loss: 104.2079\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27149.9336 - val_loss: 106.1613\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 67273.2266 - val_loss: 106.8808\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54246.0469 - val_loss: 104.9891\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1126.2139 - val_loss: 104.4111\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42870.3008 - val_loss: 105.3835\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2405.5654 - val_loss: 105.1067\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4026.6611 - val_loss: 103.4623\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 72266.8359 - val_loss: 103.1596\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41556.3633 - val_loss: 104.5778\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15897.1230 - val_loss: 105.1719\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25540.5430 - val_loss: 105.6097\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff55a6c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 19 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 106ms/step - loss: 23496.4668 - val_loss: 79.6870\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 171932.2031 - val_loss: 75.5568\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 116649.3281 - val_loss: 82.2083\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7880.3652 - val_loss: 88.1889\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 87063.0000 - val_loss: 92.1784\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 141303.2656 - val_loss: 91.2570\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 87445.4219 - val_loss: 86.9881\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 61108.4062 - val_loss: 85.2155\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 46726.1016 - val_loss: 88.7024\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38730.8867 - val_loss: 90.1890\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36680.5352 - val_loss: 87.9386\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21554.6211 - val_loss: 87.5873\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12896.7402 - val_loss: 86.7202\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22521.1934 - val_loss: 87.8074\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10637.4600 - val_loss: 89.5591\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34135.3633 - val_loss: 90.1799\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42392.8477 - val_loss: 88.6217\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1665.1483 - val_loss: 85.4423\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 99499.9219 - val_loss: 84.1545\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49002.4688 - val_loss: 85.7631\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24524.8223 - val_loss: 90.7132\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 63422.6133 - val_loss: 92.1681\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 68684.4531 - val_loss: 91.5885\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5493.3179 - val_loss: 86.8547\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 106073.4453 - val_loss: 84.5489\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 125784.1484 - val_loss: 86.9984\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 83910.1719 - val_loss: 90.2445\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17819.1055 - val_loss: 90.2346\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4484.8320 - val_loss: 89.0792\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27719.5234 - val_loss: 89.1070\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24474.5469 - val_loss: 90.7033\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5677.9492 - val_loss: 90.5621\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14160.4453 - val_loss: 88.6903\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38736.1562 - val_loss: 88.3782\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51211.7812 - val_loss: 89.7166\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15202.4854 - val_loss: 91.1811\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22849.4395 - val_loss: 90.3248\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25674.7246 - val_loss: 90.9595\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12858.4414 - val_loss: 90.4466\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2173.6223 - val_loss: 87.2534\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49056.6094 - val_loss: 87.1165\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62061.7383 - val_loss: 87.9774\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40382.6133 - val_loss: 91.3899\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3008.8728 - val_loss: 91.9619\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19035.8379 - val_loss: 90.1544\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 829.3301 - val_loss: 87.4633\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 75410.9062 - val_loss: 86.5056\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 98481.2500 - val_loss: 87.6311\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 99018.4219 - val_loss: 91.2748\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43826.8164 - val_loss: 92.6979\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf6ed324c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 20 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 23035.9590 - val_loss: 105.1645\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 158792.8438 - val_loss: 109.6150\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 106968.9766 - val_loss: 103.4308\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22888.3535 - val_loss: 101.4803\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1617.1404 - val_loss: 99.6323\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36207.6016 - val_loss: 100.4190\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7391.4697 - val_loss: 102.4459\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10068.7891 - val_loss: 101.9611\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27109.1191 - val_loss: 98.8249\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45636.4531 - val_loss: 99.2852\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 571.3482 - val_loss: 97.5947\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 97210.3828 - val_loss: 96.9720\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30335.9570 - val_loss: 100.2772\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 60105.5938 - val_loss: 102.3027\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8191.1260 - val_loss: 100.2835\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48292.8125 - val_loss: 100.0821\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2149.1450 - val_loss: 103.1245\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43068.5938 - val_loss: 102.8113\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39647.2617 - val_loss: 100.4185\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27910.8594 - val_loss: 100.8741\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30778.4805 - val_loss: 103.1349\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46047.6211 - val_loss: 102.9238\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11365.6221 - val_loss: 100.7848\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17397.5059 - val_loss: 101.4019\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11288.0908 - val_loss: 103.7077\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 69944.6016 - val_loss: 104.4265\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 54479.9492 - val_loss: 101.7612\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20803.6777 - val_loss: 101.4812\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13932.2695 - val_loss: 101.3833\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3837.4375 - val_loss: 100.8968\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1869.4463 - val_loss: 100.2945\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55444.6758 - val_loss: 98.7311\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 53071.2617 - val_loss: 100.5382\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18693.5352 - val_loss: 102.6108\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49453.6211 - val_loss: 101.7097\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2217.4329 - val_loss: 102.1178\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8696.2676 - val_loss: 100.7901\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15092.6230 - val_loss: 100.9265\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10285.2627 - val_loss: 103.1867\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 79260.7578 - val_loss: 104.1246\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 52027.5586 - val_loss: 101.4800\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19391.2266 - val_loss: 100.2062\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2092.9651 - val_loss: 99.3192\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38751.3008 - val_loss: 98.7645\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33302.5977 - val_loss: 101.5088\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12979.9414 - val_loss: 101.6223\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19823.5723 - val_loss: 100.7855\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9808.9268 - val_loss: 101.2359\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16894.0938 - val_loss: 100.8592\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13300.6670 - val_loss: 101.2738\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7ffdd940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 21 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 101.5777 - val_loss: 86.4541\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 58.9455 - val_loss: 53.4282\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44.9254 - val_loss: 29.4805\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39.5000 - val_loss: 32.1210\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31.2593 - val_loss: 36.5140\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27.9341 - val_loss: 26.4029\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22.5023 - val_loss: 11.4135\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22.5705 - val_loss: 10.3991\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.1444 - val_loss: 13.4094\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.5612 - val_loss: 5.2946\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.6923 - val_loss: 3.7750\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.5362 - val_loss: 9.3484\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.8158 - val_loss: 3.6266\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.2364 - val_loss: 5.9376\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.6778 - val_loss: 3.7070\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.6668 - val_loss: 3.2651\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9667 - val_loss: 3.2498\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5383 - val_loss: 2.5784\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.6705 - val_loss: 5.5626\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.5790 - val_loss: 3.9417\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.2099 - val_loss: 2.9079\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.2498 - val_loss: 4.9078\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2758 - val_loss: 3.7384\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1776 - val_loss: 3.8219\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6603 - val_loss: 4.8142\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5592 - val_loss: 2.5978\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9448 - val_loss: 3.4232\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5636 - val_loss: 2.8696\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.1925 - val_loss: 3.1131\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7867 - val_loss: 2.7252\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.2910 - val_loss: 2.7486\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4682 - val_loss: 2.6466\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.4138 - val_loss: 5.0162\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.8751 - val_loss: 4.1563\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8995 - val_loss: 2.5050\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3227 - val_loss: 4.7413\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.4321 - val_loss: 2.3527\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6950 - val_loss: 2.6577\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.5411 - val_loss: 4.9472\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.2385 - val_loss: 3.5126\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7125 - val_loss: 2.5414\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1977 - val_loss: 3.5688\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5263 - val_loss: 3.0031\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.7441 - val_loss: 2.9600\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.5007 - val_loss: 3.3815\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8165 - val_loss: 3.9745\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.1057 - val_loss: 2.3945\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9030 - val_loss: 3.5843\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4876 - val_loss: 3.2873\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1991 - val_loss: 2.3465\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7fb0e8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 22 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 83203.6250 - val_loss: 93.6312\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 145057.4531 - val_loss: 98.6992\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 87771.0625 - val_loss: 91.3585\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36221.4141 - val_loss: 88.0215\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37450.7383 - val_loss: 91.9396\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36482.4844 - val_loss: 92.5565\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8084.6479 - val_loss: 89.2486\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14191.7842 - val_loss: 86.7166\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59478.7969 - val_loss: 88.4689\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17511.2695 - val_loss: 92.4037\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 76115.0000 - val_loss: 96.2363\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 93343.1250 - val_loss: 95.0674\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 51473.8633 - val_loss: 89.9440\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61751.2617 - val_loss: 88.3406\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 84004.7266 - val_loss: 89.6241\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13273.8340 - val_loss: 94.1143\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 108248.6016 - val_loss: 95.9048\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73124.6250 - val_loss: 93.7250\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 65423.1523 - val_loss: 88.7919\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 86637.2188 - val_loss: 86.6705\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 91173.2734 - val_loss: 87.4559\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 65670.2812 - val_loss: 90.7337\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17553.1094 - val_loss: 92.1000\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12724.1318 - val_loss: 91.9201\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9203.9785 - val_loss: 90.9713\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2367.7881 - val_loss: 89.2962\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 71866.9062 - val_loss: 88.6609\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 65863.6953 - val_loss: 91.2387\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4647.7725 - val_loss: 93.8501\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 63316.1758 - val_loss: 94.7001\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 66991.6875 - val_loss: 93.3272\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23848.4023 - val_loss: 91.5234\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1643.7426 - val_loss: 89.0415\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27008.1582 - val_loss: 87.7706\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 78149.5547 - val_loss: 88.2871\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42145.2617 - val_loss: 90.9364\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19563.8691 - val_loss: 94.2942\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53769.0508 - val_loss: 94.4347\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50174.0312 - val_loss: 93.2495\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15901.6436 - val_loss: 91.8097\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 52081.0820 - val_loss: 90.0745\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25315.2754 - val_loss: 90.9868\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14678.6807 - val_loss: 92.1969\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32531.7539 - val_loss: 93.3147\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37316.7188 - val_loss: 92.3194\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9362.3438 - val_loss: 92.8264\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12813.9688 - val_loss: 92.0652\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3789.3340 - val_loss: 92.7278\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12502.5420 - val_loss: 92.0899\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15314.8916 - val_loss: 92.6688\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf81f14ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 23 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 64.2495 - val_loss: 40.1241\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28.2483 - val_loss: 7.7474\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27.0187 - val_loss: 19.1362\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20.6169 - val_loss: 27.9170\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.2667 - val_loss: 22.0665\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.6802 - val_loss: 12.5483\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.8550 - val_loss: 13.8920\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.0508 - val_loss: 15.1467\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.6108 - val_loss: 8.3613\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.7929 - val_loss: 9.9095\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.5970 - val_loss: 3.8516\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.3410 - val_loss: 7.1756\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9972 - val_loss: 3.3523\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1060 - val_loss: 3.1938\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6114 - val_loss: 3.9004\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8394 - val_loss: 4.3791\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8347 - val_loss: 4.1256\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4142 - val_loss: 1.7077\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4740 - val_loss: 5.1738\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3458 - val_loss: 3.2338\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0971 - val_loss: 4.1993\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1436 - val_loss: 3.7056\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7947 - val_loss: 2.2777\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0521 - val_loss: 3.9482\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2042 - val_loss: 2.5435\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4681 - val_loss: 3.3559\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7076 - val_loss: 1.7765\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6706 - val_loss: 3.9766\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8798 - val_loss: 2.0354\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4285 - val_loss: 4.1692\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5244 - val_loss: 1.9786\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6797 - val_loss: 3.7004\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3528 - val_loss: 1.8811\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0604 - val_loss: 4.1714\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5267 - val_loss: 3.3205\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3733 - val_loss: 1.9184\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8164 - val_loss: 4.3455\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9410 - val_loss: 3.3587\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2029 - val_loss: 6.9436\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.0544 - val_loss: 2.3482\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3954 - val_loss: 3.2536\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7263 - val_loss: 2.7841\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6531 - val_loss: 1.6575\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5629 - val_loss: 4.9360\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3769 - val_loss: 2.6086\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9546 - val_loss: 3.7114\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3130 - val_loss: 1.7497\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4467 - val_loss: 2.0680\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2419 - val_loss: 2.6373\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0150 - val_loss: 1.5066\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5c66aca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 24 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 4937854.0000 - val_loss: 93.4832\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3715198.7500 - val_loss: 92.3708\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3219406.5000 - val_loss: 91.5705\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3005780.5000 - val_loss: 90.5233\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1453307.5000 - val_loss: 89.7632\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 716462.8125 - val_loss: 88.9013\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 557817.1875 - val_loss: 88.1478\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 322109.3125 - val_loss: 87.3049\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 179705.7031 - val_loss: 86.4915\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 142968.3750 - val_loss: 85.5981\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 220253.9531 - val_loss: 84.8680\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 279796.3125 - val_loss: 83.9312\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 256172.6875 - val_loss: 83.1450\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 313205.5000 - val_loss: 82.2285\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 478613.2500 - val_loss: 81.3224\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 450381.7500 - val_loss: 80.4996\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 351509.7500 - val_loss: 79.6751\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 326605.6875 - val_loss: 78.9593\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 200147.3750 - val_loss: 78.2216\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 272080.8125 - val_loss: 77.4569\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 283081.9062 - val_loss: 76.7750\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 237860.0469 - val_loss: 76.1274\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 256956.8750 - val_loss: 75.4003\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 276235.4062 - val_loss: 74.5984\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 226655.9688 - val_loss: 73.7482\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 219197.6094 - val_loss: 72.9571\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 266538.0000 - val_loss: 72.2592\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 144395.4688 - val_loss: 71.5157\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 123691.9062 - val_loss: 70.7722\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 104968.9844 - val_loss: 70.0506\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 125681.8828 - val_loss: 69.3097\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 190972.8750 - val_loss: 68.6050\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 225991.9688 - val_loss: 67.9635\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 269273.7500 - val_loss: 67.1020\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 200446.5469 - val_loss: 66.4376\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 232646.6250 - val_loss: 65.8216\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 132404.6094 - val_loss: 65.1451\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 153732.3906 - val_loss: 64.3927\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 151777.7812 - val_loss: 63.8148\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 249146.1562 - val_loss: 63.1085\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 168625.9844 - val_loss: 62.5854\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 148773.0625 - val_loss: 61.8283\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 278123.6875 - val_loss: 61.2433\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 219342.1094 - val_loss: 60.5949\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 234163.2656 - val_loss: 60.0017\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 267294.2188 - val_loss: 59.3942\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 140711.0156 - val_loss: 58.7065\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 105151.5781 - val_loss: 58.0433\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 129695.6953 - val_loss: 57.5799\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 86869.8984 - val_loss: 56.9228\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf624e4b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 25 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 90060.6875 - val_loss: 76.1836\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29039.3984 - val_loss: 80.8517\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25073.5371 - val_loss: 79.6882\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53563.1367 - val_loss: 78.9499\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2754.9875 - val_loss: 81.7500\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9256.9268 - val_loss: 83.2249\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 50325.7891 - val_loss: 82.6821\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18246.1543 - val_loss: 80.8791\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7473.3208 - val_loss: 80.8977\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17299.3848 - val_loss: 81.8744\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20589.3574 - val_loss: 82.0124\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5637.9810 - val_loss: 79.2691\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 84333.7031 - val_loss: 78.3997\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45746.9141 - val_loss: 82.0368\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34175.3047 - val_loss: 83.7730\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8680.8516 - val_loss: 82.1400\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 57617.8633 - val_loss: 80.9585\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48560.5742 - val_loss: 82.0952\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21153.6016 - val_loss: 84.2873\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3519.0969 - val_loss: 87.7069\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 110767.4609 - val_loss: 88.7066\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 126818.6328 - val_loss: 87.7554\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 84127.3125 - val_loss: 84.7924\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2377.2363 - val_loss: 84.0276\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15532.1279 - val_loss: 83.1080\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27476.2207 - val_loss: 83.1622\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12641.4004 - val_loss: 83.0360\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28955.1582 - val_loss: 83.4886\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22770.3613 - val_loss: 83.6081\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34328.9688 - val_loss: 84.3947\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11425.5342 - val_loss: 84.3775\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15220.1230 - val_loss: 84.0059\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13397.8330 - val_loss: 84.6485\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9771.4072 - val_loss: 83.5381\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18866.7500 - val_loss: 83.5935\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13654.0195 - val_loss: 85.0319\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33756.5859 - val_loss: 85.1620\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7976.9746 - val_loss: 85.1875\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22156.0430 - val_loss: 85.6536\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33612.4375 - val_loss: 84.4647\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17175.8789 - val_loss: 84.8910\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12598.4189 - val_loss: 84.0936\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37190.6211 - val_loss: 83.8030\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31973.9277 - val_loss: 85.3761\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24670.0410 - val_loss: 85.8399\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25061.6562 - val_loss: 84.6121\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41265.9023 - val_loss: 84.4437\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12898.0176 - val_loss: 84.2828\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38052.1875 - val_loss: 84.7823\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8050.7080 - val_loss: 86.0091\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf601cf4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 26 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 50840.9375 - val_loss: 88.2969\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 135838.0469 - val_loss: 88.1520\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 80420.5000 - val_loss: 95.0014\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1144.6169 - val_loss: 102.0476\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 133584.1875 - val_loss: 102.8467\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 108644.8047 - val_loss: 99.8900\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33735.6016 - val_loss: 97.0625\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55373.1641 - val_loss: 94.8613\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8575.1777 - val_loss: 97.9363\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55702.6445 - val_loss: 98.1480\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14353.3916 - val_loss: 95.9512\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 58073.4531 - val_loss: 96.1347\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16213.0342 - val_loss: 97.5745\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40475.2578 - val_loss: 97.8454\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12764.5137 - val_loss: 99.7644\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44537.8906 - val_loss: 99.4180\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10087.2891 - val_loss: 98.3787\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6352.2563 - val_loss: 95.1003\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 83856.0000 - val_loss: 93.7766\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 94028.2188 - val_loss: 95.1326\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 48513.0547 - val_loss: 96.7118\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3204.2793 - val_loss: 99.6679\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69141.3828 - val_loss: 100.7655\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 73386.5469 - val_loss: 99.0315\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23264.4707 - val_loss: 96.6081\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34253.7773 - val_loss: 95.7301\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42991.9570 - val_loss: 97.5156\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 411.4895 - val_loss: 98.0711\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2203.0425 - val_loss: 99.4395\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28553.5723 - val_loss: 99.0122\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41282.9336 - val_loss: 97.5977\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9865.0723 - val_loss: 94.7583\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 95773.1250 - val_loss: 93.6293\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 60468.2109 - val_loss: 95.3595\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47600.0508 - val_loss: 99.1816\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41747.7930 - val_loss: 100.5118\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50336.6680 - val_loss: 99.4790\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16244.4248 - val_loss: 97.9701\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 904.0914 - val_loss: 94.7524\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 78968.7500 - val_loss: 94.3778\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 54517.7383 - val_loss: 95.5357\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50819.9492 - val_loss: 97.7869\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12467.0947 - val_loss: 98.4770\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3429.7798 - val_loss: 98.1790\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5901.8125 - val_loss: 97.9505\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2600.8374 - val_loss: 97.3865\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25753.3301 - val_loss: 97.0908\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24147.0645 - val_loss: 97.7661\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18954.4492 - val_loss: 99.8008\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49983.5938 - val_loss: 100.2449\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf64e23040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 27 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 163434.9688 - val_loss: 86.2994\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 620.0945 - val_loss: 100.6319\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 287220.8438 - val_loss: 104.2965\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 222034.1250 - val_loss: 101.8185\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 113652.5391 - val_loss: 97.4469\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54207.6289 - val_loss: 89.8158\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 96931.7734 - val_loss: 87.0386\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 125294.5000 - val_loss: 89.7560\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47692.5742 - val_loss: 93.1077\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5771.1509 - val_loss: 94.0711\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21694.4766 - val_loss: 90.9956\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 97949.6328 - val_loss: 89.9510\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49407.7734 - val_loss: 93.0017\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23243.6191 - val_loss: 94.3845\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13598.6064 - val_loss: 92.6942\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31598.4766 - val_loss: 93.4664\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12889.4609 - val_loss: 92.8169\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69904.9844 - val_loss: 91.9241\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9360.3242 - val_loss: 92.9285\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29756.8457 - val_loss: 94.3555\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36730.7031 - val_loss: 94.4172\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20691.0898 - val_loss: 92.9369\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30491.1445 - val_loss: 96.7570\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64114.6992 - val_loss: 96.9518\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51837.7148 - val_loss: 95.1215\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11947.1377 - val_loss: 92.5120\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 66102.7656 - val_loss: 90.0638\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 72552.8984 - val_loss: 92.0998\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23332.5566 - val_loss: 94.5932\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57425.6172 - val_loss: 96.2045\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47516.9336 - val_loss: 95.3641\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1396.0233 - val_loss: 93.7457\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5005.5356 - val_loss: 94.8429\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 65086.8945 - val_loss: 95.7630\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28173.0156 - val_loss: 94.5200\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12336.8086 - val_loss: 94.2022\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31668.2656 - val_loss: 92.8344\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35659.7617 - val_loss: 93.5814\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8941.4229 - val_loss: 95.4662\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 36479.9688 - val_loss: 94.9061\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18214.1836 - val_loss: 92.9152\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30768.2246 - val_loss: 93.1007\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23538.9688 - val_loss: 95.2667\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32168.1504 - val_loss: 96.2495\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48042.5312 - val_loss: 93.3587\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 67310.2891 - val_loss: 91.7035\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23889.8008 - val_loss: 93.9960\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21257.8398 - val_loss: 95.2074\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3559.3918 - val_loss: 96.7978\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61938.0117 - val_loss: 96.8628\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf68c0b550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 28 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 56297.1328 - val_loss: 106.8737\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84582.0703 - val_loss: 107.2557\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5485.2334 - val_loss: 103.0192\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16146.2979 - val_loss: 103.8703\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10905.3828 - val_loss: 99.1177\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 107212.3672 - val_loss: 100.5669\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59807.3008 - val_loss: 105.7999\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38793.7734 - val_loss: 106.0694\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30554.9707 - val_loss: 102.5076\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 60169.6172 - val_loss: 102.6250\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11877.6123 - val_loss: 105.3367\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49469.0469 - val_loss: 105.3038\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7505.3306 - val_loss: 102.8013\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18582.6719 - val_loss: 103.5357\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12773.7998 - val_loss: 105.2325\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 127708.4609 - val_loss: 108.8168\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 81738.2266 - val_loss: 104.9496\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15614.9453 - val_loss: 99.4133\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 131735.2031 - val_loss: 97.6521\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 103680.1875 - val_loss: 99.6094\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 86802.0469 - val_loss: 103.1474\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40575.9844 - val_loss: 104.7269\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2604.0371 - val_loss: 102.4117\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33532.8203 - val_loss: 101.7766\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24217.8047 - val_loss: 103.4665\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15753.0693 - val_loss: 106.6346\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 89771.5000 - val_loss: 108.0901\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54025.0938 - val_loss: 105.6182\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6647.3438 - val_loss: 101.7161\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29155.4961 - val_loss: 101.0076\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 48274.2812 - val_loss: 101.9166\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19952.1094 - val_loss: 104.4546\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60385.2500 - val_loss: 105.5738\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 43984.1523 - val_loss: 104.0334\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17249.3711 - val_loss: 102.8199\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22328.7383 - val_loss: 101.7680\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36750.0078 - val_loss: 102.2820\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1618.9412 - val_loss: 103.4378\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50802.5352 - val_loss: 103.8702\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31084.0195 - val_loss: 102.9253\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27876.1484 - val_loss: 101.1762\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3352.6245 - val_loss: 101.4116\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 36204.1016 - val_loss: 100.7296\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23413.1113 - val_loss: 101.6307\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3850.8955 - val_loss: 104.8733\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 77408.4844 - val_loss: 105.6573\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 74144.5312 - val_loss: 105.1444\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43331.2461 - val_loss: 101.6026\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30166.3125 - val_loss: 100.4018\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 29865.3691 - val_loss: 100.9817\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf64e23550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 29 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 7633.1802 - val_loss: 74.5384\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 248954.2031 - val_loss: 77.9064\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 192287.2969 - val_loss: 85.1088\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33259.2578 - val_loss: 90.1735\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4180.3188 - val_loss: 99.5560\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 159472.0625 - val_loss: 101.8273\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 151718.8906 - val_loss: 100.1294\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 100908.7734 - val_loss: 97.1984\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69845.9922 - val_loss: 90.1769\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 84186.8672 - val_loss: 89.3004\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 96447.2891 - val_loss: 91.2964\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24085.6777 - val_loss: 94.3788\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 35116.1250 - val_loss: 96.2513\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23948.1445 - val_loss: 94.9111\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 29747.8789 - val_loss: 93.5765\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13189.5381 - val_loss: 97.6932\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52966.5977 - val_loss: 97.6808\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55506.9727 - val_loss: 95.3344\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10538.5498 - val_loss: 93.2719\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 77870.2500 - val_loss: 90.7009\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72762.0938 - val_loss: 92.3224\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24651.0664 - val_loss: 96.0414\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21925.1562 - val_loss: 96.4753\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53528.3711 - val_loss: 96.2226\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16880.2383 - val_loss: 95.8539\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22803.5625 - val_loss: 95.0857\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2969.0037 - val_loss: 94.9491\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9484.0605 - val_loss: 96.5244\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19844.0801 - val_loss: 96.3921\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11289.1953 - val_loss: 95.2334\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22335.8828 - val_loss: 94.8397\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2940.0833 - val_loss: 95.7586\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 48379.9688 - val_loss: 96.7070\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34596.8242 - val_loss: 94.8621\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28088.4902 - val_loss: 94.9343\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6146.8672 - val_loss: 94.4756\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24994.2031 - val_loss: 94.7284\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15707.7529 - val_loss: 96.6514\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62859.1328 - val_loss: 97.2893\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30305.3691 - val_loss: 96.3991\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15879.6758 - val_loss: 93.3454\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48296.1602 - val_loss: 92.8050\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47050.8164 - val_loss: 93.5837\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30424.6621 - val_loss: 95.4477\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14309.3936 - val_loss: 95.9183\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22061.5879 - val_loss: 95.3040\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6018.2627 - val_loss: 94.5194\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7591.1792 - val_loss: 95.2081\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10568.4434 - val_loss: 95.6942\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40267.9336 - val_loss: 93.6436\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5d3240d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 30 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 187003.7031 - val_loss: 84.8522\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 74085.0391 - val_loss: 98.9465\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41302.0742 - val_loss: 101.4137\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 68290.1094 - val_loss: 99.1091\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17972.5195 - val_loss: 98.8817\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4811.8682 - val_loss: 99.0845\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10690.3135 - val_loss: 101.7566\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30106.8789 - val_loss: 100.9741\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9500.8496 - val_loss: 98.1522\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33772.8867 - val_loss: 97.3352\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27443.1621 - val_loss: 100.8951\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50493.4570 - val_loss: 102.2434\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55160.0234 - val_loss: 99.0081\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41643.9297 - val_loss: 99.0489\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5514.1187 - val_loss: 100.9272\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 65017.4531 - val_loss: 103.4389\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36284.1367 - val_loss: 102.0348\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41374.4688 - val_loss: 101.1248\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17793.7344 - val_loss: 101.0085\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18702.8906 - val_loss: 102.0611\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44068.2812 - val_loss: 101.2509\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4415.5464 - val_loss: 99.2676\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 56684.5977 - val_loss: 98.0257\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59055.1992 - val_loss: 100.5738\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7468.1440 - val_loss: 100.7974\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9243.4189 - val_loss: 102.4132\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29220.3223 - val_loss: 100.9153\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23931.2246 - val_loss: 100.7700\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18864.9160 - val_loss: 100.6568\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1084.2914 - val_loss: 98.3458\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 60526.1055 - val_loss: 98.3941\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17629.2188 - val_loss: 100.1592\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20635.6406 - val_loss: 101.8421\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5917.3408 - val_loss: 102.9938\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57555.2305 - val_loss: 103.9019\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 51203.4375 - val_loss: 101.2775\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5224.1880 - val_loss: 101.7445\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8726.1592 - val_loss: 103.8638\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45668.6992 - val_loss: 103.8403\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61467.8633 - val_loss: 101.5828\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6375.9702 - val_loss: 100.8982\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10873.2471 - val_loss: 102.9501\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61925.7891 - val_loss: 103.1296\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32212.0137 - val_loss: 102.2241\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29886.2598 - val_loss: 97.8188\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 86629.0625 - val_loss: 97.0812\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 86038.6562 - val_loss: 98.4786\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36592.6602 - val_loss: 101.6660\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34952.7148 - val_loss: 102.4420\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2402.3096 - val_loss: 101.3473\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf728924c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 31 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 67.3098 - val_loss: 48.6079\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50.3123 - val_loss: 28.2040\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39.7370 - val_loss: 35.5388\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33.0786 - val_loss: 37.6312\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29.8355 - val_loss: 26.8922\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26.1022 - val_loss: 18.0815\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23.9073 - val_loss: 17.2131\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22.1566 - val_loss: 19.2130\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18.9742 - val_loss: 14.2191\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.2913 - val_loss: 7.8931\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.0271 - val_loss: 6.9268\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.0332 - val_loss: 3.2909\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.0484 - val_loss: 2.4411\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.4576 - val_loss: 2.1513\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.9279 - val_loss: 7.2438\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.6037 - val_loss: 2.9096\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.7557 - val_loss: 3.0750\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.0997 - val_loss: 2.1689\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.0071 - val_loss: 2.7266\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3544 - val_loss: 2.8432\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.9630 - val_loss: 4.7745\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.4368 - val_loss: 2.3971\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.8829 - val_loss: 6.0625\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.4812 - val_loss: 2.4023\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.3710 - val_loss: 2.6328\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2859 - val_loss: 4.6061\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1809 - val_loss: 3.7347\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3519 - val_loss: 4.5156\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3458 - val_loss: 2.8633\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2113 - val_loss: 4.0230\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5385 - val_loss: 3.8509\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7191 - val_loss: 2.9879\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3703 - val_loss: 3.5731\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0975 - val_loss: 3.9906\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2015 - val_loss: 2.8952\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7999 - val_loss: 4.7049\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6513 - val_loss: 3.2743\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6426 - val_loss: 4.2596\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1969 - val_loss: 1.8717\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4271 - val_loss: 1.8990\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6436 - val_loss: 3.9591\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7281 - val_loss: 2.1131\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7105 - val_loss: 4.2008\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8085 - val_loss: 3.9655\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7991 - val_loss: 2.7854\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.6249 - val_loss: 3.1598\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6388 - val_loss: 4.2639\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3703 - val_loss: 2.3718\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.2939 - val_loss: 2.7287\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7508 - val_loss: 3.0901\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9948a4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 32 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 93.7854 - val_loss: 79.1218\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52.8769 - val_loss: 43.7054\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 48.9550 - val_loss: 39.0359\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35.8331 - val_loss: 40.7211\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29.9549 - val_loss: 25.3580\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24.1079 - val_loss: 16.4609\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21.8419 - val_loss: 12.7415\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22.3808 - val_loss: 8.6127\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20.0790 - val_loss: 17.3298\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18.0812 - val_loss: 6.4588\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.5453 - val_loss: 7.2440\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.7480 - val_loss: 8.7000\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.8996 - val_loss: 6.0133\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.0455 - val_loss: 5.7863\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.3951 - val_loss: 3.9505\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.9675 - val_loss: 5.3478\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.0058 - val_loss: 3.2933\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.6365 - val_loss: 6.4104\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.4330 - val_loss: 3.4466\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.4384 - val_loss: 3.3345\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.5150 - val_loss: 3.7666\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.2813 - val_loss: 5.0290\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.5155 - val_loss: 2.5570\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.9688 - val_loss: 7.1276\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.7010 - val_loss: 3.3155\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3806 - val_loss: 3.2590\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.0184 - val_loss: 4.4038\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.2589 - val_loss: 2.5615\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.8487 - val_loss: 2.3911\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9177 - val_loss: 3.0407\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0868 - val_loss: 3.4700\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.6982 - val_loss: 3.3880\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4642 - val_loss: 2.8062\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8338 - val_loss: 3.4310\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.4944 - val_loss: 3.8841\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8993 - val_loss: 2.2619\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.0897 - val_loss: 2.6123\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6104 - val_loss: 2.5075\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6872 - val_loss: 2.6194\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3905 - val_loss: 3.1028\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5621 - val_loss: 2.9273\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1420 - val_loss: 2.7505\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9730 - val_loss: 2.4866\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2999 - val_loss: 2.9146\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.1863 - val_loss: 2.6084\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4083 - val_loss: 4.7208\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6827 - val_loss: 2.3410\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.8497 - val_loss: 3.5761\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.4743 - val_loss: 2.2609\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.0122 - val_loss: 2.8945\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9e105790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 33 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 109ms/step - loss: 71.0810 - val_loss: 53.2306\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31.9569 - val_loss: 16.2581\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30.3142 - val_loss: 20.6830\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23.2853 - val_loss: 27.4341\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.8573 - val_loss: 22.7556\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.0662 - val_loss: 11.7633\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.9674 - val_loss: 11.4274\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.8899 - val_loss: 8.6119\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.0278 - val_loss: 2.3450\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.3900 - val_loss: 4.1042\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.1991 - val_loss: 6.1273\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0908 - val_loss: 3.1317\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.4596 - val_loss: 4.2676\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5954 - val_loss: 2.3217\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6599 - val_loss: 3.6868\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.2622 - val_loss: 4.5230\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9776 - val_loss: 2.4335\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9843 - val_loss: 5.0860\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.5944 - val_loss: 2.5064\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5864 - val_loss: 2.4655\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.1684 - val_loss: 5.7669\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0726 - val_loss: 2.6674\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9115 - val_loss: 6.2816\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.7248 - val_loss: 2.2641\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4552 - val_loss: 3.8278\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2022 - val_loss: 3.4289\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8685 - val_loss: 2.1050\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9117 - val_loss: 4.5841\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4803 - val_loss: 1.8737\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6236 - val_loss: 3.8450\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5645 - val_loss: 1.9300\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8984 - val_loss: 2.6626\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6997 - val_loss: 3.4778\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1516 - val_loss: 2.3134\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8891 - val_loss: 3.3597\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.2710 - val_loss: 2.2466\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0244 - val_loss: 3.3620\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6707 - val_loss: 3.1427\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.1313 - val_loss: 2.5487\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6269 - val_loss: 3.7856\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1547 - val_loss: 1.9625\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.2410 - val_loss: 5.0835\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6519 - val_loss: 3.1311\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7492 - val_loss: 1.6438\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0296 - val_loss: 4.6536\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0371 - val_loss: 1.4998\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2371 - val_loss: 2.4845\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.5598 - val_loss: 2.0120\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4313 - val_loss: 3.3715\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5363 - val_loss: 3.0053\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf79540c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 34 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 305468.6875 - val_loss: 96.3860\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 89161.3594 - val_loss: 106.0235\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 227488.7656 - val_loss: 106.3226\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 96623.7734 - val_loss: 101.8334\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44638.3125 - val_loss: 100.9225\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40213.2852 - val_loss: 102.5042\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39219.4961 - val_loss: 101.7401\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14982.4570 - val_loss: 102.6886\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47034.7578 - val_loss: 101.8829\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17248.7441 - val_loss: 102.0169\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12495.0352 - val_loss: 104.8854\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 98726.3672 - val_loss: 104.2854\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37147.6328 - val_loss: 102.4967\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28977.8320 - val_loss: 104.8411\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53195.0898 - val_loss: 104.5756\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19350.6016 - val_loss: 105.1762\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 74878.3438 - val_loss: 105.8215\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55656.1367 - val_loss: 103.5830\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52145.3867 - val_loss: 103.1111\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37580.6406 - val_loss: 105.3034\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69876.9297 - val_loss: 105.4765\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7544.0532 - val_loss: 105.0492\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29455.0625 - val_loss: 103.8596\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 91872.0391 - val_loss: 103.9525\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 58556.9805 - val_loss: 105.7564\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 58680.7500 - val_loss: 105.7921\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23816.7676 - val_loss: 104.9427\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14586.0439 - val_loss: 102.4935\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 152004.9688 - val_loss: 102.5493\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 114082.7656 - val_loss: 104.6507\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53865.5508 - val_loss: 104.4687\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42747.8320 - val_loss: 103.1840\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 57920.6758 - val_loss: 103.3990\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12928.6523 - val_loss: 104.5589\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53756.8984 - val_loss: 104.0389\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42133.3633 - val_loss: 102.3282\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47262.7617 - val_loss: 102.2144\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41752.8008 - val_loss: 103.4343\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 54502.9297 - val_loss: 104.0705\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29175.6914 - val_loss: 101.2707\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 69104.8438 - val_loss: 101.0175\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 72420.4375 - val_loss: 102.7789\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8452.1211 - val_loss: 104.4896\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 106090.2734 - val_loss: 104.0823\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36987.0117 - val_loss: 102.4399\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4907.0796 - val_loss: 103.4628\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44610.1641 - val_loss: 103.8803\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28416.7930 - val_loss: 103.1787\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11375.2158 - val_loss: 102.0538\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17829.7285 - val_loss: 102.6106\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7960040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 35 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 99.3575 - val_loss: 77.1781\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43.2503 - val_loss: 28.7747\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34.0468 - val_loss: 24.8536\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 24.9431 - val_loss: 35.8944\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23.0412 - val_loss: 32.9998\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.8848 - val_loss: 19.0701\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.6162 - val_loss: 18.5311\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.2405 - val_loss: 22.5785\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.5529 - val_loss: 13.2313\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.8266 - val_loss: 11.5707\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.9948 - val_loss: 7.7491\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.0873 - val_loss: 6.4757\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.2806 - val_loss: 4.8168\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.0867 - val_loss: 5.3166\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.1891 - val_loss: 7.3606\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.1329 - val_loss: 6.3352\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.1880 - val_loss: 6.3112\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9586 - val_loss: 7.0254\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2639 - val_loss: 4.0911\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.4794 - val_loss: 5.3189\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4964 - val_loss: 3.3592\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4867 - val_loss: 6.6863\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6317 - val_loss: 2.2708\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.9234 - val_loss: 5.0235\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.5091 - val_loss: 5.3290\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9294 - val_loss: 2.6172\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7557 - val_loss: 3.7679\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.1837 - val_loss: 4.1180\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4532 - val_loss: 3.5810\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6208 - val_loss: 3.5147\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6758 - val_loss: 2.8397\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9382 - val_loss: 2.6698\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8211 - val_loss: 3.8528\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5667 - val_loss: 2.7638\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3764 - val_loss: 3.3136\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5839 - val_loss: 3.4148\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5762 - val_loss: 2.7147\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.1801 - val_loss: 3.0510\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3926 - val_loss: 3.1331\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4071 - val_loss: 2.7778\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4850 - val_loss: 3.2063\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.8748 - val_loss: 2.1299\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.9590 - val_loss: 2.3528\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6077 - val_loss: 1.9710\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2078 - val_loss: 2.0405\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9134 - val_loss: 2.0565\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2932 - val_loss: 3.9781\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4509 - val_loss: 2.5862\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7198 - val_loss: 5.5635\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8348 - val_loss: 2.9958\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf8669c4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 36 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 77827.0000 - val_loss: 93.8225\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 59002.7617 - val_loss: 90.6204\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10568.1230 - val_loss: 92.1099\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35387.4492 - val_loss: 90.7122\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18455.7734 - val_loss: 91.0978\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26737.2305 - val_loss: 92.5375\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55373.9219 - val_loss: 87.6178\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 87464.6562 - val_loss: 86.6473\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43429.8477 - val_loss: 91.0993\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 523.8495 - val_loss: 97.4587\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 111147.9453 - val_loss: 98.1998\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 102470.5547 - val_loss: 96.0772\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12951.3301 - val_loss: 90.4811\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 88769.3516 - val_loss: 86.5978\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 104251.5156 - val_loss: 89.5003\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14363.8564 - val_loss: 91.2718\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37977.6992 - val_loss: 92.2920\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8093.3848 - val_loss: 95.6532\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56090.6133 - val_loss: 95.8029\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43349.2891 - val_loss: 94.1688\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10872.8203 - val_loss: 92.0750\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 69289.9062 - val_loss: 91.7599\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 59816.8242 - val_loss: 92.6657\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22769.0371 - val_loss: 95.8725\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43195.8281 - val_loss: 97.2243\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 60190.2031 - val_loss: 96.2966\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36518.4688 - val_loss: 93.5792\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7339.9937 - val_loss: 90.1903\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 100183.8516 - val_loss: 90.4062\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 85703.2734 - val_loss: 92.3008\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28847.7598 - val_loss: 93.8706\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26979.3066 - val_loss: 97.9413\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 69822.8125 - val_loss: 99.2557\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 92677.1641 - val_loss: 97.5859\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 65849.7578 - val_loss: 94.9382\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17597.4238 - val_loss: 94.5849\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2638.4351 - val_loss: 94.2974\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38352.8242 - val_loss: 93.8358\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32484.3320 - val_loss: 96.6730\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45064.6680 - val_loss: 97.7012\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 51415.1016 - val_loss: 96.2648\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7977.3267 - val_loss: 94.0367\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61025.1836 - val_loss: 93.9994\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2006.8750 - val_loss: 95.0556\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5666.4385 - val_loss: 95.6975\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40779.5664 - val_loss: 95.3726\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8928.0703 - val_loss: 96.9345\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40749.1797 - val_loss: 97.3237\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 45452.3867 - val_loss: 95.6201\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13813.8633 - val_loss: 95.5368\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf638fb040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 37 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 82.7164 - val_loss: 60.0956\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30.5631 - val_loss: 8.2861\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.1356 - val_loss: 17.5716\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.9800 - val_loss: 31.0378\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.8536 - val_loss: 24.4410\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.6914 - val_loss: 12.2342\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.8721 - val_loss: 13.8152\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.7556 - val_loss: 17.8707\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.2183 - val_loss: 12.6867\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.8621 - val_loss: 6.8708\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9184 - val_loss: 11.3772\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.7769 - val_loss: 2.3603\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3817 - val_loss: 4.9215\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8860 - val_loss: 2.7825\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8504 - val_loss: 4.6175\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.4260 - val_loss: 2.7620\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9984 - val_loss: 4.7421\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0558 - val_loss: 2.2993\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.0594 - val_loss: 6.5673\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3122 - val_loss: 2.3457\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.1927 - val_loss: 4.0970\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.1387 - val_loss: 2.5393\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6427 - val_loss: 5.8862\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1832 - val_loss: 2.6445\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2535 - val_loss: 3.2265\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.2859 - val_loss: 2.4443\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5429 - val_loss: 2.7221\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9571 - val_loss: 2.6215\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8866 - val_loss: 2.2808\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.1236 - val_loss: 2.9330\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5435 - val_loss: 2.2078\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9640 - val_loss: 6.7262\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3530 - val_loss: 2.9907\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6770 - val_loss: 6.6631\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2312 - val_loss: 2.4337\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9439 - val_loss: 4.6303\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2114 - val_loss: 2.3564\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9246 - val_loss: 2.5425\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.1995 - val_loss: 2.4802\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.6075 - val_loss: 2.8724\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8972 - val_loss: 2.4675\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1335 - val_loss: 2.5050\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.9823 - val_loss: 1.9833\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9769 - val_loss: 3.6946\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6633 - val_loss: 1.8824\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6257 - val_loss: 2.4752\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6047 - val_loss: 1.9503\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7296 - val_loss: 2.1000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6740 - val_loss: 1.9006\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5781 - val_loss: 2.3958\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf69976430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 38 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 108.2161 - val_loss: 85.9914\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53.7951 - val_loss: 40.5696\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 48.5919 - val_loss: 30.2704\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37.9177 - val_loss: 38.8827\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34.7563 - val_loss: 43.1392\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.3252 - val_loss: 35.1207\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26.5161 - val_loss: 21.2078\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24.9289 - val_loss: 19.1706\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.8954 - val_loss: 26.3525\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21.7848 - val_loss: 19.8749\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.0181 - val_loss: 10.7766\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.4479 - val_loss: 13.1277\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.8155 - val_loss: 10.0807\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.5564 - val_loss: 3.7205\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.0920 - val_loss: 6.6926\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.1854 - val_loss: 2.3308\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.9710 - val_loss: 4.5544\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3779 - val_loss: 3.7652\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.0876 - val_loss: 2.7571\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.5159 - val_loss: 8.3934\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.7537 - val_loss: 2.2874\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.0510 - val_loss: 5.0633\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.0361 - val_loss: 4.1084\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2484 - val_loss: 3.9579\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.0015 - val_loss: 4.6738\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8786 - val_loss: 3.7751\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3637 - val_loss: 2.7357\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7336 - val_loss: 3.3896\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.0733 - val_loss: 5.2011\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6426 - val_loss: 3.1168\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.9421 - val_loss: 4.2744\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.3646 - val_loss: 4.5294\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9864 - val_loss: 4.6814\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.3968 - val_loss: 3.7065\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7220 - val_loss: 2.8446\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8868 - val_loss: 5.1248\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4853 - val_loss: 4.9137\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8700 - val_loss: 3.7586\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.2206 - val_loss: 3.3556\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3300 - val_loss: 2.9252\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8117 - val_loss: 4.4897\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9052 - val_loss: 5.3145\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2324 - val_loss: 3.5886\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2021 - val_loss: 4.2046\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.5063 - val_loss: 3.1873\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3367 - val_loss: 3.9061\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4530 - val_loss: 5.3918\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2805 - val_loss: 4.3379\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0227 - val_loss: 3.6874\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6580 - val_loss: 3.4049\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4c15e160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 39 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 159932.2969 - val_loss: 115.5813\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 118931.0000 - val_loss: 115.1386\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35845.5391 - val_loss: 112.0147\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36372.7383 - val_loss: 112.7373\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27864.0137 - val_loss: 113.1079\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30631.1406 - val_loss: 111.2046\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34781.2148 - val_loss: 109.7844\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 22859.2715 - val_loss: 107.3526\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46146.4883 - val_loss: 109.3512\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55445.0781 - val_loss: 107.5720\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27045.9531 - val_loss: 105.2981\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31132.0332 - val_loss: 106.4039\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48407.7969 - val_loss: 105.4886\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13356.9795 - val_loss: 104.9840\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41340.0664 - val_loss: 105.6636\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51318.8945 - val_loss: 107.4308\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43491.2969 - val_loss: 104.3972\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 179300.6406 - val_loss: 102.9949\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 125367.8516 - val_loss: 105.7578\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 65432.7031 - val_loss: 109.0068\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 136958.0156 - val_loss: 108.2826\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 89606.8906 - val_loss: 106.1989\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 24500.0586 - val_loss: 102.5202\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 61703.5781 - val_loss: 102.4231\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31094.9512 - val_loss: 103.6441\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33775.5547 - val_loss: 101.5877\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16774.0117 - val_loss: 101.1249\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6616.7349 - val_loss: 100.0574\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17546.0664 - val_loss: 101.4885\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 100231.8281 - val_loss: 101.7536\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 57078.1836 - val_loss: 99.2662\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31602.9434 - val_loss: 98.6959\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10257.7354 - val_loss: 99.1716\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9099.7686 - val_loss: 99.7028\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 76030.1172 - val_loss: 100.5340\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 76696.4688 - val_loss: 98.5383\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32793.3633 - val_loss: 96.2000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69020.6016 - val_loss: 97.9048\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18738.3359 - val_loss: 100.9861\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 154497.6094 - val_loss: 101.2676\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 138297.4062 - val_loss: 99.9122\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37781.6211 - val_loss: 98.7439\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25094.3770 - val_loss: 100.4726\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 37026.0000 - val_loss: 100.1379\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31582.6250 - val_loss: 99.6523\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16965.0059 - val_loss: 101.3619\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34460.6328 - val_loss: 101.9046\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31645.4844 - val_loss: 100.4126\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50136.5156 - val_loss: 100.5583\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22441.2871 - val_loss: 102.3823\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4dce0c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 40 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 89.7286 - val_loss: 76.7983\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 74.7650 - val_loss: 56.4878\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 59.0588 - val_loss: 42.9040\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43.5235 - val_loss: 33.2311\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47.0834 - val_loss: 25.9434\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39.8645 - val_loss: 24.4606\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37.0144 - val_loss: 24.8178\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.7148 - val_loss: 23.1864\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31.5821 - val_loss: 16.7174\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28.7825 - val_loss: 9.0792\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 26.4859 - val_loss: 9.4963\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25.4849 - val_loss: 11.6434\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21.2826 - val_loss: 10.4969\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19.5538 - val_loss: 5.0255\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.0986 - val_loss: 6.7687\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.9400 - val_loss: 3.4745\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.0299 - val_loss: 7.4361\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.2347 - val_loss: 3.8080\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.8258 - val_loss: 5.1895\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.4119 - val_loss: 5.8222\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.0024 - val_loss: 3.7840\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.8451 - val_loss: 2.5150\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.6986 - val_loss: 7.1051\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.9059 - val_loss: 5.9587\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.2135 - val_loss: 2.2936\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.9153 - val_loss: 2.8755\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.1618 - val_loss: 6.7116\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.9723 - val_loss: 5.7391\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.0752 - val_loss: 3.1499\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6033 - val_loss: 4.0556\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.8916 - val_loss: 3.9786\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.1874 - val_loss: 4.7339\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.7517 - val_loss: 3.4742\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.8864 - val_loss: 3.1309\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9666 - val_loss: 7.2690\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2502 - val_loss: 2.3917\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.0274 - val_loss: 3.9527\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1987 - val_loss: 3.0245\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5897 - val_loss: 3.1587\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7520 - val_loss: 4.8839\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3879 - val_loss: 2.4169\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1618 - val_loss: 3.8537\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.1985 - val_loss: 3.7754\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9.2569 - val_loss: 2.4628\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 13.4578 - val_loss: 7.1417\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.5766 - val_loss: 7.2720\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.0477 - val_loss: 2.3683\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9.0620 - val_loss: 2.6950\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 9.6802 - val_loss: 4.8646\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.5826 - val_loss: 5.0504\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf638b34c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 41 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 94869.4141 - val_loss: 82.6498\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 57493.8828 - val_loss: 94.7733\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 206614.6094 - val_loss: 98.6281\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 170486.1875 - val_loss: 96.7283\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 107947.8672 - val_loss: 92.9346\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20531.7715 - val_loss: 90.2127\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31367.6641 - val_loss: 89.8296\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24476.1270 - val_loss: 90.5462\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15933.5381 - val_loss: 90.4605\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29047.0137 - val_loss: 91.3663\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39171.6328 - val_loss: 91.0306\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41770.7070 - val_loss: 89.2768\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55112.3008 - val_loss: 88.8238\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33609.2461 - val_loss: 90.5112\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20353.1074 - val_loss: 91.2445\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9402.7578 - val_loss: 90.1404\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55010.8008 - val_loss: 89.4356\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 30483.8613 - val_loss: 90.7553\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12487.1064 - val_loss: 90.7237\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15008.0381 - val_loss: 90.2451\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21399.1230 - val_loss: 89.4235\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31140.8711 - val_loss: 89.8327\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6693.5527 - val_loss: 92.1639\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41135.8906 - val_loss: 92.7621\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 75168.6016 - val_loss: 91.9324\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40268.8320 - val_loss: 89.5670\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26920.3320 - val_loss: 89.2215\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6334.4673 - val_loss: 88.6060\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 52639.0586 - val_loss: 88.2535\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38060.3945 - val_loss: 89.8636\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27961.3027 - val_loss: 90.8344\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10032.8350 - val_loss: 88.6772\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32318.6680 - val_loss: 88.9942\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36420.4688 - val_loss: 90.5799\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2477.9856 - val_loss: 93.9322\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 141537.4531 - val_loss: 95.5101\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 71236.4609 - val_loss: 92.5189\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8244.8164 - val_loss: 90.9255\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1407.3662 - val_loss: 90.1041\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37905.3633 - val_loss: 90.9186\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16593.2031 - val_loss: 92.7622\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 86352.9453 - val_loss: 93.4240\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17977.2656 - val_loss: 92.0777\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22800.4316 - val_loss: 90.3259\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27848.5684 - val_loss: 90.1430\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75888.0391 - val_loss: 90.6885\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18035.7988 - val_loss: 92.5666\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31242.9531 - val_loss: 92.8919\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2139.4695 - val_loss: 92.2979\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13151.6436 - val_loss: 92.4497\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf6aec1ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 42 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 164651.7812 - val_loss: 101.6776\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 29129.0059 - val_loss: 100.9032\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1673.2985 - val_loss: 94.3797\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 131090.6250 - val_loss: 91.3763\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63436.6562 - val_loss: 95.3173\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 428.9546 - val_loss: 97.9660\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19484.4004 - val_loss: 97.9526\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38350.6641 - val_loss: 96.0843\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35708.7578 - val_loss: 97.6751\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19439.8691 - val_loss: 98.6246\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14378.0771 - val_loss: 95.1948\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43541.2344 - val_loss: 95.4984\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39899.5938 - val_loss: 97.0704\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23005.5020 - val_loss: 101.7447\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 74158.0312 - val_loss: 102.1504\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 68078.9453 - val_loss: 100.9600\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9238.3535 - val_loss: 96.4083\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 70760.5859 - val_loss: 93.6726\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 57539.8867 - val_loss: 95.1453\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25561.0742 - val_loss: 99.0660\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62582.1250 - val_loss: 100.1302\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40764.2500 - val_loss: 97.7410\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7169.6118 - val_loss: 94.0541\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 72886.1016 - val_loss: 92.2552\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 78968.3203 - val_loss: 93.5768\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43331.8242 - val_loss: 97.0728\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17633.3516 - val_loss: 97.8876\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52043.9023 - val_loss: 96.8111\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1498.5752 - val_loss: 94.8141\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43524.8320 - val_loss: 94.8723\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45767.9570 - val_loss: 96.5599\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9141.2002 - val_loss: 98.3319\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52056.2188 - val_loss: 99.4718\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46306.4805 - val_loss: 98.7340\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4603.8838 - val_loss: 97.4235\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12877.0391 - val_loss: 96.4156\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26853.9648 - val_loss: 95.9686\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21616.5156 - val_loss: 97.9024\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19033.0879 - val_loss: 97.4661\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2945.4268 - val_loss: 97.8425\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32454.2070 - val_loss: 97.5832\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9849.4443 - val_loss: 96.3329\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15316.1943 - val_loss: 96.6597\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11614.5918 - val_loss: 97.3034\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 27400.5430 - val_loss: 97.8510\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5237.6157 - val_loss: 96.7188\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12427.8242 - val_loss: 96.6844\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3447.5645 - val_loss: 96.3913\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9762.7158 - val_loss: 97.3469\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 769.8008 - val_loss: 96.3256\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf858d69d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 43 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 81.5700 - val_loss: 62.3421\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.4416 - val_loss: 24.7989\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41.1618 - val_loss: 19.2303\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30.3129 - val_loss: 29.8685\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25.6074 - val_loss: 31.9073\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 24.1603 - val_loss: 21.5697\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22.2902 - val_loss: 8.5221\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18.9041 - val_loss: 14.3232\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.2794 - val_loss: 14.5094\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.0225 - val_loss: 5.5709\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.4728 - val_loss: 6.6403\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.2101 - val_loss: 4.9533\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.0681 - val_loss: 2.9774\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.8504 - val_loss: 3.4930\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.3964 - val_loss: 3.4802\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.4062 - val_loss: 3.3571\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2228 - val_loss: 5.1141\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.2646 - val_loss: 2.1347\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6736 - val_loss: 3.3241\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.8549 - val_loss: 1.9191\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.2166 - val_loss: 4.4426\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9827 - val_loss: 1.8340\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8921 - val_loss: 1.8913\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9372 - val_loss: 2.0457\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9569 - val_loss: 3.2285\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9554 - val_loss: 2.0283\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.1317 - val_loss: 6.8922\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7863 - val_loss: 1.7850\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8617 - val_loss: 2.1545\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8033 - val_loss: 3.4940\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5903 - val_loss: 1.8832\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.9606 - val_loss: 2.6316\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6002 - val_loss: 2.1748\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2771 - val_loss: 3.1342\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.8757 - val_loss: 1.8130\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3040 - val_loss: 2.0147\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8982 - val_loss: 1.6781\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6343 - val_loss: 1.6269\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3023 - val_loss: 2.2926\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3889 - val_loss: 1.9003\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7645 - val_loss: 2.0367\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7205 - val_loss: 3.3899\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1853 - val_loss: 2.1107\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9855 - val_loss: 2.0549\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5371 - val_loss: 1.5194\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7112 - val_loss: 1.4865\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7399 - val_loss: 1.4754\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.8412 - val_loss: 3.2671\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9768 - val_loss: 1.5502\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7625 - val_loss: 1.8116\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf79540ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 44 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 70.0535 - val_loss: 55.0733\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 55.0371 - val_loss: 34.2046\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41.3513 - val_loss: 38.5858\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36.6338 - val_loss: 35.7525\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33.2774 - val_loss: 19.9239\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 27.3963 - val_loss: 21.7678\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26.4584 - val_loss: 16.6142\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 21.9347 - val_loss: 13.6359\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.9785 - val_loss: 6.0671\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.4396 - val_loss: 5.1841\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16.4655 - val_loss: 4.4944\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.7265 - val_loss: 4.5488\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.8635 - val_loss: 6.8753\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.2765 - val_loss: 5.9538\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.9469 - val_loss: 5.3089\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.8707 - val_loss: 6.2709\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.9898 - val_loss: 5.8260\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9734 - val_loss: 8.7729\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4072 - val_loss: 3.5476\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.4247 - val_loss: 7.2988\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7834 - val_loss: 5.6549\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4821 - val_loss: 3.8057\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.8168 - val_loss: 6.2131\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.6628 - val_loss: 6.1186\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.0367 - val_loss: 4.6164\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.1358 - val_loss: 4.5668\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4535 - val_loss: 3.6189\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.4758 - val_loss: 10.0531\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.2620 - val_loss: 4.4636\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.7815 - val_loss: 4.5106\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9647 - val_loss: 7.9836\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4559 - val_loss: 5.1262\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7171 - val_loss: 5.7869\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.2480 - val_loss: 3.7242\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6891 - val_loss: 3.5420\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9194 - val_loss: 5.2341\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.9512 - val_loss: 4.3640\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4617 - val_loss: 4.7566\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5571 - val_loss: 3.5107\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7406 - val_loss: 5.1203\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5850 - val_loss: 5.4608\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3741 - val_loss: 3.7415\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7543 - val_loss: 4.0955\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.0118 - val_loss: 4.3469\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2182 - val_loss: 4.7615\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9258 - val_loss: 5.8998\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3701 - val_loss: 3.7227\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4344 - val_loss: 5.7027\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9341 - val_loss: 5.4029\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8670 - val_loss: 3.9316\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf86e9cb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 45 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 98608.5234 - val_loss: 97.8191\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72130.9375 - val_loss: 98.1727\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 63956.9727 - val_loss: 93.2916\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 64762.7305 - val_loss: 91.8153\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24039.8457 - val_loss: 94.7476\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9333.5439 - val_loss: 95.4237\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8063.6694 - val_loss: 93.9364\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19569.6191 - val_loss: 92.8192\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17039.5820 - val_loss: 96.3586\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31284.3379 - val_loss: 96.2487\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30829.1836 - val_loss: 96.8335\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 81666.3281 - val_loss: 97.1000\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49742.9297 - val_loss: 93.0726\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 49905.4375 - val_loss: 93.3671\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1184.0107 - val_loss: 95.0284\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 44164.3750 - val_loss: 96.0535\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44641.4492 - val_loss: 93.6431\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45418.1562 - val_loss: 92.4456\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19230.3926 - val_loss: 94.2279\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24165.2363 - val_loss: 98.5800\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 91053.2812 - val_loss: 100.1495\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 104516.3047 - val_loss: 98.1259\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 53542.7148 - val_loss: 94.9713\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 40674.1641 - val_loss: 92.3789\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33354.5781 - val_loss: 93.7942\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5313.0806 - val_loss: 95.9594\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47966.9414 - val_loss: 97.0030\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41466.8438 - val_loss: 95.9398\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19315.9434 - val_loss: 94.9209\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4620.9023 - val_loss: 94.3021\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21288.7031 - val_loss: 94.6785\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21507.8828 - val_loss: 95.1802\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6421.4331 - val_loss: 94.8955\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16094.8271 - val_loss: 95.9964\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 26326.5625 - val_loss: 96.9716\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 42224.8867 - val_loss: 95.6975\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1692.1614 - val_loss: 93.2015\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33714.5820 - val_loss: 92.5279\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57460.5273 - val_loss: 93.1860\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7196.6274 - val_loss: 95.5231\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 48788.0430 - val_loss: 97.2151\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44558.2539 - val_loss: 96.8327\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29361.6484 - val_loss: 95.7218\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24306.1602 - val_loss: 94.3414\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13367.7334 - val_loss: 95.5137\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9971.1104 - val_loss: 97.0009\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19230.2793 - val_loss: 97.2753\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 48656.4883 - val_loss: 96.0879\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 24221.1504 - val_loss: 94.0428\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31766.0762 - val_loss: 93.5142\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf8137e160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 46 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 148903.3281 - val_loss: 72.9863\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7226.0854 - val_loss: 87.6474\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 259161.7969 - val_loss: 93.3467\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 204257.8750 - val_loss: 90.7894\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 136947.2500 - val_loss: 87.3897\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13511.1436 - val_loss: 82.5350\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 91847.6328 - val_loss: 82.4228\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 101006.4844 - val_loss: 84.5423\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29631.3789 - val_loss: 87.5372\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66105.1641 - val_loss: 90.3391\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 68171.1719 - val_loss: 88.7780\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17138.4180 - val_loss: 85.9876\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 62534.8945 - val_loss: 85.0487\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37251.6055 - val_loss: 86.2801\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4481.7983 - val_loss: 87.4791\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6805.2646 - val_loss: 86.4810\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18834.2129 - val_loss: 85.5190\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38665.8477 - val_loss: 87.7551\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42881.3008 - val_loss: 88.3109\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10123.0762 - val_loss: 85.1625\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 62638.6836 - val_loss: 84.6148\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49146.3320 - val_loss: 87.4046\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15361.8779 - val_loss: 91.2805\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 143581.5156 - val_loss: 92.9535\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 135288.9688 - val_loss: 91.3453\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 92203.5859 - val_loss: 89.5098\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11763.5908 - val_loss: 87.2628\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 114691.8281 - val_loss: 86.2804\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 81519.6094 - val_loss: 88.4774\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32097.9629 - val_loss: 90.7495\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 62631.0742 - val_loss: 91.4105\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52625.6133 - val_loss: 89.9245\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18496.4258 - val_loss: 90.1286\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28657.9121 - val_loss: 89.4709\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19013.9375 - val_loss: 89.4909\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6021.8198 - val_loss: 88.9876\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23510.6289 - val_loss: 90.0349\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3373.0737 - val_loss: 89.6772\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3398.8555 - val_loss: 90.0300\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 58594.2227 - val_loss: 90.2630\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8321.9092 - val_loss: 89.4740\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26279.2363 - val_loss: 90.8650\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34556.9375 - val_loss: 90.9542\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31410.6641 - val_loss: 90.2328\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22178.7285 - val_loss: 88.9630\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21045.7383 - val_loss: 90.0418\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19904.1191 - val_loss: 90.7508\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18260.4668 - val_loss: 89.6483\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39546.1016 - val_loss: 88.3010\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47206.7656 - val_loss: 89.0898\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5c66a790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 47 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2265\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf82358790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 48 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 108439.3672 - val_loss: 114.7249\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 151050.7969 - val_loss: 113.4942\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 82814.9141 - val_loss: 108.4479\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30469.3691 - val_loss: 98.0987\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 183961.5625 - val_loss: 93.5073\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 115522.8672 - val_loss: 97.3970\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 95624.1641 - val_loss: 104.6933\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10358.5869 - val_loss: 105.7793\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21397.8965 - val_loss: 102.8527\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18522.7305 - val_loss: 103.6041\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34888.2305 - val_loss: 107.9251\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 78863.2266 - val_loss: 108.8218\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83825.0078 - val_loss: 104.9395\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15795.5859 - val_loss: 98.7904\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 196390.8750 - val_loss: 96.4420\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 114425.1562 - val_loss: 99.1791\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 72903.0391 - val_loss: 104.7653\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15766.9131 - val_loss: 106.1512\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45515.9961 - val_loss: 105.4512\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30091.5957 - val_loss: 104.1541\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21734.1875 - val_loss: 99.9927\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 108458.1797 - val_loss: 98.0642\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 107958.0625 - val_loss: 99.5402\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 67186.2891 - val_loss: 102.4605\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4621.8760 - val_loss: 103.3082\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15759.9141 - val_loss: 102.3830\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4690.0605 - val_loss: 100.2497\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87781.6953 - val_loss: 99.4427\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 82197.2266 - val_loss: 100.4488\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 56030.8438 - val_loss: 103.1820\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28080.5371 - val_loss: 103.4135\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17171.4922 - val_loss: 101.6837\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36576.0391 - val_loss: 102.1224\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10687.4424 - val_loss: 103.1062\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32605.0586 - val_loss: 102.8484\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26017.2930 - val_loss: 101.1895\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 46288.0586 - val_loss: 100.9707\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20764.1621 - val_loss: 102.8556\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34490.6992 - val_loss: 103.5699\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31902.0391 - val_loss: 102.6442\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1960.7650 - val_loss: 102.7110\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6132.1367 - val_loss: 102.3567\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31343.4219 - val_loss: 101.5197\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17517.4355 - val_loss: 102.6316\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 2602.5188 - val_loss: 104.7249\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 71029.1016 - val_loss: 105.1595\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66184.3906 - val_loss: 103.7538\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 58776.7383 - val_loss: 101.3987\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17809.2969 - val_loss: 101.3835\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20791.6387 - val_loss: 102.7384\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf64e239d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 49 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 77.4304 - val_loss: 62.9066\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 46.6550 - val_loss: 33.8198\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41.0985 - val_loss: 30.9862\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31.8087 - val_loss: 31.5638\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26.3273 - val_loss: 22.5059\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21.3339 - val_loss: 12.0555\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.4583 - val_loss: 6.0395\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.1438 - val_loss: 3.4356\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.4607 - val_loss: 5.9515\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.6226 - val_loss: 6.6240\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.0469 - val_loss: 5.5726\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.8455 - val_loss: 1.9787\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.5601 - val_loss: 6.4348\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.7242 - val_loss: 2.2647\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.7285 - val_loss: 3.1047\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.2154 - val_loss: 2.1547\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.2316 - val_loss: 3.1778\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.9474 - val_loss: 4.3525\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3417 - val_loss: 3.1738\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8005 - val_loss: 3.5681\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.1997 - val_loss: 2.8100\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.4364 - val_loss: 3.4152\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9552 - val_loss: 2.6580\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3522 - val_loss: 5.3530\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4412 - val_loss: 3.1360\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1469 - val_loss: 5.2599\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3963 - val_loss: 2.7005\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8152 - val_loss: 3.0070\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8417 - val_loss: 2.8716\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.5819 - val_loss: 4.8030\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3764 - val_loss: 3.6909\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5752 - val_loss: 3.7034\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5355 - val_loss: 3.3754\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0483 - val_loss: 4.3886\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0581 - val_loss: 2.7601\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2421 - val_loss: 5.7865\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.0527 - val_loss: 2.9119\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6671 - val_loss: 4.4959\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1843 - val_loss: 2.6880\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1458 - val_loss: 4.8497\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.0166 - val_loss: 3.0244\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.2552 - val_loss: 5.4513\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6889 - val_loss: 2.9686\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3011 - val_loss: 4.5761\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.7378 - val_loss: 3.2202\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3607 - val_loss: 2.6441\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9378 - val_loss: 6.6681\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7970 - val_loss: 2.9036\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5241 - val_loss: 4.4227\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8436 - val_loss: 3.1711\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5c6be670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 50 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 70.5259 - val_loss: 50.8807\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35.0051 - val_loss: 20.1982\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29.9444 - val_loss: 26.0246\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23.6636 - val_loss: 23.4674\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.2814 - val_loss: 11.2797\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.1612 - val_loss: 12.5422\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.3971 - val_loss: 4.8341\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.8698 - val_loss: 3.9945\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.0936 - val_loss: 5.2709\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.4620 - val_loss: 8.3622\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.9470 - val_loss: 5.4825\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6096 - val_loss: 5.8988\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.8113 - val_loss: 5.6998\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.1922 - val_loss: 5.1673\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.1418 - val_loss: 3.7341\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.2144 - val_loss: 7.6945\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.0504 - val_loss: 3.9251\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2669 - val_loss: 5.9728\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0944 - val_loss: 6.6776\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3429 - val_loss: 3.3750\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3961 - val_loss: 9.7042\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3275 - val_loss: 3.4964\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6842 - val_loss: 4.8696\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8354 - val_loss: 3.4268\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7058 - val_loss: 5.1834\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3100 - val_loss: 3.4806\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3024 - val_loss: 5.3995\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4841 - val_loss: 4.6729\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.5486 - val_loss: 4.9770\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0392 - val_loss: 3.2765\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9045 - val_loss: 3.5537\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7065 - val_loss: 5.5791\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9598 - val_loss: 3.2676\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.5911 - val_loss: 6.2551\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5117 - val_loss: 3.3483\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9229 - val_loss: 4.6173\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1020 - val_loss: 3.9497\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8269 - val_loss: 4.7683\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3042 - val_loss: 4.0649\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4370 - val_loss: 3.6119\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7349 - val_loss: 3.5699\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9573 - val_loss: 4.3027\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9971 - val_loss: 3.2277\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6393 - val_loss: 3.7593\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4335 - val_loss: 3.5350\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2286 - val_loss: 5.2022\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4095 - val_loss: 4.9362\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.6535 - val_loss: 3.6632\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6570 - val_loss: 3.1449\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7612 - val_loss: 3.4833\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5200d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 51 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 593660.7500 - val_loss: 90.6411\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 226550.0000 - val_loss: 104.4970\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 75056.6797 - val_loss: 106.9413\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 68901.7891 - val_loss: 101.6737\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 48779.1875 - val_loss: 101.0232\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 76262.3594 - val_loss: 99.9425\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31901.2988 - val_loss: 99.8417\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35817.7812 - val_loss: 105.6582\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 172344.2031 - val_loss: 108.3901\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 350559.1875 - val_loss: 105.8167\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 148330.2969 - val_loss: 100.4950\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38653.9961 - val_loss: 98.5687\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 119364.0234 - val_loss: 102.6267\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 59990.0664 - val_loss: 103.3680\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6583.4883 - val_loss: 104.1122\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 99932.5078 - val_loss: 103.4327\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21831.9121 - val_loss: 98.9720\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 207979.3906 - val_loss: 97.4678\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 113039.0000 - val_loss: 99.6935\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42478.1875 - val_loss: 104.8325\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 37891.6211 - val_loss: 110.1562\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 283799.0625 - val_loss: 111.4424\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 279472.5938 - val_loss: 110.2327\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 327077.2500 - val_loss: 105.7734\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 61948.1445 - val_loss: 102.0894\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39033.6680 - val_loss: 96.1644\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 204076.3750 - val_loss: 94.4169\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 235549.1875 - val_loss: 96.5547\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 177991.7969 - val_loss: 100.1755\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54955.7383 - val_loss: 104.4490\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 52354.9727 - val_loss: 106.3092\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13805.6875 - val_loss: 106.0376\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 121055.5234 - val_loss: 105.6209\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 114267.0625 - val_loss: 103.9255\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 81202.4766 - val_loss: 100.8984\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51124.2383 - val_loss: 99.1284\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 136077.6406 - val_loss: 100.8274\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29456.0371 - val_loss: 102.2262\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6678.0957 - val_loss: 100.9230\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 74063.4297 - val_loss: 101.9263\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5482.8071 - val_loss: 101.9175\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49406.4375 - val_loss: 101.6941\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55876.5078 - val_loss: 103.8256\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 38144.9062 - val_loss: 103.7799\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5834.7607 - val_loss: 104.5201\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 131082.3125 - val_loss: 103.8778\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19613.0508 - val_loss: 101.1670\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20644.7988 - val_loss: 100.5432\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 71421.5391 - val_loss: 102.6952\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39706.8750 - val_loss: 102.9599\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf53297e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 52 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 47713.8594 - val_loss: 105.5728\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 91228.9688 - val_loss: 108.0748\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 68822.3672 - val_loss: 105.3624\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24967.8477 - val_loss: 97.9667\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 147263.3281 - val_loss: 96.1187\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 119681.7344 - val_loss: 98.8414\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18874.1074 - val_loss: 102.5146\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36389.4961 - val_loss: 106.1263\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45742.5469 - val_loss: 103.7002\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5203.8262 - val_loss: 100.0838\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 73291.2891 - val_loss: 100.1161\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56375.8828 - val_loss: 100.9446\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 70124.5234 - val_loss: 106.0697\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 110552.5156 - val_loss: 107.7691\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 95405.6406 - val_loss: 105.1084\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28969.7109 - val_loss: 101.9070\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 64429.4258 - val_loss: 101.0625\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 58176.5273 - val_loss: 103.4197\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15757.3945 - val_loss: 103.1312\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 26169.3242 - val_loss: 103.9140\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4266.4927 - val_loss: 104.1169\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23928.2598 - val_loss: 101.8898\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56139.8477 - val_loss: 101.1110\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49290.6680 - val_loss: 102.8534\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 32218.0332 - val_loss: 103.9049\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11537.8203 - val_loss: 103.6877\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37198.4688 - val_loss: 102.8370\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7436.9028 - val_loss: 103.2453\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15814.7578 - val_loss: 103.5630\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19898.5820 - val_loss: 100.5394\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47389.3633 - val_loss: 100.4402\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 55712.5508 - val_loss: 102.1115\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19217.9531 - val_loss: 103.9779\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 42743.1367 - val_loss: 104.7259\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30091.4336 - val_loss: 103.5979\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1283.6066 - val_loss: 103.7717\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19751.1035 - val_loss: 102.3157\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19986.7500 - val_loss: 103.2150\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21720.1094 - val_loss: 102.3573\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6535.4297 - val_loss: 103.2599\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 639.4102 - val_loss: 102.6935\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1715.5713 - val_loss: 103.4388\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45889.2695 - val_loss: 103.1005\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9726.8994 - val_loss: 100.6550\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55785.2500 - val_loss: 100.6670\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 59537.6914 - val_loss: 101.3564\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31226.1348 - val_loss: 103.5509\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25890.1094 - val_loss: 104.6126\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 19351.3691 - val_loss: 103.0312\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 41751.4531 - val_loss: 102.3393\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5221a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 53 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 56.1083 - val_loss: 34.8352\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27.3041 - val_loss: 3.8193\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22.0628 - val_loss: 18.9460\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.0572 - val_loss: 26.4804\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.6194 - val_loss: 20.0738\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.3869 - val_loss: 8.9881\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.1525 - val_loss: 7.8133\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.3629 - val_loss: 14.9642\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.9961 - val_loss: 9.4965\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9985 - val_loss: 3.7387\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.8891 - val_loss: 8.1030\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0726 - val_loss: 4.9928\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5731 - val_loss: 2.7568\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6766 - val_loss: 6.5730\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.9353 - val_loss: 2.8675\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8903 - val_loss: 4.1248\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4083 - val_loss: 3.1495\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.3984 - val_loss: 2.4246\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0005 - val_loss: 3.4253\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.4078 - val_loss: 2.5083\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1570 - val_loss: 3.6592\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6505 - val_loss: 2.4272\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5293 - val_loss: 2.4624\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0880 - val_loss: 3.6688\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0957 - val_loss: 2.5838\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.1092 - val_loss: 3.7805\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.5169 - val_loss: 2.5903\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3483 - val_loss: 4.8107\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8265 - val_loss: 2.6324\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.4915 - val_loss: 2.2301\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.3397 - val_loss: 3.8723\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.2295 - val_loss: 2.2809\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.1046 - val_loss: 3.1633\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.3864 - val_loss: 2.5965\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4440 - val_loss: 2.3998\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3443 - val_loss: 4.7495\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5280 - val_loss: 3.2121\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2656 - val_loss: 5.2423\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4344 - val_loss: 2.6507\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7886 - val_loss: 2.6122\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2220 - val_loss: 2.4899\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.8919 - val_loss: 2.2226\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.1910 - val_loss: 2.4581\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9280 - val_loss: 2.1071\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.4781 - val_loss: 2.9866\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.4677 - val_loss: 3.0138\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.8845 - val_loss: 2.1721\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.1524 - val_loss: 3.0256\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.8495 - val_loss: 2.3011\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5848 - val_loss: 3.1318\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf68c0b790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 54 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 217731.3750 - val_loss: 103.5359\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42229.2695 - val_loss: 103.4044\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6054.5376 - val_loss: 101.7238\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23540.2969 - val_loss: 101.8052\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 138755.4062 - val_loss: 104.9910\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 120610.9219 - val_loss: 100.9003\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 45421.8867 - val_loss: 100.1117\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 26511.1934 - val_loss: 100.8651\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14722.4326 - val_loss: 101.9090\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47573.0469 - val_loss: 102.4848\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30806.7871 - val_loss: 100.2533\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 58046.8867 - val_loss: 99.8480\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62985.0195 - val_loss: 101.2646\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44067.0898 - val_loss: 101.5707\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20713.2969 - val_loss: 100.6130\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19664.3086 - val_loss: 102.0508\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40156.3867 - val_loss: 101.3517\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 40081.0195 - val_loss: 99.8965\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39688.0781 - val_loss: 101.1737\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25096.1348 - val_loss: 101.1742\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29109.8066 - val_loss: 99.4062\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 74812.1484 - val_loss: 98.5460\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44098.9258 - val_loss: 98.2779\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 83767.7578 - val_loss: 100.4432\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28168.4082 - val_loss: 102.5173\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 87074.9609 - val_loss: 102.1388\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69449.5625 - val_loss: 100.3198\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43026.2344 - val_loss: 99.9569\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30611.5820 - val_loss: 100.1592\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21580.2207 - val_loss: 101.7289\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 64357.2227 - val_loss: 101.6479\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 59050.2891 - val_loss: 99.2569\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 62498.0664 - val_loss: 98.6057\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41737.6523 - val_loss: 100.0428\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7066.0938 - val_loss: 100.7659\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18127.4219 - val_loss: 101.0422\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22449.1270 - val_loss: 99.8207\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 50988.6719 - val_loss: 99.3409\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34406.1797 - val_loss: 100.4834\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 66742.7656 - val_loss: 101.0812\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27135.7129 - val_loss: 100.2461\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34738.5938 - val_loss: 100.2708\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13373.7129 - val_loss: 100.9115\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26545.7617 - val_loss: 101.3224\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7153.1646 - val_loss: 101.7010\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53598.2812 - val_loss: 101.5324\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18036.5195 - val_loss: 100.8843\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40767.4805 - val_loss: 99.7506\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 55129.4922 - val_loss: 101.3536\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31590.5879 - val_loss: 101.4448\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf72c78280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 55 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 31371.8223 - val_loss: 83.1030\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 44482.1602 - val_loss: 81.1903\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 53577.9492 - val_loss: 86.0143\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39039.5742 - val_loss: 86.8619\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 926.9773 - val_loss: 83.9408\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 72211.4844 - val_loss: 82.8093\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 43933.1758 - val_loss: 86.7885\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31410.3281 - val_loss: 88.3734\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2393.8525 - val_loss: 89.3021\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 67106.7188 - val_loss: 89.5225\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11804.3281 - val_loss: 87.2360\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31976.0664 - val_loss: 88.3327\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22703.2871 - val_loss: 82.5497\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 113012.1953 - val_loss: 82.2830\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 102537.5547 - val_loss: 84.3460\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48451.1406 - val_loss: 88.6934\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49314.8594 - val_loss: 91.3261\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45818.1367 - val_loss: 90.9070\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19685.7031 - val_loss: 88.3435\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64820.9922 - val_loss: 86.8616\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 47342.4727 - val_loss: 88.4701\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1799.5654 - val_loss: 91.5025\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29474.5781 - val_loss: 93.2029\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54988.3281 - val_loss: 93.4744\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38870.3867 - val_loss: 89.9730\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29337.0488 - val_loss: 89.1405\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9482.7539 - val_loss: 89.6499\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 49137.5391 - val_loss: 93.3096\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 74920.8203 - val_loss: 94.7963\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 76325.4688 - val_loss: 92.0312\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3549.1633 - val_loss: 91.4901\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12815.2686 - val_loss: 90.5968\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40536.6172 - val_loss: 87.6438\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 67916.4688 - val_loss: 88.2907\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 52490.2461 - val_loss: 89.2983\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24841.1504 - val_loss: 93.1752\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 84512.5469 - val_loss: 95.2071\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 89931.9609 - val_loss: 94.1471\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53588.1289 - val_loss: 91.8538\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35434.8125 - val_loss: 90.8923\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30873.6387 - val_loss: 91.9901\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2789.1296 - val_loss: 95.0473\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 53357.1836 - val_loss: 96.2650\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 72363.8828 - val_loss: 95.5955\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56668.8750 - val_loss: 92.9472\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33660.1875 - val_loss: 91.9578\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29201.8711 - val_loss: 94.3261\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52973.2812 - val_loss: 94.6407\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46127.2383 - val_loss: 93.0707\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4899.6011 - val_loss: 91.0007\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7630b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 56 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 13638.4346 - val_loss: 111.2418\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 283930.0000 - val_loss: 113.2890\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 172721.5938 - val_loss: 108.4485\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 104752.6250 - val_loss: 100.0725\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34548.3594 - val_loss: 97.2028\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 75049.3281 - val_loss: 97.9661\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12773.8955 - val_loss: 100.8164\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51054.4844 - val_loss: 102.1151\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43396.7930 - val_loss: 100.8043\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3608.6160 - val_loss: 101.1769\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19449.3203 - val_loss: 99.9595\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9810.3984 - val_loss: 100.9644\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14525.8418 - val_loss: 99.7223\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37046.4219 - val_loss: 99.3522\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17314.6387 - val_loss: 100.7652\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17331.3711 - val_loss: 100.6172\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11017.2529 - val_loss: 99.8187\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29579.2871 - val_loss: 99.7170\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14890.7617 - val_loss: 99.4150\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61259.9883 - val_loss: 98.7211\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13562.9404 - val_loss: 101.6189\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 59641.8008 - val_loss: 103.0223\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41830.5703 - val_loss: 102.1979\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1564.1819 - val_loss: 99.0448\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 70222.5469 - val_loss: 97.5852\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 51749.9648 - val_loss: 98.7033\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42557.8242 - val_loss: 101.4305\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28688.6152 - val_loss: 102.8031\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13905.5986 - val_loss: 100.3236\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5767.2461 - val_loss: 97.5796\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 67477.3125 - val_loss: 97.1359\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 79394.1406 - val_loss: 98.1517\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19442.7871 - val_loss: 101.2084\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1647.5164 - val_loss: 101.2059\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 137.3728 - val_loss: 102.0375\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43490.4727 - val_loss: 102.1086\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7537.2124 - val_loss: 100.7685\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23647.7402 - val_loss: 99.3548\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11421.1484 - val_loss: 100.6030\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30413.6582 - val_loss: 100.7113\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20655.8789 - val_loss: 100.6296\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48354.1484 - val_loss: 101.6879\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16759.6426 - val_loss: 101.1847\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28530.3086 - val_loss: 101.3776\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9645.3252 - val_loss: 99.6642\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24419.2031 - val_loss: 98.5190\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33780.6602 - val_loss: 100.2983\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16368.5547 - val_loss: 101.0478\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29800.4961 - val_loss: 99.8225\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29566.3125 - val_loss: 99.0284\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf86e9c430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 57 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 92.8658 - val_loss: 76.9993\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.9728 - val_loss: 31.2897\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34.5912 - val_loss: 24.2410\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25.6851 - val_loss: 29.8936\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23.8054 - val_loss: 29.8495\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.3096 - val_loss: 19.3726\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 18.4884 - val_loss: 14.7144\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.2648 - val_loss: 15.4524\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.0868 - val_loss: 9.8500\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.6278 - val_loss: 4.4068\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5359 - val_loss: 6.5729\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0916 - val_loss: 4.1163\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8872 - val_loss: 6.6559\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.8024 - val_loss: 5.8039\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2281 - val_loss: 4.3815\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.0309 - val_loss: 5.1178\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5821 - val_loss: 4.0428\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9205 - val_loss: 6.2262\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.6329 - val_loss: 4.0214\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9614 - val_loss: 9.1002\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.6500 - val_loss: 3.9229\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9991 - val_loss: 4.6482\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5522 - val_loss: 4.2958\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4122 - val_loss: 4.6784\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7832 - val_loss: 5.3292\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0232 - val_loss: 5.7810\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1293 - val_loss: 4.6271\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8508 - val_loss: 4.0021\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5865 - val_loss: 6.4919\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8253 - val_loss: 3.9068\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9249 - val_loss: 6.7745\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6305 - val_loss: 4.1746\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2522 - val_loss: 5.8079\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8184 - val_loss: 5.2313\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8025 - val_loss: 3.7285\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1131 - val_loss: 5.7695\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.9491 - val_loss: 4.4651\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7668 - val_loss: 4.2530\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3798 - val_loss: 6.1562\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5171 - val_loss: 3.8238\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9141 - val_loss: 5.4329\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9285 - val_loss: 5.4490\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.6301 - val_loss: 5.0040\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.5212 - val_loss: 4.8263\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7580 - val_loss: 3.5364\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4969 - val_loss: 5.8792\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3905 - val_loss: 3.6056\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8449 - val_loss: 5.0324\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4669 - val_loss: 4.0021\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9789 - val_loss: 5.3599\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7eae7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 58 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 4957045.0000 - val_loss: 97.5343\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4168098.0000 - val_loss: 96.4602\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3604308.2500 - val_loss: 95.6749\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1599785.2500 - val_loss: 94.9138\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 904490.6250 - val_loss: 94.2576\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 628543.3125 - val_loss: 93.5285\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 366323.6250 - val_loss: 92.7828\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 336592.5312 - val_loss: 92.1709\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 246623.3750 - val_loss: 91.5181\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 182233.8750 - val_loss: 90.8876\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 272030.3750 - val_loss: 90.2842\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 205865.5625 - val_loss: 89.7246\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 236694.3750 - val_loss: 89.0260\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 271604.6562 - val_loss: 88.3464\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 190640.9531 - val_loss: 87.7331\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 291807.6250 - val_loss: 87.0774\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 220802.6875 - val_loss: 86.4312\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 164644.5469 - val_loss: 85.8262\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 246811.8906 - val_loss: 85.2322\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 335622.4375 - val_loss: 84.5401\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 208034.4062 - val_loss: 83.9447\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 316204.9062 - val_loss: 83.4200\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 576126.6875 - val_loss: 82.7823\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 247290.1250 - val_loss: 82.2154\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 130366.5391 - val_loss: 81.6697\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 130667.4844 - val_loss: 81.0620\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 112512.3672 - val_loss: 80.4574\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 130242.0156 - val_loss: 79.9353\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 188726.1250 - val_loss: 79.3674\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 236099.0000 - val_loss: 78.8656\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 163103.9375 - val_loss: 78.3569\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 173774.7812 - val_loss: 77.7804\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 277018.3750 - val_loss: 77.1572\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 204213.2031 - val_loss: 76.6314\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 271519.5625 - val_loss: 76.1105\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 198745.0000 - val_loss: 75.6139\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 273591.4375 - val_loss: 75.1324\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 229039.6875 - val_loss: 74.6552\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 208725.8125 - val_loss: 74.1531\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 122605.5391 - val_loss: 73.6408\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 106250.3672 - val_loss: 73.0938\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 278135.7500 - val_loss: 72.5432\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 219190.5312 - val_loss: 72.0753\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 235724.4531 - val_loss: 71.6030\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 122447.9062 - val_loss: 71.0945\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 125458.8438 - val_loss: 70.6239\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 172068.1250 - val_loss: 70.1308\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 235145.2656 - val_loss: 69.6553\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 262399.1562 - val_loss: 69.2318\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 270553.5312 - val_loss: 68.7483\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7b6e4820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 59 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 71.1433 - val_loss: 52.9288\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31.7905 - val_loss: 9.8914\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33.8154 - val_loss: 19.3029\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24.9851 - val_loss: 32.5254\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24.1284 - val_loss: 29.6961\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.4840 - val_loss: 18.4685\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19.8307 - val_loss: 14.0846\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.9085 - val_loss: 16.3587\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.0213 - val_loss: 16.8614\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.4157 - val_loss: 10.4062\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.4218 - val_loss: 6.3269\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.4119 - val_loss: 6.1752\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.0312 - val_loss: 3.9431\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.8367 - val_loss: 9.8034\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.0091 - val_loss: 3.2740\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.4061 - val_loss: 6.8973\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.6054 - val_loss: 7.2302\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8112 - val_loss: 4.0633\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.2072 - val_loss: 5.4939\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.3813 - val_loss: 3.8807\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1375 - val_loss: 4.6525\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7665 - val_loss: 5.4688\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.0551 - val_loss: 4.3080\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3646 - val_loss: 5.9825\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7322 - val_loss: 5.4778\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.3983 - val_loss: 5.2258\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3782 - val_loss: 3.0926\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.1609 - val_loss: 7.8013\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.8357 - val_loss: 2.0673\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2366 - val_loss: 4.7760\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3371 - val_loss: 2.9426\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8896 - val_loss: 2.4764\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9751 - val_loss: 4.3465\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9505 - val_loss: 3.1960\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2461 - val_loss: 4.9290\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8977 - val_loss: 3.3494\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7980 - val_loss: 5.1844\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9963 - val_loss: 3.8346\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4272 - val_loss: 2.9367\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4191 - val_loss: 4.9157\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5296 - val_loss: 2.8444\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1211 - val_loss: 5.2818\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0214 - val_loss: 3.9058\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8261 - val_loss: 3.5224\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.3163 - val_loss: 5.0381\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8973 - val_loss: 2.6797\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0650 - val_loss: 5.3261\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3840 - val_loss: 2.1686\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.7516 - val_loss: 4.7616\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6367 - val_loss: 2.9292\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf6b25b430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 60 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 69.8220 - val_loss: 46.9534\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36.7210 - val_loss: 15.7102\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30.7017 - val_loss: 28.5413\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27.3974 - val_loss: 34.9048\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.1036 - val_loss: 18.9171\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.7469 - val_loss: 11.9857\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.8958 - val_loss: 14.3335\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.8763 - val_loss: 10.4032\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.1512 - val_loss: 3.0077\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.1438 - val_loss: 5.2666\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.7861 - val_loss: 10.0778\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.2996 - val_loss: 2.5910\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.4549 - val_loss: 9.1074\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2337 - val_loss: 8.8664\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.3955 - val_loss: 5.1931\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.6799 - val_loss: 5.8899\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.3856 - val_loss: 4.8197\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.7063 - val_loss: 3.7928\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.5384 - val_loss: 6.7503\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9539 - val_loss: 3.2308\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.3579 - val_loss: 4.1740\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.7804 - val_loss: 3.8985\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.0994 - val_loss: 2.7195\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.6525 - val_loss: 4.5499\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.7182 - val_loss: 3.4210\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4762 - val_loss: 3.7593\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.8176 - val_loss: 2.8045\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1993 - val_loss: 2.9185\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6865 - val_loss: 3.4118\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7302 - val_loss: 3.0354\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7707 - val_loss: 2.9893\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.4002 - val_loss: 3.5701\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8970 - val_loss: 2.8590\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9162 - val_loss: 4.7195\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.0216 - val_loss: 2.8637\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6971 - val_loss: 2.8754\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8770 - val_loss: 3.2329\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8944 - val_loss: 2.6007\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0478 - val_loss: 4.9458\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8465 - val_loss: 2.5162\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.8229 - val_loss: 2.7426\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2766 - val_loss: 3.4378\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7054 - val_loss: 2.6908\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.8847 - val_loss: 2.5257\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0614 - val_loss: 2.3220\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7522 - val_loss: 2.4304\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8556 - val_loss: 3.4464\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2913 - val_loss: 2.6603\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4334 - val_loss: 2.2758\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2707 - val_loss: 2.9108\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfd7960700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 61 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 112819.0391 - val_loss: 110.2338\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 109431.6875 - val_loss: 114.1784\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 72134.9453 - val_loss: 107.6811\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43956.9336 - val_loss: 106.8974\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27611.9570 - val_loss: 110.6829\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34622.3125 - val_loss: 109.4997\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27014.6133 - val_loss: 106.6333\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55353.2305 - val_loss: 105.4336\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 35082.1406 - val_loss: 108.6825\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9483.6641 - val_loss: 114.7025\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 140036.8594 - val_loss: 116.5938\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 133908.4219 - val_loss: 114.2930\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 94259.0859 - val_loss: 109.3719\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22243.5430 - val_loss: 104.1973\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 110769.1719 - val_loss: 101.9212\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 89877.8438 - val_loss: 104.4566\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 70200.7109 - val_loss: 108.3199\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13936.0645 - val_loss: 108.7200\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8652.0156 - val_loss: 106.5231\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2112.7246 - val_loss: 106.0707\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30042.1094 - val_loss: 109.1502\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 46301.0273 - val_loss: 109.5926\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6505.0620 - val_loss: 107.8678\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10272.9873 - val_loss: 105.3964\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 70242.1016 - val_loss: 104.4170\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 56552.7305 - val_loss: 105.7002\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32195.4805 - val_loss: 107.5308\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23385.7402 - val_loss: 107.7247\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22546.5703 - val_loss: 106.3234\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31489.3594 - val_loss: 106.7491\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15203.2842 - val_loss: 107.6608\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33965.4102 - val_loss: 108.1197\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36017.4570 - val_loss: 105.8831\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27284.9844 - val_loss: 105.6578\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32099.6816 - val_loss: 107.1852\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26995.4316 - val_loss: 107.5445\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26746.9844 - val_loss: 105.8371\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25909.1934 - val_loss: 105.9080\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7147.3486 - val_loss: 107.2737\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9711.4443 - val_loss: 107.4602\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22953.9707 - val_loss: 106.2450\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10029.4922 - val_loss: 103.5284\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 70542.4688 - val_loss: 102.5988\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 80038.1562 - val_loss: 104.1152\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 49872.7617 - val_loss: 106.6466\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1365.3422 - val_loss: 106.7180\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25506.0566 - val_loss: 105.1028\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10008.8809 - val_loss: 105.2020\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17626.8340 - val_loss: 106.2002\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20433.7285 - val_loss: 106.5661\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf52d594c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 62 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 72.1101 - val_loss: 48.2875\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29.2840 - val_loss: 6.8616\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30.3498 - val_loss: 17.4900\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22.2608 - val_loss: 31.2649\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22.6391 - val_loss: 22.7209\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.4713 - val_loss: 10.2915\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.6046 - val_loss: 12.1356\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.9795 - val_loss: 20.0590\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.2310 - val_loss: 10.7044\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.8947 - val_loss: 5.2353\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.6083 - val_loss: 11.0675\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.3244 - val_loss: 10.5691\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.7049 - val_loss: 4.1511\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.4810 - val_loss: 7.2278\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.0969 - val_loss: 6.7176\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.1087 - val_loss: 3.6842\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.4786 - val_loss: 7.0152\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.9297 - val_loss: 3.3993\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3106 - val_loss: 4.6638\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7548 - val_loss: 4.2130\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1406 - val_loss: 3.2431\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.8447 - val_loss: 4.5018\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.9283 - val_loss: 3.2162\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6844 - val_loss: 4.1391\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1249 - val_loss: 2.9436\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9815 - val_loss: 5.8485\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4394 - val_loss: 2.9781\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8208 - val_loss: 4.8102\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6365 - val_loss: 2.6043\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.8061 - val_loss: 3.5405\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1642 - val_loss: 2.8134\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8532 - val_loss: 3.9216\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8863 - val_loss: 2.6705\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7508 - val_loss: 2.6858\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4405 - val_loss: 4.2613\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8114 - val_loss: 2.6459\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0852 - val_loss: 3.0550\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1094 - val_loss: 2.5677\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.9503 - val_loss: 3.5279\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5645 - val_loss: 2.6607\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1843 - val_loss: 6.0129\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1128 - val_loss: 2.6595\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8510 - val_loss: 4.9537\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1333 - val_loss: 2.5742\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7207 - val_loss: 4.8818\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9237 - val_loss: 2.5808\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1239 - val_loss: 4.1319\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8396 - val_loss: 3.1450\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3787 - val_loss: 2.6006\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9489 - val_loss: 4.3307\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4d12e5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 63 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 4890642.5000 - val_loss: 109.1622\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4120236.2500 - val_loss: 106.9932\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3237884.0000 - val_loss: 105.5289\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2021135.0000 - val_loss: 104.4147\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1206677.7500 - val_loss: 103.3912\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 718558.1875 - val_loss: 102.3456\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 391942.4688 - val_loss: 101.3120\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 468005.7500 - val_loss: 100.3224\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 502100.5938 - val_loss: 99.4121\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 515422.5312 - val_loss: 98.3914\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 417206.1250 - val_loss: 97.5437\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 352602.4062 - val_loss: 96.6063\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 240622.3906 - val_loss: 95.7906\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 200645.7969 - val_loss: 94.8187\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 159509.5469 - val_loss: 93.9859\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 288616.4062 - val_loss: 93.0514\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 346953.6250 - val_loss: 92.2049\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 298601.8750 - val_loss: 91.4976\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 156150.6562 - val_loss: 90.5393\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 167258.5000 - val_loss: 89.7597\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 175146.3906 - val_loss: 89.0510\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 232130.2656 - val_loss: 88.1721\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 238171.7344 - val_loss: 87.3688\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 238050.9219 - val_loss: 86.5812\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 121756.2656 - val_loss: 85.7575\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 155748.7344 - val_loss: 84.9813\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 233552.7344 - val_loss: 84.3050\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 163365.8281 - val_loss: 83.5605\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 134770.2969 - val_loss: 82.8266\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 149532.7969 - val_loss: 82.1461\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 319831.2500 - val_loss: 81.4648\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 306962.6875 - val_loss: 80.7220\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 264882.9062 - val_loss: 80.0504\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 247320.3906 - val_loss: 79.5204\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 159468.9688 - val_loss: 78.9014\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 143859.1406 - val_loss: 78.2684\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 118249.7500 - val_loss: 77.5647\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 289821.5625 - val_loss: 76.9501\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 443829.3125 - val_loss: 76.3906\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 385195.7500 - val_loss: 75.8250\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 305939.4688 - val_loss: 75.3197\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 285150.7500 - val_loss: 74.9103\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 232438.1875 - val_loss: 74.3929\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 178505.1562 - val_loss: 73.9023\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 119028.6016 - val_loss: 73.2839\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 146385.3750 - val_loss: 72.7346\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 230930.9688 - val_loss: 72.1346\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 120800.7656 - val_loss: 71.5297\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 112065.3984 - val_loss: 70.9996\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 96917.3359 - val_loss: 70.3861\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf53bb5040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 64 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1909.2206 - val_loss: 77.7337\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 157111.0156 - val_loss: 73.1878\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 107638.4141 - val_loss: 79.8706\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49861.4922 - val_loss: 81.7034\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1020.8794 - val_loss: 83.9790\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 70009.3047 - val_loss: 84.2346\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43052.0117 - val_loss: 80.9366\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28179.1504 - val_loss: 81.5840\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4722.1914 - val_loss: 80.1956\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 69300.3828 - val_loss: 79.8939\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37050.8047 - val_loss: 85.5916\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 93331.7734 - val_loss: 87.0958\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 69858.1953 - val_loss: 84.5396\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23265.1367 - val_loss: 81.7230\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 88505.7734 - val_loss: 80.1728\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57380.5586 - val_loss: 83.0961\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8644.6855 - val_loss: 86.0421\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 92747.6172 - val_loss: 88.6787\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 101876.6719 - val_loss: 88.1630\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26153.6543 - val_loss: 86.5804\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24728.8750 - val_loss: 85.3573\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1594.1893 - val_loss: 85.5202\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22754.9316 - val_loss: 85.6452\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17625.8066 - val_loss: 86.7517\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36794.4883 - val_loss: 87.2726\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23371.6230 - val_loss: 87.4961\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1898.1947 - val_loss: 88.0114\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29061.2344 - val_loss: 88.1849\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18518.0430 - val_loss: 86.2410\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61788.9219 - val_loss: 85.6853\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 69084.6328 - val_loss: 86.7409\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15321.3340 - val_loss: 87.2996\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5750.0781 - val_loss: 87.9233\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40811.2930 - val_loss: 87.6794\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15291.9814 - val_loss: 86.8115\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44777.0000 - val_loss: 86.8653\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24230.5410 - val_loss: 87.5026\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20279.0977 - val_loss: 87.5732\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43124.7734 - val_loss: 86.7383\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34361.2969 - val_loss: 86.8536\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13300.7373 - val_loss: 87.9018\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20026.5938 - val_loss: 87.9786\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11333.8516 - val_loss: 87.1666\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37679.6055 - val_loss: 87.2441\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19758.6621 - val_loss: 86.7609\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49859.3867 - val_loss: 87.0710\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11040.4941 - val_loss: 88.6073\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29480.3027 - val_loss: 89.3672\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47304.1133 - val_loss: 87.6319\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23973.4746 - val_loss: 87.1568\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf72ddd4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 65 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 91.8531 - val_loss: 75.9221\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51.4275 - val_loss: 39.6209\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34.1670 - val_loss: 9.6516\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31.3547 - val_loss: 26.4225\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24.0981 - val_loss: 32.5038\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24.0490 - val_loss: 25.5830\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20.3759 - val_loss: 16.4897\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.7312 - val_loss: 13.5888\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.3356 - val_loss: 17.2119\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.5510 - val_loss: 14.1383\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.3642 - val_loss: 9.3954\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.1856 - val_loss: 11.4151\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.3660 - val_loss: 5.9367\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.7331 - val_loss: 4.3028\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.1965 - val_loss: 6.0097\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.0494 - val_loss: 6.2358\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2530 - val_loss: 6.1197\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2861 - val_loss: 5.4536\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.3209 - val_loss: 5.3402\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.1101 - val_loss: 6.0144\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.3064 - val_loss: 3.8425\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9680 - val_loss: 4.6500\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9406 - val_loss: 3.9341\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2596 - val_loss: 5.8102\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9296 - val_loss: 2.4826\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7751 - val_loss: 3.8919\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4048 - val_loss: 3.3354\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.4885 - val_loss: 4.2761\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.2235 - val_loss: 2.2188\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.8586 - val_loss: 6.3181\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.0772 - val_loss: 2.1614\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1621 - val_loss: 5.9480\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9365 - val_loss: 2.5895\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9236 - val_loss: 3.5441\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9964 - val_loss: 5.8105\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4375 - val_loss: 4.2059\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4390 - val_loss: 1.9932\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0435 - val_loss: 5.6547\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6435 - val_loss: 4.1466\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 7.7829 - val_loss: 2.9733\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.2452 - val_loss: 3.6018\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.4102 - val_loss: 4.2380\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.5916 - val_loss: 3.5584\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.3234 - val_loss: 2.9034\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5471 - val_loss: 4.5758\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.8172 - val_loss: 3.1829\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8515 - val_loss: 4.8692\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2659 - val_loss: 3.7538\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0062 - val_loss: 3.3778\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9210 - val_loss: 3.8004\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf54b3eee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 66 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 81.9780 - val_loss: 60.7583\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34.0648 - val_loss: 18.3161\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 33.0900 - val_loss: 18.6081\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24.7606 - val_loss: 33.8840\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.8185 - val_loss: 32.1823\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.3110 - val_loss: 21.1665\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18.0948 - val_loss: 13.6403\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.6757 - val_loss: 17.5905\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.5377 - val_loss: 17.5700\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.1694 - val_loss: 7.9242\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.6907 - val_loss: 11.9643\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.1344 - val_loss: 7.9134\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.1270 - val_loss: 2.9671\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.9933 - val_loss: 11.3363\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.0290 - val_loss: 6.6661\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.6778 - val_loss: 7.3489\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.6359 - val_loss: 9.8839\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.8186 - val_loss: 6.6581\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.8380 - val_loss: 9.1026\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.7346 - val_loss: 5.9088\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.1185 - val_loss: 5.5130\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4834 - val_loss: 7.2560\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4951 - val_loss: 7.5499\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.7954 - val_loss: 5.6538\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.7096 - val_loss: 4.8895\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9355 - val_loss: 9.4671\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2429 - val_loss: 3.2818\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5165 - val_loss: 4.4137\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0957 - val_loss: 9.4002\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.0035 - val_loss: 2.6986\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6411 - val_loss: 8.8534\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5041 - val_loss: 4.8137\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7685 - val_loss: 6.3424\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7102 - val_loss: 5.3301\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.7747 - val_loss: 1.9676\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.0405 - val_loss: 9.8475\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4677 - val_loss: 1.9802\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2600 - val_loss: 5.6694\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.3447 - val_loss: 3.1073\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4674 - val_loss: 2.6436\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1973 - val_loss: 4.6296\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5213 - val_loss: 3.5452\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2902 - val_loss: 3.9110\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0099 - val_loss: 2.7990\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.8964 - val_loss: 3.9530\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.8880 - val_loss: 2.8691\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3593 - val_loss: 2.8190\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1492 - val_loss: 5.3381\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2755 - val_loss: 1.9688\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8816 - val_loss: 6.2897\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4c15e040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 67 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 83.4131 - val_loss: 58.5122\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.1743 - val_loss: 7.9080\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29.4977 - val_loss: 11.4789\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20.6107 - val_loss: 26.3616\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20.5594 - val_loss: 26.2977\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18.3865 - val_loss: 15.0269\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.2147 - val_loss: 10.1672\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.9092 - val_loss: 11.7945\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.4804 - val_loss: 12.2875\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.6377 - val_loss: 7.7986\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.0384 - val_loss: 6.9942\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.8638 - val_loss: 7.5003\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5549 - val_loss: 5.8886\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7585 - val_loss: 7.1430\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8435 - val_loss: 6.0639\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1726 - val_loss: 7.3124\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3591 - val_loss: 5.7101\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6622 - val_loss: 7.4626\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4633 - val_loss: 5.8754\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.4579 - val_loss: 6.0729\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1907 - val_loss: 6.5878\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0430 - val_loss: 5.8325\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6506 - val_loss: 6.2402\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0428 - val_loss: 5.8506\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4307 - val_loss: 6.4476\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.7942 - val_loss: 5.8961\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0691 - val_loss: 5.7660\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3874 - val_loss: 6.0103\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5501 - val_loss: 5.7087\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0622 - val_loss: 5.7931\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2455 - val_loss: 6.2141\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5954 - val_loss: 5.8474\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1815 - val_loss: 6.7679\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6387 - val_loss: 5.5673\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3871 - val_loss: 6.1247\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6106 - val_loss: 5.6478\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.2333 - val_loss: 5.6835\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.2752 - val_loss: 5.5132\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.6451 - val_loss: 5.7560\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.7185 - val_loss: 5.5418\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.5659 - val_loss: 5.5508\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1782 - val_loss: 5.4129\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1603 - val_loss: 5.3823\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4609 - val_loss: 5.8670\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0433 - val_loss: 5.3910\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1421 - val_loss: 7.5541\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9545 - val_loss: 5.1104\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1488 - val_loss: 6.3808\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6747 - val_loss: 5.0645\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3690 - val_loss: 5.8396\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5eb25820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 68 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 72.7020 - val_loss: 50.3720\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27.9716 - val_loss: 4.7769\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26.5820 - val_loss: 11.6597\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18.9916 - val_loss: 25.4344\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20.3490 - val_loss: 25.0521\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.0910 - val_loss: 13.0048\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.6246 - val_loss: 7.2225\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.0142 - val_loss: 12.6994\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.0473 - val_loss: 14.4816\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.6344 - val_loss: 5.8636\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.6615 - val_loss: 6.5458\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.8726 - val_loss: 6.7641\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9435 - val_loss: 3.1063\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2157 - val_loss: 4.7133\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5433 - val_loss: 3.2566\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6111 - val_loss: 4.5365\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0424 - val_loss: 3.0062\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6561 - val_loss: 5.2217\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8754 - val_loss: 3.2653\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4432 - val_loss: 4.0139\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6286 - val_loss: 3.6368\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8495 - val_loss: 3.5998\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6734 - val_loss: 3.2910\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4604 - val_loss: 4.5981\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8081 - val_loss: 3.2466\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5975 - val_loss: 3.5028\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4070 - val_loss: 4.3427\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5630 - val_loss: 3.3005\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8055 - val_loss: 3.4381\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0283 - val_loss: 4.1965\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5637 - val_loss: 3.3611\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8861 - val_loss: 3.8701\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0196 - val_loss: 3.6177\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2403 - val_loss: 4.3829\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9375 - val_loss: 3.2897\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8562 - val_loss: 4.7736\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8937 - val_loss: 3.2919\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7109 - val_loss: 4.0044\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7533 - val_loss: 3.5467\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6475 - val_loss: 4.2878\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6992 - val_loss: 3.3070\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0285 - val_loss: 4.3564\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1575 - val_loss: 3.6030\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4637 - val_loss: 3.3742\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4218 - val_loss: 4.0345\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3013 - val_loss: 4.3428\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6657 - val_loss: 3.7082\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0972 - val_loss: 3.3419\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7212 - val_loss: 3.6268\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.3535 - val_loss: 3.9576\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf71e3faf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 69 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 69.6055 - val_loss: 42.9340\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23.4044 - val_loss: 6.1631\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24.6721 - val_loss: 11.6061\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.3753 - val_loss: 25.3984\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.1921 - val_loss: 22.1546\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.7506 - val_loss: 10.2622\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.1951 - val_loss: 5.8392\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.0620 - val_loss: 10.7849\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.3666 - val_loss: 13.3344\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.1071 - val_loss: 8.0487\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6245 - val_loss: 5.7773\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5671 - val_loss: 7.0255\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1006 - val_loss: 3.8081\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6479 - val_loss: 4.2395\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9286 - val_loss: 3.8607\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8258 - val_loss: 3.8842\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3107 - val_loss: 4.0346\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7818 - val_loss: 4.6245\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6109 - val_loss: 3.9118\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.0738 - val_loss: 4.6744\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6334 - val_loss: 3.8000\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1408 - val_loss: 4.2748\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4413 - val_loss: 3.8371\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6417 - val_loss: 4.3471\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6645 - val_loss: 4.3756\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9765 - val_loss: 4.5036\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8239 - val_loss: 4.4740\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6445 - val_loss: 4.0917\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9219 - val_loss: 4.4515\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4447 - val_loss: 4.0131\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8364 - val_loss: 4.2921\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7610 - val_loss: 4.6490\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1667 - val_loss: 5.1246\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1594 - val_loss: 4.0408\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1179 - val_loss: 4.7767\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2206 - val_loss: 4.0474\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7363 - val_loss: 4.1992\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6650 - val_loss: 4.1251\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4870 - val_loss: 4.9858\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5804 - val_loss: 4.1150\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2591 - val_loss: 4.2912\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0178 - val_loss: 4.0243\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.3099 - val_loss: 3.8417\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2131 - val_loss: 3.8931\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5793 - val_loss: 3.9052\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6953 - val_loss: 5.1499\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9388 - val_loss: 4.1255\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5552 - val_loss: 4.1623\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4182 - val_loss: 3.9604\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8694 - val_loss: 3.9722\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf86e9c430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 70 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 182210.1875 - val_loss: 106.1159\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 313906.2500 - val_loss: 96.7668\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 572044.9375 - val_loss: 95.3807\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 597268.1875 - val_loss: 105.0495\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 132941.2344 - val_loss: 110.2745\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 377361.5938 - val_loss: 109.9580\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 406487.2188 - val_loss: 104.1724\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 258856.1094 - val_loss: 103.1147\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 145641.4219 - val_loss: 107.6970\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 237328.8438 - val_loss: 110.8013\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 461252.4688 - val_loss: 107.3058\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 207931.5625 - val_loss: 103.3192\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 174364.9531 - val_loss: 104.1892\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 236719.6875 - val_loss: 104.4499\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24941.5527 - val_loss: 103.9302\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 155406.2969 - val_loss: 106.2386\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 98847.4219 - val_loss: 104.9091\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 79199.1484 - val_loss: 102.1222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 245775.4219 - val_loss: 103.7138\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53721.8125 - val_loss: 103.1843\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 136222.3125 - val_loss: 100.4153\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 240372.1094 - val_loss: 102.2681\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 199830.4688 - val_loss: 103.9282\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51388.2617 - val_loss: 104.5442\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 54741.6992 - val_loss: 106.5479\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 292576.3438 - val_loss: 106.2294\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 279927.7500 - val_loss: 100.6441\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 200908.7656 - val_loss: 100.5602\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 161554.1094 - val_loss: 103.4453\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 56001.4531 - val_loss: 104.4908\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41454.1172 - val_loss: 101.6079\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 177256.5469 - val_loss: 98.2862\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 298470.1562 - val_loss: 98.1807\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 268572.3438 - val_loss: 102.5083\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 84192.1016 - val_loss: 102.6614\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 114433.7344 - val_loss: 103.6396\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 79746.9062 - val_loss: 103.3856\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 79563.6016 - val_loss: 102.2902\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 129834.1016 - val_loss: 102.2401\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 26215.2793 - val_loss: 104.5375\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 303485.2500 - val_loss: 105.0108\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 125819.4219 - val_loss: 101.3572\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 178781.7969 - val_loss: 100.1850\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 61273.9023 - val_loss: 102.5112\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 98225.1250 - val_loss: 101.8446\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 160652.0156 - val_loss: 101.2270\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 71270.8984 - val_loss: 103.1528\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26591.6172 - val_loss: 102.4108\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 61027.3828 - val_loss: 100.9417\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 121871.5781 - val_loss: 100.8384\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7c86a550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 71 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 34665.8086 - val_loss: 104.6873\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 201890.6406 - val_loss: 103.4064\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 166879.9062 - val_loss: 94.2259\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 93612.9375 - val_loss: 81.6491\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 83873.4375 - val_loss: 77.8474\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 71412.7031 - val_loss: 83.4941\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7998.0444 - val_loss: 91.3879\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 99447.8828 - val_loss: 94.4624\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 95274.0859 - val_loss: 89.2197\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23566.3535 - val_loss: 83.5148\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35337.8555 - val_loss: 82.4539\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26244.5078 - val_loss: 86.9311\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 34453.5391 - val_loss: 88.1548\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12121.6152 - val_loss: 80.7281\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 60349.9531 - val_loss: 78.3225\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 94410.5000 - val_loss: 82.5573\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38391.9531 - val_loss: 87.5805\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16790.3516 - val_loss: 88.7124\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20483.3047 - val_loss: 87.0307\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19551.3652 - val_loss: 86.4206\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5438.5620 - val_loss: 89.6042\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8160.1421 - val_loss: 89.5420\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25328.6562 - val_loss: 84.9244\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5440.7642 - val_loss: 85.3868\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9032.6602 - val_loss: 90.0523\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25307.6953 - val_loss: 90.5634\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14450.7314 - val_loss: 83.8608\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 98148.0469 - val_loss: 80.7517\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 67177.2578 - val_loss: 89.0902\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 32043.1309 - val_loss: 89.8691\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1165.6302 - val_loss: 86.4326\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23742.9062 - val_loss: 87.9694\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8647.0127 - val_loss: 87.6496\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11582.7998 - val_loss: 86.4055\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6234.4126 - val_loss: 88.9864\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6782.3950 - val_loss: 89.9314\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34803.7500 - val_loss: 87.4689\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9304.3418 - val_loss: 84.3248\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44016.9062 - val_loss: 87.9056\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 57533.0781 - val_loss: 87.6835\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4651.5386 - val_loss: 88.2901\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18635.3223 - val_loss: 90.7622\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15698.4258 - val_loss: 88.1596\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27271.8887 - val_loss: 87.2542\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20616.2344 - val_loss: 91.1663\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35345.2852 - val_loss: 90.6447\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44855.9453 - val_loss: 86.0901\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 69231.0078 - val_loss: 84.5552\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36415.4883 - val_loss: 89.2192\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 58160.2305 - val_loss: 91.5008\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5d35ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 72 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 338400.8438 - val_loss: 106.9522\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 113937.9219 - val_loss: 102.6826\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 252047.2344 - val_loss: 100.7351\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 166754.4688 - val_loss: 102.2131\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 71570.9453 - val_loss: 101.8207\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 113182.0156 - val_loss: 104.8933\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 234609.0781 - val_loss: 104.4457\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 158300.8594 - val_loss: 101.4555\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 220271.5312 - val_loss: 100.6110\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 183969.7344 - val_loss: 102.9369\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 175524.8750 - val_loss: 105.0784\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 241634.6875 - val_loss: 103.2865\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 36922.8945 - val_loss: 100.7986\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 355850.9375 - val_loss: 100.4346\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 135964.1250 - val_loss: 102.0650\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 149213.8125 - val_loss: 103.3766\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 99817.3125 - val_loss: 102.2276\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45985.6445 - val_loss: 99.8251\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 370941.1562 - val_loss: 99.1488\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 298646.4062 - val_loss: 102.7658\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 209236.2344 - val_loss: 103.8376\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35101.4375 - val_loss: 102.5948\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 190432.6875 - val_loss: 101.9734\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33023.3242 - val_loss: 102.8069\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 95152.6016 - val_loss: 102.4393\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11233.0225 - val_loss: 101.9147\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 113898.9766 - val_loss: 102.7991\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 180478.2344 - val_loss: 104.2245\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 134357.9844 - val_loss: 102.2067\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 77441.3047 - val_loss: 101.5632\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 86052.8828 - val_loss: 102.1919\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 78884.3281 - val_loss: 105.3397\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 401345.4062 - val_loss: 105.9024\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 375168.0938 - val_loss: 105.1202\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 222115.0781 - val_loss: 102.7878\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 181745.1250 - val_loss: 101.0891\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 215164.5000 - val_loss: 101.0063\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 129631.3047 - val_loss: 102.7660\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 94473.7656 - val_loss: 104.2955\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 272357.0312 - val_loss: 103.9794\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 170543.8750 - val_loss: 102.3151\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12256.3564 - val_loss: 102.3576\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 151737.0000 - val_loss: 102.4676\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 72486.8047 - val_loss: 101.8959\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 58760.8828 - val_loss: 101.6153\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 72779.8281 - val_loss: 101.8404\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29694.5332 - val_loss: 101.0836\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 64706.4062 - val_loss: 101.1339\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 97871.0078 - val_loss: 101.5722\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 71267.0625 - val_loss: 102.2367\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf68c0b790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 73 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 21267.1484 - val_loss: 82.3234\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 151049.2656 - val_loss: 84.2778\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 144737.9219 - val_loss: 80.4792\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29052.5234 - val_loss: 79.4135\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3553.3906 - val_loss: 79.4753\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40520.0391 - val_loss: 79.8546\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27422.7852 - val_loss: 85.0662\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 73795.0625 - val_loss: 85.9777\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 72970.2578 - val_loss: 85.9741\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9867.6807 - val_loss: 83.7184\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 75730.7578 - val_loss: 81.0507\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 66205.2344 - val_loss: 82.3231\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 116.8230 - val_loss: 83.4171\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3676.7903 - val_loss: 84.6372\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44460.3672 - val_loss: 84.2613\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37840.8242 - val_loss: 83.4416\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19156.3984 - val_loss: 83.1852\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11992.1338 - val_loss: 82.8238\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 48405.0000 - val_loss: 83.2349\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9392.5371 - val_loss: 84.5202\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 51014.5195 - val_loss: 85.5667\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39834.7188 - val_loss: 84.1124\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26585.1719 - val_loss: 83.7200\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22789.5547 - val_loss: 84.5740\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15401.0146 - val_loss: 84.3724\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3077.4231 - val_loss: 82.9441\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 61272.7109 - val_loss: 82.9494\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 55967.2773 - val_loss: 85.1104\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16321.1875 - val_loss: 88.0706\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 67457.4375 - val_loss: 88.7120\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 70483.4453 - val_loss: 87.9887\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 59129.9219 - val_loss: 85.9451\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32534.8320 - val_loss: 85.4010\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12224.8076 - val_loss: 86.7878\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24740.2090 - val_loss: 86.5147\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5921.8857 - val_loss: 85.6239\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15905.4141 - val_loss: 82.4039\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 139058.2031 - val_loss: 81.1104\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 106883.1328 - val_loss: 82.5087\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45014.0312 - val_loss: 85.1059\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33092.0195 - val_loss: 87.4158\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39382.7383 - val_loss: 86.3672\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1005.7662 - val_loss: 84.7334\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 66489.1094 - val_loss: 84.3229\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49980.1484 - val_loss: 85.7540\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24409.0566 - val_loss: 87.3781\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8811.5723 - val_loss: 87.6088\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32461.1836 - val_loss: 86.8503\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8284.6172 - val_loss: 87.2985\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46062.7383 - val_loss: 87.2844\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf75205940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 74 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 87.9611 - val_loss: 67.2925\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.6111 - val_loss: 26.9496\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37.0397 - val_loss: 17.5809\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28.8184 - val_loss: 27.4517\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23.7720 - val_loss: 25.9183\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.9306 - val_loss: 15.4581\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16.0820 - val_loss: 9.7336\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.7906 - val_loss: 10.3280\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.5903 - val_loss: 5.3196\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.2097 - val_loss: 3.4443\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.1380 - val_loss: 4.2136\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.3866 - val_loss: 3.9095\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4302 - val_loss: 4.1374\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4486 - val_loss: 8.1185\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.0465 - val_loss: 3.3716\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6722 - val_loss: 5.3058\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0623 - val_loss: 4.6550\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1917 - val_loss: 5.9054\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3808 - val_loss: 5.3411\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0273 - val_loss: 5.3169\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6269 - val_loss: 3.6489\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8000 - val_loss: 3.3975\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6662 - val_loss: 6.1908\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7942 - val_loss: 5.1188\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3401 - val_loss: 5.8543\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3134 - val_loss: 3.3545\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5523 - val_loss: 4.5240\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6437 - val_loss: 4.0524\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9710 - val_loss: 3.8431\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5915 - val_loss: 3.5291\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8566 - val_loss: 4.3385\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1172 - val_loss: 4.4336\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0489 - val_loss: 5.6303\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6133 - val_loss: 3.2795\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0831 - val_loss: 4.4215\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8751 - val_loss: 3.8870\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0289 - val_loss: 4.8357\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6219 - val_loss: 3.1728\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7261 - val_loss: 6.2224\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7392 - val_loss: 3.3873\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4245 - val_loss: 3.9239\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7188 - val_loss: 3.1475\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9801 - val_loss: 4.7176\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6004 - val_loss: 5.8589\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6294 - val_loss: 3.5130\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5364 - val_loss: 4.6945\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0527 - val_loss: 3.0599\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4024 - val_loss: 4.2261\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2337 - val_loss: 3.7507\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0894 - val_loss: 3.3112\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf54478670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 75 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 89.0576 - val_loss: 75.3105\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44.1735 - val_loss: 37.4651\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36.1051 - val_loss: 30.6861\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28.8018 - val_loss: 37.9014\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28.2021 - val_loss: 37.7443\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24.5044 - val_loss: 24.4175\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22.2874 - val_loss: 16.1422\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.5776 - val_loss: 20.6842\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.6834 - val_loss: 21.8251\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.6186 - val_loss: 11.4525\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.9971 - val_loss: 11.2799\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.2058 - val_loss: 12.1742\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.6832 - val_loss: 6.0901\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.9537 - val_loss: 5.8513\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.3735 - val_loss: 4.8891\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.7726 - val_loss: 3.1827\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.3991 - val_loss: 5.3216\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.8751 - val_loss: 4.1515\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2774 - val_loss: 4.1575\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.6516 - val_loss: 4.6500\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.9160 - val_loss: 3.6461\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3879 - val_loss: 4.4894\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.2962 - val_loss: 3.8148\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.8425 - val_loss: 4.8968\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.2136 - val_loss: 7.2608\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2048 - val_loss: 3.7222\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4461 - val_loss: 5.2410\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.8102 - val_loss: 3.7429\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.9482 - val_loss: 3.1022\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.6135 - val_loss: 4.2696\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.1816 - val_loss: 3.7568\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7163 - val_loss: 3.9171\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5142 - val_loss: 3.1709\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.1081 - val_loss: 3.5705\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9406 - val_loss: 3.6841\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5931 - val_loss: 3.4587\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6148 - val_loss: 3.4851\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0228 - val_loss: 3.2833\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2648 - val_loss: 4.3259\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6252 - val_loss: 2.8144\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1583 - val_loss: 3.9853\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4511 - val_loss: 3.2776\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4016 - val_loss: 2.8469\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1739 - val_loss: 2.8732\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9057 - val_loss: 3.2172\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6288 - val_loss: 2.9435\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1771 - val_loss: 3.0722\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1309 - val_loss: 3.9601\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4672 - val_loss: 2.6680\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5765 - val_loss: 2.8884\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5888f9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 76 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 133621.2344 - val_loss: 122.5548\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18830.8164 - val_loss: 135.0820\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 264470.3750 - val_loss: 139.2786\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 166405.3750 - val_loss: 133.4950\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 152091.0312 - val_loss: 124.7524\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42103.3867 - val_loss: 121.9114\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32725.3750 - val_loss: 122.6185\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18886.2090 - val_loss: 123.1001\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3842.6570 - val_loss: 120.9657\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 63312.5664 - val_loss: 119.5163\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45120.4258 - val_loss: 121.6223\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47884.2773 - val_loss: 124.2873\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38646.2617 - val_loss: 120.8353\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32293.1445 - val_loss: 120.4955\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29783.7734 - val_loss: 122.3186\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11744.7979 - val_loss: 122.0873\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36031.1562 - val_loss: 119.7215\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 59515.2500 - val_loss: 119.6361\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33267.4453 - val_loss: 122.2405\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 67131.0547 - val_loss: 123.1276\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20981.9883 - val_loss: 121.0320\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28904.7598 - val_loss: 119.1859\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42672.1250 - val_loss: 119.4304\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10408.1152 - val_loss: 122.3874\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 72557.0391 - val_loss: 124.1302\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32081.7500 - val_loss: 122.4433\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25528.5625 - val_loss: 120.8010\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46039.7539 - val_loss: 118.4232\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39674.5938 - val_loss: 119.9937\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12996.3662 - val_loss: 120.9368\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2245.2754 - val_loss: 120.1335\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24429.3281 - val_loss: 121.1819\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28656.7969 - val_loss: 118.8815\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 296.2931 - val_loss: 117.6052\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 51672.3906 - val_loss: 119.2437\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5748.7061 - val_loss: 119.2415\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26337.7285 - val_loss: 119.9217\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30705.5059 - val_loss: 118.5860\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30619.6250 - val_loss: 118.4456\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34472.2969 - val_loss: 121.7737\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 73317.0547 - val_loss: 123.3574\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 101408.5000 - val_loss: 120.8654\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11483.8359 - val_loss: 119.6818\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15226.3770 - val_loss: 121.9259\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 80741.6250 - val_loss: 122.6574\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 64546.3242 - val_loss: 120.2564\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4826.0488 - val_loss: 119.3455\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8852.0654 - val_loss: 118.6093\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45033.5742 - val_loss: 118.1261\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 28211.7832 - val_loss: 120.5756\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf3c98c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 77 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 88.2002 - val_loss: 74.4975\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61.2738 - val_loss: 55.1470\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.4053 - val_loss: 45.8514\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.4862 - val_loss: 31.9354\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36.3372 - val_loss: 23.3732\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28.9653 - val_loss: 23.2641\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29.4581 - val_loss: 18.5579\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25.6463 - val_loss: 14.2247\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.9150 - val_loss: 4.3590\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.6936 - val_loss: 5.3122\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.0609 - val_loss: 4.2574\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20.3313 - val_loss: 7.7346\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.7370 - val_loss: 5.7615\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.6326 - val_loss: 6.9130\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.0200 - val_loss: 3.9581\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.1319 - val_loss: 7.0490\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.4232 - val_loss: 3.4289\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.4504 - val_loss: 4.8706\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.4582 - val_loss: 3.6651\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.4426 - val_loss: 2.9020\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.5518 - val_loss: 7.0244\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.0010 - val_loss: 3.2306\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.5681 - val_loss: 3.7685\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.5241 - val_loss: 3.9500\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.4325 - val_loss: 3.8933\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.8029 - val_loss: 4.1002\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.5431 - val_loss: 3.4252\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.4613 - val_loss: 3.5850\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.0878 - val_loss: 4.1432\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2667 - val_loss: 4.5493\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.0669 - val_loss: 4.5302\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.8206 - val_loss: 3.7762\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3550 - val_loss: 3.7174\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.5470 - val_loss: 3.7342\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.4686 - val_loss: 6.1228\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.3382 - val_loss: 4.7800\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2758 - val_loss: 4.2218\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.7510 - val_loss: 3.0313\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.8277 - val_loss: 4.9634\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.3331 - val_loss: 3.3860\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.8472 - val_loss: 4.0288\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.8056 - val_loss: 4.0672\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.0208 - val_loss: 4.5632\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.3704 - val_loss: 4.3424\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.4159 - val_loss: 3.6635\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.2170 - val_loss: 3.2138\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3861 - val_loss: 6.1182\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.6413 - val_loss: 3.4886\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.7966 - val_loss: 4.1028\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.6030 - val_loss: 4.1894\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc1c3ac10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 78 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 101ms/step - loss: 74.8398 - val_loss: 56.0599\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31.8661 - val_loss: 10.1608\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32.2410 - val_loss: 18.2415\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23.8134 - val_loss: 31.6378\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23.4130 - val_loss: 28.1269\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21.2296 - val_loss: 15.9688\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.7799 - val_loss: 13.4489\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.2116 - val_loss: 15.6458\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.7654 - val_loss: 15.1367\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.6797 - val_loss: 9.5938\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.3389 - val_loss: 5.9918\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.1036 - val_loss: 4.3267\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.4059 - val_loss: 3.3861\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.7482 - val_loss: 3.7047\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.1165 - val_loss: 6.7659\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.6144 - val_loss: 2.4579\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.5678 - val_loss: 4.9561\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9203 - val_loss: 2.7951\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.8250 - val_loss: 2.7685\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5806 - val_loss: 6.3066\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4276 - val_loss: 2.7773\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9676 - val_loss: 7.7015\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1687 - val_loss: 3.3749\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4203 - val_loss: 3.2110\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4566 - val_loss: 3.3205\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1597 - val_loss: 3.6511\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9521 - val_loss: 3.6817\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0484 - val_loss: 3.7594\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0165 - val_loss: 3.3477\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.2522 - val_loss: 4.6122\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9870 - val_loss: 3.3029\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.7745 - val_loss: 4.6787\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0734 - val_loss: 3.1390\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1202 - val_loss: 3.6769\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6999 - val_loss: 3.6417\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9746 - val_loss: 5.6390\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6304 - val_loss: 3.5616\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0710 - val_loss: 3.9135\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4093 - val_loss: 3.6403\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6559 - val_loss: 4.1086\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7902 - val_loss: 3.2275\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.6878 - val_loss: 3.9636\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7033 - val_loss: 3.1592\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0566 - val_loss: 5.5429\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4188 - val_loss: 3.1786\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3936 - val_loss: 5.0820\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9964 - val_loss: 3.6210\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4650 - val_loss: 4.1291\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.9182 - val_loss: 3.1532\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.4497 - val_loss: 3.6523\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf532b4d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 79 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 112ms/step - loss: 5071477.5000 - val_loss: 106.7852\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4747511.0000 - val_loss: 103.6460\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4781205.0000 - val_loss: 102.2197\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4230686.5000 - val_loss: 100.9186\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2311166.0000 - val_loss: 99.9758\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1940861.5000 - val_loss: 98.8827\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1491212.6250 - val_loss: 97.2702\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 948860.3125 - val_loss: 96.3406\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 797882.5000 - val_loss: 94.8074\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 654228.3125 - val_loss: 93.6697\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 469615.5312 - val_loss: 92.5485\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 447000.7500 - val_loss: 91.3450\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 337574.5312 - val_loss: 90.3601\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 367297.0938 - val_loss: 89.3241\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 260987.0781 - val_loss: 88.2190\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 267444.7188 - val_loss: 87.0105\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 207358.7031 - val_loss: 85.9710\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 302417.9062 - val_loss: 84.7434\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 166460.1719 - val_loss: 83.5458\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 101546.1719 - val_loss: 82.4706\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 139521.7344 - val_loss: 81.1933\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 122924.5781 - val_loss: 79.9907\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 127327.9453 - val_loss: 78.8653\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 115645.3516 - val_loss: 77.7184\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 94743.4297 - val_loss: 76.6559\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 105314.8281 - val_loss: 75.6440\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 86341.0625 - val_loss: 74.6852\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 107827.8516 - val_loss: 73.4584\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 197766.7031 - val_loss: 72.4030\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 281710.9375 - val_loss: 71.2455\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 192753.9062 - val_loss: 70.2665\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 262124.0000 - val_loss: 69.4765\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 270888.1562 - val_loss: 68.4883\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 213707.1562 - val_loss: 67.5298\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 139845.6094 - val_loss: 66.6505\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 117196.1484 - val_loss: 65.7701\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 123877.8984 - val_loss: 64.9043\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 285550.4688 - val_loss: 63.9726\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 302206.1875 - val_loss: 63.1834\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 329600.5938 - val_loss: 62.5259\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 337617.6562 - val_loss: 62.0095\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 560025.1875 - val_loss: 61.3969\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 444842.5312 - val_loss: 60.8792\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 445671.3125 - val_loss: 60.3871\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 362611.9062 - val_loss: 59.8090\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 297866.9688 - val_loss: 59.3952\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 237692.1094 - val_loss: 58.8430\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 225166.8438 - val_loss: 58.3752\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 212515.0000 - val_loss: 57.8580\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 230293.9219 - val_loss: 57.3338\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf68c0be50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 80 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 70.0543 - val_loss: 46.5030\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27.7722 - val_loss: 13.2469\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 25.7584 - val_loss: 21.0682\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.6073 - val_loss: 28.3026\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.4746 - val_loss: 19.0749\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.2342 - val_loss: 9.1582\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.7722 - val_loss: 16.2261\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.5454 - val_loss: 10.8125\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.5345 - val_loss: 7.1455\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.8794 - val_loss: 3.8293\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.0087 - val_loss: 5.7143\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.0201 - val_loss: 4.4108\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.4217 - val_loss: 3.1582\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.0198 - val_loss: 3.6829\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.4628 - val_loss: 4.4481\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2183 - val_loss: 2.8280\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4131 - val_loss: 3.1669\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.0761 - val_loss: 3.4942\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.6857 - val_loss: 2.8533\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9070 - val_loss: 2.8784\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.1688 - val_loss: 3.6301\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2292 - val_loss: 2.9482\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.7958 - val_loss: 4.1187\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9104 - val_loss: 3.0963\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9380 - val_loss: 2.3083\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4718 - val_loss: 4.7512\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8596 - val_loss: 2.6864\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0578 - val_loss: 4.6773\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9238 - val_loss: 2.1653\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9313 - val_loss: 2.3472\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3422 - val_loss: 4.2020\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.0592 - val_loss: 2.2173\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.9540 - val_loss: 3.4946\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1104 - val_loss: 2.0012\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.1832 - val_loss: 2.2900\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7408 - val_loss: 2.9526\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6586 - val_loss: 3.5151\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4059 - val_loss: 1.6637\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8069 - val_loss: 3.4496\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9599 - val_loss: 2.2435\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0467 - val_loss: 2.7866\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8248 - val_loss: 2.6637\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4521 - val_loss: 2.9198\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7480 - val_loss: 2.0516\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7734 - val_loss: 2.7679\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3795 - val_loss: 2.2352\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6176 - val_loss: 1.6098\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1303 - val_loss: 1.6930\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.9025 - val_loss: 2.4884\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0939 - val_loss: 1.5629\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf601420d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 81 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 3237291.5000 - val_loss: 94.1761\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5454988.5000 - val_loss: 93.0114\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4766531.0000 - val_loss: 92.0323\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3400817.2500 - val_loss: 91.2001\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1872747.3750 - val_loss: 90.4179\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1204263.1250 - val_loss: 89.8958\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 794406.8125 - val_loss: 89.3281\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 589796.8125 - val_loss: 88.5220\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 717716.5000 - val_loss: 87.8806\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 615405.8125 - val_loss: 87.1397\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 691444.8750 - val_loss: 86.4065\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 611051.5000 - val_loss: 85.7756\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 264025.0625 - val_loss: 85.1033\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 335817.1562 - val_loss: 84.3371\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 398169.5625 - val_loss: 83.5448\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 197936.2500 - val_loss: 82.7903\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 167699.7656 - val_loss: 82.0811\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 96018.3438 - val_loss: 81.3212\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 112113.1875 - val_loss: 80.5430\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 118120.3125 - val_loss: 79.8435\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 156223.7812 - val_loss: 79.2226\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 269879.7500 - val_loss: 78.5369\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 289364.1250 - val_loss: 77.8449\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 190408.2188 - val_loss: 77.2027\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 231502.2969 - val_loss: 76.5458\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 245508.3750 - val_loss: 75.9055\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 124632.6328 - val_loss: 75.3365\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 138319.0312 - val_loss: 74.7170\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 269090.8438 - val_loss: 73.9977\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 217698.3281 - val_loss: 73.3720\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 174346.3438 - val_loss: 72.7859\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 276962.1875 - val_loss: 72.2327\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 267282.3125 - val_loss: 71.6675\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 234000.0312 - val_loss: 70.9962\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 190021.2656 - val_loss: 70.2956\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 163152.1562 - val_loss: 69.6136\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 160389.4062 - val_loss: 69.0004\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 245606.0000 - val_loss: 68.4050\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 251400.7344 - val_loss: 67.7547\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 140396.3281 - val_loss: 67.1558\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 242963.6094 - val_loss: 66.4704\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 424360.7500 - val_loss: 65.8964\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 609875.1875 - val_loss: 65.3439\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 374634.6875 - val_loss: 64.8940\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 290485.7812 - val_loss: 64.3934\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 228006.8438 - val_loss: 63.9497\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 185929.6875 - val_loss: 63.3248\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 287883.2500 - val_loss: 62.7912\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 173533.2812 - val_loss: 62.2556\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 264461.3438 - val_loss: 61.7225\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9948a940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 82 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 61000.2305 - val_loss: 83.5699\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 166727.0469 - val_loss: 86.2103\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 87652.4688 - val_loss: 94.0585\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 69898.8516 - val_loss: 96.4812\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46261.1445 - val_loss: 93.9286\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22382.4805 - val_loss: 93.0533\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22429.4355 - val_loss: 96.1797\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 71705.8125 - val_loss: 97.5250\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 43031.4102 - val_loss: 93.8806\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26904.5742 - val_loss: 92.5166\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25162.1289 - val_loss: 93.7483\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45865.4492 - val_loss: 94.8311\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 657.0060 - val_loss: 95.0330\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1252.9844 - val_loss: 94.9348\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1029.0096 - val_loss: 95.7377\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 63662.3633 - val_loss: 97.7456\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 64076.9805 - val_loss: 95.3296\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15433.3320 - val_loss: 91.9260\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 64449.3477 - val_loss: 91.0767\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42938.5352 - val_loss: 92.4112\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11134.9453 - val_loss: 95.1579\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30664.3262 - val_loss: 97.1673\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 64427.8086 - val_loss: 95.8098\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9137.6377 - val_loss: 94.1326\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50142.4219 - val_loss: 93.1229\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35782.5508 - val_loss: 94.5457\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25771.9531 - val_loss: 95.6498\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16523.7012 - val_loss: 95.5006\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14628.8291 - val_loss: 94.2782\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13532.7285 - val_loss: 94.5125\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11627.4707 - val_loss: 94.4761\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6570.4453 - val_loss: 95.2058\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13796.2188 - val_loss: 94.4553\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26456.9629 - val_loss: 95.6669\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17677.9531 - val_loss: 95.9452\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 42213.3438 - val_loss: 93.9974\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7644.1973 - val_loss: 93.7987\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13157.3906 - val_loss: 95.3229\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17024.5469 - val_loss: 94.8293\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10181.5508 - val_loss: 95.2335\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3115.9238 - val_loss: 95.4866\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14261.8818 - val_loss: 95.2459\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33171.6250 - val_loss: 94.1893\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39052.9062 - val_loss: 95.0387\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10805.2861 - val_loss: 95.1887\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37246.3438 - val_loss: 91.0678\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60622.2109 - val_loss: 90.4735\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 111317.4219 - val_loss: 91.4992\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 80306.0078 - val_loss: 93.6998\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20314.9492 - val_loss: 98.0217\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf88756ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 83 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 60.9682 - val_loss: 34.4775\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19.6613 - val_loss: 10.9864\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.2839 - val_loss: 10.8812\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.0569 - val_loss: 14.4838\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6139 - val_loss: 5.6629\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.7381 - val_loss: 5.6580\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7193 - val_loss: 10.6858\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4398 - val_loss: 7.2933\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7600 - val_loss: 6.0652\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3302 - val_loss: 7.4703\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8748 - val_loss: 7.3641\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7591 - val_loss: 6.0699\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2145 - val_loss: 7.8061\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8990 - val_loss: 3.9400\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.6864 - val_loss: 7.8381\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8262 - val_loss: 3.6491\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1084 - val_loss: 5.0139\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2826 - val_loss: 5.9066\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.5483 - val_loss: 3.7939\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2881 - val_loss: 5.5147\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2005 - val_loss: 3.0368\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2421 - val_loss: 3.9817\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4464 - val_loss: 3.5723\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4136 - val_loss: 4.3325\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2547 - val_loss: 3.0524\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.3554 - val_loss: 3.0105\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6452 - val_loss: 3.1768\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.6550 - val_loss: 3.4029\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3464 - val_loss: 5.9450\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7636 - val_loss: 2.9751\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8825 - val_loss: 3.3767\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6118 - val_loss: 4.2466\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5185 - val_loss: 2.9932\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8095 - val_loss: 3.1480\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9838 - val_loss: 3.8221\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0469 - val_loss: 3.0340\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3000 - val_loss: 2.9180\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9838 - val_loss: 3.1029\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.3495 - val_loss: 3.9494\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4713 - val_loss: 2.9771\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0804 - val_loss: 2.9968\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.1126 - val_loss: 3.4985\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9766 - val_loss: 3.0046\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1877 - val_loss: 3.2328\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4119 - val_loss: 2.9752\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.3850 - val_loss: 3.1258\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7698 - val_loss: 2.9248\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8942 - val_loss: 3.4758\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7007 - val_loss: 3.1251\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0889 - val_loss: 3.1577\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5c6b91f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 84 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 73.4426 - val_loss: 57.3152\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45.9671 - val_loss: 26.9893\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.3267 - val_loss: 37.9302\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35.1299 - val_loss: 38.3959\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31.0965 - val_loss: 28.1507\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26.7733 - val_loss: 17.5351\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24.1143 - val_loss: 19.9367\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.2154 - val_loss: 15.8855\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18.8516 - val_loss: 9.6245\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.1101 - val_loss: 9.0966\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.6789 - val_loss: 8.1090\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.2674 - val_loss: 11.5165\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.4194 - val_loss: 7.9616\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.3955 - val_loss: 10.6432\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16.5487 - val_loss: 9.2683\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16.2962 - val_loss: 9.8405\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.7471 - val_loss: 8.6769\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.5899 - val_loss: 8.3274\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.4406 - val_loss: 12.2294\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.8670 - val_loss: 8.2752\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.1185 - val_loss: 9.0504\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.2547 - val_loss: 8.3346\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.6162 - val_loss: 8.8999\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.5597 - val_loss: 9.9058\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.5586 - val_loss: 8.1433\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.0369 - val_loss: 9.6569\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.8977 - val_loss: 8.2740\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.6089 - val_loss: 9.4898\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.7279 - val_loss: 8.8397\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.6065 - val_loss: 8.8247\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.2267 - val_loss: 10.4875\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.3658 - val_loss: 8.1496\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.1433 - val_loss: 8.8787\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.6276 - val_loss: 8.8362\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.5548 - val_loss: 8.8005\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.7337 - val_loss: 8.8184\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.3043 - val_loss: 11.0794\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.9681 - val_loss: 8.5376\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.0808 - val_loss: 8.2980\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.4216 - val_loss: 9.2362\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.6438 - val_loss: 8.3177\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.6083 - val_loss: 9.4362\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.9821 - val_loss: 9.2186\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.1452 - val_loss: 8.5426\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.7084 - val_loss: 8.7918\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.1030 - val_loss: 8.8360\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.4167 - val_loss: 8.4678\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.9336 - val_loss: 11.2588\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.1394 - val_loss: 8.9041\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.9490 - val_loss: 9.9113\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf638fb160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 85 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 83.3460 - val_loss: 58.5345\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.6921 - val_loss: 8.6183\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29.4980 - val_loss: 10.8217\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20.8084 - val_loss: 24.8514\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.8393 - val_loss: 26.7088\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.0172 - val_loss: 16.0725\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.5908 - val_loss: 9.2441\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.9356 - val_loss: 9.8971\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.5048 - val_loss: 12.5246\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.5953 - val_loss: 11.1137\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.3875 - val_loss: 9.2791\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.3115 - val_loss: 9.1895\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0691 - val_loss: 10.2116\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5304 - val_loss: 7.6371\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.3281 - val_loss: 7.6918\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.5476 - val_loss: 5.8042\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3454 - val_loss: 6.4308\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.1822 - val_loss: 5.2706\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8315 - val_loss: 6.5456\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8763 - val_loss: 5.3243\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9706 - val_loss: 5.3709\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7892 - val_loss: 5.6925\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5878 - val_loss: 5.5049\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1741 - val_loss: 6.1327\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8090 - val_loss: 5.6925\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7151 - val_loss: 5.7522\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1609 - val_loss: 5.5626\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.8250 - val_loss: 6.5060\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4100 - val_loss: 5.4391\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5185 - val_loss: 5.4834\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6494 - val_loss: 5.6351\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2515 - val_loss: 6.3311\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7338 - val_loss: 5.9246\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1831 - val_loss: 5.8113\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6793 - val_loss: 5.6429\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3668 - val_loss: 5.7832\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0061 - val_loss: 5.9097\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5251 - val_loss: 6.5337\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7244 - val_loss: 5.6799\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5352 - val_loss: 5.7092\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4710 - val_loss: 5.6646\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2396 - val_loss: 5.6532\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.7581 - val_loss: 5.6160\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9735 - val_loss: 5.4917\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6233 - val_loss: 5.4588\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.8077 - val_loss: 5.5075\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4718 - val_loss: 5.5882\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2845 - val_loss: 6.9290\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1055 - val_loss: 5.4787\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6948 - val_loss: 6.1209\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4dce0820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 86 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 96.0692 - val_loss: 75.1848\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 46.3295 - val_loss: 26.8098\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35.5478 - val_loss: 14.2825\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26.0236 - val_loss: 30.9376\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23.8427 - val_loss: 31.6993\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22.0133 - val_loss: 23.4612\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18.6198 - val_loss: 14.7998\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.3991 - val_loss: 15.0038\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.2024 - val_loss: 16.6337\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.2567 - val_loss: 15.4265\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.2067 - val_loss: 10.7382\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.0242 - val_loss: 9.9769\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.0343 - val_loss: 9.2603\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6770 - val_loss: 6.3009\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.2812 - val_loss: 11.3029\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.2059 - val_loss: 6.3219\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.9651 - val_loss: 6.4599\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.0206 - val_loss: 7.3568\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.6392 - val_loss: 6.7879\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.3881 - val_loss: 7.8846\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.7962 - val_loss: 6.7940\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.0650 - val_loss: 6.1930\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.3549 - val_loss: 6.1439\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.9985 - val_loss: 6.0920\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3162 - val_loss: 6.4838\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7348 - val_loss: 6.0332\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9618 - val_loss: 6.0010\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2749 - val_loss: 7.1009\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2892 - val_loss: 6.1854\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.1574 - val_loss: 5.9547\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8899 - val_loss: 6.1116\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4769 - val_loss: 6.3078\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6577 - val_loss: 5.9788\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.3281 - val_loss: 5.8732\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.7693 - val_loss: 5.9849\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7805 - val_loss: 5.8872\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2394 - val_loss: 5.7149\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6330 - val_loss: 5.5058\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1815 - val_loss: 5.3603\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.4952 - val_loss: 5.1665\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.4175 - val_loss: 5.3328\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1562 - val_loss: 5.2424\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8271 - val_loss: 5.4126\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6082 - val_loss: 5.1764\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7900 - val_loss: 5.1672\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5553 - val_loss: 5.2281\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5526 - val_loss: 5.0295\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3969 - val_loss: 4.9714\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.8984 - val_loss: 4.9451\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4348 - val_loss: 4.8303\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfbb95bb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 87 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 81333.6562 - val_loss: 109.8753\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 130280.0234 - val_loss: 111.7681\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 84120.8516 - val_loss: 107.3989\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 31945.7891 - val_loss: 100.9494\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 86226.0703 - val_loss: 99.7937\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 65084.6914 - val_loss: 102.7841\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9752.3242 - val_loss: 103.5814\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4037.5161 - val_loss: 103.8174\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19277.0176 - val_loss: 104.7641\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43004.7891 - val_loss: 106.6137\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49444.3281 - val_loss: 104.0173\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20472.0000 - val_loss: 99.7018\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 137085.2812 - val_loss: 97.9665\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 65000.7188 - val_loss: 99.9507\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26548.1406 - val_loss: 104.2921\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48277.4492 - val_loss: 105.7064\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 68132.0391 - val_loss: 104.2277\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20295.3281 - val_loss: 101.0740\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 60322.9688 - val_loss: 100.1645\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21259.7441 - val_loss: 102.3160\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14081.8174 - val_loss: 105.3811\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 74057.1875 - val_loss: 106.1245\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40122.6562 - val_loss: 104.6480\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19291.1992 - val_loss: 99.7219\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 78862.7266 - val_loss: 97.0664\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 115651.2344 - val_loss: 100.1746\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23783.6328 - val_loss: 101.3442\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37282.2109 - val_loss: 102.5059\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3090.0454 - val_loss: 101.8463\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35164.4961 - val_loss: 101.9835\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28598.9629 - val_loss: 104.5717\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64931.7617 - val_loss: 105.5178\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20769.2676 - val_loss: 103.8566\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27620.8613 - val_loss: 101.8313\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2984.7500 - val_loss: 103.1173\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27489.1445 - val_loss: 103.3253\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11811.6699 - val_loss: 102.1487\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12925.6123 - val_loss: 101.9098\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30101.8750 - val_loss: 103.0902\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28841.1055 - val_loss: 103.4891\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11761.7432 - val_loss: 102.2023\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 48612.4883 - val_loss: 100.3186\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11517.9893 - val_loss: 102.3519\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5583.7456 - val_loss: 105.0116\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30844.3984 - val_loss: 105.2990\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 64559.4883 - val_loss: 103.9760\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1309.1846 - val_loss: 103.6941\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15125.1445 - val_loss: 104.8832\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44554.0586 - val_loss: 105.4260\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 81961.9062 - val_loss: 104.4523\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf55df9b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 88 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 29295.1113 - val_loss: 90.8377\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15587.1152 - val_loss: 92.5585\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24421.3477 - val_loss: 90.0349\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47454.1953 - val_loss: 90.0013\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13045.6426 - val_loss: 94.6460\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 74936.9297 - val_loss: 94.8117\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 49214.2461 - val_loss: 93.0888\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10858.8916 - val_loss: 88.0655\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 144645.1406 - val_loss: 86.9890\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 121024.4219 - val_loss: 88.6408\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 100569.4531 - val_loss: 92.2603\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19372.8652 - val_loss: 93.2002\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24797.1582 - val_loss: 91.9465\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21048.2031 - val_loss: 92.3105\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5804.1553 - val_loss: 90.9537\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44307.4766 - val_loss: 90.8656\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40847.4883 - val_loss: 92.8749\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50427.5234 - val_loss: 93.8469\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 60078.5078 - val_loss: 91.8135\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48117.1875 - val_loss: 90.9555\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27497.9727 - val_loss: 93.1855\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29106.3887 - val_loss: 93.4602\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24826.2422 - val_loss: 93.0551\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29816.9180 - val_loss: 92.5266\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9200.3945 - val_loss: 94.4973\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 70677.3438 - val_loss: 95.2101\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38681.9805 - val_loss: 94.4874\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15809.7520 - val_loss: 93.3709\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8380.9238 - val_loss: 90.4739\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 114515.0156 - val_loss: 89.6595\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 172980.7969 - val_loss: 90.8326\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 112080.5234 - val_loss: 92.5810\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 75940.3359 - val_loss: 94.6384\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29181.0137 - val_loss: 95.8811\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29682.0723 - val_loss: 94.8890\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10108.2891 - val_loss: 92.9722\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49474.2812 - val_loss: 92.7987\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 60054.9258 - val_loss: 93.8708\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28265.9629 - val_loss: 95.2588\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15904.4189 - val_loss: 96.1426\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1291.6027 - val_loss: 95.2126\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 53081.1328 - val_loss: 94.8360\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28797.6543 - val_loss: 95.4066\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4491.3989 - val_loss: 95.9169\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 781.0249 - val_loss: 96.1552\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20543.4316 - val_loss: 95.3024\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41121.8477 - val_loss: 95.6052\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11905.0771 - val_loss: 94.9165\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31391.2734 - val_loss: 95.1102\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21826.5566 - val_loss: 96.5028\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf3f5f5b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 89 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 80.3661 - val_loss: 62.7875\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38.8596 - val_loss: 20.6428\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30.1691 - val_loss: 25.1633\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24.9637 - val_loss: 31.7838\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.9519 - val_loss: 25.4750\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20.8882 - val_loss: 14.5113\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.5701 - val_loss: 17.0097\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.3536 - val_loss: 15.9125\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.0592 - val_loss: 9.9534\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.1391 - val_loss: 10.9483\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.7758 - val_loss: 7.4853\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.3626 - val_loss: 9.1292\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.2503 - val_loss: 5.8537\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.1204 - val_loss: 8.4200\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.9382 - val_loss: 5.5751\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.8102 - val_loss: 7.1397\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.3349 - val_loss: 10.3623\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.7604 - val_loss: 5.2011\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.8115 - val_loss: 9.1150\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.7746 - val_loss: 7.7472\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.4985 - val_loss: 7.2690\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.6688 - val_loss: 7.3955\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.5636 - val_loss: 5.5094\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.0909 - val_loss: 7.7195\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.4294 - val_loss: 5.1813\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.3241 - val_loss: 8.4935\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.0466 - val_loss: 5.8839\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.8419 - val_loss: 5.5448\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.6171 - val_loss: 8.9646\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.9019 - val_loss: 5.7540\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.9982 - val_loss: 5.0512\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7670 - val_loss: 6.7448\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.6625 - val_loss: 7.0446\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.7566 - val_loss: 6.0266\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.8126 - val_loss: 5.9965\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.5275 - val_loss: 5.7461\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8009 - val_loss: 6.5711\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8728 - val_loss: 4.9865\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.4766 - val_loss: 5.4014\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8427 - val_loss: 5.9652\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.6003 - val_loss: 5.5247\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.0266 - val_loss: 5.2953\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6752 - val_loss: 5.6106\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4986 - val_loss: 5.3879\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2535 - val_loss: 5.7827\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.9895 - val_loss: 5.2404\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.2942 - val_loss: 5.6132\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.6065 - val_loss: 6.8124\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.5218 - val_loss: 5.1186\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.2116 - val_loss: 5.4814\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf411f5820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 90 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 1147.1377 - val_loss: 121.1877\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 233850.3438 - val_loss: 125.0451\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 246136.7656 - val_loss: 115.8153\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 56206.7031 - val_loss: 108.2318\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16463.8184 - val_loss: 105.7937\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 21736.9160 - val_loss: 107.6243\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20115.7871 - val_loss: 107.8311\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4835.0210 - val_loss: 109.0038\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 28186.9941 - val_loss: 107.7688\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16618.2031 - val_loss: 107.3610\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10508.8916 - val_loss: 112.2334\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 95026.4688 - val_loss: 113.1255\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 97315.3047 - val_loss: 110.2711\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 76151.1484 - val_loss: 105.9966\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 35969.6367 - val_loss: 104.7448\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 42326.3164 - val_loss: 106.5547\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15863.9043 - val_loss: 106.2641\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 2465.8008 - val_loss: 108.2098\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 40913.2891 - val_loss: 106.9038\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 31021.6406 - val_loss: 104.3232\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 54414.3320 - val_loss: 103.9300\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23287.2734 - val_loss: 106.4791\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 71928.0938 - val_loss: 106.6740\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13609.5693 - val_loss: 105.2698\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 41143.5117 - val_loss: 105.4371\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3437.2959 - val_loss: 104.3597\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 51814.4688 - val_loss: 105.5226\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 21942.1719 - val_loss: 108.2106\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 60277.2227 - val_loss: 108.0888\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 30209.0762 - val_loss: 105.9369\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 303.8893 - val_loss: 106.2875\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 37308.2031 - val_loss: 107.7058\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 46657.9844 - val_loss: 108.6290\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 49457.5195 - val_loss: 106.0881\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6166.3315 - val_loss: 106.5304\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 22149.0059 - val_loss: 105.1697\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 23324.1406 - val_loss: 104.5716\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 12734.1221 - val_loss: 106.5262\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 34931.1094 - val_loss: 107.2295\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 33237.1562 - val_loss: 104.9825\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 37602.4844 - val_loss: 104.2795\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 2080.1340 - val_loss: 105.1918\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 22551.6660 - val_loss: 104.9273\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 20071.5938 - val_loss: 104.7821\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 42916.1367 - val_loss: 104.3733\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 30438.7266 - val_loss: 106.4306\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12858.4199 - val_loss: 105.6764\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7781.9819 - val_loss: 103.9596\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1240.7650 - val_loss: 104.1786\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 6402.5410 - val_loss: 105.7808\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7b97c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 91 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 242ms/step - loss: 83.7232 - val_loss: 67.2321\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 59.2986 - val_loss: 55.5109\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 45.4741 - val_loss: 43.9819\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 37.0883 - val_loss: 38.2520\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 31.3535 - val_loss: 35.3697\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 26.9020 - val_loss: 24.4013\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 19.4368 - val_loss: 12.9866\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 17.2388 - val_loss: 6.8890\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 16.2155 - val_loss: 7.2131\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 16.7460 - val_loss: 5.9015\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.7660 - val_loss: 6.9846\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.1642 - val_loss: 6.7197\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.1504 - val_loss: 5.9179\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.9701 - val_loss: 5.5734\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 13.8143 - val_loss: 5.5219\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.1955 - val_loss: 6.0376\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.0637 - val_loss: 5.4692\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.5716 - val_loss: 5.2145\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.4388 - val_loss: 5.1185\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.7219 - val_loss: 6.5245\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 12.6325 - val_loss: 6.1780\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.9239 - val_loss: 5.0376\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.2925 - val_loss: 5.0446\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.1527 - val_loss: 5.0844\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.7126 - val_loss: 4.9689\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.8734 - val_loss: 6.6551\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.1172 - val_loss: 5.6049\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.9037 - val_loss: 4.8578\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.2912 - val_loss: 9.1790\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.7868 - val_loss: 4.8220\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.3578 - val_loss: 7.4699\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.3793 - val_loss: 4.5778\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.5428 - val_loss: 5.2882\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.1776 - val_loss: 6.9764\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.8566 - val_loss: 4.6395\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.5259 - val_loss: 4.4159\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.0951 - val_loss: 4.6977\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.3369 - val_loss: 7.0542\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.7929 - val_loss: 4.4520\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.7144 - val_loss: 5.3281\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 12.4159 - val_loss: 4.3520\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.3041 - val_loss: 6.1044\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.8007 - val_loss: 4.2875\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.5313 - val_loss: 5.1714\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.1972 - val_loss: 4.2822\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.7437 - val_loss: 4.1118\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.5016 - val_loss: 4.1722\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.9436 - val_loss: 4.6502\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.3413 - val_loss: 5.0596\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.2393 - val_loss: 4.2911\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4290a940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 92 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 96.8690 - val_loss: 75.5888\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 53.1198 - val_loss: 34.4790\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 29.2290 - val_loss: 3.5718\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28.5192 - val_loss: 10.4144\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 21.6327 - val_loss: 25.0050\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 20.4086 - val_loss: 19.9127\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.2977 - val_loss: 7.6716\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.7489 - val_loss: 6.0308\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.1446 - val_loss: 12.3479\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.1299 - val_loss: 7.4417\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.3757 - val_loss: 4.4290\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.3268 - val_loss: 4.8103\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.6841 - val_loss: 6.1019\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.5737 - val_loss: 4.7297\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.2728 - val_loss: 4.6883\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.9445 - val_loss: 4.6143\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.1887 - val_loss: 6.7818\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 11.5881 - val_loss: 4.4892\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.5890 - val_loss: 4.7433\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1330 - val_loss: 6.1798\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6351 - val_loss: 4.6213\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 9.9045 - val_loss: 4.5380\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.4767 - val_loss: 4.6740\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.9504 - val_loss: 4.5084\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 8.8228 - val_loss: 5.6253\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 9.9751 - val_loss: 4.9003\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 8.9979 - val_loss: 4.6060\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 7.8391 - val_loss: 4.5697\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 8.3874 - val_loss: 4.1637\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.7540 - val_loss: 4.2787\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.4757 - val_loss: 3.8237\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.6233 - val_loss: 3.9482\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.4334 - val_loss: 3.7712\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.7610 - val_loss: 3.7084\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.5613 - val_loss: 4.1102\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4291 - val_loss: 3.6958\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.2007 - val_loss: 3.5822\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 7.5477 - val_loss: 3.5562\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.4985 - val_loss: 3.4296\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.7511 - val_loss: 3.9376\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.7641 - val_loss: 4.7366\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.4140 - val_loss: 4.6655\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.4555 - val_loss: 4.2245\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.9203 - val_loss: 4.4104\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 7.0235 - val_loss: 4.2478\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.3837 - val_loss: 4.3325\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.4142 - val_loss: 4.4651\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.8749 - val_loss: 3.5943\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8756 - val_loss: 3.2537\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1598 - val_loss: 3.9593\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf53bb55e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 93 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 107ms/step - loss: 82.1479 - val_loss: 66.1045\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 52.2594 - val_loss: 42.4215\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45.5627 - val_loss: 47.6950\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38.9776 - val_loss: 48.7929\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36.6673 - val_loss: 39.4133\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30.6019 - val_loss: 27.8934\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27.4214 - val_loss: 22.8192\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24.7666 - val_loss: 19.8665\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22.0456 - val_loss: 11.2950\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.7831 - val_loss: 13.7532\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19.6368 - val_loss: 10.0469\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.4870 - val_loss: 9.4484\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.2430 - val_loss: 12.3732\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.3442 - val_loss: 10.0056\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.8251 - val_loss: 5.6042\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.7418 - val_loss: 6.0249\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.1689 - val_loss: 7.9539\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.5928 - val_loss: 4.2743\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.6481 - val_loss: 10.2291\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.5600 - val_loss: 2.5496\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.2072 - val_loss: 3.6153\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.5550 - val_loss: 5.3816\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.6949 - val_loss: 3.1711\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.6018 - val_loss: 5.4524\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.5186 - val_loss: 4.7476\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.2819 - val_loss: 3.3262\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.7247 - val_loss: 3.2926\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.1801 - val_loss: 3.1827\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.3712 - val_loss: 4.1508\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.6329 - val_loss: 3.6172\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.0123 - val_loss: 6.3053\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.6352 - val_loss: 3.4084\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.6626 - val_loss: 2.5815\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.3977 - val_loss: 5.6882\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.3615 - val_loss: 4.9608\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.9345 - val_loss: 5.0917\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.5548 - val_loss: 2.4607\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.5770 - val_loss: 2.8103\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.4977 - val_loss: 4.1184\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.9006 - val_loss: 3.4286\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.3690 - val_loss: 3.4668\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.5409 - val_loss: 3.0010\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.1243 - val_loss: 2.5277\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9757 - val_loss: 4.3699\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3638 - val_loss: 2.5853\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.4873 - val_loss: 2.9658\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.0339 - val_loss: 2.8056\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.0846 - val_loss: 2.3326\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.4028 - val_loss: 5.6996\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4653 - val_loss: 2.5108\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4f9b7670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 94 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 69.6709 - val_loss: 46.6761\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30.3308 - val_loss: 6.7670\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31.1407 - val_loss: 10.8272\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.2751 - val_loss: 24.5402\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20.8937 - val_loss: 17.8519\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16.9597 - val_loss: 6.0539\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.2472 - val_loss: 5.4068\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.8800 - val_loss: 8.7511\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.2672 - val_loss: 8.2209\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.3860 - val_loss: 5.3460\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.3093 - val_loss: 7.1316\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.6939 - val_loss: 8.4514\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1230 - val_loss: 6.1956\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.1333 - val_loss: 5.7284\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8908 - val_loss: 5.4128\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8997 - val_loss: 5.2438\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4895 - val_loss: 5.1983\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6637 - val_loss: 5.2360\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.3050 - val_loss: 4.8531\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.3190 - val_loss: 4.7404\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5310 - val_loss: 4.7137\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3363 - val_loss: 6.0347\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0445 - val_loss: 4.6511\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4923 - val_loss: 4.5548\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6311 - val_loss: 4.4349\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5963 - val_loss: 5.7793\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5314 - val_loss: 4.3798\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6706 - val_loss: 4.3205\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7462 - val_loss: 4.3969\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9673 - val_loss: 4.5047\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6924 - val_loss: 4.5297\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8506 - val_loss: 4.1383\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3346 - val_loss: 4.1760\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9372 - val_loss: 4.1344\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9734 - val_loss: 5.0441\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8328 - val_loss: 4.7120\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6140 - val_loss: 4.0565\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1654 - val_loss: 5.3195\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.3828 - val_loss: 5.7749\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5564 - val_loss: 3.9536\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8377 - val_loss: 3.9876\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3175 - val_loss: 3.6934\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9472 - val_loss: 4.2712\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.9327 - val_loss: 3.9866\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1569 - val_loss: 3.6824\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6198 - val_loss: 3.7699\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3035 - val_loss: 4.4209\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5135 - val_loss: 4.4058\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1920 - val_loss: 5.5903\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8490 - val_loss: 4.2660\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf8669c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 95 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 113ms/step - loss: 80.0381 - val_loss: 61.0676\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45.3358 - val_loss: 22.3843\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41.2922 - val_loss: 30.7914\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 32.8900 - val_loss: 37.3791\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30.6638 - val_loss: 31.7503\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26.1935 - val_loss: 21.3087\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.9985 - val_loss: 18.8361\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20.8409 - val_loss: 17.6942\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.2213 - val_loss: 10.9248\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17.4682 - val_loss: 8.6801\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.3681 - val_loss: 8.1248\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.1820 - val_loss: 8.9537\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.4823 - val_loss: 6.7989\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.1114 - val_loss: 6.9420\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.8121 - val_loss: 6.8664\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.6308 - val_loss: 6.6349\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.7614 - val_loss: 6.4323\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.3650 - val_loss: 6.4677\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.6937 - val_loss: 5.5434\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.3525 - val_loss: 5.5951\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.8433 - val_loss: 5.0306\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.7393 - val_loss: 6.8818\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.9094 - val_loss: 5.3693\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.6542 - val_loss: 6.1285\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.7966 - val_loss: 4.6418\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.2664 - val_loss: 8.4386\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.3096 - val_loss: 4.8675\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.4279 - val_loss: 5.2644\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.6956 - val_loss: 9.6759\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.6417 - val_loss: 4.9972\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.6242 - val_loss: 8.7050\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.5815 - val_loss: 6.5659\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.5492 - val_loss: 4.5610\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.1110 - val_loss: 6.8055\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.6100 - val_loss: 4.4763\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.2730 - val_loss: 5.8818\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.1742 - val_loss: 4.2741\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.9502 - val_loss: 9.1754\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.5799 - val_loss: 4.0202\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.8538 - val_loss: 5.1361\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.5974 - val_loss: 6.1204\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.7501 - val_loss: 4.5493\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.1414 - val_loss: 5.9638\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.2303 - val_loss: 5.2349\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.6755 - val_loss: 4.0683\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.0595 - val_loss: 5.2573\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.5981 - val_loss: 6.4139\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.9699 - val_loss: 4.6316\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.0713 - val_loss: 4.5326\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.2451 - val_loss: 3.8363\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7eae78b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 96 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 89.9221 - val_loss: 66.5616\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38.3985 - val_loss: 17.9562\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23.6315 - val_loss: 7.5925\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18.1570 - val_loss: 23.7068\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.7289 - val_loss: 25.7064\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.8665 - val_loss: 17.6537\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.5782 - val_loss: 14.7329\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.7696 - val_loss: 18.4866\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.6282 - val_loss: 17.2139\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.2728 - val_loss: 12.1036\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.6908 - val_loss: 10.9026\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.5640 - val_loss: 12.2352\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7411 - val_loss: 11.3869\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1608 - val_loss: 8.9070\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0788 - val_loss: 7.5763\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9505 - val_loss: 7.6757\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5632 - val_loss: 6.3281\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1180 - val_loss: 8.0619\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6073 - val_loss: 5.2329\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5802 - val_loss: 10.7195\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6858 - val_loss: 2.5801\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.4617 - val_loss: 7.3271\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.1865 - val_loss: 2.9175\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6010 - val_loss: 5.0376\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8174 - val_loss: 5.0743\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7301 - val_loss: 2.7529\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0299 - val_loss: 5.7775\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1785 - val_loss: 2.6842\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4021 - val_loss: 4.4326\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0819 - val_loss: 3.4819\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1459 - val_loss: 2.6860\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7722 - val_loss: 2.6906\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.5741 - val_loss: 2.7220\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7469 - val_loss: 3.1045\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3980 - val_loss: 2.9305\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4684 - val_loss: 2.8593\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9658 - val_loss: 3.0223\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3156 - val_loss: 4.3927\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.8743 - val_loss: 2.8217\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.1566 - val_loss: 3.5324\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5874 - val_loss: 2.2575\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0044 - val_loss: 2.8192\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4155 - val_loss: 3.1846\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6118 - val_loss: 2.1098\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2322 - val_loss: 3.2746\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5127 - val_loss: 2.0755\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3981 - val_loss: 4.0814\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0692 - val_loss: 3.4476\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9011 - val_loss: 3.5708\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8617 - val_loss: 2.1571\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf904fd820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 97 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 82.4372 - val_loss: 55.1679\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31.9909 - val_loss: 2.2617\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24.1872 - val_loss: 2.1778\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16.4231 - val_loss: 17.9952\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16.4024 - val_loss: 19.6542\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.6716 - val_loss: 7.3063\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.0943 - val_loss: 2.2241\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.6082 - val_loss: 9.1202\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.1813 - val_loss: 9.8053\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.0284 - val_loss: 4.1113\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.7966 - val_loss: 6.6475\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6425 - val_loss: 2.8220\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9294 - val_loss: 6.5828\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4936 - val_loss: 2.8912\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6141 - val_loss: 2.5091\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.5674 - val_loss: 4.2763\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.5434 - val_loss: 3.1536\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6576 - val_loss: 2.9494\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3418 - val_loss: 3.6667\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.5048 - val_loss: 2.5002\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3828 - val_loss: 2.8625\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5655 - val_loss: 2.5476\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4663 - val_loss: 3.3397\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0812 - val_loss: 2.5524\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2388 - val_loss: 2.5496\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2939 - val_loss: 2.6485\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6692 - val_loss: 2.5270\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0016 - val_loss: 2.7188\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7284 - val_loss: 3.2996\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7015 - val_loss: 3.5286\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5954 - val_loss: 3.2477\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.7462 - val_loss: 2.6767\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7233 - val_loss: 3.1666\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9390 - val_loss: 2.5860\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9837 - val_loss: 4.1511\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6565 - val_loss: 2.7522\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4194 - val_loss: 2.7583\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2258 - val_loss: 2.6369\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.4423 - val_loss: 3.2773\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4722 - val_loss: 2.5090\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4553 - val_loss: 2.5799\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5820 - val_loss: 2.4607\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2695 - val_loss: 2.6124\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6964 - val_loss: 2.7145\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4644 - val_loss: 2.5634\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5147 - val_loss: 2.5993\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7962 - val_loss: 2.4971\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9818 - val_loss: 2.6221\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8325 - val_loss: 3.3458\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9011 - val_loss: 2.6179\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5d3a8280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 98 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 98ms/step - loss: 73.3386 - val_loss: 46.7441\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38.6102 - val_loss: 18.4502\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33.0859 - val_loss: 21.2394\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26.2896 - val_loss: 28.9981\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.9556 - val_loss: 15.6452\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.4915 - val_loss: 14.3806\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.8153 - val_loss: 18.6685\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.6625 - val_loss: 12.4510\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.1549 - val_loss: 10.6462\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.0955 - val_loss: 14.5091\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.9709 - val_loss: 10.8012\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.3047 - val_loss: 11.6557\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.1588 - val_loss: 10.6855\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.7764 - val_loss: 10.7003\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.3898 - val_loss: 10.5985\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.3468 - val_loss: 11.7678\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.3309 - val_loss: 9.8466\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.4911 - val_loss: 10.6918\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.8252 - val_loss: 12.1188\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.2203 - val_loss: 9.5484\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.1039 - val_loss: 10.6793\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.4513 - val_loss: 9.9756\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.8877 - val_loss: 9.4514\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.9924 - val_loss: 9.6289\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.4364 - val_loss: 9.1121\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.1141 - val_loss: 10.9794\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.2554 - val_loss: 9.6129\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.4233 - val_loss: 10.2622\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.1613 - val_loss: 10.0365\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.7565 - val_loss: 9.0022\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.2382 - val_loss: 8.9029\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.0080 - val_loss: 8.6733\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.6443 - val_loss: 10.2493\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.3183 - val_loss: 8.7754\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.9820 - val_loss: 9.1210\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.7401 - val_loss: 8.5278\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.1798 - val_loss: 8.5492\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.5882 - val_loss: 10.2591\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.5149 - val_loss: 8.6762\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.7034 - val_loss: 9.1962\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.1566 - val_loss: 8.3384\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.7249 - val_loss: 8.6156\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.1204 - val_loss: 8.3240\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5690 - val_loss: 8.1052\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.7794 - val_loss: 8.2555\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.8964 - val_loss: 8.1601\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5821 - val_loss: 8.3068\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.4557 - val_loss: 8.3235\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.1812 - val_loss: 7.8427\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9291 - val_loss: 10.1017\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf51982550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 99 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 99258.3984 - val_loss: 117.3531\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 124374.9766 - val_loss: 120.8818\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 79785.1875 - val_loss: 112.8098\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54994.4023 - val_loss: 110.1888\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33712.2188 - val_loss: 113.0668\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 60780.5195 - val_loss: 114.2176\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27020.2422 - val_loss: 110.1319\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 78772.8516 - val_loss: 106.4136\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 80368.8984 - val_loss: 108.3415\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20602.1719 - val_loss: 110.1896\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49402.9570 - val_loss: 112.5523\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 53904.4219 - val_loss: 110.6802\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6257.0029 - val_loss: 107.8039\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35825.9766 - val_loss: 107.3555\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32853.4688 - val_loss: 108.1245\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16994.7031 - val_loss: 112.5460\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 99223.2969 - val_loss: 114.8230\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 125948.2266 - val_loss: 112.4462\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 43373.9180 - val_loss: 108.5788\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23281.7207 - val_loss: 107.1357\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26077.7695 - val_loss: 108.6258\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1134.9889 - val_loss: 107.7582\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1558.2302 - val_loss: 105.4595\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36618.4688 - val_loss: 105.6626\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26175.4121 - val_loss: 106.7766\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14043.8828 - val_loss: 110.5577\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 67060.9766 - val_loss: 111.1152\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 78124.3125 - val_loss: 110.3463\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 61179.9258 - val_loss: 108.3379\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17468.2344 - val_loss: 105.2256\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 85905.3984 - val_loss: 103.7085\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 71153.0781 - val_loss: 105.7391\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40188.3008 - val_loss: 108.6910\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23548.6094 - val_loss: 108.8704\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 55788.9688 - val_loss: 108.0894\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22349.7246 - val_loss: 107.0701\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2183.8105 - val_loss: 106.4680\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6643.8677 - val_loss: 106.9356\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22972.6836 - val_loss: 107.2886\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5358.3340 - val_loss: 106.4823\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25476.7441 - val_loss: 107.0601\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9136.0791 - val_loss: 104.4782\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54956.4609 - val_loss: 104.0720\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12687.4512 - val_loss: 105.1543\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22835.6016 - val_loss: 107.6463\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 56994.4922 - val_loss: 108.4956\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28945.2695 - val_loss: 105.6083\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30265.8652 - val_loss: 104.3564\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22559.9023 - val_loss: 106.0509\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9850.8057 - val_loss: 109.0910\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf82ed9310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 100 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 98.4294 - val_loss: 75.5908\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 53.8746 - val_loss: 34.6136\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.4599 - val_loss: 8.4376\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.8488 - val_loss: 12.7107\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.7394 - val_loss: 24.5008\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.9947 - val_loss: 17.7248\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.8412 - val_loss: 8.3115\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.5992 - val_loss: 10.0691\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.6180 - val_loss: 15.5837\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.8267 - val_loss: 13.4387\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.0667 - val_loss: 8.1638\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.2942 - val_loss: 7.6136\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.5925 - val_loss: 12.6374\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9742 - val_loss: 9.9429\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6602 - val_loss: 5.6858\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9119 - val_loss: 8.2980\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0199 - val_loss: 6.9190\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4926 - val_loss: 7.7647\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8987 - val_loss: 4.1728\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.5525 - val_loss: 8.2573\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8373 - val_loss: 4.4592\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1926 - val_loss: 4.1823\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5361 - val_loss: 4.5973\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1866 - val_loss: 4.0321\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2577 - val_loss: 5.0834\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.8305 - val_loss: 4.2562\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3446 - val_loss: 4.7689\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0647 - val_loss: 4.1355\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2177 - val_loss: 5.0666\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2193 - val_loss: 4.0699\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4945 - val_loss: 4.1637\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5360 - val_loss: 4.4705\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5142 - val_loss: 4.3318\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4662 - val_loss: 4.6683\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7497 - val_loss: 4.2314\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5088 - val_loss: 4.3225\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4669 - val_loss: 4.2057\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8985 - val_loss: 5.2303\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1553 - val_loss: 4.4204\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0097 - val_loss: 4.7474\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0105 - val_loss: 4.3466\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.3043 - val_loss: 4.1321\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4612 - val_loss: 3.9730\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.0747 - val_loss: 5.3017\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.9748 - val_loss: 4.0292\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7278 - val_loss: 4.4388\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6036 - val_loss: 4.4978\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2174 - val_loss: 4.1566\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7424 - val_loss: 4.8693\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5392 - val_loss: 3.9090\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7e4515e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 101 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 80.9173 - val_loss: 59.5744\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42.1216 - val_loss: 21.9637\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 36.1608 - val_loss: 33.6596\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.6063 - val_loss: 40.5411\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28.2896 - val_loss: 30.3981\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23.2153 - val_loss: 16.1415\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21.1752 - val_loss: 17.2224\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16.1543 - val_loss: 15.5231\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.6008 - val_loss: 6.9225\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.0611 - val_loss: 7.9110\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.6854 - val_loss: 5.5074\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.8998 - val_loss: 8.9274\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.1269 - val_loss: 8.2564\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.0698 - val_loss: 6.9171\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.7662 - val_loss: 2.6327\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.5027 - val_loss: 6.5930\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.6927 - val_loss: 2.2211\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.0228 - val_loss: 5.4449\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.4919 - val_loss: 2.1605\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.2908 - val_loss: 6.4931\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.5605 - val_loss: 2.3599\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.7997 - val_loss: 7.4643\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.3652 - val_loss: 1.6686\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.5575 - val_loss: 4.3507\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5951 - val_loss: 2.8583\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5013 - val_loss: 3.8231\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9415 - val_loss: 1.3991\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.1477 - val_loss: 2.0491\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.5996 - val_loss: 3.2906\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.6962 - val_loss: 1.3655\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7811 - val_loss: 4.0461\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3863 - val_loss: 1.7751\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.7598 - val_loss: 2.8386\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9543 - val_loss: 2.8202\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6408 - val_loss: 2.7199\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5575 - val_loss: 4.2316\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.5001 - val_loss: 1.4730\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.6082 - val_loss: 4.3611\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9419 - val_loss: 2.2763\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1301 - val_loss: 3.8639\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.5876 - val_loss: 2.7266\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1272 - val_loss: 1.4240\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3323 - val_loss: 3.8455\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8416 - val_loss: 1.4427\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7252 - val_loss: 2.0167\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0721 - val_loss: 4.2683\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9207 - val_loss: 1.6124\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9809 - val_loss: 2.3916\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2949 - val_loss: 1.8822\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2960 - val_loss: 2.8187\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf407f5430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 102 finished\n"
     ]
    }
   ],
   "source": [
    "zipcodes = nv_zipcodes\n",
    "dict_mape3 = {}\n",
    "dict_pred3 = {}\n",
    "\n",
    "for zipcode in range(len(zipcodes)):\n",
    "\n",
    "    # init a RMM model\n",
    "    rnn_model = Sequential()\n",
    "    # add 4 layers of RNN and a last layer\n",
    "\n",
    "    # we define shape on first layer, (60,1) because we use 60 inputs per prediction\n",
    "    rnn_model.add(LSTM(units= 60, return_sequences = False, input_shape=((60,1))))\n",
    "    rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # 3 other layers\n",
    "    #rnn_model.add(LSTM(units= 30, return_sequences = True))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # return_sequence is False because we want only 1 output after this layer\n",
    "    #rnn_model.add(LSTM(units= 60, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # last layer \n",
    "\n",
    "    rnn_model.add(Dense(units=1))\n",
    "\n",
    "    # compile - because this is a regression model we want to minimize MSE\n",
    "\n",
    "    rnn_model.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "\n",
    "    # We get only the specific column(Zipcode from our train and test datas)\n",
    "    train_data = train.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    test_data = test.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # We are using normalizaion rather than standascaler. \n",
    "    # In a upward trending timeseries it is better to not start from negative\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Because we are using 60 previous values to model and predict the next value, \n",
    "    # We set X_train from arrays of 60 for each y_train value\n",
    "    # Same idea for test data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(train_data_scaled)):\n",
    "        X_train.append(train_data_scaled[i-60:i])\n",
    "        y_train.append(train_data_scaled[i])\n",
    "\n",
    "    data_total = pd.concat((train.iloc[:,zipcode:zipcode+1], test.iloc[:,zipcode:zipcode+1]),axis=0)\n",
    "    inputs = data_total[len(train)-60:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(60,len(inputs)):\n",
    "        X_test.append(inputs[i-60:i])\n",
    "        y_test.append(inputs[i])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(test_data)\n",
    "\n",
    "    # We need numpy arrays for our model\n",
    "    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # We fit our data to our zipcode specific data\n",
    "    rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, scaler.transform(y_test)))\n",
    "\n",
    "    # Make predictions on the data\n",
    "\n",
    "    y_hat_raw = rnn_model.predict(X_test)\n",
    "    y_hat = scaler.inverse_transform(y_hat_raw)\n",
    "\n",
    "    # Use the score on unseen test data to calculate the MAPE\n",
    "\n",
    "    dict_mape3[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_test)/y_test))      \n",
    "\n",
    "    # We get the last 60 values from our test data which is basically last 60 values in the data set\n",
    "    last_60 = df_time_series.iloc[-60:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # Before we use our data we scale it\n",
    "    last_60 = scaler.transform(last_60)\n",
    "    \n",
    "    # Our input should be in (x,60,1) format\n",
    "    x_new_pred = last_60[-60:].reshape(1,60,1)\n",
    "\n",
    "    # make a prediction, add to the last_60 for the next prediction and \n",
    "    y_pred = rnn_model.predict(x_new_pred)\n",
    "\n",
    "    # We add our predition to our list of predictions for zipcode specific predictions list\n",
    "    dict_pred3[zipcodes[zipcode]]=scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(f'Iteration number {zipcode} finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_keys3 = list(dict_mape3.keys())\n",
    "rnn_mape3 = list(dict_mape3.values())\n",
    "rnn_pred3 = []\n",
    "rnn_dict3 = {}\n",
    "for zipcode in dict_pred.keys():\n",
    "    rnn_pred3.append(dict_pred3[zipcode].astype(int)[0][0])\n",
    "for zc in rnn_keys3:\n",
    "    a = []\n",
    "    a.append(dict_mape3[zc])\n",
    "    a.append(dict_pred3[zc].astype(float)[0][0])\n",
    "    a.append('RNN_w/_D.o.')\n",
    "    rnn_dict3[zc] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20615423245296247"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_mape3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 204ms/step - loss: 234627.2656 - val_loss: 108.0782\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 87520.8516 - val_loss: 109.1298\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11603.6758 - val_loss: 98.8315\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 192975.8125 - val_loss: 95.4436\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 104755.2734 - val_loss: 99.8683\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25568.2480 - val_loss: 106.4565\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 98417.2188 - val_loss: 109.3366\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 109331.9219 - val_loss: 107.7963\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3524.3215 - val_loss: 104.3141\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 102540.1484 - val_loss: 100.9593\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 111772.1328 - val_loss: 102.0068\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2979.5508 - val_loss: 104.1795\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 44385.2148 - val_loss: 104.6547\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9660.9209 - val_loss: 102.9972\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47661.8164 - val_loss: 102.8103\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25546.1934 - val_loss: 104.6062\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 179734.1250 - val_loss: 105.7449\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12894.6689 - val_loss: 102.8031\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 65363.4414 - val_loss: 102.0974\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 559.5097 - val_loss: 100.8246\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 131894.5156 - val_loss: 101.2260\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 85238.2031 - val_loss: 107.9800\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 61211.5469 - val_loss: 109.2327\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 83670.5234 - val_loss: 107.3826\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17321.3828 - val_loss: 104.2918\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26480.4004 - val_loss: 103.3685\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31951.7500 - val_loss: 104.6636\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18727.8828 - val_loss: 103.9075\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22910.0762 - val_loss: 105.6710\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23677.1309 - val_loss: 104.6141\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18353.3555 - val_loss: 104.4763\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15406.8408 - val_loss: 104.2223\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26464.9609 - val_loss: 100.8229\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 114357.1328 - val_loss: 99.0906\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 76653.6484 - val_loss: 100.6205\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 54709.5664 - val_loss: 106.6482\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 123075.7891 - val_loss: 108.4962\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 131137.1094 - val_loss: 105.9344\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 76983.3984 - val_loss: 102.9915\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32216.1680 - val_loss: 101.3414\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15526.7979 - val_loss: 103.1361\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 41002.0781 - val_loss: 104.2466\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 61444.2773 - val_loss: 102.5627\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38720.6367 - val_loss: 101.1944\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23780.9160 - val_loss: 103.5954\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 56388.8477 - val_loss: 103.8038\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 65331.0938 - val_loss: 103.0132\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38491.1562 - val_loss: 102.2833\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9268.4873 - val_loss: 104.3604\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 65404.6914 - val_loss: 104.6598\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf476151f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 0 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 363504.6250 - val_loss: 85.2714\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 199537.0469 - val_loss: 76.5473\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 332224.6250 - val_loss: 83.3850\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 126093.8125 - val_loss: 88.8230\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 45400.4102 - val_loss: 88.2966\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 172332.3594 - val_loss: 85.1949\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 332642.4688 - val_loss: 87.9196\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 165909.6875 - val_loss: 95.5954\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 259849.9688 - val_loss: 96.8569\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 150897.9062 - val_loss: 93.7161\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 119279.3047 - val_loss: 92.1358\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 101362.6016 - val_loss: 95.1242\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 188301.1719 - val_loss: 96.1168\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 129106.7656 - val_loss: 93.4041\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 128477.7266 - val_loss: 92.9816\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 61407.4023 - val_loss: 95.8909\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 95047.9062 - val_loss: 96.0901\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 57850.2969 - val_loss: 94.0364\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 161708.3125 - val_loss: 92.9473\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28158.9434 - val_loss: 96.5550\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 125226.6953 - val_loss: 97.0240\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 70747.0156 - val_loss: 95.5694\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 79504.6562 - val_loss: 94.4101\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 124569.1875 - val_loss: 96.3749\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35557.8438 - val_loss: 96.2939\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 52612.8398 - val_loss: 95.3075\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 49211.0508 - val_loss: 94.1757\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 61134.1172 - val_loss: 95.0053\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 67539.7266 - val_loss: 96.6074\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 74061.1484 - val_loss: 96.2971\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17940.0684 - val_loss: 96.8358\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 43172.4961 - val_loss: 96.2410\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 54522.9062 - val_loss: 97.3062\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 66989.7500 - val_loss: 96.3948\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32743.8984 - val_loss: 95.8440\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 27265.5625 - val_loss: 95.4625\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 27313.1289 - val_loss: 95.4450\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40821.8438 - val_loss: 94.9766\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36855.0977 - val_loss: 94.8049\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35030.6562 - val_loss: 96.6890\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 122719.2109 - val_loss: 97.2857\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26418.4004 - val_loss: 95.4793\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 63962.1758 - val_loss: 96.2004\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 90078.4766 - val_loss: 95.9360\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 36856.1211 - val_loss: 97.8751\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 57941.2891 - val_loss: 98.5493\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 65904.5391 - val_loss: 97.8195\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 45868.1328 - val_loss: 97.7713\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47047.7578 - val_loss: 99.0320\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 94475.7891 - val_loss: 97.5145\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf40c8d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 1 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 72.4579 - val_loss: 48.6055\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 52.9057 - val_loss: 44.7748\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45.5615 - val_loss: 52.1257\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40.3728 - val_loss: 32.3378\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.8648 - val_loss: 18.2238\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30.2128 - val_loss: 23.8539\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29.2585 - val_loss: 17.2352\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.7578 - val_loss: 4.0543\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25.1043 - val_loss: 14.5670\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23.5962 - val_loss: 5.4048\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.9835 - val_loss: 6.8766\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.7377 - val_loss: 5.9203\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.7782 - val_loss: 11.0906\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.3421 - val_loss: 6.6896\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20.4462 - val_loss: 4.7469\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.3110 - val_loss: 5.0710\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.0180 - val_loss: 5.2346\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.9799 - val_loss: 8.0413\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.1378 - val_loss: 4.2864\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.3198 - val_loss: 8.9047\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.6615 - val_loss: 5.7994\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.5621 - val_loss: 4.0532\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.5705 - val_loss: 5.8745\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.4359 - val_loss: 4.3379\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.8681 - val_loss: 9.8045\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.2633 - val_loss: 3.3248\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.2381 - val_loss: 6.2091\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.1562 - val_loss: 7.4545\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.2872 - val_loss: 6.3962\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.4317 - val_loss: 2.8973\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.1902 - val_loss: 9.2614\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.9741 - val_loss: 2.5991\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.8202 - val_loss: 8.6538\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.0573 - val_loss: 4.1340\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 11.4784 - val_loss: 4.1336\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.5898 - val_loss: 5.4911\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.5686 - val_loss: 6.5953\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.7736 - val_loss: 1.9395\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.5115 - val_loss: 11.3058\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.8601 - val_loss: 2.8657\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.2208 - val_loss: 6.6103\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.4398 - val_loss: 3.6650\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.4110 - val_loss: 7.0755\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.2689 - val_loss: 6.9076\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.0328 - val_loss: 4.2970\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.6475 - val_loss: 8.4338\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.1499 - val_loss: 6.3867\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.2455 - val_loss: 3.1737\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.2507 - val_loss: 8.6656\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.8882 - val_loss: 2.6883\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf52682dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 2 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 69.6576 - val_loss: 27.6336\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33.6836 - val_loss: 7.7549\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26.6967 - val_loss: 36.3573\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25.9958 - val_loss: 30.3489\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.1190 - val_loss: 13.1382\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.0051 - val_loss: 13.2045\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.6090 - val_loss: 20.6177\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.7745 - val_loss: 15.8793\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.0565 - val_loss: 7.4320\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.6551 - val_loss: 8.6432\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.5122 - val_loss: 2.8595\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.9585 - val_loss: 8.0112\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.9680 - val_loss: 3.2200\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.0276 - val_loss: 9.3545\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.7294 - val_loss: 2.4947\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.9627 - val_loss: 9.4409\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.2714 - val_loss: 3.1407\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.6910 - val_loss: 7.0585\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.3995 - val_loss: 5.3002\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.7172 - val_loss: 4.1607\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.0362 - val_loss: 4.7386\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.0800 - val_loss: 3.1260\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.6076 - val_loss: 2.7684\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.6714 - val_loss: 3.9581\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.7262 - val_loss: 4.3198\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.3643 - val_loss: 3.4667\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.2739 - val_loss: 3.4627\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.1690 - val_loss: 5.2657\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.2976 - val_loss: 3.6644\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.5052 - val_loss: 2.5369\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.1394 - val_loss: 3.7402\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.5785 - val_loss: 2.3723\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.3985 - val_loss: 2.8426\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7540 - val_loss: 2.5864\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.4770 - val_loss: 4.0138\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.0738 - val_loss: 4.4023\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.1471 - val_loss: 5.9211\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.5069 - val_loss: 3.6559\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.2605 - val_loss: 3.7411\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.5549 - val_loss: 5.1361\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.6231 - val_loss: 3.0367\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8960 - val_loss: 2.7202\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7260 - val_loss: 2.9309\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7987 - val_loss: 4.9942\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.0079 - val_loss: 2.1146\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.9999 - val_loss: 3.3311\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.0933 - val_loss: 2.6348\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.5296 - val_loss: 3.0440\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.2366 - val_loss: 2.5430\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.1715 - val_loss: 2.7736\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf96242b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 3 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 60.5376 - val_loss: 40.8625\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 56.8986 - val_loss: 38.1854\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38.3608 - val_loss: 44.3147\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35.2717 - val_loss: 28.8470\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 30.6749 - val_loss: 18.4176\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.7317 - val_loss: 23.9015\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.4509 - val_loss: 5.9833\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.9701 - val_loss: 7.9742\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20.5625 - val_loss: 4.5844\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.2254 - val_loss: 8.4672\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.2759 - val_loss: 5.3184\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.3901 - val_loss: 12.5158\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.6807 - val_loss: 3.9739\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.1357 - val_loss: 8.3976\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20.4608 - val_loss: 4.3987\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.8944 - val_loss: 5.1671\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.9410 - val_loss: 10.4106\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.0912 - val_loss: 4.9475\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.1984 - val_loss: 5.1617\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.5945 - val_loss: 4.1185\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.1203 - val_loss: 5.1792\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.1980 - val_loss: 9.5646\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.4358 - val_loss: 5.0834\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.7174 - val_loss: 5.3030\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.1888 - val_loss: 5.0640\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.1198 - val_loss: 8.5481\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.0042 - val_loss: 5.0205\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.8388 - val_loss: 4.7074\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.4360 - val_loss: 8.5407\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.4355 - val_loss: 4.9103\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.6393 - val_loss: 5.0329\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.7642 - val_loss: 6.1133\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.9945 - val_loss: 5.8848\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.4203 - val_loss: 4.2982\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.7066 - val_loss: 5.1859\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.6536 - val_loss: 5.3194\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.4062 - val_loss: 6.6073\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.3360 - val_loss: 3.6521\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.0669 - val_loss: 6.1198\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.7525 - val_loss: 4.6428\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.9794 - val_loss: 6.2570\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.8497 - val_loss: 4.3806\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.4617 - val_loss: 3.2766\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.5793 - val_loss: 6.1526\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.0410 - val_loss: 4.1148\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4211 - val_loss: 3.3249\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.8293 - val_loss: 3.4997\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.6362 - val_loss: 7.9194\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.7068 - val_loss: 3.3027\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.8512 - val_loss: 3.6236\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff0615dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 4 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 88651.9219 - val_loss: 85.0691\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 152459.8750 - val_loss: 90.4594\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 77423.7734 - val_loss: 86.6692\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 84993.0938 - val_loss: 82.1315\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 74109.5938 - val_loss: 87.6163\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 86518.5000 - val_loss: 90.4646\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39062.8633 - val_loss: 86.9960\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36222.5625 - val_loss: 86.0048\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 76674.3125 - val_loss: 88.1223\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 2130.0437 - val_loss: 93.7852\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 155252.4375 - val_loss: 94.7127\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 49187.7891 - val_loss: 93.8249\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12681.9727 - val_loss: 91.4344\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22199.3770 - val_loss: 85.8347\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 206988.0625 - val_loss: 84.8457\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 222145.0469 - val_loss: 87.1195\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 133802.0156 - val_loss: 91.2360\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7173.1514 - val_loss: 96.2141\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 40014.8672 - val_loss: 97.4304\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 49661.3438 - val_loss: 94.9676\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11092.4346 - val_loss: 94.4060\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9634.7344 - val_loss: 99.3955\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 157415.0938 - val_loss: 100.7913\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 141985.0469 - val_loss: 98.7292\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 58072.1055 - val_loss: 95.3753\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 69396.4141 - val_loss: 93.6759\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 48806.9961 - val_loss: 95.0748\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9319.8115 - val_loss: 98.3920\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 55170.3438 - val_loss: 98.7081\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 84405.7734 - val_loss: 98.0465\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 63184.5391 - val_loss: 93.0896\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 83961.8984 - val_loss: 91.9532\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 71403.9766 - val_loss: 93.5292\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25955.2188 - val_loss: 95.7587\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 60647.9492 - val_loss: 98.4140\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 21013.0684 - val_loss: 97.1251\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17756.4199 - val_loss: 96.8466\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 41812.4609 - val_loss: 96.1927\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13932.5752 - val_loss: 96.7787\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14961.4082 - val_loss: 96.0872\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33922.3711 - val_loss: 94.8185\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 45449.0742 - val_loss: 94.7531\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 53987.6875 - val_loss: 95.8217\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17744.0000 - val_loss: 98.1677\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 57540.2617 - val_loss: 98.2360\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29167.4863 - val_loss: 97.8645\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15239.6924 - val_loss: 95.3349\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 86531.1875 - val_loss: 94.6528\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 54966.8047 - val_loss: 95.2819\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 30102.9121 - val_loss: 97.2220\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf8d0f5ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 5 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 249544.1094 - val_loss: 82.6892\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 130091.7266 - val_loss: 101.7305\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 273385.0938 - val_loss: 108.8486\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 220605.8125 - val_loss: 101.6791\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 38352.8047 - val_loss: 95.9520\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29300.0039 - val_loss: 94.6003\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 102266.7188 - val_loss: 96.6207\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7189.6948 - val_loss: 96.1974\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26975.6621 - val_loss: 98.1458\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9268.9482 - val_loss: 96.2345\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46599.2188 - val_loss: 97.3282\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43050.3984 - val_loss: 97.2129\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13844.5908 - val_loss: 98.2527\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20093.2520 - val_loss: 98.1973\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19575.0234 - val_loss: 94.5343\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 112727.1172 - val_loss: 93.8439\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 83461.8516 - val_loss: 96.1993\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 69697.4766 - val_loss: 102.0423\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 130589.5781 - val_loss: 102.8974\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 118357.0391 - val_loss: 100.5505\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 64316.8867 - val_loss: 97.3162\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 72026.0000 - val_loss: 95.8352\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 79367.6875 - val_loss: 98.5943\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 91002.3750 - val_loss: 100.0982\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 61209.7500 - val_loss: 97.8447\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 42555.3242 - val_loss: 97.7609\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25236.7148 - val_loss: 99.8055\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35649.1562 - val_loss: 99.8947\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36744.8477 - val_loss: 98.1342\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31172.3984 - val_loss: 98.2314\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26821.8164 - val_loss: 99.6183\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15307.7793 - val_loss: 100.4622\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 40841.6328 - val_loss: 97.4964\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 107188.7812 - val_loss: 96.5219\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 62830.8008 - val_loss: 97.9302\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 5519.0039 - val_loss: 99.4546\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11790.4727 - val_loss: 101.1024\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 64313.9883 - val_loss: 100.6203\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 24060.4727 - val_loss: 98.1991\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 27474.4668 - val_loss: 98.4046\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17594.8340 - val_loss: 97.5960\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 33220.9570 - val_loss: 96.6743\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 75218.9844 - val_loss: 100.3273\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 4264.0171 - val_loss: 103.8586\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 78051.2891 - val_loss: 104.3152\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 129195.8984 - val_loss: 103.0277\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 71592.8125 - val_loss: 100.2840\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 27085.3438 - val_loss: 98.7937\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17025.8164 - val_loss: 101.5948\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 38135.5742 - val_loss: 101.6244\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9748fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 6 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 67.8008 - val_loss: 42.7928\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 52.9612 - val_loss: 40.5571\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 40.6830 - val_loss: 34.9888\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 35.4021 - val_loss: 19.7504\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 29.7829 - val_loss: 25.5242\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25.7567 - val_loss: 9.5243\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23.9769 - val_loss: 7.8282\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 22.1938 - val_loss: 6.4349\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20.8290 - val_loss: 9.7489\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21.3395 - val_loss: 2.4791\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.6987 - val_loss: 9.8404\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19.0090 - val_loss: 4.0385\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20.2096 - val_loss: 12.0645\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.7920 - val_loss: 3.5490\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.8484 - val_loss: 6.2414\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.5558 - val_loss: 4.0025\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.6833 - val_loss: 6.6280\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.3449 - val_loss: 4.2240\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.2973 - val_loss: 7.6380\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.7117 - val_loss: 4.3519\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.3180 - val_loss: 8.1958\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.1560 - val_loss: 2.9957\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 15.2546 - val_loss: 3.9095\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.4194 - val_loss: 5.9196\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.0109 - val_loss: 5.3687\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.2032 - val_loss: 3.5249\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.7302 - val_loss: 6.1973\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.4132 - val_loss: 2.9304\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.0365 - val_loss: 6.5469\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.4981 - val_loss: 3.0566\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.6330 - val_loss: 11.3178\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.0736 - val_loss: 2.9105\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.8211 - val_loss: 2.5635\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6429 - val_loss: 5.3751\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.6281 - val_loss: 7.5610\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.1406 - val_loss: 1.7823\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.9413 - val_loss: 5.4987\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.4369 - val_loss: 4.9992\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.7777 - val_loss: 1.7711\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.3414 - val_loss: 5.0087\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.3460 - val_loss: 4.8108\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6307 - val_loss: 7.9339\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.7059 - val_loss: 2.2467\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.4674 - val_loss: 8.4919\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.3027 - val_loss: 2.6996\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.4926 - val_loss: 7.9244\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.1892 - val_loss: 1.8699\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10.6568 - val_loss: 3.3486\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.4006 - val_loss: 6.1580\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.4031 - val_loss: 2.1790\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf40f950d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 7 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 205306.7969 - val_loss: 98.3661\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13107.4502 - val_loss: 115.0270\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 255921.0000 - val_loss: 116.1384\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 208945.9219 - val_loss: 111.7797\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 99556.2734 - val_loss: 105.7915\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 46135.0703 - val_loss: 97.9925\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 154727.6094 - val_loss: 97.1235\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 137972.7969 - val_loss: 99.3901\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 85525.2891 - val_loss: 103.7425\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 64894.2031 - val_loss: 105.0594\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 58644.5781 - val_loss: 103.9512\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 25166.5254 - val_loss: 100.0487\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 72913.4141 - val_loss: 98.4526\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 86416.4688 - val_loss: 98.5044\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 60335.3828 - val_loss: 100.2954\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4076.9724 - val_loss: 100.8899\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13225.2207 - val_loss: 99.4774\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 38164.0977 - val_loss: 99.3293\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 20228.4473 - val_loss: 101.1623\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14173.7285 - val_loss: 101.2661\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 53399.7500 - val_loss: 100.3353\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31129.7930 - val_loss: 99.2604\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 93842.2188 - val_loss: 101.6411\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 60391.8750 - val_loss: 101.1469\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26569.6504 - val_loss: 99.5197\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47550.6172 - val_loss: 98.9554\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5956.3271 - val_loss: 101.3629\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 57532.0195 - val_loss: 101.2015\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31885.3711 - val_loss: 99.6470\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 37876.7930 - val_loss: 99.2070\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41600.8945 - val_loss: 100.0903\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 38801.7422 - val_loss: 103.6996\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 77023.4375 - val_loss: 104.6980\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 108201.4375 - val_loss: 102.2632\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 56075.7812 - val_loss: 98.4848\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 32162.5098 - val_loss: 98.1052\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28141.9121 - val_loss: 99.9125\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20128.0234 - val_loss: 102.9010\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 107544.0234 - val_loss: 103.2493\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 105989.5312 - val_loss: 102.5374\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 63872.2227 - val_loss: 99.4363\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 50921.9297 - val_loss: 98.0446\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 41084.6992 - val_loss: 99.4449\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14897.8008 - val_loss: 99.0592\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 65335.3477 - val_loss: 99.4554\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16870.7070 - val_loss: 99.8738\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8121.7485 - val_loss: 99.5664\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2981.1309 - val_loss: 99.2740\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28491.4512 - val_loss: 99.3017\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15294.7207 - val_loss: 99.2447\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf32672040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 8 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 68.7480 - val_loss: 54.5353\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 51.0314 - val_loss: 53.9631\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43.6048 - val_loss: 37.5319\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36.8943 - val_loss: 17.3346\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31.6691 - val_loss: 17.5780\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26.5210 - val_loss: 11.4191\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.9460 - val_loss: 6.6037\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26.6558 - val_loss: 6.6502\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23.4759 - val_loss: 5.2172\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23.6976 - val_loss: 12.2904\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.7858 - val_loss: 4.9406\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.7508 - val_loss: 6.7618\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.2491 - val_loss: 7.0067\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.7997 - val_loss: 6.1029\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.0156 - val_loss: 5.3111\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.6005 - val_loss: 5.7326\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.8516 - val_loss: 8.7965\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.3241 - val_loss: 4.6755\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.7534 - val_loss: 6.2334\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.2727 - val_loss: 7.3543\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.7247 - val_loss: 9.5676\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.0469 - val_loss: 8.2092\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.8129 - val_loss: 4.3966\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.8853 - val_loss: 4.8053\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.8361 - val_loss: 5.5066\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.0388 - val_loss: 5.5174\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.3740 - val_loss: 5.7987\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.3346 - val_loss: 6.5410\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.2213 - val_loss: 3.9281\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.6761 - val_loss: 4.0667\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.7117 - val_loss: 4.2186\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.2420 - val_loss: 5.0241\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.6435 - val_loss: 5.6299\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.7949 - val_loss: 5.0908\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.3023 - val_loss: 4.1412\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.8592 - val_loss: 4.0599\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.8838 - val_loss: 5.5850\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.5085 - val_loss: 3.9844\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 11.3974 - val_loss: 3.1689\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.6322 - val_loss: 4.8921\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.8381 - val_loss: 4.5227\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.9372 - val_loss: 2.8259\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.6840 - val_loss: 5.1920\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.6075 - val_loss: 4.1998\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.3484 - val_loss: 5.4959\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.1933 - val_loss: 4.0655\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.2502 - val_loss: 4.5538\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.1586 - val_loss: 2.7578\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5475 - val_loss: 3.7179\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.1769 - val_loss: 3.7390\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4352c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 9 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 234531.8125 - val_loss: 78.5276\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 168311.7031 - val_loss: 98.2557\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 219845.4531 - val_loss: 98.2792\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 189578.4688 - val_loss: 95.6125\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 96632.1016 - val_loss: 89.1087\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 65886.8984 - val_loss: 87.8745\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38214.2773 - val_loss: 92.4516\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 79776.1562 - val_loss: 92.2370\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16318.5771 - val_loss: 89.0939\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 69295.7500 - val_loss: 87.9384\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 55672.2891 - val_loss: 92.4569\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 40559.6016 - val_loss: 99.4124\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 203981.0156 - val_loss: 101.8102\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 179307.2656 - val_loss: 100.0609\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 124856.0625 - val_loss: 95.3761\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4308.0576 - val_loss: 90.7052\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 62857.3281 - val_loss: 89.9198\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 81098.7422 - val_loss: 92.6253\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 17861.7754 - val_loss: 95.2330\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 64325.6641 - val_loss: 96.4127\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 54082.0977 - val_loss: 95.1301\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7285.7017 - val_loss: 92.9839\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 77541.1875 - val_loss: 92.7843\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 36247.8789 - val_loss: 95.1161\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 32149.6738 - val_loss: 94.6613\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8578.2227 - val_loss: 95.0141\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3991.9172 - val_loss: 93.9605\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 59694.9727 - val_loss: 94.0161\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 57264.6172 - val_loss: 95.1353\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 243.3148 - val_loss: 95.6381\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28837.8125 - val_loss: 95.7866\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16219.3770 - val_loss: 93.2063\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 71924.7266 - val_loss: 93.2850\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44160.3125 - val_loss: 95.7584\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 46083.0195 - val_loss: 96.0282\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 2637.1807 - val_loss: 96.8324\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 74717.5547 - val_loss: 97.3528\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23065.4004 - val_loss: 94.3733\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 42122.8867 - val_loss: 93.1872\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 74790.7891 - val_loss: 94.6336\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39826.5156 - val_loss: 97.2873\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 49905.8867 - val_loss: 96.9585\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 65275.5938 - val_loss: 95.4285\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9063.3926 - val_loss: 94.8638\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 41854.5977 - val_loss: 95.3720\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 42527.3438 - val_loss: 93.4306\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3574.0740 - val_loss: 91.0042\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 138246.9375 - val_loss: 90.1339\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 137824.2188 - val_loss: 93.5624\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10756.8848 - val_loss: 96.2899\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf8d0f5ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 10 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 178248.5156 - val_loss: 102.9908\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 127874.1484 - val_loss: 96.4518\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 114156.9375 - val_loss: 100.2072\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 168502.6250 - val_loss: 102.3471\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28848.8125 - val_loss: 98.4521\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 34435.5625 - val_loss: 101.5563\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 169489.9531 - val_loss: 101.0101\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 55530.4062 - val_loss: 98.0794\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7449.1348 - val_loss: 96.6143\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18107.9414 - val_loss: 99.6466\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 119441.5547 - val_loss: 100.6501\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 51795.9727 - val_loss: 98.3366\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 32618.6309 - val_loss: 100.0456\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 108603.4766 - val_loss: 98.6571\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 77045.5859 - val_loss: 94.5340\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 156282.1719 - val_loss: 94.3866\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 65267.1328 - val_loss: 96.3241\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 40176.4492 - val_loss: 97.8223\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 67295.7344 - val_loss: 95.5579\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 99203.5078 - val_loss: 96.3438\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33213.9609 - val_loss: 98.7495\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21719.2363 - val_loss: 100.6382\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 255861.1094 - val_loss: 102.8855\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 149568.2344 - val_loss: 98.8251\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 65769.4766 - val_loss: 97.7350\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21427.8730 - val_loss: 98.1962\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 48417.3125 - val_loss: 98.6617\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20191.7480 - val_loss: 96.4135\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 196511.5781 - val_loss: 95.2276\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 109587.1406 - val_loss: 97.7178\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28930.7637 - val_loss: 98.0094\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 32460.3613 - val_loss: 97.8861\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16803.1289 - val_loss: 98.1285\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18957.4102 - val_loss: 98.0780\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8903.7783 - val_loss: 97.8398\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 29113.4434 - val_loss: 99.3061\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 41918.4180 - val_loss: 99.3646\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 24415.1309 - val_loss: 96.8417\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 129196.1328 - val_loss: 96.2836\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55339.1250 - val_loss: 98.2159\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 63908.0469 - val_loss: 100.8707\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 119711.5547 - val_loss: 100.8883\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 48178.9961 - val_loss: 98.6275\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 53318.0234 - val_loss: 95.1038\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 194774.1875 - val_loss: 94.6103\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 143092.7031 - val_loss: 98.2500\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 58003.6367 - val_loss: 98.8322\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50465.6406 - val_loss: 97.6699\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 51107.1328 - val_loss: 98.1401\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35363.3633 - val_loss: 98.2205\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf6ed321f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 11 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 121056.9453 - val_loss: 100.3211\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 134099.5469 - val_loss: 92.4688\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 109553.2266 - val_loss: 94.6461\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 92373.0391 - val_loss: 98.7504\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 67245.7891 - val_loss: 94.0877\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 117840.2344 - val_loss: 93.4970\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 59039.6523 - val_loss: 97.4985\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 100227.1172 - val_loss: 97.4312\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 22201.9941 - val_loss: 97.1533\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 42475.5352 - val_loss: 95.4610\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 49717.8867 - val_loss: 96.9458\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 143546.5625 - val_loss: 98.0096\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 112807.1562 - val_loss: 94.6861\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17202.0078 - val_loss: 96.2358\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 103667.6406 - val_loss: 95.7910\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36838.7617 - val_loss: 94.5305\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50952.2031 - val_loss: 95.2606\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 27270.0664 - val_loss: 98.3329\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 98522.4375 - val_loss: 98.1602\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 44632.7773 - val_loss: 95.8583\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 106897.2109 - val_loss: 94.4631\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 47158.6289 - val_loss: 96.7041\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 100820.0625 - val_loss: 98.0933\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20173.2109 - val_loss: 97.4429\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 71934.3047 - val_loss: 97.3115\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4038.6323 - val_loss: 96.8624\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28788.1914 - val_loss: 97.3384\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10966.5615 - val_loss: 97.9120\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 39904.9492 - val_loss: 95.1251\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 201133.1719 - val_loss: 94.5467\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 160394.2031 - val_loss: 97.8908\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 51948.2656 - val_loss: 100.2384\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 130924.4766 - val_loss: 99.6265\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 101102.1016 - val_loss: 97.5020\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 34123.1602 - val_loss: 95.3312\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 162361.1562 - val_loss: 96.0007\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 75878.8750 - val_loss: 97.6794\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 91854.4141 - val_loss: 98.7812\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 48041.7812 - val_loss: 97.2571\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 73751.3125 - val_loss: 96.8358\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26724.2109 - val_loss: 99.1551\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 136023.9219 - val_loss: 99.5473\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 46522.8164 - val_loss: 97.3604\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 57017.9688 - val_loss: 96.4404\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 38929.2383 - val_loss: 98.9534\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 69738.9766 - val_loss: 99.5498\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 61734.0078 - val_loss: 98.5294\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 48548.3438 - val_loss: 98.3588\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41749.9180 - val_loss: 97.9560\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15376.7061 - val_loss: 97.7809\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf8137e550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 12 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 482459.6875 - val_loss: 117.0145\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 322118.7188 - val_loss: 97.7826\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 327493.5938 - val_loss: 88.3490\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 215397.0469 - val_loss: 98.4246\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 187718.6406 - val_loss: 100.0538\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 152450.1406 - val_loss: 94.0085\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 77163.5000 - val_loss: 92.0368\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 67520.9844 - val_loss: 96.7146\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 117883.0781 - val_loss: 96.0816\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50772.5938 - val_loss: 94.1460\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 103235.1016 - val_loss: 94.4963\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 43457.4727 - val_loss: 93.9978\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 69449.0000 - val_loss: 95.8833\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 59093.8945 - val_loss: 95.2158\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 61924.0312 - val_loss: 93.6205\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 61082.7227 - val_loss: 96.0625\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47807.0273 - val_loss: 97.2204\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 121600.3984 - val_loss: 95.0587\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30972.4316 - val_loss: 93.4259\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 44614.6016 - val_loss: 92.6921\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 158639.9375 - val_loss: 94.4951\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 159819.4688 - val_loss: 97.2178\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43172.4023 - val_loss: 92.3325\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 204647.0312 - val_loss: 91.7388\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 158655.5469 - val_loss: 95.0458\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 79842.5625 - val_loss: 97.7564\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 117313.9609 - val_loss: 97.1688\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 49545.6484 - val_loss: 94.3560\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 60500.7695 - val_loss: 93.4164\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 41639.4219 - val_loss: 95.8789\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 77848.3672 - val_loss: 97.0840\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 81921.8984 - val_loss: 94.7737\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 72430.0547 - val_loss: 93.4273\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 175519.4375 - val_loss: 93.6118\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 48644.2695 - val_loss: 96.3100\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 91811.5234 - val_loss: 95.6661\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39604.6875 - val_loss: 93.2984\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 88363.4062 - val_loss: 92.8478\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 57419.2188 - val_loss: 94.5686\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17511.2559 - val_loss: 96.2878\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 98104.2109 - val_loss: 96.9040\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 96835.5000 - val_loss: 94.3095\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 83842.0625 - val_loss: 93.8664\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 87671.0156 - val_loss: 96.3723\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 74522.9531 - val_loss: 96.7729\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 86868.2266 - val_loss: 94.2200\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 68351.4609 - val_loss: 93.8709\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 56091.9336 - val_loss: 95.3621\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 70970.7188 - val_loss: 96.3320\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18227.8691 - val_loss: 94.4856\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf3db18af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 13 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 102787.1016 - val_loss: 103.3169\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 207452.3906 - val_loss: 108.0614\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 158244.4531 - val_loss: 102.1289\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 53801.8711 - val_loss: 93.7694\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 147113.0938 - val_loss: 89.7025\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 124083.5547 - val_loss: 93.8277\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39386.1172 - val_loss: 99.0611\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 65601.1797 - val_loss: 99.7381\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47693.7148 - val_loss: 99.4117\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10681.2715 - val_loss: 97.8410\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9662.5967 - val_loss: 98.3407\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16388.0195 - val_loss: 96.3927\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 84580.7031 - val_loss: 96.4262\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45071.1719 - val_loss: 98.6162\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30604.5293 - val_loss: 98.2479\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3274.6824 - val_loss: 99.3298\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48137.5742 - val_loss: 98.6531\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62267.6133 - val_loss: 97.0956\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34915.5664 - val_loss: 96.6305\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11870.2275 - val_loss: 97.0355\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61065.2305 - val_loss: 99.3515\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56994.7227 - val_loss: 99.9570\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34457.4258 - val_loss: 98.0349\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18825.7168 - val_loss: 97.3657\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 76372.7578 - val_loss: 98.9133\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8746.8574 - val_loss: 98.7717\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25171.5391 - val_loss: 97.2816\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41234.6172 - val_loss: 97.7524\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22980.5234 - val_loss: 98.7428\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5404.6426 - val_loss: 101.8304\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 126973.0625 - val_loss: 103.0634\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 102319.7188 - val_loss: 100.7355\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35856.1875 - val_loss: 98.1189\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9688.7725 - val_loss: 95.0553\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 145416.1250 - val_loss: 94.5340\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 68585.0312 - val_loss: 95.8600\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 103199.9062 - val_loss: 98.9996\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66438.3906 - val_loss: 99.1644\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47079.4023 - val_loss: 99.5603\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16289.8779 - val_loss: 98.3155\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10101.6328 - val_loss: 98.9568\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24579.2188 - val_loss: 98.0442\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49307.2148 - val_loss: 99.4244\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4384.5332 - val_loss: 97.9673\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29937.9863 - val_loss: 98.5997\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 24221.7012 - val_loss: 101.6172\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48744.6055 - val_loss: 102.2877\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 68660.8203 - val_loss: 99.4833\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 49349.5938 - val_loss: 98.9400\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7142.4902 - val_loss: 98.4592\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf71079550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 14 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 14966.8047 - val_loss: 87.3566\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 80087.1641 - val_loss: 91.3654\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 119357.3516 - val_loss: 87.8892\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 94928.2734 - val_loss: 87.6850\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 2580.9739 - val_loss: 93.1259\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 163796.6562 - val_loss: 95.4524\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 90568.2031 - val_loss: 93.0958\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 73583.6016 - val_loss: 87.4627\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 71793.2656 - val_loss: 87.0641\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 80693.0312 - val_loss: 87.9622\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 33747.8789 - val_loss: 89.7175\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 84097.5312 - val_loss: 91.8273\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 17988.9805 - val_loss: 91.0716\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 28351.8984 - val_loss: 91.4324\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 73252.2266 - val_loss: 90.6280\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10469.9570 - val_loss: 91.4649\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 29299.1836 - val_loss: 90.3390\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18490.0684 - val_loss: 91.6972\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 32872.4844 - val_loss: 91.6364\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 41386.8867 - val_loss: 90.3500\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 38749.7969 - val_loss: 89.5475\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 69502.6797 - val_loss: 89.6438\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 38089.8789 - val_loss: 93.8539\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 70203.8984 - val_loss: 95.5786\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 63166.8750 - val_loss: 95.0401\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 27235.0957 - val_loss: 91.4992\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18555.8262 - val_loss: 89.2562\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4201.0845 - val_loss: 89.9209\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 75900.7266 - val_loss: 93.2072\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 88644.8359 - val_loss: 93.3078\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 46958.0781 - val_loss: 91.8645\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 45094.1133 - val_loss: 93.0879\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13760.5439 - val_loss: 95.8865\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 91601.5547 - val_loss: 96.0678\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 83747.6406 - val_loss: 94.4522\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3001.9275 - val_loss: 94.3377\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13403.3408 - val_loss: 93.3479\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 38270.1523 - val_loss: 93.4208\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 31941.5625 - val_loss: 94.6960\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 73056.7734 - val_loss: 95.0510\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 34282.6250 - val_loss: 94.3142\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23758.5469 - val_loss: 93.6496\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8996.1494 - val_loss: 94.1021\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1134.9763 - val_loss: 92.3619\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 103253.6328 - val_loss: 91.5851\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 116744.4375 - val_loss: 93.8405\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18743.3438 - val_loss: 95.9588\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 58257.3242 - val_loss: 96.9478\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 102089.8125 - val_loss: 96.1009\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 38172.9297 - val_loss: 94.1539\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf35a63940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 15 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 623612.1250 - val_loss: 78.6637\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 132447.7969 - val_loss: 97.5584\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 298196.0938 - val_loss: 97.4122\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 128208.4219 - val_loss: 91.6712\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 280044.6875 - val_loss: 89.6938\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 203614.5469 - val_loss: 93.3386\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 155782.3750 - val_loss: 98.0261\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 212208.9531 - val_loss: 98.5550\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 84741.6484 - val_loss: 94.0985\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 127331.9766 - val_loss: 92.9238\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 181307.0938 - val_loss: 95.7149\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10540.3359 - val_loss: 98.9400\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 284117.4062 - val_loss: 98.9647\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 266501.0000 - val_loss: 96.8392\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 156495.5000 - val_loss: 92.3188\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 117250.3828 - val_loss: 91.8947\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 54961.9062 - val_loss: 94.3152\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 108152.4141 - val_loss: 95.6826\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 63938.9531 - val_loss: 93.4482\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 124657.3438 - val_loss: 94.3616\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 75767.8516 - val_loss: 95.5193\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 65097.6523 - val_loss: 97.0912\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 111564.1875 - val_loss: 97.7042\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 123449.0000 - val_loss: 94.3677\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 106157.5625 - val_loss: 94.1579\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 87105.7266 - val_loss: 95.7457\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27699.8418 - val_loss: 96.8142\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 66045.2969 - val_loss: 96.0025\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43791.7734 - val_loss: 95.1810\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50905.7617 - val_loss: 96.7143\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 94253.8203 - val_loss: 96.8562\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 68058.1875 - val_loss: 94.1742\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 127376.7109 - val_loss: 94.5820\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 65266.6719 - val_loss: 95.8602\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 73210.6016 - val_loss: 96.2461\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34320.1016 - val_loss: 95.2551\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27568.9609 - val_loss: 96.3254\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34169.0391 - val_loss: 97.2068\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 85868.6875 - val_loss: 96.2272\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 41373.5664 - val_loss: 93.5752\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 127174.3125 - val_loss: 93.6793\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 110963.7266 - val_loss: 95.7378\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35437.6992 - val_loss: 98.2449\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 124932.0625 - val_loss: 97.8260\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 78377.3516 - val_loss: 95.1624\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 151132.0781 - val_loss: 94.4415\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 137504.7500 - val_loss: 96.0419\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43938.1562 - val_loss: 96.7697\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10808.1221 - val_loss: 96.3552\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 46285.1836 - val_loss: 97.5052\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf1bd3bc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 16 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 87.0943 - val_loss: 61.9744\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 50.9999 - val_loss: 41.8239\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 44.6299 - val_loss: 43.0473\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35.6604 - val_loss: 41.5430\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 31.1033 - val_loss: 19.1134\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28.0720 - val_loss: 20.6524\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24.2254 - val_loss: 14.2126\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22.5132 - val_loss: 4.7618\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21.4172 - val_loss: 10.7324\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20.6590 - val_loss: 5.3590\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 19.1562 - val_loss: 9.9908\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.6635 - val_loss: 4.1456\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.6111 - val_loss: 5.6385\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.2533 - val_loss: 3.0678\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.0762 - val_loss: 2.3684\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.2920 - val_loss: 3.2823\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.7259 - val_loss: 3.0769\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.2048 - val_loss: 7.9417\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.0721 - val_loss: 3.7294\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.9350 - val_loss: 3.4254\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.6078 - val_loss: 2.7760\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.3763 - val_loss: 4.0834\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.3830 - val_loss: 3.9417\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.4359 - val_loss: 3.0308\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.4472 - val_loss: 6.1834\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.7440 - val_loss: 3.0163\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.5442 - val_loss: 2.9846\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.2405 - val_loss: 2.4219\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.9572 - val_loss: 2.5352\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.5165 - val_loss: 2.7900\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.6848 - val_loss: 6.8805\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.5650 - val_loss: 2.0846\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.2665 - val_loss: 5.1858\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.6311 - val_loss: 2.2806\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.8854 - val_loss: 2.9745\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.4295 - val_loss: 2.9687\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.5500 - val_loss: 4.0181\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.5379 - val_loss: 3.1323\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4227 - val_loss: 5.5108\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.1406 - val_loss: 3.3430\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.2516 - val_loss: 2.6972\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.0491 - val_loss: 6.8142\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.6613 - val_loss: 6.5381\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.4860 - val_loss: 2.1762\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.8455 - val_loss: 5.6843\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.5678 - val_loss: 2.4380\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.0260 - val_loss: 9.1320\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.2014 - val_loss: 7.2750\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.6099 - val_loss: 8.5972\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.6414 - val_loss: 2.5421\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf35a63700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 17 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 64.6973 - val_loss: 37.4475\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29.9127 - val_loss: 23.0632\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24.4820 - val_loss: 35.6692\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24.2400 - val_loss: 29.5035\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20.8260 - val_loss: 17.3358\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19.0237 - val_loss: 22.2461\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.4299 - val_loss: 15.2825\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.1687 - val_loss: 12.7094\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.1188 - val_loss: 5.5819\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.2388 - val_loss: 3.7463\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.3281 - val_loss: 5.4617\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.6153 - val_loss: 2.5402\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.8527 - val_loss: 7.2363\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.6703 - val_loss: 6.3880\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.4943 - val_loss: 5.5519\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.7737 - val_loss: 2.4070\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.0400 - val_loss: 5.9468\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.6459 - val_loss: 3.8640\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.7573 - val_loss: 3.1147\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.6472 - val_loss: 2.7460\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.1540 - val_loss: 4.7453\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.6542 - val_loss: 3.2368\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.3786 - val_loss: 3.1671\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.9580 - val_loss: 2.6090\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.5548 - val_loss: 4.1678\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.4025 - val_loss: 2.8842\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9551 - val_loss: 3.7218\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.8237 - val_loss: 4.5741\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.8871 - val_loss: 9.8350\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3945 - val_loss: 2.8395\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3581 - val_loss: 6.6749\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.7724 - val_loss: 2.5399\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9167 - val_loss: 4.8060\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4603 - val_loss: 4.2528\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.9236 - val_loss: 2.8562\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.8939 - val_loss: 2.8709\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2735 - val_loss: 2.3196\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2761 - val_loss: 3.1912\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.5404 - val_loss: 1.9730\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4204 - val_loss: 4.5997\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6784 - val_loss: 3.1028\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9308 - val_loss: 2.0330\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2159 - val_loss: 3.3925\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.9799 - val_loss: 2.5335\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4169 - val_loss: 2.9945\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3843 - val_loss: 7.4812\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6889 - val_loss: 3.7046\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0069 - val_loss: 6.0984\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0929 - val_loss: 2.2037\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6233 - val_loss: 4.9345\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf555c0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 18 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 100176.8984 - val_loss: 121.5683\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 318695.4688 - val_loss: 113.2455\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79329.5234 - val_loss: 105.7825\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 109341.0391 - val_loss: 103.4864\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5760.3755 - val_loss: 109.5213\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80476.2734 - val_loss: 108.5928\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15849.5576 - val_loss: 101.5788\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 204492.2344 - val_loss: 100.9662\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 141940.1094 - val_loss: 108.0264\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61620.8438 - val_loss: 107.7412\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 88230.4141 - val_loss: 103.7107\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 112320.5000 - val_loss: 102.9083\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49608.8125 - val_loss: 105.9923\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58438.5195 - val_loss: 106.4351\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 75452.8125 - val_loss: 104.3575\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39228.2930 - val_loss: 103.4484\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42519.0195 - val_loss: 101.8311\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44053.0625 - val_loss: 102.9602\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14220.5723 - val_loss: 102.9762\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66982.4766 - val_loss: 102.3210\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46234.2539 - val_loss: 106.4853\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 103624.1016 - val_loss: 106.4614\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51195.1445 - val_loss: 104.9790\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68001.1328 - val_loss: 101.9039\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66398.9062 - val_loss: 103.9017\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48972.8359 - val_loss: 104.2239\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50749.3633 - val_loss: 101.5531\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55192.6445 - val_loss: 100.6501\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38012.0859 - val_loss: 103.1909\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54723.1602 - val_loss: 103.7380\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50965.6016 - val_loss: 102.9561\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23377.3691 - val_loss: 102.5269\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30130.6875 - val_loss: 103.3978\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46397.4648 - val_loss: 102.3959\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1015.8071 - val_loss: 102.1695\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23226.8320 - val_loss: 102.6607\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12925.6055 - val_loss: 102.4205\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1928.6788 - val_loss: 103.2801\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31459.8027 - val_loss: 102.6860\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17539.6426 - val_loss: 103.7811\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89390.9531 - val_loss: 103.3979\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35069.4453 - val_loss: 101.6793\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32103.1914 - val_loss: 101.9100\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26318.4688 - val_loss: 103.5010\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5887.1235 - val_loss: 102.6383\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13474.4395 - val_loss: 102.9856\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41692.8867 - val_loss: 103.2450\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9160.3779 - val_loss: 100.1593\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61388.1328 - val_loss: 100.2494\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24169.0371 - val_loss: 101.1824\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf83ce2700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 19 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 109938.4453 - val_loss: 103.8969\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 350151.5312 - val_loss: 104.0039\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 157295.3750 - val_loss: 97.4208\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39439.7188 - val_loss: 88.7461\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 192292.4688 - val_loss: 84.5818\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 147945.3750 - val_loss: 87.4858\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73333.0234 - val_loss: 93.3628\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46903.7383 - val_loss: 94.9985\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 94579.5859 - val_loss: 92.8968\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33409.8633 - val_loss: 92.5999\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32793.9453 - val_loss: 98.1627\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61435.2812 - val_loss: 99.2390\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 109019.8594 - val_loss: 97.4918\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59317.7500 - val_loss: 94.4300\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51298.1953 - val_loss: 86.8193\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 202791.0000 - val_loss: 85.9429\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 210566.2656 - val_loss: 87.5353\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 162928.1250 - val_loss: 94.4442\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3597.3372 - val_loss: 99.0733\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 117804.8125 - val_loss: 100.3751\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 182070.0156 - val_loss: 98.7127\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 95397.9453 - val_loss: 94.8065\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39555.7188 - val_loss: 89.7847\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 104338.7578 - val_loss: 88.5746\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 164660.0469 - val_loss: 90.3388\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87748.5391 - val_loss: 94.6929\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9107.8818 - val_loss: 96.7335\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9973.4121 - val_loss: 95.0396\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54911.4297 - val_loss: 94.4319\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57094.6445 - val_loss: 97.1651\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42363.4609 - val_loss: 97.1398\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74460.5781 - val_loss: 97.5238\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26255.4219 - val_loss: 100.2561\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 107125.5000 - val_loss: 101.2027\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76284.5781 - val_loss: 99.3686\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60074.8555 - val_loss: 95.9846\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76660.6016 - val_loss: 94.7099\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71267.9688 - val_loss: 95.4229\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29938.5781 - val_loss: 97.1860\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11185.4902 - val_loss: 98.3166\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33595.5938 - val_loss: 99.1279\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49331.8359 - val_loss: 98.3684\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24286.4629 - val_loss: 97.5415\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16824.4766 - val_loss: 96.4022\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73280.8438 - val_loss: 97.2294\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20463.0527 - val_loss: 99.0358\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 67616.0000 - val_loss: 99.3586\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16429.8711 - val_loss: 98.7699\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46155.5859 - val_loss: 98.0559\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29164.5137 - val_loss: 99.3073\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5ebb3b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 20 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 30808.8789 - val_loss: 99.5609\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 289801.0000 - val_loss: 94.7285\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 126733.2266 - val_loss: 99.9288\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27236.0996 - val_loss: 105.1766\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25659.3887 - val_loss: 104.0509\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22274.0566 - val_loss: 105.3837\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 740.5267 - val_loss: 103.5208\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 77997.2812 - val_loss: 102.9991\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61617.3945 - val_loss: 107.6300\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48748.1875 - val_loss: 109.4939\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32531.6641 - val_loss: 102.9898\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69290.7656 - val_loss: 101.4643\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76145.6094 - val_loss: 105.6024\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55832.7383 - val_loss: 104.4670\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33650.1758 - val_loss: 105.9162\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3730.3389 - val_loss: 112.5812\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 203157.9688 - val_loss: 115.0283\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 209670.9844 - val_loss: 111.1140\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69502.6094 - val_loss: 105.7081\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51905.5781 - val_loss: 103.1315\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62891.7812 - val_loss: 104.5079\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32812.6367 - val_loss: 106.3103\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18431.0566 - val_loss: 107.3637\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50119.8594 - val_loss: 106.2594\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26297.4414 - val_loss: 102.8549\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57910.5273 - val_loss: 102.9161\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9620.2236 - val_loss: 105.3225\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45852.6719 - val_loss: 105.8259\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31608.2461 - val_loss: 101.7643\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 115455.6328 - val_loss: 100.3980\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37244.3281 - val_loss: 104.6379\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9057.9912 - val_loss: 105.0521\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9198.5088 - val_loss: 106.6179\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81964.1484 - val_loss: 107.1617\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73821.6328 - val_loss: 104.3877\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72770.7344 - val_loss: 102.8595\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16813.3340 - val_loss: 106.0120\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 42134.6758 - val_loss: 106.7438\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39308.0312 - val_loss: 104.2631\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8826.4688 - val_loss: 100.2032\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 104017.3672 - val_loss: 99.8550\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 113669.0781 - val_loss: 101.6673\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 89735.4062 - val_loss: 103.8871\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 51777.0312 - val_loss: 104.6797\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32258.8066 - val_loss: 102.5869\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43971.1680 - val_loss: 102.0377\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30368.8984 - val_loss: 103.7629\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52111.2617 - val_loss: 105.2070\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 39340.6133 - val_loss: 103.0451\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 95730.4062 - val_loss: 102.2113\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf64e23d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 21 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 74.2760 - val_loss: 53.3553\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.0404 - val_loss: 36.6071\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 39.5714 - val_loss: 44.6687\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.7318 - val_loss: 34.0046\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.0139 - val_loss: 21.6803\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25.6266 - val_loss: 26.3662\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24.9550 - val_loss: 15.8470\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21.4775 - val_loss: 13.8048\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20.0137 - val_loss: 3.4846\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19.0356 - val_loss: 2.8722\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.4550 - val_loss: 7.2819\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.4578 - val_loss: 2.4943\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.8260 - val_loss: 6.6300\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.8325 - val_loss: 2.8882\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.0765 - val_loss: 6.4431\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.6081 - val_loss: 3.0581\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.3903 - val_loss: 6.6377\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.9569 - val_loss: 4.2935\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.0295 - val_loss: 5.3426\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.1209 - val_loss: 6.8514\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.8716 - val_loss: 7.7791\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.1820 - val_loss: 3.3968\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.6553 - val_loss: 5.6422\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.9195 - val_loss: 2.6293\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.6867 - val_loss: 6.7694\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.8882 - val_loss: 2.9643\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.0037 - val_loss: 5.6929\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.6590 - val_loss: 2.3137\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.4078 - val_loss: 7.8758\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.4512 - val_loss: 3.4943\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.9827 - val_loss: 8.2237\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4727 - val_loss: 2.5074\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6774 - val_loss: 3.6982\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.1444 - val_loss: 5.5539\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.0135 - val_loss: 2.3596\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4423 - val_loss: 5.2745\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4364 - val_loss: 4.0151\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.7164 - val_loss: 2.9440\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.7445 - val_loss: 2.9091\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1756 - val_loss: 5.3151\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.7242 - val_loss: 3.7007\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4642 - val_loss: 6.1867\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0938 - val_loss: 3.7362\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.5123 - val_loss: 2.3056\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4044 - val_loss: 7.4997\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.0423 - val_loss: 2.4236\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1614 - val_loss: 8.0253\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.2812 - val_loss: 3.5558\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9552 - val_loss: 6.9287\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.7226 - val_loss: 3.2533\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf52bb89d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 22 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 119013.3828 - val_loss: 122.7611\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 302548.1250 - val_loss: 126.1755\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 154767.1250 - val_loss: 117.3865\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83985.6016 - val_loss: 105.9924\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 81473.7266 - val_loss: 104.4615\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 84420.4844 - val_loss: 108.1955\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13836.9883 - val_loss: 112.8586\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 95491.4766 - val_loss: 111.9827\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 92754.5312 - val_loss: 109.9009\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74651.8047 - val_loss: 105.4237\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43309.2148 - val_loss: 107.7475\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50248.4297 - val_loss: 109.1719\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63922.9922 - val_loss: 108.4769\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34883.0781 - val_loss: 103.3527\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 136029.6719 - val_loss: 101.2893\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 96818.6562 - val_loss: 102.7036\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18795.1191 - val_loss: 104.1410\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53419.3711 - val_loss: 104.1902\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70653.3125 - val_loss: 106.5978\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24903.6504 - val_loss: 106.5366\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25019.0254 - val_loss: 104.0164\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 83000.5625 - val_loss: 103.5630\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 81062.2578 - val_loss: 106.0701\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21681.5566 - val_loss: 106.9198\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34180.7539 - val_loss: 105.6661\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23738.4570 - val_loss: 105.2611\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37082.9570 - val_loss: 107.2876\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36178.0156 - val_loss: 107.7024\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31946.2461 - val_loss: 106.0980\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84011.1250 - val_loss: 104.5807\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 40333.6094 - val_loss: 106.7249\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38609.9414 - val_loss: 107.1296\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69899.4766 - val_loss: 105.3043\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20287.9766 - val_loss: 104.8377\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13437.7041 - val_loss: 104.6510\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 247.2401 - val_loss: 103.2800\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 129195.9609 - val_loss: 102.5097\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 93661.2578 - val_loss: 103.2664\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76425.6875 - val_loss: 106.4770\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4635.3398 - val_loss: 106.7464\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46492.6758 - val_loss: 106.0795\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26125.2695 - val_loss: 103.2428\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 59179.8672 - val_loss: 102.8669\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22410.3867 - val_loss: 104.1976\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14815.4297 - val_loss: 107.7762\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 109848.8281 - val_loss: 109.5118\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71587.1562 - val_loss: 107.2321\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 50125.8867 - val_loss: 103.6186\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47161.7656 - val_loss: 101.9220\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 92811.1484 - val_loss: 103.3691\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf2e5c61f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 23 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 89.2059 - val_loss: 70.8658\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40.9500 - val_loss: 18.6659\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 43.8277 - val_loss: 30.7180\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30.8197 - val_loss: 43.4049\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30.6668 - val_loss: 38.4819\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 27.0478 - val_loss: 24.5655\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 23.7370 - val_loss: 20.5603\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20.2170 - val_loss: 23.4318\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.1897 - val_loss: 9.4181\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.7469 - val_loss: 7.0149\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.9089 - val_loss: 5.3657\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.9929 - val_loss: 5.0303\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.1401 - val_loss: 12.3661\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.0278 - val_loss: 6.9743\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 14.2318 - val_loss: 10.3298\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 14.3147 - val_loss: 6.6817\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 12.7720 - val_loss: 6.6256\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 13.1249 - val_loss: 4.8416\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.5663 - val_loss: 4.4321\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.9626 - val_loss: 6.9769\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.3986 - val_loss: 3.7689\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.3888 - val_loss: 6.7681\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.5059 - val_loss: 3.6488\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.4156 - val_loss: 8.2329\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.5592 - val_loss: 3.6442\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.1794 - val_loss: 9.8894\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.9527 - val_loss: 3.1546\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.7063 - val_loss: 4.5301\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.5908 - val_loss: 4.2356\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.9065 - val_loss: 3.5817\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.0206 - val_loss: 4.5297\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.5846 - val_loss: 3.8484\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.8709 - val_loss: 4.4673\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.9402 - val_loss: 3.1864\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.6141 - val_loss: 5.2955\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.7506 - val_loss: 3.7245\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6241 - val_loss: 6.1109\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.1503 - val_loss: 3.8756\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3609 - val_loss: 5.3737\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1656 - val_loss: 2.4348\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.3065 - val_loss: 5.4146\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.1651 - val_loss: 6.7841\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.4991 - val_loss: 6.4927\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.7353 - val_loss: 3.0793\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.3088 - val_loss: 4.2821\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.1524 - val_loss: 2.3831\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.5558 - val_loss: 2.5984\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.0305 - val_loss: 5.0472\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.5678 - val_loss: 2.3208\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.5967 - val_loss: 6.1155\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf22b0d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 24 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 8986407.0000 - val_loss: 102.4497\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6560506.0000 - val_loss: 100.3865\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5299580.0000 - val_loss: 99.9126\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4250134.5000 - val_loss: 99.2466\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 2227399.0000 - val_loss: 98.8359\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1342594.3750 - val_loss: 98.3556\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 917152.4375 - val_loss: 98.1674\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 565935.0000 - val_loss: 97.9534\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 482263.2500 - val_loss: 97.7110\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 319289.2812 - val_loss: 97.5318\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 254016.1094 - val_loss: 97.3219\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 210838.6406 - val_loss: 97.1302\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 207850.9219 - val_loss: 96.9836\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 277927.7500 - val_loss: 96.8049\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 292738.8438 - val_loss: 96.6462\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 453200.0938 - val_loss: 96.5138\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 500029.3750 - val_loss: 96.3908\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 721205.2500 - val_loss: 96.2408\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 334922.0625 - val_loss: 96.0316\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 441964.5938 - val_loss: 95.9202\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 397743.9688 - val_loss: 95.7762\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 492800.4062 - val_loss: 95.6345\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 732203.4375 - val_loss: 95.5214\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 599978.2500 - val_loss: 95.4951\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 420008.0625 - val_loss: 95.3587\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 471434.4062 - val_loss: 95.2347\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 423113.7500 - val_loss: 95.1176\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 464321.5312 - val_loss: 95.0421\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 289699.6250 - val_loss: 94.9246\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 280800.6875 - val_loss: 94.8158\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 343846.5000 - val_loss: 94.7079\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 312788.3750 - val_loss: 94.6106\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 224245.8438 - val_loss: 94.5336\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 199584.2969 - val_loss: 94.4562\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 187748.5469 - val_loss: 94.3697\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 139001.1719 - val_loss: 94.2727\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 158479.6250 - val_loss: 94.1893\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 196149.1875 - val_loss: 94.0648\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 145763.8750 - val_loss: 93.8817\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 150502.5469 - val_loss: 93.7489\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 399087.5312 - val_loss: 93.6568\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 347716.8438 - val_loss: 93.5863\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 349952.2188 - val_loss: 93.5016\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 411458.7812 - val_loss: 93.3789\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 248987.3438 - val_loss: 93.3091\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 177818.4688 - val_loss: 93.2635\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 151915.3594 - val_loss: 93.2016\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 142831.1719 - val_loss: 93.1081\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 303940.1562 - val_loss: 93.0214\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 323179.1250 - val_loss: 92.9563\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9948aee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 25 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 40410.6875 - val_loss: 89.0787\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 189238.0469 - val_loss: 94.2319\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 144680.0625 - val_loss: 90.3593\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14732.3486 - val_loss: 86.5425\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44628.6172 - val_loss: 86.7503\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 75955.4219 - val_loss: 90.2654\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 63070.0586 - val_loss: 94.4989\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35886.4961 - val_loss: 94.1163\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19128.9414 - val_loss: 90.8521\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12008.9131 - val_loss: 92.7376\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37440.7930 - val_loss: 92.9549\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4270.8130 - val_loss: 89.7862\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 142006.6562 - val_loss: 88.6728\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 120560.4609 - val_loss: 91.8617\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 61303.5195 - val_loss: 96.1470\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81144.4922 - val_loss: 97.2891\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 92534.5859 - val_loss: 95.2503\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42217.0156 - val_loss: 90.9533\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 115467.9453 - val_loss: 89.1508\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 104115.9375 - val_loss: 91.8995\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56297.1367 - val_loss: 95.4030\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49556.6758 - val_loss: 96.1037\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10209.8701 - val_loss: 93.9262\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7041.7969 - val_loss: 93.4437\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27008.4219 - val_loss: 93.0646\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 133168.7969 - val_loss: 91.4914\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68458.2031 - val_loss: 94.5287\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50389.8906 - val_loss: 96.0165\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23176.7090 - val_loss: 95.3971\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31738.3652 - val_loss: 96.2943\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3221.7146 - val_loss: 95.7847\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30714.5859 - val_loss: 96.0828\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4353.2402 - val_loss: 95.3883\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54419.7148 - val_loss: 95.9108\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 2435.8931 - val_loss: 95.0594\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52556.3750 - val_loss: 95.1238\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12898.7178 - val_loss: 96.9492\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25457.7344 - val_loss: 99.4130\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 94700.8516 - val_loss: 100.5235\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 92571.7969 - val_loss: 98.2586\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16817.2656 - val_loss: 97.3542\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 49522.7109 - val_loss: 97.5555\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30549.9238 - val_loss: 98.0439\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54229.5117 - val_loss: 97.1349\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 34871.4180 - val_loss: 95.9154\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26508.0254 - val_loss: 95.4814\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26321.9355 - val_loss: 96.7344\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2497.1631 - val_loss: 97.2738\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3507.0645 - val_loss: 96.0763\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30078.7070 - val_loss: 93.3074\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4d1c2c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 26 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 150040.1250 - val_loss: 101.0662\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 184748.3438 - val_loss: 108.4271\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 130620.0234 - val_loss: 98.5691\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 131519.0469 - val_loss: 96.1328\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 92236.5000 - val_loss: 99.3715\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 44336.1797 - val_loss: 105.5012\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 108781.8438 - val_loss: 106.1946\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71582.9844 - val_loss: 104.5617\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27903.1445 - val_loss: 100.3448\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 75832.6484 - val_loss: 99.8155\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38216.6055 - val_loss: 101.5938\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5580.9233 - val_loss: 101.7333\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9849.9189 - val_loss: 102.2883\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66681.8281 - val_loss: 101.5906\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23770.9941 - val_loss: 101.7244\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24681.2812 - val_loss: 100.7738\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 87906.0703 - val_loss: 102.3922\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33906.8359 - val_loss: 102.4527\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24291.5254 - val_loss: 100.6008\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84128.7344 - val_loss: 99.3609\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69403.8125 - val_loss: 101.0541\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18512.8203 - val_loss: 103.2215\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54144.0547 - val_loss: 103.3577\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67968.4375 - val_loss: 102.2812\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4379.2822 - val_loss: 101.7277\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 433.6033 - val_loss: 102.2218\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35857.6055 - val_loss: 101.5947\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9310.4443 - val_loss: 97.7737\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 117231.4375 - val_loss: 97.2470\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 120382.7109 - val_loss: 98.6345\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60255.0859 - val_loss: 100.7185\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15685.9395 - val_loss: 101.5310\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7773.4170 - val_loss: 100.2607\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 47126.8008 - val_loss: 100.2001\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19209.4141 - val_loss: 101.3682\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24980.0332 - val_loss: 102.1162\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19710.4004 - val_loss: 99.9244\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38063.4922 - val_loss: 99.4603\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63308.3086 - val_loss: 101.7757\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13505.2256 - val_loss: 102.3267\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8811.9600 - val_loss: 100.5142\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23554.4805 - val_loss: 100.7212\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2588.9385 - val_loss: 102.2653\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 33040.2344 - val_loss: 101.5989\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8332.0381 - val_loss: 102.2790\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3655.0398 - val_loss: 101.8396\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3946.1426 - val_loss: 103.4301\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 92935.1562 - val_loss: 102.8797\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28458.6113 - val_loss: 100.5938\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37252.7227 - val_loss: 99.1033\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5bb5dd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 27 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 139144.0781 - val_loss: 85.6042\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 249926.6562 - val_loss: 89.5860\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 122596.6953 - val_loss: 84.0715\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 122124.3984 - val_loss: 80.6476\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 73948.1641 - val_loss: 83.7224\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 31113.7539 - val_loss: 92.7066\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 285927.1562 - val_loss: 96.6665\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 226979.5781 - val_loss: 96.3748\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 206621.7031 - val_loss: 92.1188\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 63248.7891 - val_loss: 90.2765\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 126.2955 - val_loss: 89.9702\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 36183.8789 - val_loss: 91.2292\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6585.1367 - val_loss: 90.0434\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42253.4844 - val_loss: 90.6410\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11100.8555 - val_loss: 93.2724\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 62095.6445 - val_loss: 94.4219\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 73761.4297 - val_loss: 93.6868\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 31548.3027 - val_loss: 91.4372\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 159007.1406 - val_loss: 90.4265\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 30983.7129 - val_loss: 91.8759\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 81577.8438 - val_loss: 95.3591\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 99066.5625 - val_loss: 95.8954\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 30811.7207 - val_loss: 94.8919\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 66106.5078 - val_loss: 94.4203\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60194.0742 - val_loss: 94.3345\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12784.4053 - val_loss: 91.3834\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 124415.0391 - val_loss: 90.6020\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 130495.3828 - val_loss: 92.4495\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80696.7500 - val_loss: 95.6246\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85269.6172 - val_loss: 96.4862\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 64380.6133 - val_loss: 95.8848\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 37321.6406 - val_loss: 94.2418\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 92695.7656 - val_loss: 93.0429\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 35647.5977 - val_loss: 94.3230\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5504.0381 - val_loss: 96.4266\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66002.1250 - val_loss: 97.2335\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25028.8691 - val_loss: 96.5729\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24958.4141 - val_loss: 94.6496\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 41230.2539 - val_loss: 93.4384\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 101608.9531 - val_loss: 94.5420\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 16093.8672 - val_loss: 96.8929\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 94653.1484 - val_loss: 97.4503\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 83563.0703 - val_loss: 95.7291\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20009.0723 - val_loss: 93.6937\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31919.5059 - val_loss: 92.8285\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 75257.2656 - val_loss: 94.9968\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19564.5645 - val_loss: 97.4383\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 133412.0625 - val_loss: 98.3949\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64907.7695 - val_loss: 96.7232\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32732.1289 - val_loss: 94.5167\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7eae79d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 28 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 338713.1562 - val_loss: 102.3369\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30315.3652 - val_loss: 108.1902\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79280.1719 - val_loss: 107.7909\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36861.7188 - val_loss: 108.8419\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20900.2598 - val_loss: 110.7619\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 53794.7383 - val_loss: 107.7120\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12787.5215 - val_loss: 107.8517\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8090.6597 - val_loss: 107.2136\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29893.3359 - val_loss: 107.2738\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 93304.1953 - val_loss: 108.6205\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18820.7637 - val_loss: 107.6920\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27073.5723 - val_loss: 103.3322\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 145161.6875 - val_loss: 102.4833\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 66789.5391 - val_loss: 106.5933\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 73625.3906 - val_loss: 110.3119\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 109230.8438 - val_loss: 107.1744\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29602.6387 - val_loss: 101.8706\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 108191.6484 - val_loss: 100.2325\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 108994.4766 - val_loss: 103.4511\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22594.9980 - val_loss: 106.9131\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 89401.5078 - val_loss: 108.0589\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36616.2500 - val_loss: 104.7788\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12113.7246 - val_loss: 105.4579\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19694.0605 - val_loss: 104.6681\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33934.8789 - val_loss: 104.4060\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10235.6553 - val_loss: 108.4081\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 163475.1406 - val_loss: 110.1680\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 90498.5156 - val_loss: 107.4007\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58445.1523 - val_loss: 104.1219\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45407.2070 - val_loss: 101.8241\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77732.1406 - val_loss: 102.3886\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19104.3496 - val_loss: 105.4677\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 90612.2734 - val_loss: 107.6702\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40193.2148 - val_loss: 103.3042\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50701.6484 - val_loss: 101.5779\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18747.7324 - val_loss: 102.2375\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79488.0625 - val_loss: 101.1273\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 94685.5859 - val_loss: 102.6810\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 57101.0859 - val_loss: 106.3795\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77937.5547 - val_loss: 107.1974\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79434.2266 - val_loss: 105.4454\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7597.4258 - val_loss: 104.7178\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22587.7695 - val_loss: 106.7237\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 95281.1484 - val_loss: 107.7108\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 99380.6094 - val_loss: 106.4199\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36088.9180 - val_loss: 103.5434\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 92105.5234 - val_loss: 100.5407\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51641.7461 - val_loss: 100.9859\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49198.1758 - val_loss: 104.1357\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46491.6133 - val_loss: 104.4336\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5221a790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 29 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 143630.8281 - val_loss: 85.5973\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 74541.0938 - val_loss: 95.0285\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28421.1582 - val_loss: 90.9065\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 67774.6953 - val_loss: 89.6385\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 27636.5625 - val_loss: 95.2290\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 148730.5625 - val_loss: 95.6270\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 57046.3633 - val_loss: 91.5243\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13928.8174 - val_loss: 91.8265\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21071.3770 - val_loss: 93.4269\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23001.8320 - val_loss: 92.9318\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19360.3027 - val_loss: 91.8527\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 66616.9297 - val_loss: 90.3042\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 58806.6328 - val_loss: 94.1414\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 60543.8750 - val_loss: 95.7850\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 55180.0391 - val_loss: 90.6827\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55006.5234 - val_loss: 91.2677\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 69331.0234 - val_loss: 92.9935\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15765.4277 - val_loss: 98.2905\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 155470.2656 - val_loss: 100.1941\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 53176.6836 - val_loss: 97.1856\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 63188.1719 - val_loss: 92.9816\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26538.1758 - val_loss: 90.8048\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 90585.2812 - val_loss: 92.6010\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25879.4980 - val_loss: 94.6758\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 57199.5078 - val_loss: 94.3289\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 22412.5254 - val_loss: 93.9584\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24722.0723 - val_loss: 92.2880\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 63720.8164 - val_loss: 92.4870\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 41603.5742 - val_loss: 94.2601\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 20133.3672 - val_loss: 94.3050\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10731.0742 - val_loss: 94.9533\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7488.5576 - val_loss: 97.0389\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 141709.1250 - val_loss: 98.1954\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 97550.9844 - val_loss: 95.5454\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24368.1719 - val_loss: 94.4100\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14435.3340 - val_loss: 93.9955\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 26023.2441 - val_loss: 94.7753\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8585.2783 - val_loss: 94.6451\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 32511.0195 - val_loss: 93.2649\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 52228.8281 - val_loss: 93.1610\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 39028.9961 - val_loss: 93.9201\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5925.6904 - val_loss: 97.6756\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 60599.0273 - val_loss: 98.4544\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43281.6758 - val_loss: 96.6207\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14490.0127 - val_loss: 94.0425\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15238.6016 - val_loss: 94.1747\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 38991.3516 - val_loss: 95.3858\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28645.6934 - val_loss: 95.8086\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7792.0698 - val_loss: 94.0603\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12076.9863 - val_loss: 93.1451\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5a001430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 30 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 70698.0000 - val_loss: 112.8591\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 444998.4062 - val_loss: 117.3616\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 372519.7188 - val_loss: 105.7357\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 81181.4844 - val_loss: 97.2915\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7473.8813 - val_loss: 94.3526\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 49699.6602 - val_loss: 98.7724\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 62153.6562 - val_loss: 97.9252\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 26369.4902 - val_loss: 100.0475\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 121981.5000 - val_loss: 100.0960\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3418.6855 - val_loss: 98.3063\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 34564.5117 - val_loss: 97.9696\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25035.1504 - val_loss: 90.3886\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 251303.4531 - val_loss: 87.0983\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 152851.8281 - val_loss: 90.3637\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 95135.2656 - val_loss: 96.1602\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 24037.8379 - val_loss: 98.5694\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 44721.3164 - val_loss: 97.5811\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6212.8364 - val_loss: 94.5373\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 102237.0234 - val_loss: 93.9045\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 55099.4102 - val_loss: 94.7781\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20329.4219 - val_loss: 98.4794\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 68252.2656 - val_loss: 100.5413\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 78788.9375 - val_loss: 98.8871\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13089.0703 - val_loss: 96.0486\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 48202.3164 - val_loss: 95.5939\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 22923.4531 - val_loss: 96.8834\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9285.3730 - val_loss: 101.6096\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 150476.2500 - val_loss: 102.6474\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 115776.6953 - val_loss: 101.2717\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 56357.1992 - val_loss: 97.9752\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26871.7520 - val_loss: 93.1676\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 75974.6172 - val_loss: 92.3452\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 97394.3984 - val_loss: 93.0085\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13327.6426 - val_loss: 97.6696\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 46233.1016 - val_loss: 99.9607\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 105128.2812 - val_loss: 100.2709\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 67241.7969 - val_loss: 96.7844\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11836.6279 - val_loss: 92.9316\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 109236.0938 - val_loss: 91.8588\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 169490.5156 - val_loss: 93.0849\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 65077.6719 - val_loss: 96.4026\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19157.2559 - val_loss: 96.7963\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6630.0645 - val_loss: 98.1921\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 54677.0000 - val_loss: 98.2312\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 33980.9531 - val_loss: 95.7606\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 34471.7891 - val_loss: 95.7537\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21779.5645 - val_loss: 96.5924\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 45811.5156 - val_loss: 98.2853\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20728.3789 - val_loss: 97.0694\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 3477.5168 - val_loss: 94.1383\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf3ad7be50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 31 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 70.8944 - val_loss: 42.3331\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 48.1223 - val_loss: 46.9469\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 40.8804 - val_loss: 43.8916\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34.5498 - val_loss: 20.5200\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 30.2398 - val_loss: 20.5613\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 27.4367 - val_loss: 16.7363\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23.1521 - val_loss: 5.7837\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22.3701 - val_loss: 7.4644\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19.7891 - val_loss: 6.8199\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.0216 - val_loss: 6.7853\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19.5046 - val_loss: 4.9657\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.2620 - val_loss: 5.7335\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.5603 - val_loss: 6.7847\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18.7052 - val_loss: 4.8101\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.6983 - val_loss: 6.2594\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 18.1617 - val_loss: 6.2794\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.6085 - val_loss: 3.7903\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.6040 - val_loss: 5.4270\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.8883 - val_loss: 6.3791\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.7429 - val_loss: 5.1779\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.8535 - val_loss: 8.4457\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.6107 - val_loss: 5.7124\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.9636 - val_loss: 5.0055\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.7589 - val_loss: 5.3579\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.1678 - val_loss: 4.6830\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 13.9645 - val_loss: 6.2000\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.5530 - val_loss: 5.1176\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.8427 - val_loss: 4.3500\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.6407 - val_loss: 4.2969\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.2797 - val_loss: 6.2395\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.0628 - val_loss: 3.3556\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.8833 - val_loss: 2.5059\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.9598 - val_loss: 4.6136\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.6964 - val_loss: 10.7462\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.8211 - val_loss: 2.3447\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.4750 - val_loss: 5.4861\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.9483 - val_loss: 5.4343\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.7165 - val_loss: 2.3864\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.7783 - val_loss: 6.0701\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.5975 - val_loss: 5.6396\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1865 - val_loss: 6.3496\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.4553 - val_loss: 4.3456\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.7037 - val_loss: 2.5418\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.6361 - val_loss: 7.8416\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.9765 - val_loss: 9.0653\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.1232 - val_loss: 1.6676\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.4950 - val_loss: 6.5231\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.1144 - val_loss: 5.2364\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.2182 - val_loss: 2.0403\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.1200 - val_loss: 8.8303\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf27716160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 32 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 184ms/step - loss: 62.0856 - val_loss: 42.3973\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 44.7986 - val_loss: 38.8007\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 34.9234 - val_loss: 39.7308\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 30.2236 - val_loss: 21.1170\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 24.1383 - val_loss: 17.6325\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 21.0337 - val_loss: 7.5170\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19.6201 - val_loss: 8.0195\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 18.5960 - val_loss: 5.3905\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.1244 - val_loss: 12.5875\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.5633 - val_loss: 6.5222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 17.2741 - val_loss: 8.2860\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 18.8546 - val_loss: 4.0305\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.2129 - val_loss: 7.7801\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.7648 - val_loss: 4.4232\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 14.9646 - val_loss: 3.8767\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.3236 - val_loss: 4.4759\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.7028 - val_loss: 3.8649\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.4545 - val_loss: 6.1173\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.2850 - val_loss: 6.0291\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 15.5943 - val_loss: 7.5711\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.0333 - val_loss: 3.4834\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.5252 - val_loss: 4.0016\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 14.6535 - val_loss: 3.8783\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.8424 - val_loss: 6.9974\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.4965 - val_loss: 5.8548\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.4287 - val_loss: 6.2775\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.5781 - val_loss: 3.8674\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.1574 - val_loss: 5.4656\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12.4256 - val_loss: 3.5121\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.2711 - val_loss: 3.4991\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.4319 - val_loss: 4.4840\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.5402 - val_loss: 3.8286\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.1889 - val_loss: 3.9708\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 9.6091 - val_loss: 5.2114\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.4896 - val_loss: 2.8669\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.8348 - val_loss: 3.5600\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 10.0421 - val_loss: 3.0015\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.6013 - val_loss: 4.6656\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.0431 - val_loss: 3.5193\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.6735 - val_loss: 2.2237\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.8165 - val_loss: 3.8812\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.0639 - val_loss: 2.8466\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.1428 - val_loss: 4.8123\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.3439 - val_loss: 3.3017\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.4388 - val_loss: 6.6016\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.3445 - val_loss: 3.2098\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.0766 - val_loss: 2.0363\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10.2739 - val_loss: 4.9367\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8103 - val_loss: 2.7705\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.3007 - val_loss: 2.5747\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf31b1c3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 33 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 79.3021 - val_loss: 51.2972\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 37.3922 - val_loss: 20.2377\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 35.7275 - val_loss: 35.5236\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28.9697 - val_loss: 37.8068\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 27.0280 - val_loss: 19.5180\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22.8515 - val_loss: 20.3580\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.7842 - val_loss: 13.5730\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.3012 - val_loss: 3.8560\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.4333 - val_loss: 4.5534\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.3437 - val_loss: 5.2736\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.7759 - val_loss: 3.3629\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.3141 - val_loss: 4.3354\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.4833 - val_loss: 7.1886\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.8943 - val_loss: 4.1518\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.5102 - val_loss: 3.4297\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.3811 - val_loss: 3.4738\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.9938 - val_loss: 3.4975\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.8385 - val_loss: 5.8470\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.4106 - val_loss: 4.0109\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.0594 - val_loss: 3.1529\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.4078 - val_loss: 3.7518\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.3664 - val_loss: 4.0687\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.9701 - val_loss: 3.0407\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.6023 - val_loss: 4.9517\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.9811 - val_loss: 4.9000\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7967 - val_loss: 4.5818\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.2739 - val_loss: 5.5989\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.1895 - val_loss: 4.6098\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7558 - val_loss: 3.1376\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.0850 - val_loss: 4.6631\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.0324 - val_loss: 2.4056\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.2281 - val_loss: 4.2731\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.0757 - val_loss: 3.1677\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.6454 - val_loss: 4.7408\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.1705 - val_loss: 4.4917\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.5822 - val_loss: 1.8300\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0099 - val_loss: 2.0487\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0564 - val_loss: 4.6734\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.4942 - val_loss: 2.5275\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.8531 - val_loss: 6.6936\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.0687 - val_loss: 1.8865\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.7840 - val_loss: 7.4772\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.9533 - val_loss: 1.9168\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.1099 - val_loss: 3.9312\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.4134 - val_loss: 3.6838\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.8112 - val_loss: 1.8924\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.8890 - val_loss: 9.1754\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5736 - val_loss: 1.7455\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.3207 - val_loss: 3.2323\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4524 - val_loss: 2.1206\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf27716940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 34 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 118200.3125 - val_loss: 105.5260\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 156233.2031 - val_loss: 98.7906\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 234535.5000 - val_loss: 107.6282\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 332067.1562 - val_loss: 108.9608\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 180992.8750 - val_loss: 100.5475\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 177734.7969 - val_loss: 97.8874\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 139560.9844 - val_loss: 101.8355\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 114878.7734 - val_loss: 101.7750\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 70899.5859 - val_loss: 97.3859\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 219807.2500 - val_loss: 95.9353\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 185799.6406 - val_loss: 100.0641\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 67701.0625 - val_loss: 101.4373\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29702.7305 - val_loss: 99.4401\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 91289.8750 - val_loss: 99.6096\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 49774.3633 - val_loss: 102.2151\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 113997.8281 - val_loss: 102.5148\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 45374.7188 - val_loss: 100.9469\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 62845.4023 - val_loss: 99.7442\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 25541.8574 - val_loss: 96.9018\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 115308.9062 - val_loss: 97.5287\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25304.8730 - val_loss: 98.8004\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 70236.3203 - val_loss: 100.9948\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 107371.7656 - val_loss: 104.8229\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 188135.5312 - val_loss: 104.3581\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 118663.0234 - val_loss: 98.3806\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 113703.7344 - val_loss: 97.0106\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 120206.7266 - val_loss: 99.1510\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 63204.2578 - val_loss: 103.4055\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 174729.4844 - val_loss: 102.5349\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 83649.3750 - val_loss: 99.8919\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 84739.7500 - val_loss: 97.0661\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 175325.6094 - val_loss: 98.3568\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 101211.2422 - val_loss: 103.0421\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 130628.5781 - val_loss: 104.4469\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 147322.7969 - val_loss: 100.9282\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55308.6523 - val_loss: 98.7513\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 99208.0312 - val_loss: 99.1118\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10782.8252 - val_loss: 100.3938\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 96281.7734 - val_loss: 101.0213\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13840.5000 - val_loss: 100.7312\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25745.3027 - val_loss: 100.6054\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 56265.9922 - val_loss: 102.2507\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50915.7734 - val_loss: 102.2758\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 51016.9609 - val_loss: 100.3128\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 104749.7422 - val_loss: 100.3489\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 36530.1562 - val_loss: 100.5307\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38940.5938 - val_loss: 101.1543\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8007.3159 - val_loss: 104.4109\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 215936.9062 - val_loss: 104.6752\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 235088.0000 - val_loss: 103.6815\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf3dea01f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 35 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 73.4926 - val_loss: 47.3249\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34.4365 - val_loss: 12.0185\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 31.2645 - val_loss: 38.2875\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27.2926 - val_loss: 36.5227\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 23.8020 - val_loss: 18.0745\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22.2252 - val_loss: 22.6771\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.5831 - val_loss: 27.4196\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.4516 - val_loss: 12.9665\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.5583 - val_loss: 14.1357\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.1589 - val_loss: 11.1986\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.4229 - val_loss: 8.2385\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.7429 - val_loss: 7.5591\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.9312 - val_loss: 5.5062\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.3477 - val_loss: 9.7679\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.1749 - val_loss: 3.7636\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.6218 - val_loss: 6.9676\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.3075 - val_loss: 2.5356\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.5666 - val_loss: 8.8045\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.6478 - val_loss: 3.5754\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.9396 - val_loss: 6.9704\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.3395 - val_loss: 2.6536\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.6813 - val_loss: 4.5923\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.1506 - val_loss: 4.3727\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.1212 - val_loss: 2.7245\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.5479 - val_loss: 3.4438\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.0871 - val_loss: 2.8983\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.9729 - val_loss: 4.5005\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9690 - val_loss: 3.1200\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.1920 - val_loss: 2.6543\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.3755 - val_loss: 3.6237\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.5879 - val_loss: 2.9161\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7967 - val_loss: 3.2956\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.8471 - val_loss: 3.8107\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.8290 - val_loss: 4.1943\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.4742 - val_loss: 2.8732\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.6617 - val_loss: 2.5882\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.1581 - val_loss: 4.1725\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.3426 - val_loss: 4.1965\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.3189 - val_loss: 6.2133\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.4419 - val_loss: 4.5927\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.5390 - val_loss: 3.5546\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.7791 - val_loss: 2.7875\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.3522 - val_loss: 2.8509\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.4606 - val_loss: 3.0652\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.8020 - val_loss: 2.8105\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.4161 - val_loss: 2.8331\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.7282 - val_loss: 5.0691\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9.9835 - val_loss: 3.6921\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.0547 - val_loss: 4.9717\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.0090 - val_loss: 2.4934\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf82358430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 36 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 19036.3301 - val_loss: 95.0840\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 214234.5625 - val_loss: 94.3191\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 157767.4531 - val_loss: 100.1888\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 17884.6680 - val_loss: 101.9322\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 155708.4062 - val_loss: 101.9501\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 40062.0898 - val_loss: 99.8413\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 49489.4531 - val_loss: 101.5644\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9443.2383 - val_loss: 100.6298\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16952.8809 - val_loss: 97.1451\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 105245.4062 - val_loss: 97.1797\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 44105.0977 - val_loss: 99.6736\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 86175.9453 - val_loss: 99.9170\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 27695.8711 - val_loss: 101.4157\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 22017.3359 - val_loss: 100.8068\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23248.5879 - val_loss: 98.6835\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 119590.6953 - val_loss: 97.5073\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 91858.3984 - val_loss: 100.0241\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 26403.9258 - val_loss: 101.0571\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 34253.0820 - val_loss: 100.3003\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10070.9199 - val_loss: 100.2473\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1217.7672 - val_loss: 101.9116\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 51307.7578 - val_loss: 101.1178\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 30543.7559 - val_loss: 102.2399\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 87601.0000 - val_loss: 101.7233\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23512.2383 - val_loss: 100.0981\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 30527.2539 - val_loss: 98.6209\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13861.9043 - val_loss: 101.9307\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 20896.5566 - val_loss: 102.7319\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 59817.3164 - val_loss: 100.0855\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23322.6074 - val_loss: 93.8621\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 95910.6250 - val_loss: 90.1400\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 83993.2500 - val_loss: 93.7555\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 136319.8750 - val_loss: 97.0645\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12657.7061 - val_loss: 99.4512\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 39226.0039 - val_loss: 101.6555\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 81579.8125 - val_loss: 101.0125\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9994.6025 - val_loss: 99.4865\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 91395.4922 - val_loss: 97.1160\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 20898.0762 - val_loss: 94.9495\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 156827.8125 - val_loss: 93.7397\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 181301.4375 - val_loss: 95.7962\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 101866.7344 - val_loss: 97.9849\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 12868.8623 - val_loss: 100.3632\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 53666.7227 - val_loss: 101.0802\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 57227.6055 - val_loss: 100.1518\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 14122.2217 - val_loss: 97.8415\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 69386.6562 - val_loss: 97.4223\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 56124.6328 - val_loss: 99.2319\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7672.8267 - val_loss: 99.6323\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 45399.1719 - val_loss: 98.5312\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf6b0f5040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 37 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 85.8328 - val_loss: 51.8457\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31.1960 - val_loss: 4.3919\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 28.2844 - val_loss: 27.2723\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25.4694 - val_loss: 37.4676\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 22.0913 - val_loss: 22.3896\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.4745 - val_loss: 11.6773\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 18.0049 - val_loss: 18.9768\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.1649 - val_loss: 19.3426\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.2557 - val_loss: 13.6370\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.2750 - val_loss: 11.3796\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.0328 - val_loss: 14.4825\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.9920 - val_loss: 10.6406\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.9918 - val_loss: 3.5619\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.3786 - val_loss: 5.1443\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.1651 - val_loss: 2.9445\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.4932 - val_loss: 2.8080\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.4206 - val_loss: 5.9860\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8190 - val_loss: 2.5352\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.6610 - val_loss: 4.5463\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.8477 - val_loss: 2.7103\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.3963 - val_loss: 3.2437\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.7627 - val_loss: 3.3294\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.1840 - val_loss: 2.8198\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.3312 - val_loss: 4.8005\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.7249 - val_loss: 2.6391\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6669 - val_loss: 3.4974\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.1503 - val_loss: 2.9041\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.4472 - val_loss: 2.9673\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.8534 - val_loss: 3.5346\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.5454 - val_loss: 2.6416\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.3150 - val_loss: 3.6921\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.7195 - val_loss: 3.0633\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.4645 - val_loss: 2.2463\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.2412 - val_loss: 3.4373\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.9275 - val_loss: 2.8130\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.3947 - val_loss: 2.6586\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.7506 - val_loss: 2.8489\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.7474 - val_loss: 5.0797\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.4693 - val_loss: 2.8046\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.0678 - val_loss: 2.6361\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.8583 - val_loss: 2.1947\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.9638 - val_loss: 2.5865\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.6107 - val_loss: 2.3898\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.3077 - val_loss: 3.1344\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.7372 - val_loss: 2.1552\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.4956 - val_loss: 2.4270\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.6194 - val_loss: 3.8050\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.7227 - val_loss: 4.3501\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.1269 - val_loss: 2.2555\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.6960 - val_loss: 2.6805\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf2c001d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 38 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 88.7129 - val_loss: 63.9323\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43.4998 - val_loss: 30.8454\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 39.7495 - val_loss: 33.3927\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 30.6189 - val_loss: 34.1981\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 25.6781 - val_loss: 19.6257\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.4233 - val_loss: 16.8765\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19.0922 - val_loss: 10.7287\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.6450 - val_loss: 8.0299\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17.7706 - val_loss: 6.3877\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.9525 - val_loss: 12.1553\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.1416 - val_loss: 4.9673\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.1913 - val_loss: 5.8846\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.2947 - val_loss: 3.6880\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.4662 - val_loss: 10.1626\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.8536 - val_loss: 4.1008\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.6550 - val_loss: 9.2964\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.2225 - val_loss: 4.0761\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.8499 - val_loss: 6.9169\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.8806 - val_loss: 5.1742\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.3161 - val_loss: 4.8882\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.9146 - val_loss: 6.2152\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12.2809 - val_loss: 4.3631\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.9093 - val_loss: 7.5864\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.2824 - val_loss: 4.5192\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.9577 - val_loss: 7.5353\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.8700 - val_loss: 7.6551\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.5720 - val_loss: 3.0552\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.5989 - val_loss: 7.4873\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 10.5295 - val_loss: 3.6705\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.4623 - val_loss: 6.7294\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.6291 - val_loss: 7.0891\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.2216 - val_loss: 3.4500\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.7491 - val_loss: 9.1754\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7362 - val_loss: 3.5882\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.3227 - val_loss: 11.3447\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.8929 - val_loss: 3.7506\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5332 - val_loss: 5.3994\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.0192 - val_loss: 4.7543\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.6166 - val_loss: 4.6264\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7444 - val_loss: 5.3039\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0248 - val_loss: 4.5310\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8111 - val_loss: 4.1959\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.1068 - val_loss: 5.9016\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.3455 - val_loss: 5.9894\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.1841 - val_loss: 5.8454\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.9283 - val_loss: 3.3915\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.6686 - val_loss: 9.4262\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.1576 - val_loss: 3.4928\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.5502 - val_loss: 6.0114\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.7837 - val_loss: 3.3886\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf71079d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 39 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 127210.9062 - val_loss: 101.1409\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 79877.4531 - val_loss: 91.2308\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 314034.5000 - val_loss: 91.1230\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 159386.9375 - val_loss: 99.5298\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 136769.2344 - val_loss: 99.8560\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 85002.0391 - val_loss: 99.7006\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 117468.7500 - val_loss: 94.7035\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15655.0918 - val_loss: 93.5894\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 200584.2812 - val_loss: 97.6545\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 116118.2500 - val_loss: 98.3199\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 61988.8281 - val_loss: 95.5662\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6648.1514 - val_loss: 95.5075\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 62790.6719 - val_loss: 97.9080\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 38627.5391 - val_loss: 99.0947\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 81739.5625 - val_loss: 96.0977\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 53620.0938 - val_loss: 95.4884\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 107415.4766 - val_loss: 98.3280\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29839.0039 - val_loss: 98.5546\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 44298.5781 - val_loss: 97.8769\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 27046.3945 - val_loss: 96.9520\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 79293.6953 - val_loss: 96.7684\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26560.0059 - val_loss: 96.6767\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 20026.1895 - val_loss: 96.6004\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33867.1367 - val_loss: 96.1982\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 29883.8125 - val_loss: 96.6860\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32379.8027 - val_loss: 98.3476\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 39717.0898 - val_loss: 98.9071\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10251.3271 - val_loss: 97.8129\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 53812.6680 - val_loss: 99.9724\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 76929.7500 - val_loss: 100.7861\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23337.4551 - val_loss: 99.2767\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 56123.9023 - val_loss: 100.3626\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 50707.0508 - val_loss: 103.4833\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 92115.3125 - val_loss: 102.9574\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 69510.3125 - val_loss: 100.5261\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 93603.3984 - val_loss: 101.1378\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24246.8105 - val_loss: 103.3624\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 111924.4609 - val_loss: 104.4114\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 112491.8984 - val_loss: 103.4368\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 49950.0430 - val_loss: 102.0598\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 50937.7500 - val_loss: 103.1057\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 25816.0234 - val_loss: 102.4207\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43431.1328 - val_loss: 103.1483\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15295.5195 - val_loss: 103.8437\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 99070.4688 - val_loss: 102.6303\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 26351.7598 - val_loss: 100.8312\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 40714.7539 - val_loss: 99.2931\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 129701.7656 - val_loss: 99.6620\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19595.6016 - val_loss: 102.8619\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 90676.0156 - val_loss: 105.5933\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf20a20d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 40 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 90.3436 - val_loss: 70.7393\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 70.2161 - val_loss: 65.2734\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 57.4884 - val_loss: 44.5284\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 54.0712 - val_loss: 44.4780\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 52.0448 - val_loss: 44.5219\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 45.3145 - val_loss: 32.8007\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 45.2293 - val_loss: 35.6077\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 40.7129 - val_loss: 26.9417\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 41.0424 - val_loss: 24.2437\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38.5156 - val_loss: 26.9217\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 37.0857 - val_loss: 13.0133\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 38.6139 - val_loss: 21.4564\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 33.8301 - val_loss: 19.4666\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 32.6269 - val_loss: 5.8152\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 32.7816 - val_loss: 10.6838\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 26.3618 - val_loss: 13.0193\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 25.0650 - val_loss: 8.6889\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25.5681 - val_loss: 5.2982\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 22.1757 - val_loss: 11.2517\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.6171 - val_loss: 18.8606\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 26.2077 - val_loss: 5.1093\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.4568 - val_loss: 14.4783\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 16.2165 - val_loss: 7.5883\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.2991 - val_loss: 12.2830\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.9273 - val_loss: 4.2383\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.4520 - val_loss: 10.7248\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.8895 - val_loss: 6.7338\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.6565 - val_loss: 10.8310\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15.7660 - val_loss: 6.7258\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.8563 - val_loss: 3.8839\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 16.0897 - val_loss: 8.8463\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.1651 - val_loss: 9.5651\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.9371 - val_loss: 9.9511\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.3253 - val_loss: 6.4488\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.8264 - val_loss: 5.6299\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.4701 - val_loss: 8.5716\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.5028 - val_loss: 7.3958\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.5565 - val_loss: 6.2806\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12.8909 - val_loss: 4.8698\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.3145 - val_loss: 7.3637\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.4635 - val_loss: 6.9047\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.5763 - val_loss: 3.0783\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 18.2099 - val_loss: 15.1177\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.2860 - val_loss: 3.1667\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.5602 - val_loss: 2.9263\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.3214 - val_loss: 12.0461\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.9027 - val_loss: 3.4403\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.0665 - val_loss: 3.7068\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.7589 - val_loss: 9.5832\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.1533 - val_loss: 6.8549\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf135271f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 41 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 106811.3047 - val_loss: 71.5004\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 111564.8984 - val_loss: 78.0677\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 87075.5156 - val_loss: 73.4731\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 99784.9766 - val_loss: 74.1081\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 99607.6094 - val_loss: 82.4185\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 179683.5938 - val_loss: 85.1172\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 137776.5781 - val_loss: 81.7768\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24598.4102 - val_loss: 75.4597\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 241246.0781 - val_loss: 73.3756\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 201716.5469 - val_loss: 79.8845\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 79456.0547 - val_loss: 85.6698\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 86848.1094 - val_loss: 87.4439\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 109790.5859 - val_loss: 85.9758\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 26634.4746 - val_loss: 81.9439\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 143956.3906 - val_loss: 80.4736\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 149812.8438 - val_loss: 85.4325\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35816.3398 - val_loss: 87.3385\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1646.7799 - val_loss: 87.0950\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43282.1992 - val_loss: 87.3400\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19120.0312 - val_loss: 88.3538\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30763.0234 - val_loss: 88.6733\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 35800.2812 - val_loss: 87.4048\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 47956.8672 - val_loss: 86.9982\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11682.0479 - val_loss: 88.8594\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 89155.6484 - val_loss: 89.4694\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 46630.5312 - val_loss: 86.9396\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 71520.0234 - val_loss: 87.1965\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 845.3182 - val_loss: 86.1646\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 90530.4766 - val_loss: 85.9408\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 52079.2148 - val_loss: 88.4991\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 75087.9531 - val_loss: 89.5922\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 33342.5508 - val_loss: 86.2663\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 114114.8828 - val_loss: 85.8695\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 81542.0625 - val_loss: 87.4053\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 92922.7188 - val_loss: 91.0630\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28471.6445 - val_loss: 91.3971\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 53441.8828 - val_loss: 90.7062\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50405.8945 - val_loss: 90.3868\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20640.7520 - val_loss: 91.0757\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 58136.0195 - val_loss: 91.4890\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 39839.3242 - val_loss: 89.9965\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4500.1426 - val_loss: 89.2724\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 34240.1211 - val_loss: 90.2063\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20033.2812 - val_loss: 90.4266\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15868.0098 - val_loss: 90.9336\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28306.3809 - val_loss: 92.8370\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 83434.1875 - val_loss: 92.5134\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 83883.6094 - val_loss: 91.3160\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 46321.7812 - val_loss: 88.5387\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 92203.6953 - val_loss: 88.3497\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf1792daf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 42 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 91889.5156 - val_loss: 102.8069\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38093.7461 - val_loss: 100.9211\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6346.8687 - val_loss: 106.7499\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 61888.3359 - val_loss: 104.6368\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 26576.0703 - val_loss: 97.9251\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 67843.3594 - val_loss: 99.6676\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 79764.0391 - val_loss: 103.6074\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 50428.2383 - val_loss: 102.4798\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 33174.5977 - val_loss: 98.8802\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 83170.7500 - val_loss: 97.4049\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 38203.2227 - val_loss: 100.0250\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 86166.6875 - val_loss: 103.3234\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1740.7393 - val_loss: 100.7423\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 98079.9922 - val_loss: 97.4811\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 56845.3008 - val_loss: 99.7059\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16662.5293 - val_loss: 99.4935\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6236.9888 - val_loss: 99.1147\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11348.5625 - val_loss: 100.8600\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 54897.9258 - val_loss: 100.2592\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 57895.6250 - val_loss: 99.9187\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 33429.6484 - val_loss: 99.2970\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18982.6504 - val_loss: 101.8767\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 31523.6816 - val_loss: 102.1774\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 65628.4688 - val_loss: 98.7867\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 84221.1562 - val_loss: 98.2927\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23022.3672 - val_loss: 101.1229\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 58393.1445 - val_loss: 102.6783\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11489.0107 - val_loss: 99.7616\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 82425.2422 - val_loss: 98.0584\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 92560.5234 - val_loss: 99.9186\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 2734.0234 - val_loss: 100.7250\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20253.6719 - val_loss: 98.2919\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 72891.1719 - val_loss: 98.0878\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 72190.4844 - val_loss: 99.8014\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 36106.4219 - val_loss: 102.6874\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 40181.0117 - val_loss: 103.0628\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 55860.2422 - val_loss: 101.4359\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22372.8027 - val_loss: 98.7125\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 141132.0781 - val_loss: 97.1957\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 138555.2500 - val_loss: 99.4352\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 25492.4160 - val_loss: 101.1523\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11005.3027 - val_loss: 102.5481\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 30491.1777 - val_loss: 103.2252\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47192.0938 - val_loss: 101.7983\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 17566.0879 - val_loss: 102.4599\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55943.4023 - val_loss: 98.5411\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 44955.3086 - val_loss: 98.6624\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32736.7305 - val_loss: 99.8005\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 34823.1367 - val_loss: 102.6304\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 82868.8594 - val_loss: 104.2406\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf20a20dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 43 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 56.9259 - val_loss: 27.4475\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43.5063 - val_loss: 31.3083\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 32.7638 - val_loss: 38.7839\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29.9840 - val_loss: 21.3684\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 25.2444 - val_loss: 10.2496\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20.3039 - val_loss: 13.5824\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18.7568 - val_loss: 5.1546\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.6466 - val_loss: 13.6912\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.7008 - val_loss: 6.5709\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.2481 - val_loss: 7.5718\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17.5689 - val_loss: 14.8262\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.6487 - val_loss: 3.6955\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16.3809 - val_loss: 8.7352\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.0905 - val_loss: 5.7354\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.3260 - val_loss: 3.9151\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.1939 - val_loss: 6.4014\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.3540 - val_loss: 4.5072\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.5285 - val_loss: 4.5996\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.7541 - val_loss: 4.2510\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.4727 - val_loss: 4.5478\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.9056 - val_loss: 3.6268\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.3949 - val_loss: 2.8703\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.3357 - val_loss: 2.6585\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.8288 - val_loss: 6.6356\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.6277 - val_loss: 3.1747\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.0265 - val_loss: 4.6303\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.1074 - val_loss: 3.0386\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.3251 - val_loss: 3.2258\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.8522 - val_loss: 1.9161\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4323 - val_loss: 4.9368\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.7698 - val_loss: 2.1873\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.1057 - val_loss: 3.8813\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.9517 - val_loss: 1.7776\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.4356 - val_loss: 3.2260\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.2252 - val_loss: 6.4285\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9790 - val_loss: 1.6098\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.7016 - val_loss: 4.7650\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.9773 - val_loss: 7.8890\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.4963 - val_loss: 2.4544\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.8969 - val_loss: 8.1156\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.7021 - val_loss: 1.7158\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0767 - val_loss: 4.6298\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.3112 - val_loss: 2.1993\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.4404 - val_loss: 4.9593\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.4272 - val_loss: 3.1172\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3307 - val_loss: 1.5040\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.1546 - val_loss: 3.7931\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.4601 - val_loss: 1.8476\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.8742 - val_loss: 1.7456\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.7669 - val_loss: 2.0153\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf32672280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 44 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 71.7942 - val_loss: 48.5049\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 64.0140 - val_loss: 39.8678\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 50.6330 - val_loss: 51.7486\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 41.1838 - val_loss: 39.0666\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 35.7407 - val_loss: 22.4286\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 35.3242 - val_loss: 23.2293\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 32.4691 - val_loss: 27.4621\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28.6493 - val_loss: 13.5416\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28.9069 - val_loss: 5.3281\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 22.2108 - val_loss: 15.1485\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21.0150 - val_loss: 4.6889\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 23.6955 - val_loss: 10.7062\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 20.5970 - val_loss: 5.0604\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 17.6807 - val_loss: 6.6246\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.6747 - val_loss: 13.3322\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.5347 - val_loss: 5.0351\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.3394 - val_loss: 9.9693\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.8228 - val_loss: 8.2304\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.5886 - val_loss: 7.1173\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.2906 - val_loss: 6.5459\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 13.7108 - val_loss: 9.8017\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.6906 - val_loss: 8.4879\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 15.1082 - val_loss: 4.7277\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.8441 - val_loss: 11.6394\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 12.9655 - val_loss: 5.3924\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.0682 - val_loss: 8.9699\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.3061 - val_loss: 4.4339\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12.6488 - val_loss: 11.6574\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.9044 - val_loss: 5.8596\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 12.6971 - val_loss: 7.7606\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.8684 - val_loss: 8.8185\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.1687 - val_loss: 4.9776\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.6603 - val_loss: 9.0818\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.6940 - val_loss: 6.4113\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.0905 - val_loss: 6.3361\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.0687 - val_loss: 4.7991\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.8020 - val_loss: 6.3300\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.4808 - val_loss: 4.6155\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.2676 - val_loss: 7.1359\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.5109 - val_loss: 6.4805\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.3596 - val_loss: 5.5171\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 10.2136 - val_loss: 4.8647\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.0118 - val_loss: 5.9920\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.7957 - val_loss: 3.9033\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.4392 - val_loss: 7.7403\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10.3759 - val_loss: 3.6038\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.9044 - val_loss: 6.5890\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 11.5912 - val_loss: 6.5869\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.3097 - val_loss: 5.3103\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.2189 - val_loss: 4.0458\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4d6ccc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 45 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 13298.3711 - val_loss: 104.0288\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 305661.5625 - val_loss: 108.5189\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 302993.3750 - val_loss: 100.3105\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 123006.4453 - val_loss: 94.1199\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 12726.7842 - val_loss: 93.7245\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 41981.1680 - val_loss: 94.2245\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 17890.2832 - val_loss: 95.1268\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 23935.1621 - val_loss: 94.4269\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 46610.6992 - val_loss: 93.0187\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 46176.7461 - val_loss: 94.7423\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 14109.7451 - val_loss: 98.1335\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 96511.1875 - val_loss: 98.6943\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 94670.2344 - val_loss: 98.1513\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 63083.7500 - val_loss: 96.6398\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 30528.9766 - val_loss: 94.0782\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 68695.2969 - val_loss: 93.2983\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 65930.4453 - val_loss: 94.9921\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 18401.4629 - val_loss: 95.7902\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 43340.6562 - val_loss: 96.0233\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9765.5752 - val_loss: 98.0426\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 32868.6836 - val_loss: 97.9099\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 34576.4492 - val_loss: 97.2306\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4621.3130 - val_loss: 96.4208\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14085.0645 - val_loss: 96.8248\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24293.4375 - val_loss: 96.6171\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 17097.5020 - val_loss: 96.6874\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12583.9434 - val_loss: 98.9461\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 38309.4023 - val_loss: 98.9191\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14759.9189 - val_loss: 97.3307\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 17762.1348 - val_loss: 98.0280\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 80194.4531 - val_loss: 97.6803\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9535.0674 - val_loss: 95.3797\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 23003.8164 - val_loss: 94.1612\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 70489.2891 - val_loss: 96.3508\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 45933.0742 - val_loss: 97.9824\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19305.0176 - val_loss: 99.0018\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 49266.6562 - val_loss: 98.2337\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 72478.7656 - val_loss: 96.5106\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9871.9297 - val_loss: 94.1542\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 71398.2578 - val_loss: 93.8722\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 127136.2500 - val_loss: 94.3521\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19848.6328 - val_loss: 96.8047\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 18617.3828 - val_loss: 100.8704\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 88906.5234 - val_loss: 102.5239\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 103637.7578 - val_loss: 101.1988\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 65914.3984 - val_loss: 99.4733\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 38234.0664 - val_loss: 96.9950\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 87885.5078 - val_loss: 96.1976\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 62929.9883 - val_loss: 97.6155\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32602.6211 - val_loss: 97.6109\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5c6b9430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 46 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 52514.2852 - val_loss: 84.2970\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 436928.9688 - val_loss: 91.3780\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 191892.5469 - val_loss: 96.7695\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 58602.3633 - val_loss: 104.1686\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 107806.7969 - val_loss: 108.6379\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 101737.4297 - val_loss: 106.7200\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 85442.5469 - val_loss: 103.9904\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9889.2559 - val_loss: 98.0265\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 137354.5469 - val_loss: 97.5735\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 101109.1094 - val_loss: 99.4503\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 48772.5273 - val_loss: 103.4649\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11570.5977 - val_loss: 103.3758\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 41335.5078 - val_loss: 101.2209\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 65574.5234 - val_loss: 100.2786\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 86692.8125 - val_loss: 102.6646\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 51869.5977 - val_loss: 102.3673\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7011.1660 - val_loss: 104.0233\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 96402.3125 - val_loss: 103.1757\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 49156.5742 - val_loss: 101.6802\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 44696.8125 - val_loss: 99.7220\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 62903.8945 - val_loss: 101.2771\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 44155.8594 - val_loss: 100.9538\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6555.9077 - val_loss: 99.2346\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 82227.3047 - val_loss: 98.4350\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 56791.8008 - val_loss: 99.8372\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 31590.0820 - val_loss: 103.1292\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 96663.1172 - val_loss: 104.0850\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 108319.1016 - val_loss: 103.5388\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6599.9224 - val_loss: 102.1304\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 71558.0156 - val_loss: 100.9986\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3318.5913 - val_loss: 101.4484\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 40291.1680 - val_loss: 101.3111\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 30357.0098 - val_loss: 99.4196\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 97828.6641 - val_loss: 98.7902\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 84868.8203 - val_loss: 100.6210\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4774.1914 - val_loss: 103.2252\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 71800.0625 - val_loss: 103.5396\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 90657.9375 - val_loss: 101.4145\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 48671.2188 - val_loss: 99.5716\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4773.4048 - val_loss: 99.2201\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 57456.2773 - val_loss: 99.7073\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3204.0566 - val_loss: 101.8492\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 70378.4531 - val_loss: 102.0159\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 85734.8984 - val_loss: 101.4931\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 41678.1367 - val_loss: 100.1648\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9224.3867 - val_loss: 97.4016\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 92075.3047 - val_loss: 96.8238\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 118190.6875 - val_loss: 98.0185\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 76268.3359 - val_loss: 99.8454\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 78918.9453 - val_loss: 100.5876\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf48131430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 47 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2275\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5bb5da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 48 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 29513.0879 - val_loss: 130.3569\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 510957.6875 - val_loss: 133.6250\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 460025.0938 - val_loss: 117.5840\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 143156.2031 - val_loss: 104.5113\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 177546.5938 - val_loss: 99.0549\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 99681.9219 - val_loss: 103.4823\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31409.5195 - val_loss: 103.9288\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9347.3311 - val_loss: 105.4431\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 84689.7734 - val_loss: 103.8331\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 74648.4297 - val_loss: 105.2349\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 101196.1328 - val_loss: 104.1524\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19501.4004 - val_loss: 106.0058\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 72981.3125 - val_loss: 104.8670\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9638.3057 - val_loss: 100.6013\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 64045.0938 - val_loss: 101.2674\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43481.3789 - val_loss: 104.0429\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 25714.3809 - val_loss: 104.6735\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32011.9609 - val_loss: 100.1869\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 130114.5391 - val_loss: 98.5847\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 122412.0625 - val_loss: 103.6351\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 70456.6953 - val_loss: 104.8294\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 64347.3867 - val_loss: 102.9185\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33810.4062 - val_loss: 101.7666\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 27439.0371 - val_loss: 102.8274\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8077.3042 - val_loss: 101.5546\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 97158.9062 - val_loss: 100.0534\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 51044.4766 - val_loss: 102.0453\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4714.3584 - val_loss: 104.8472\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 77865.0312 - val_loss: 105.8964\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 59936.4023 - val_loss: 103.2391\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8743.1992 - val_loss: 102.6939\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 124182.6875 - val_loss: 101.9484\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25049.7480 - val_loss: 103.8153\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 57737.9141 - val_loss: 103.9301\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8347.0859 - val_loss: 102.9000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 37380.5000 - val_loss: 101.1112\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 71159.9688 - val_loss: 100.5627\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5500.0078 - val_loss: 103.9308\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 61918.1562 - val_loss: 105.1733\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 73968.4766 - val_loss: 104.7299\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14330.9707 - val_loss: 100.1178\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 103982.7344 - val_loss: 98.4780\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 90631.0000 - val_loss: 99.8001\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 56660.8828 - val_loss: 103.0317\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17279.7617 - val_loss: 106.6085\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 126093.6875 - val_loss: 106.6710\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 138753.2969 - val_loss: 105.7429\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 111927.0391 - val_loss: 103.3689\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3350.7109 - val_loss: 102.8817\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 32971.7969 - val_loss: 101.1001\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf1de974c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 49 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 72.9494 - val_loss: 53.8133\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 47.7786 - val_loss: 36.3682\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 35.7377 - val_loss: 36.6364\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28.4807 - val_loss: 23.3156\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 28.7402 - val_loss: 11.1476\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 22.5582 - val_loss: 22.7168\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22.4134 - val_loss: 4.8299\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 21.0193 - val_loss: 7.9713\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24.5226 - val_loss: 15.8201\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 20.2897 - val_loss: 2.5208\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 19.3837 - val_loss: 8.7178\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.4448 - val_loss: 8.9818\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 15.7791 - val_loss: 3.2640\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.5219 - val_loss: 5.6484\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15.7647 - val_loss: 3.7730\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.5331 - val_loss: 4.0443\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.3966 - val_loss: 5.3221\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.7071 - val_loss: 2.9930\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.2252 - val_loss: 4.1581\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.9021 - val_loss: 4.2408\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.5206 - val_loss: 3.6323\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.9323 - val_loss: 3.4796\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.6290 - val_loss: 2.4473\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.9202 - val_loss: 6.4649\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.1917 - val_loss: 3.6765\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.4727 - val_loss: 2.7120\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.7551 - val_loss: 3.1762\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.8432 - val_loss: 3.7254\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.3299 - val_loss: 3.2560\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.8381 - val_loss: 2.1740\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.6596 - val_loss: 2.5958\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.5927 - val_loss: 4.3391\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.0939 - val_loss: 8.5581\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.2391 - val_loss: 5.5614\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.7889 - val_loss: 4.2444\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.9723 - val_loss: 2.7114\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.5241 - val_loss: 2.5862\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.8450 - val_loss: 4.5977\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.6829 - val_loss: 3.8140\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.3405 - val_loss: 3.8157\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.3781 - val_loss: 3.2918\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.5562 - val_loss: 6.8997\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.1873 - val_loss: 2.3985\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.5950 - val_loss: 3.1659\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.2788 - val_loss: 4.4961\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7696 - val_loss: 2.5091\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.1320 - val_loss: 2.9301\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.8181 - val_loss: 5.8257\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.1887 - val_loss: 4.4547\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9092 - val_loss: 4.9414\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf0e94aaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 50 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 77.0424 - val_loss: 53.4368\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 42.1092 - val_loss: 28.8839\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 34.0760 - val_loss: 36.9333\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 27.2942 - val_loss: 28.5521\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 22.1019 - val_loss: 16.5232\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17.1442 - val_loss: 7.0581\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.8456 - val_loss: 6.4537\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.5480 - val_loss: 3.9989\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.8268 - val_loss: 5.2903\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.5466 - val_loss: 8.2421\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.1908 - val_loss: 6.9642\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.0955 - val_loss: 6.2306\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.4853 - val_loss: 7.2915\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.6638 - val_loss: 4.8229\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.8935 - val_loss: 12.7255\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.0638 - val_loss: 4.0059\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.2914 - val_loss: 9.3873\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.7821 - val_loss: 3.7221\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.0591 - val_loss: 5.7536\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.8980 - val_loss: 7.9905\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.5744 - val_loss: 8.0106\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.4935 - val_loss: 5.7133\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.4356 - val_loss: 3.8656\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.7676 - val_loss: 7.6824\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.6770 - val_loss: 4.6602\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.8843 - val_loss: 4.9720\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4307 - val_loss: 5.6852\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.5559 - val_loss: 6.9562\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6549 - val_loss: 5.6680\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.8629 - val_loss: 8.5155\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.2457 - val_loss: 5.3129\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.9677 - val_loss: 6.8864\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.6072 - val_loss: 4.2132\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.1325 - val_loss: 7.9478\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.7081 - val_loss: 4.2798\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.6604 - val_loss: 7.0395\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.8579 - val_loss: 6.3762\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.0928 - val_loss: 6.3529\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.7757 - val_loss: 5.4001\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.3221 - val_loss: 7.1537\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.9237 - val_loss: 5.1185\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.7619 - val_loss: 5.8984\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.8304 - val_loss: 6.4186\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.9522 - val_loss: 5.3700\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.7469 - val_loss: 4.3431\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.1708 - val_loss: 3.8148\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5655 - val_loss: 6.5743\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.0808 - val_loss: 4.8078\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.0753 - val_loss: 3.6909\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.5736 - val_loss: 3.7747\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdefbc1b1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 51 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 1233304.7500 - val_loss: 60.2710\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 727953.8125 - val_loss: 82.0357\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 384715.9062 - val_loss: 97.4696\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 82236.0234 - val_loss: 111.4648\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 696596.5000 - val_loss: 117.1113\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 578965.3750 - val_loss: 110.6826\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 241978.4688 - val_loss: 102.8670\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 31851.3652 - val_loss: 98.4376\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9319.7695 - val_loss: 95.6635\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 147181.0312 - val_loss: 96.4644\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18747.7188 - val_loss: 102.0965\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 256588.9219 - val_loss: 102.5886\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 102866.4062 - val_loss: 99.3617\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 116820.4375 - val_loss: 99.3447\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 48996.7422 - val_loss: 97.5186\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 83066.8906 - val_loss: 97.4778\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47568.1094 - val_loss: 101.1812\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 148512.2656 - val_loss: 102.4070\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 188657.2344 - val_loss: 99.1519\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 105678.5469 - val_loss: 93.8205\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 254357.5469 - val_loss: 92.2912\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 246600.3438 - val_loss: 94.2302\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 63489.8477 - val_loss: 99.7419\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 121862.7109 - val_loss: 102.1241\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 140978.1562 - val_loss: 101.2906\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 58065.6836 - val_loss: 98.4218\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 106614.3516 - val_loss: 97.4308\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 104869.1641 - val_loss: 99.8450\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 95722.1562 - val_loss: 100.5401\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 71140.6250 - val_loss: 98.2311\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 69056.9375 - val_loss: 97.1000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 73579.7734 - val_loss: 99.8074\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14023.9492 - val_loss: 103.6530\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 236306.4219 - val_loss: 104.2411\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 211385.6719 - val_loss: 102.0616\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 145608.3125 - val_loss: 99.0836\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 43667.4062 - val_loss: 97.9872\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29968.7168 - val_loss: 101.3250\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 192081.9531 - val_loss: 101.8053\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 59029.7383 - val_loss: 99.9646\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 75520.3047 - val_loss: 96.1377\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 127428.5234 - val_loss: 95.2445\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 176832.4062 - val_loss: 96.3474\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 60061.9141 - val_loss: 99.4952\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 172.6118 - val_loss: 100.3069\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 60762.6523 - val_loss: 99.7826\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13036.3311 - val_loss: 97.8047\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 98901.0234 - val_loss: 96.5151\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 102782.3594 - val_loss: 97.3618\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5235.0508 - val_loss: 101.4042\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf105b6790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 52 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 14818.3418 - val_loss: 127.6077\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 498493.6875 - val_loss: 119.0359\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 225303.7031 - val_loss: 110.1474\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 124999.8672 - val_loss: 99.2021\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 169295.3750 - val_loss: 97.0092\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 74969.7734 - val_loss: 99.0969\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 64428.6992 - val_loss: 105.8259\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 186976.0000 - val_loss: 109.0190\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 125254.8281 - val_loss: 104.0716\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 47428.3516 - val_loss: 101.2522\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13168.9004 - val_loss: 98.5677\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 146593.0469 - val_loss: 99.0907\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14112.4297 - val_loss: 100.9359\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 60862.2695 - val_loss: 103.4037\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 72689.6328 - val_loss: 101.8075\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 877.1040 - val_loss: 102.2336\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 92367.9141 - val_loss: 103.0417\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 21237.4492 - val_loss: 97.7184\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 57908.4883 - val_loss: 96.4499\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 103513.3516 - val_loss: 99.4445\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13564.5898 - val_loss: 100.0948\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 15149.9668 - val_loss: 94.6905\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 178431.2812 - val_loss: 92.1813\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 199800.0469 - val_loss: 96.6241\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 30009.7539 - val_loss: 99.4715\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 33915.3633 - val_loss: 100.7797\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 89996.7891 - val_loss: 99.8727\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12455.1406 - val_loss: 97.3403\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 103362.2500 - val_loss: 97.2054\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 72561.3203 - val_loss: 98.9519\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 518.6997 - val_loss: 101.2391\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 42968.9570 - val_loss: 101.7655\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 64528.0664 - val_loss: 101.4377\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 42792.2539 - val_loss: 97.4717\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 113641.0391 - val_loss: 95.5837\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 74946.9766 - val_loss: 98.5927\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24579.1934 - val_loss: 102.5340\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 130655.4062 - val_loss: 103.4581\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 66182.8438 - val_loss: 102.4725\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 33559.6836 - val_loss: 100.7126\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10895.2305 - val_loss: 97.9194\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 122300.0547 - val_loss: 96.3746\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 130259.5547 - val_loss: 97.7332\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 37404.0898 - val_loss: 101.0750\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 20402.5371 - val_loss: 101.5736\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11820.4775 - val_loss: 102.8927\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 23957.4824 - val_loss: 101.9659\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20714.4492 - val_loss: 99.1311\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 27169.5332 - val_loss: 98.7008\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 143691.2031 - val_loss: 101.3085\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf22b3f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 53 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 82.5055 - val_loss: 39.0863\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 33.1499 - val_loss: 4.2902\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 31.6779 - val_loss: 29.9530\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 24.9067 - val_loss: 34.2467\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22.4183 - val_loss: 20.6898\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20.1138 - val_loss: 11.9571\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.1035 - val_loss: 20.1749\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.9735 - val_loss: 15.0601\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 15.9002 - val_loss: 11.5824\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.4798 - val_loss: 13.5553\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 14.0939 - val_loss: 10.1253\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 13.8739 - val_loss: 7.0749\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.1675 - val_loss: 3.4057\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 12.0256 - val_loss: 4.0246\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.0051 - val_loss: 8.2260\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.8467 - val_loss: 2.5799\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 12.8987 - val_loss: 5.5508\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.1343 - val_loss: 10.2408\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.8221 - val_loss: 4.0416\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.1348 - val_loss: 5.9887\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.6962 - val_loss: 3.6358\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10.5044 - val_loss: 3.7330\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.3408 - val_loss: 3.2453\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.2971 - val_loss: 3.2111\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.7389 - val_loss: 2.9396\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.7268 - val_loss: 2.5956\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.4242 - val_loss: 2.5818\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.0422 - val_loss: 3.7411\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.1028 - val_loss: 2.8557\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.4912 - val_loss: 3.4715\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 9.8465 - val_loss: 3.9184\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.0579 - val_loss: 3.0779\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3437 - val_loss: 3.9061\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.6419 - val_loss: 2.8693\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.4551 - val_loss: 3.6647\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.1203 - val_loss: 3.8649\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.7093 - val_loss: 3.3657\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.8601 - val_loss: 5.8014\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.1713 - val_loss: 7.0976\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.8682 - val_loss: 5.7929\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.4447 - val_loss: 8.3004\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.1905 - val_loss: 4.7301\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.5892 - val_loss: 5.8866\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.9378 - val_loss: 6.1969\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.9957 - val_loss: 2.9052\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6264 - val_loss: 4.6179\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.9849 - val_loss: 2.2523\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1321 - val_loss: 2.3890\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.9642 - val_loss: 3.4342\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1572 - val_loss: 3.7222\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf44e2c9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 54 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 403490.0625 - val_loss: 94.0085\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16610.3340 - val_loss: 114.6273\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 800291.5625 - val_loss: 120.3355\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 609941.5000 - val_loss: 113.0799\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 298009.5938 - val_loss: 104.7303\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 34638.3008 - val_loss: 101.8114\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23257.4004 - val_loss: 102.5470\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8035.6572 - val_loss: 99.4750\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 220870.0781 - val_loss: 99.0014\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 264681.4688 - val_loss: 102.4443\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 27652.9375 - val_loss: 102.6028\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22899.4121 - val_loss: 101.4662\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 127528.2344 - val_loss: 100.6388\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 118032.5234 - val_loss: 102.6024\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 32556.8496 - val_loss: 103.0105\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 41768.5469 - val_loss: 102.8220\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 62258.8672 - val_loss: 101.8368\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 50403.0781 - val_loss: 102.2805\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5710.7515 - val_loss: 102.7918\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 56130.9922 - val_loss: 102.1405\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 46835.9688 - val_loss: 102.8221\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 46394.0742 - val_loss: 102.8726\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33486.9180 - val_loss: 100.4407\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 184682.4062 - val_loss: 99.8213\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 175092.0938 - val_loss: 101.0322\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33099.2461 - val_loss: 103.2063\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 104095.1406 - val_loss: 103.9360\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 85190.1250 - val_loss: 102.7762\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18502.3184 - val_loss: 101.7660\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 27992.4473 - val_loss: 102.2853\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 42658.1445 - val_loss: 101.7535\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 34956.4805 - val_loss: 100.2928\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 71585.1875 - val_loss: 101.0629\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 21038.9785 - val_loss: 101.9904\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 60072.2891 - val_loss: 101.5095\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 45092.1602 - val_loss: 101.3845\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9876.8945 - val_loss: 101.8070\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6005.4790 - val_loss: 101.0545\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 44485.4219 - val_loss: 101.0524\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15406.1904 - val_loss: 103.6546\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 172353.4531 - val_loss: 104.5417\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 115221.1562 - val_loss: 101.9787\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11169.1123 - val_loss: 98.3717\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 175049.7969 - val_loss: 97.8093\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 127264.1875 - val_loss: 99.3373\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55627.8438 - val_loss: 100.4939\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 49517.2930 - val_loss: 100.7665\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 22633.5898 - val_loss: 100.0015\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 58522.8672 - val_loss: 99.3728\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 35308.1289 - val_loss: 100.4274\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf6ed32820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 55 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 160898.5625 - val_loss: 103.4994\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 135540.1094 - val_loss: 102.6320\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 72305.0234 - val_loss: 97.1786\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 55334.3359 - val_loss: 95.8332\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55939.2695 - val_loss: 99.1680\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 186718.7188 - val_loss: 103.2012\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 126530.6016 - val_loss: 100.1873\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13535.5625 - val_loss: 100.4184\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 58677.8281 - val_loss: 100.6644\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22404.3574 - val_loss: 95.6409\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 94646.1562 - val_loss: 95.1615\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 27542.0898 - val_loss: 97.0123\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 2638.9690 - val_loss: 101.4758\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 113143.1875 - val_loss: 105.7016\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 129004.0781 - val_loss: 103.3797\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9257.1924 - val_loss: 96.1160\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47933.4922 - val_loss: 93.9547\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 151395.1875 - val_loss: 97.0125\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35540.7930 - val_loss: 100.9416\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 24269.7422 - val_loss: 101.5500\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 38940.7539 - val_loss: 100.4366\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5548.0063 - val_loss: 96.6135\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 134011.5625 - val_loss: 95.2275\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 120139.0625 - val_loss: 96.2325\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 78893.0000 - val_loss: 98.5927\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 30845.2305 - val_loss: 102.1482\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 34261.4609 - val_loss: 103.3298\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 79731.5312 - val_loss: 102.3752\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44991.1250 - val_loss: 99.4353\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28393.6211 - val_loss: 99.6686\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16474.9648 - val_loss: 101.1761\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 40385.0820 - val_loss: 101.5500\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31766.1543 - val_loss: 100.0104\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 25521.6641 - val_loss: 100.9073\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15894.1064 - val_loss: 103.4520\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 76241.5000 - val_loss: 103.8638\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 108892.1484 - val_loss: 102.1328\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18709.7461 - val_loss: 98.5011\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 25270.8066 - val_loss: 96.6796\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 89847.3047 - val_loss: 97.9361\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 72497.3906 - val_loss: 99.9668\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3272.9944 - val_loss: 102.1243\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 45689.5000 - val_loss: 102.3836\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 74192.0156 - val_loss: 101.1451\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3207.8340 - val_loss: 99.5504\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 29811.0000 - val_loss: 99.4947\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1278.0090 - val_loss: 101.1232\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34094.0977 - val_loss: 100.9354\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1368.5581 - val_loss: 101.5401\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 45971.1562 - val_loss: 101.5683\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf2dad3940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 56 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 18947.3164 - val_loss: 82.7516\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 268373.1562 - val_loss: 81.5294\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 210594.2031 - val_loss: 87.5486\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 52311.3320 - val_loss: 94.5729\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38866.9648 - val_loss: 97.7559\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10661.4717 - val_loss: 94.4809\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 45277.9648 - val_loss: 93.6297\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 39910.8008 - val_loss: 96.4973\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 52520.2617 - val_loss: 97.0566\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6459.7490 - val_loss: 99.0862\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 69018.5469 - val_loss: 99.3316\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7939.7646 - val_loss: 99.0593\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33527.8164 - val_loss: 98.0389\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3178.4475 - val_loss: 94.7025\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 109153.3828 - val_loss: 93.9066\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 85403.6484 - val_loss: 96.7303\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 24881.6895 - val_loss: 97.1618\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8572.0518 - val_loss: 97.6535\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 36159.5117 - val_loss: 98.4533\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5240.6641 - val_loss: 97.3746\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3367.6675 - val_loss: 96.5387\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 34110.9023 - val_loss: 99.4161\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 79424.4844 - val_loss: 103.2508\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 199150.4531 - val_loss: 102.8355\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 111894.6562 - val_loss: 100.9042\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 97601.1328 - val_loss: 96.2710\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 71448.0234 - val_loss: 94.4342\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 81358.6484 - val_loss: 95.8135\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 24604.5996 - val_loss: 97.2262\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15882.2793 - val_loss: 97.9153\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24599.3594 - val_loss: 97.1700\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 94320.3594 - val_loss: 97.4714\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 20577.0918 - val_loss: 100.0432\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 58499.2578 - val_loss: 99.8304\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 27380.5117 - val_loss: 99.1942\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 21705.6582 - val_loss: 96.0940\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 66683.6250 - val_loss: 94.5291\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 76162.7266 - val_loss: 97.0565\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18015.6035 - val_loss: 100.4132\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 60523.3828 - val_loss: 100.8497\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 109295.4219 - val_loss: 98.9742\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 48349.0703 - val_loss: 98.9290\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28448.3281 - val_loss: 98.4463\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9587.7842 - val_loss: 98.3368\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 26385.1113 - val_loss: 97.6121\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 45857.9609 - val_loss: 97.3875\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3572.8840 - val_loss: 99.3111\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 76983.0859 - val_loss: 100.2593\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 62698.4414 - val_loss: 99.3869\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 35159.7422 - val_loss: 97.4474\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf45ed1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 57 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 49.6074 - val_loss: 17.8135\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35.0740 - val_loss: 23.9311\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 24.7911 - val_loss: 31.5633\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 23.7608 - val_loss: 20.0100\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20.9369 - val_loss: 19.0860\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15.7807 - val_loss: 10.0067\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.3526 - val_loss: 3.3718\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.1822 - val_loss: 7.8982\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.7808 - val_loss: 3.0575\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.6344 - val_loss: 6.5202\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.0167 - val_loss: 3.6683\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.3074 - val_loss: 7.6356\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.0059 - val_loss: 6.9568\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.8704 - val_loss: 3.2566\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.2973 - val_loss: 4.7391\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0816 - val_loss: 4.0126\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.2493 - val_loss: 5.3100\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.1494 - val_loss: 5.6208\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.0322 - val_loss: 5.1386\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.2118 - val_loss: 8.4616\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.6225 - val_loss: 5.2102\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.6438 - val_loss: 9.3009\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.4910 - val_loss: 3.3296\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9806 - val_loss: 7.2035\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.1108 - val_loss: 3.1793\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.1684 - val_loss: 4.8370\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.6113 - val_loss: 7.6074\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.0257 - val_loss: 3.7958\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.1361 - val_loss: 5.9905\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5952 - val_loss: 6.0088\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.3046 - val_loss: 4.1079\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0527 - val_loss: 5.4690\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.4702 - val_loss: 3.3530\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.3609 - val_loss: 5.4018\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.4737 - val_loss: 4.5854\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.5662 - val_loss: 4.2914\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.1998 - val_loss: 4.1208\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.6202 - val_loss: 3.2057\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.5888 - val_loss: 3.2864\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.4201 - val_loss: 7.8246\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.7657 - val_loss: 3.6928\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.1254 - val_loss: 5.7248\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6448 - val_loss: 3.1832\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.1371 - val_loss: 3.9734\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.0868 - val_loss: 3.2835\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.5877 - val_loss: 4.9252\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.4793 - val_loss: 3.5592\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.0615 - val_loss: 4.7395\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.5765 - val_loss: 3.2970\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.7062 - val_loss: 4.4338\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf143fe160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 58 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 4932253.0000 - val_loss: 100.3029\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 2498057.0000 - val_loss: 99.6617\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1385552.6250 - val_loss: 99.3639\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1410498.6250 - val_loss: 99.1943\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1088355.0000 - val_loss: 99.0034\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 723215.6250 - val_loss: 98.8567\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 808498.4375 - val_loss: 98.7674\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 832487.3125 - val_loss: 98.6554\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 524412.6250 - val_loss: 98.5207\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 551211.8125 - val_loss: 98.3988\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 329763.5312 - val_loss: 98.3012\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 345099.7812 - val_loss: 98.1963\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 246227.3125 - val_loss: 98.1035\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 265450.5312 - val_loss: 97.9927\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 302004.1562 - val_loss: 97.8843\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 183125.5469 - val_loss: 97.7690\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 343203.2500 - val_loss: 97.6739\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 316913.5312 - val_loss: 97.5984\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 176612.8906 - val_loss: 97.5418\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 211813.2812 - val_loss: 97.4546\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 403633.1562 - val_loss: 97.3284\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 633716.0625 - val_loss: 97.2548\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 546424.6875 - val_loss: 97.1666\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 446613.4062 - val_loss: 97.1386\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 598642.5000 - val_loss: 97.0991\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 480480.0938 - val_loss: 97.0889\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 472655.0625 - val_loss: 97.0979\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 481838.2500 - val_loss: 97.0942\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 563629.8125 - val_loss: 97.1050\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 445905.6875 - val_loss: 97.1266\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 427909.0625 - val_loss: 97.1107\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 224870.0781 - val_loss: 97.0849\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 172028.9531 - val_loss: 97.0534\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 179489.4844 - val_loss: 97.0149\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 108659.8438 - val_loss: 96.9673\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 169981.1094 - val_loss: 96.9194\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 212842.2031 - val_loss: 96.8857\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 192578.0312 - val_loss: 96.8507\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 171896.0469 - val_loss: 96.8133\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 265972.9688 - val_loss: 96.7698\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 355748.3750 - val_loss: 96.7244\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 534421.0000 - val_loss: 96.6955\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 320991.9062 - val_loss: 96.6654\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 241296.6094 - val_loss: 96.6305\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 344329.0625 - val_loss: 96.6433\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 354069.0938 - val_loss: 96.6631\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 258730.7344 - val_loss: 96.6733\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 125720.3047 - val_loss: 96.6700\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 103526.2500 - val_loss: 96.6418\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 104249.5000 - val_loss: 96.6117\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf17065670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 59 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 61.4650 - val_loss: 29.0099\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 36.9639 - val_loss: 28.0361\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 29.9349 - val_loss: 34.0009\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 27.9083 - val_loss: 23.3965\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 22.9696 - val_loss: 18.1048\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20.7603 - val_loss: 21.4738\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18.1936 - val_loss: 10.0026\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.9101 - val_loss: 8.8751\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.8530 - val_loss: 9.1000\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.0630 - val_loss: 11.8451\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.8721 - val_loss: 8.9496\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.8691 - val_loss: 7.8770\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.2910 - val_loss: 10.2349\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.5614 - val_loss: 7.7548\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.2549 - val_loss: 14.5327\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.0530 - val_loss: 3.1531\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.3724 - val_loss: 9.2038\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.2180 - val_loss: 4.2584\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.9044 - val_loss: 9.8992\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.4573 - val_loss: 3.2313\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.8614 - val_loss: 5.8448\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.4150 - val_loss: 4.4391\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.1069 - val_loss: 8.7483\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.5152 - val_loss: 2.9259\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.7291 - val_loss: 11.7953\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.9621 - val_loss: 2.7717\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.0664 - val_loss: 7.3497\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7366 - val_loss: 3.2248\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.7998 - val_loss: 9.1656\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.5474 - val_loss: 3.4000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.2907 - val_loss: 6.7715\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.4228 - val_loss: 2.8152\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.1466 - val_loss: 3.8161\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.3971 - val_loss: 5.9900\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.5607 - val_loss: 5.6014\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.0725 - val_loss: 3.9322\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.5617 - val_loss: 4.2458\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.9271 - val_loss: 3.9680\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.5998 - val_loss: 8.1335\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.3637 - val_loss: 2.2753\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2471 - val_loss: 5.9490\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.1740 - val_loss: 3.0645\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.4359 - val_loss: 4.6414\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.1115 - val_loss: 3.5435\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.4116 - val_loss: 3.4797\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0597 - val_loss: 6.6971\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.0669 - val_loss: 4.0967\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.6404 - val_loss: 4.7203\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.0455 - val_loss: 2.1720\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.1847 - val_loss: 6.8138\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf0171dd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 60 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 72.7034 - val_loss: 48.8448\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 36.5845 - val_loss: 19.4770\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 34.2711 - val_loss: 34.7259\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 29.8855 - val_loss: 37.8321\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 26.1549 - val_loss: 21.0256\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 22.2683 - val_loss: 13.0606\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 18.8200 - val_loss: 17.4783\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.8926 - val_loss: 5.4827\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 16.1239 - val_loss: 3.6157\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.9711 - val_loss: 9.9360\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.0844 - val_loss: 4.7140\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 14.4660 - val_loss: 4.2881\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.2416 - val_loss: 6.7671\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 13.3610 - val_loss: 3.9545\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.1052 - val_loss: 4.0813\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.3638 - val_loss: 6.1003\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 12.9469 - val_loss: 6.0667\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.5916 - val_loss: 7.5643\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.9297 - val_loss: 4.2228\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.1147 - val_loss: 4.1931\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.5272 - val_loss: 4.0372\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 11.1280 - val_loss: 5.0357\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.8253 - val_loss: 4.3509\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.6443 - val_loss: 5.0726\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.8650 - val_loss: 4.7017\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.6553 - val_loss: 4.6316\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.0244 - val_loss: 5.6789\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 11.6426 - val_loss: 5.7367\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.2208 - val_loss: 4.5422\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 10.8891 - val_loss: 4.4984\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 11.2923 - val_loss: 4.9831\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.6989 - val_loss: 4.4910\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.4662 - val_loss: 4.5534\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.4331 - val_loss: 4.4866\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.4662 - val_loss: 3.9918\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 10.1804 - val_loss: 4.8999\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.7364 - val_loss: 4.1573\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.6560 - val_loss: 4.0455\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.1203 - val_loss: 3.5554\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.6241 - val_loss: 3.8405\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 8.6806 - val_loss: 4.5923\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.4859 - val_loss: 3.8111\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.8054 - val_loss: 4.0163\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 9.5659 - val_loss: 6.7125\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.1431 - val_loss: 3.9855\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.3146 - val_loss: 5.1371\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0633 - val_loss: 3.9158\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.0968 - val_loss: 3.2243\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0909 - val_loss: 3.0284\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.3978 - val_loss: 3.0652\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf69976a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 61 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 38578.1133 - val_loss: 81.2907\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 374485.9062 - val_loss: 79.3272\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 438483.5938 - val_loss: 86.4930\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 217157.5469 - val_loss: 93.7656\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 20234.4746 - val_loss: 101.3866\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 139069.5625 - val_loss: 105.6494\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 204729.7656 - val_loss: 104.3005\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 73628.1328 - val_loss: 99.2239\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 51679.8438 - val_loss: 97.1634\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 79303.4375 - val_loss: 101.3603\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 62227.6719 - val_loss: 101.6075\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 55820.1992 - val_loss: 99.9009\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 54171.2852 - val_loss: 98.6688\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11305.1699 - val_loss: 98.7493\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 101940.0938 - val_loss: 97.6695\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 33423.5391 - val_loss: 99.8151\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 29998.8359 - val_loss: 100.6186\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11109.8096 - val_loss: 98.5572\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15461.5264 - val_loss: 98.6577\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 20237.4180 - val_loss: 100.7452\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9582.4014 - val_loss: 102.7628\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 140916.2656 - val_loss: 104.3303\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 91412.7812 - val_loss: 103.2635\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 53113.1133 - val_loss: 99.5358\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4402.2979 - val_loss: 98.2198\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 56683.3828 - val_loss: 96.6777\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 201619.0625 - val_loss: 96.8187\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 73875.6875 - val_loss: 100.1256\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8674.8594 - val_loss: 103.0388\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 103113.6250 - val_loss: 103.8707\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 118465.3125 - val_loss: 100.9360\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 31616.2012 - val_loss: 97.9289\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20303.5312 - val_loss: 98.1821\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 35578.9141 - val_loss: 99.9573\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 57795.5664 - val_loss: 100.7638\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6509.8530 - val_loss: 97.6825\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 59874.3477 - val_loss: 97.7083\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10278.6875 - val_loss: 97.0022\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28027.0137 - val_loss: 97.4385\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 23817.3711 - val_loss: 97.8645\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7714.8223 - val_loss: 98.4971\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 56439.2969 - val_loss: 99.6442\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 63195.0078 - val_loss: 101.3228\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 71912.3516 - val_loss: 98.4363\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7040.8452 - val_loss: 95.5598\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 66088.1641 - val_loss: 95.5485\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 113015.7734 - val_loss: 97.6040\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 22844.4004 - val_loss: 99.8970\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 43572.9688 - val_loss: 101.1092\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18229.0273 - val_loss: 100.0795\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf14f984c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 62 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 46.9115 - val_loss: 6.4294\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 33.0970 - val_loss: 24.0614\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25.0178 - val_loss: 33.3738\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 22.7957 - val_loss: 15.0235\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 22.5709 - val_loss: 17.3548\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 19.9457 - val_loss: 24.8258\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.7241 - val_loss: 12.9116\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.6005 - val_loss: 14.9527\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.7487 - val_loss: 15.6759\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.8333 - val_loss: 10.5598\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.6780 - val_loss: 4.6030\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.4278 - val_loss: 9.7017\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.0247 - val_loss: 4.7981\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.1687 - val_loss: 5.9666\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.8680 - val_loss: 4.0953\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.5702 - val_loss: 5.6742\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.4895 - val_loss: 4.3711\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.2467 - val_loss: 4.0746\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.1123 - val_loss: 4.0806\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.2500 - val_loss: 5.1050\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.5058 - val_loss: 4.2581\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.2039 - val_loss: 4.2047\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.3994 - val_loss: 4.6936\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.8272 - val_loss: 3.8754\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.3087 - val_loss: 4.6733\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.0901 - val_loss: 3.7218\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.4388 - val_loss: 4.1711\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2106 - val_loss: 3.2901\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5539 - val_loss: 3.7608\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.3545 - val_loss: 3.5476\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.3110 - val_loss: 7.2042\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3494 - val_loss: 3.3896\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.2741 - val_loss: 5.2190\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.3678 - val_loss: 3.4971\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.4667 - val_loss: 3.3931\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.2810 - val_loss: 2.8577\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.6725 - val_loss: 3.6019\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.1765 - val_loss: 3.4371\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.5847 - val_loss: 8.2577\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.6845 - val_loss: 4.5866\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.9992 - val_loss: 8.6307\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.0611 - val_loss: 3.0104\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4871 - val_loss: 7.9551\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.1600 - val_loss: 3.3868\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.0916 - val_loss: 10.7949\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.5535 - val_loss: 3.6292\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.1360 - val_loss: 6.4207\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.0468 - val_loss: 3.9468\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.7160 - val_loss: 2.8354\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.0458 - val_loss: 6.3838\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf4d1c2c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 63 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 6676865.0000 - val_loss: 98.0999\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5623938.5000 - val_loss: 98.3367\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4680919.0000 - val_loss: 98.4358\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3408060.2500 - val_loss: 98.0830\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1913100.6250 - val_loss: 98.0976\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 1371565.1250 - val_loss: 98.1130\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1294806.3750 - val_loss: 98.0860\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 958894.3125 - val_loss: 98.0307\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 484165.4688 - val_loss: 97.9573\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 317840.6875 - val_loss: 97.8867\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 208060.4375 - val_loss: 97.8188\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 242247.4219 - val_loss: 97.7130\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 161228.7031 - val_loss: 97.6118\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 174632.0781 - val_loss: 97.4757\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 229286.7344 - val_loss: 97.3580\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 211407.3750 - val_loss: 97.2573\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 256430.2031 - val_loss: 97.1376\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 379040.2188 - val_loss: 97.0173\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 363250.8438 - val_loss: 96.9520\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 242803.1094 - val_loss: 96.8425\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 346576.0938 - val_loss: 96.7567\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 236260.8750 - val_loss: 96.6720\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 208067.8125 - val_loss: 96.5979\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 345093.7812 - val_loss: 96.5292\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 195188.2812 - val_loss: 96.4482\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 185175.6094 - val_loss: 96.3884\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 210921.3125 - val_loss: 96.3409\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 376113.1562 - val_loss: 96.2996\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 282219.9062 - val_loss: 96.2587\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 464078.7812 - val_loss: 96.1861\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 448073.8438 - val_loss: 96.1103\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 337662.0938 - val_loss: 96.0163\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 350066.1562 - val_loss: 95.9432\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 347749.7812 - val_loss: 95.8470\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 234262.5469 - val_loss: 95.7385\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 172178.1250 - val_loss: 95.6828\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 144118.6562 - val_loss: 95.6052\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 142333.5781 - val_loss: 95.5232\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 229479.9531 - val_loss: 95.4538\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 305546.8750 - val_loss: 95.3992\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 161969.8750 - val_loss: 95.3180\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 147770.7812 - val_loss: 95.2513\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 152984.0781 - val_loss: 95.1911\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 257654.3125 - val_loss: 95.1200\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 528216.0000 - val_loss: 95.0922\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 534779.6250 - val_loss: 95.1123\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 491442.0938 - val_loss: 95.1366\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 679193.5000 - val_loss: 95.0925\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 478182.4688 - val_loss: 95.1541\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 471943.1562 - val_loss: 95.1754\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf588bc940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 64 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 102292.8047 - val_loss: 114.2777\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 221820.5469 - val_loss: 118.2795\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 191511.3438 - val_loss: 108.5595\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11513.1152 - val_loss: 107.7860\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11870.9902 - val_loss: 105.2288\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 77561.6484 - val_loss: 105.0596\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 49793.7031 - val_loss: 108.2551\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 80992.7109 - val_loss: 108.3773\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76675.0469 - val_loss: 105.6459\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49894.0234 - val_loss: 104.6970\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25361.8281 - val_loss: 106.3692\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 45982.5781 - val_loss: 106.6401\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13882.1182 - val_loss: 107.6992\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 64042.7969 - val_loss: 108.1011\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27699.1250 - val_loss: 104.9557\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 73126.7188 - val_loss: 104.2751\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54636.4453 - val_loss: 107.1183\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 63664.7227 - val_loss: 108.0494\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21990.4570 - val_loss: 103.9410\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 105440.6406 - val_loss: 101.2056\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 77137.6406 - val_loss: 102.9865\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 26239.0566 - val_loss: 106.2879\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 79954.1484 - val_loss: 106.6026\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 64221.3008 - val_loss: 103.6985\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 77117.0781 - val_loss: 103.1926\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4276.1616 - val_loss: 103.4190\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15048.5508 - val_loss: 104.4881\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19663.3789 - val_loss: 104.4001\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10920.0645 - val_loss: 104.2778\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52960.6758 - val_loss: 104.5822\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7080.9727 - val_loss: 103.5395\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 23865.1855 - val_loss: 105.4095\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 115198.9219 - val_loss: 105.7988\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 71810.5625 - val_loss: 104.0995\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 99032.6484 - val_loss: 101.5375\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 98095.4297 - val_loss: 100.7871\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 93328.2344 - val_loss: 103.8865\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8311.8740 - val_loss: 104.9031\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33488.0273 - val_loss: 101.1357\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 145519.0781 - val_loss: 99.2879\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 170541.6875 - val_loss: 101.6521\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 71032.7891 - val_loss: 104.9455\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 130674.5391 - val_loss: 105.3832\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 64818.1836 - val_loss: 104.1849\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 48638.0078 - val_loss: 101.6237\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 47413.5508 - val_loss: 101.1349\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 59264.9492 - val_loss: 101.5116\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 33445.8438 - val_loss: 102.9448\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 47403.6953 - val_loss: 103.5976\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 39680.9062 - val_loss: 102.3872\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfc6f86e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 65 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 56.7431 - val_loss: 23.3504\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 34.3441 - val_loss: 29.1196\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 27.5941 - val_loss: 31.8255\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 26.7884 - val_loss: 27.1777\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 23.1441 - val_loss: 21.4031\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22.7233 - val_loss: 24.0107\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 20.3754 - val_loss: 14.3903\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 18.6149 - val_loss: 18.6311\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.8899 - val_loss: 4.8502\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 16.3879 - val_loss: 10.4826\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 15.4749 - val_loss: 4.3307\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.7868 - val_loss: 11.6426\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.9453 - val_loss: 8.5880\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.1733 - val_loss: 8.5855\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.5516 - val_loss: 6.7524\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.8785 - val_loss: 7.5744\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.4003 - val_loss: 6.0935\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.1446 - val_loss: 4.1607\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.6891 - val_loss: 2.8677\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.7248 - val_loss: 6.2419\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.8183 - val_loss: 3.3010\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.8882 - val_loss: 6.2012\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.7625 - val_loss: 2.7177\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.0359 - val_loss: 11.7721\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.4574 - val_loss: 2.7074\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.9408 - val_loss: 11.0928\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.9069 - val_loss: 2.8372\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.3501 - val_loss: 3.3499\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.3215 - val_loss: 3.9560\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.5567 - val_loss: 3.8309\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10.4236 - val_loss: 4.9408\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.3363 - val_loss: 4.5388\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.6662 - val_loss: 4.6117\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.5469 - val_loss: 5.3826\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.5521 - val_loss: 7.2068\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.8056 - val_loss: 5.1421\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.6378 - val_loss: 5.6678\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.0354 - val_loss: 2.8052\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.1193 - val_loss: 7.5443\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.9251 - val_loss: 3.3520\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.8527 - val_loss: 9.3247\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.5927 - val_loss: 2.2098\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.6036 - val_loss: 6.6459\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.9953 - val_loss: 5.0888\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.9372 - val_loss: 6.4289\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.0985 - val_loss: 3.3038\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.8502 - val_loss: 4.9991\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.6478 - val_loss: 3.0903\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.0793 - val_loss: 7.7115\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.5128 - val_loss: 3.2772\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf1e0024c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 66 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 65.7018 - val_loss: 32.9198\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 39.9249 - val_loss: 32.9392\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 31.4627 - val_loss: 44.6643\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 30.3843 - val_loss: 34.6834\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 27.0809 - val_loss: 23.9403\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23.0821 - val_loss: 27.8822\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21.3148 - val_loss: 16.9412\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.0703 - val_loss: 12.7422\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.0535 - val_loss: 8.9648\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.4999 - val_loss: 5.2475\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.4142 - val_loss: 6.9682\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.0717 - val_loss: 7.1069\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.8900 - val_loss: 6.8611\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.1635 - val_loss: 9.8594\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.9070 - val_loss: 5.3501\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.8372 - val_loss: 8.0771\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.9064 - val_loss: 5.0505\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.3660 - val_loss: 6.1415\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.5992 - val_loss: 3.3958\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.6614 - val_loss: 11.0270\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.0422 - val_loss: 3.4143\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.6807 - val_loss: 11.7781\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.3186 - val_loss: 2.8547\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12.4116 - val_loss: 7.7761\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.2799 - val_loss: 6.8577\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.0155 - val_loss: 2.8218\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.2141 - val_loss: 8.3003\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.2917 - val_loss: 3.1704\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.8536 - val_loss: 7.4713\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.0405 - val_loss: 4.6141\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.1967 - val_loss: 3.1620\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.8415 - val_loss: 5.5370\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7179 - val_loss: 2.8379\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.1710 - val_loss: 7.9953\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.0654 - val_loss: 4.1110\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.8736 - val_loss: 2.4554\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.5766 - val_loss: 4.9963\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.5581 - val_loss: 3.6993\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.9578 - val_loss: 2.7865\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7624 - val_loss: 5.9592\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.8186 - val_loss: 2.5052\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.7896 - val_loss: 7.1024\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7854 - val_loss: 2.6681\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.8377 - val_loss: 3.8925\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9.2345 - val_loss: 3.0575\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.6279 - val_loss: 2.9902\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.7602 - val_loss: 4.3147\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10.0635 - val_loss: 2.6257\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.6701 - val_loss: 4.8645\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.1462 - val_loss: 3.0001\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf214ad4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 67 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 79.1207 - val_loss: 46.9554\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 32.8995 - val_loss: 8.5498\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28.5477 - val_loss: 19.5085\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 22.8235 - val_loss: 32.4971\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 23.3783 - val_loss: 22.5443\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.6336 - val_loss: 9.3249\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 18.1276 - val_loss: 14.0616\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.3790 - val_loss: 18.9817\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.4825 - val_loss: 8.3911\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.4101 - val_loss: 9.2192\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.7782 - val_loss: 6.8561\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12.3389 - val_loss: 8.5959\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.1185 - val_loss: 7.4162\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.4578 - val_loss: 9.6286\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.5144 - val_loss: 5.9633\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.4031 - val_loss: 7.3360\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.8450 - val_loss: 7.5588\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.7754 - val_loss: 6.0417\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.5451 - val_loss: 8.3638\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.2173 - val_loss: 6.4964\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.3904 - val_loss: 7.5888\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.1412 - val_loss: 6.2844\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.9406 - val_loss: 6.3418\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.2509 - val_loss: 6.5248\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.0733 - val_loss: 6.2420\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.8911 - val_loss: 6.1803\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.3200 - val_loss: 7.6866\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.2160 - val_loss: 5.9131\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.2061 - val_loss: 6.8587\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.9826 - val_loss: 7.8190\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.2119 - val_loss: 8.8768\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.1712 - val_loss: 7.6939\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.2751 - val_loss: 8.3071\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.7272 - val_loss: 6.5888\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.3530 - val_loss: 6.9656\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.1759 - val_loss: 5.7998\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.2591 - val_loss: 5.7142\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.1045 - val_loss: 7.3976\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.4703 - val_loss: 6.0309\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.4516 - val_loss: 6.3914\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.3601 - val_loss: 5.8047\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.9997 - val_loss: 5.8461\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.4745 - val_loss: 6.1157\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.3004 - val_loss: 6.2723\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.6240 - val_loss: 6.5252\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.1275 - val_loss: 5.9228\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 7.3836 - val_loss: 6.9278\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 8.2938 - val_loss: 6.0318\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 8.4987 - val_loss: 5.5472\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 7.6254 - val_loss: 5.5326\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdefef51d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 68 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 47.3443 - val_loss: 4.5631\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 31.8885 - val_loss: 9.3786\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 20.0341 - val_loss: 30.3897\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 21.4050 - val_loss: 21.7927\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.9668 - val_loss: 7.8399\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.3933 - val_loss: 10.9946\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15.3710 - val_loss: 16.3370\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.3171 - val_loss: 7.5898\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 13.6014 - val_loss: 11.6554\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.8768 - val_loss: 7.5584\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.6650 - val_loss: 3.7374\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.8957 - val_loss: 3.8173\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.3659 - val_loss: 3.3673\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9.8286 - val_loss: 7.0218\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 9.4051 - val_loss: 4.2698\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.2203 - val_loss: 4.9819\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.3682 - val_loss: 4.2794\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.2137 - val_loss: 3.4770\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.2138 - val_loss: 3.2947\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 8.1748 - val_loss: 3.1291\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.6113 - val_loss: 4.0424\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.8299 - val_loss: 3.9549\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.4539 - val_loss: 3.4744\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.1545 - val_loss: 3.8662\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.3731 - val_loss: 3.7457\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 7.4957 - val_loss: 3.5781\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.1592 - val_loss: 3.3449\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.1185 - val_loss: 6.6655\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.9339 - val_loss: 3.6467\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.9623 - val_loss: 3.7301\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.6235 - val_loss: 3.4778\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.7273 - val_loss: 3.8916\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.5972 - val_loss: 3.6656\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.2273 - val_loss: 3.7484\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.3329 - val_loss: 3.4065\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.3485 - val_loss: 4.0254\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.7084 - val_loss: 3.3979\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.9829 - val_loss: 4.6883\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.5525 - val_loss: 3.6574\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.5774 - val_loss: 4.2632\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.7928 - val_loss: 6.0991\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.6474 - val_loss: 4.5409\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.1198 - val_loss: 6.6347\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.8474 - val_loss: 3.7562\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.9530 - val_loss: 5.1177\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.1986 - val_loss: 3.8202\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.0768 - val_loss: 5.6704\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.0029 - val_loss: 4.4140\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.2371 - val_loss: 3.5695\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.1237 - val_loss: 3.4166\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf0740a040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 69 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 62.5324 - val_loss: 34.6807\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 25.9368 - val_loss: 5.6478\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 23.9631 - val_loss: 21.7556\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 19.5903 - val_loss: 23.6876\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.5804 - val_loss: 9.0719\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.3869 - val_loss: 13.4144\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.4448 - val_loss: 6.7705\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.4659 - val_loss: 6.5691\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.7571 - val_loss: 7.6949\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.2404 - val_loss: 6.0691\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.3859 - val_loss: 4.8312\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1909 - val_loss: 5.8617\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.0530 - val_loss: 4.4287\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.3580 - val_loss: 5.8480\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.1706 - val_loss: 4.8233\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.2034 - val_loss: 5.1674\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.1252 - val_loss: 4.6947\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.5026 - val_loss: 4.6480\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.3786 - val_loss: 4.9997\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.0708 - val_loss: 4.8404\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.9341 - val_loss: 4.9666\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.0071 - val_loss: 4.6081\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.0563 - val_loss: 4.7430\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.1761 - val_loss: 4.7923\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.3065 - val_loss: 5.9146\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.6300 - val_loss: 5.4716\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.8319 - val_loss: 5.1258\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.5674 - val_loss: 5.3150\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.7801 - val_loss: 5.4234\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.0831 - val_loss: 5.9264\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.1126 - val_loss: 5.0896\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.6336 - val_loss: 6.6027\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.8386 - val_loss: 5.9628\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.5860 - val_loss: 5.3783\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.3784 - val_loss: 4.5976\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.1792 - val_loss: 4.9342\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.4453 - val_loss: 7.2748\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.1705 - val_loss: 5.3623\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.6018 - val_loss: 5.3800\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.2298 - val_loss: 4.9969\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.4010 - val_loss: 5.1174\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.2206 - val_loss: 4.6193\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.6520 - val_loss: 5.0915\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.7575 - val_loss: 5.6362\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.5614 - val_loss: 5.0115\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.2263 - val_loss: 4.8539\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.6404 - val_loss: 4.3614\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 7.8261 - val_loss: 4.5725\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.8344 - val_loss: 4.7119\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.5711 - val_loss: 5.8074\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdeebc14af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 70 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 1311779.6250 - val_loss: 123.6787\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1176364.8750 - val_loss: 101.9503\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 357836.1875 - val_loss: 84.6960\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 747691.5000 - val_loss: 87.1922\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 389680.6250 - val_loss: 94.2125\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 354450.4688 - val_loss: 107.8314\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 767719.8750 - val_loss: 112.9429\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 836613.3750 - val_loss: 108.1596\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 595406.5000 - val_loss: 100.3424\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 91440.6797 - val_loss: 94.4109\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 230651.3438 - val_loss: 94.4783\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 360845.7500 - val_loss: 100.7959\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 406606.9062 - val_loss: 103.7534\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 281222.5312 - val_loss: 99.9958\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 89719.8984 - val_loss: 98.4107\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 72576.1562 - val_loss: 100.7376\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 217858.7656 - val_loss: 104.4967\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 508576.3750 - val_loss: 104.0670\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 186026.7500 - val_loss: 100.3450\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 157324.2969 - val_loss: 98.7223\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 90917.5234 - val_loss: 96.1662\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 219780.5781 - val_loss: 95.3618\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 252381.7031 - val_loss: 99.8057\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 123994.5625 - val_loss: 100.3498\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 142594.6719 - val_loss: 99.3345\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 47942.8086 - val_loss: 99.7138\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 65993.6016 - val_loss: 99.2083\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 103624.1797 - val_loss: 95.9730\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 410036.0312 - val_loss: 95.5365\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 260697.4531 - val_loss: 101.0238\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 150178.2812 - val_loss: 102.2256\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 146126.5938 - val_loss: 99.6631\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 125599.8828 - val_loss: 99.2168\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 66156.4844 - val_loss: 98.9375\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 139231.8750 - val_loss: 96.9797\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 109789.5234 - val_loss: 97.5462\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 361239.1562 - val_loss: 97.7242\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 58769.8555 - val_loss: 100.1027\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 162873.4531 - val_loss: 99.5086\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47700.6953 - val_loss: 95.5453\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 439665.9375 - val_loss: 94.5368\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 270137.9062 - val_loss: 96.5665\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 26245.4922 - val_loss: 100.0270\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 99684.1250 - val_loss: 100.3865\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 76770.1875 - val_loss: 98.7002\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34956.5078 - val_loss: 98.2206\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 174089.1719 - val_loss: 97.4277\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 150096.3125 - val_loss: 98.2656\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 58990.8555 - val_loss: 99.9454\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 128253.4453 - val_loss: 100.5038\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfa6e2c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 71 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 208970.3281 - val_loss: 89.2537\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 74583.2812 - val_loss: 92.5282\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29369.3906 - val_loss: 79.4360\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 176042.5781 - val_loss: 82.0537\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 108365.8047 - val_loss: 92.0638\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 62166.8633 - val_loss: 95.4292\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 29159.1211 - val_loss: 90.0020\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 59186.0078 - val_loss: 89.0092\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 32851.7539 - val_loss: 94.3891\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 61207.1992 - val_loss: 96.8001\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8493.1113 - val_loss: 95.3167\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 43050.1875 - val_loss: 93.4957\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5379.2437 - val_loss: 87.0764\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 116227.8828 - val_loss: 84.4169\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 75634.0391 - val_loss: 90.6336\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8166.4390 - val_loss: 98.4081\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 89550.3047 - val_loss: 102.0376\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 99641.7188 - val_loss: 97.0530\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 20383.1738 - val_loss: 90.5199\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12009.4023 - val_loss: 87.8203\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 27985.4180 - val_loss: 91.8355\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 139558.4375 - val_loss: 101.0250\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 196277.7812 - val_loss: 102.4385\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 87077.0078 - val_loss: 94.1741\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28507.9414 - val_loss: 93.3794\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14149.8701 - val_loss: 92.7512\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19015.8184 - val_loss: 93.9929\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8867.4326 - val_loss: 94.0842\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 39253.6289 - val_loss: 91.9891\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 39702.2852 - val_loss: 97.1672\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 55219.6367 - val_loss: 97.8580\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25287.5449 - val_loss: 93.8115\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 18732.6016 - val_loss: 91.9783\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 25319.4609 - val_loss: 94.8417\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50048.0742 - val_loss: 98.7932\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 53980.9062 - val_loss: 98.5835\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 22722.0566 - val_loss: 92.0097\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 49736.7227 - val_loss: 89.6532\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 29935.5996 - val_loss: 93.6584\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 45298.9180 - val_loss: 100.0054\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 94671.1875 - val_loss: 102.4404\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13048.2568 - val_loss: 98.5083\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3860.1934 - val_loss: 91.3240\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 113403.4844 - val_loss: 87.7147\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 113948.4844 - val_loss: 91.7046\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 47357.3242 - val_loss: 99.5434\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 37954.8828 - val_loss: 99.8188\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 31817.6250 - val_loss: 96.2101\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 61540.6445 - val_loss: 95.2476\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4059.1375 - val_loss: 99.9444\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf0e94af70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 72 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 1372281.3750 - val_loss: 91.2730\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 301746.4375 - val_loss: 103.0239\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1152137.0000 - val_loss: 106.5048\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 577274.9375 - val_loss: 101.8222\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 88518.0469 - val_loss: 97.9363\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 282949.3750 - val_loss: 97.9634\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 110152.4766 - val_loss: 101.4522\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 209350.5156 - val_loss: 102.1111\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 110514.6484 - val_loss: 99.5347\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 123369.2734 - val_loss: 96.1339\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 596461.1250 - val_loss: 96.5436\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 375743.3750 - val_loss: 98.0903\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 176207.0000 - val_loss: 100.3344\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 292652.7812 - val_loss: 100.1327\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 56823.1641 - val_loss: 98.2090\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 219823.4219 - val_loss: 97.5674\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 164529.9375 - val_loss: 99.3048\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 177779.6719 - val_loss: 99.3761\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 118682.7266 - val_loss: 98.7651\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 46388.2070 - val_loss: 99.2996\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 70060.2422 - val_loss: 98.2092\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 159704.3750 - val_loss: 98.4789\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 103984.5156 - val_loss: 99.6212\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 55193.0391 - val_loss: 99.8359\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 74819.3906 - val_loss: 99.5497\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 27414.8359 - val_loss: 98.3116\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 219536.7500 - val_loss: 98.2805\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 40454.5391 - val_loss: 99.2721\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 115520.0234 - val_loss: 99.0991\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 70997.0000 - val_loss: 99.6945\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44805.2891 - val_loss: 100.1530\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 44587.1992 - val_loss: 100.8097\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 135741.7969 - val_loss: 100.8010\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 134381.9531 - val_loss: 99.9202\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25737.3438 - val_loss: 100.8302\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12435.1318 - val_loss: 100.5952\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 46756.7852 - val_loss: 98.6933\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 252611.7031 - val_loss: 98.6269\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 75588.1016 - val_loss: 99.1447\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 182984.5781 - val_loss: 100.4728\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 175129.2969 - val_loss: 100.6184\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 53487.4727 - val_loss: 101.2189\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 181505.0625 - val_loss: 101.6278\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 81040.7656 - val_loss: 100.3184\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31714.2969 - val_loss: 97.4452\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 524869.5625 - val_loss: 96.2379\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 537856.5000 - val_loss: 97.9385\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 222477.5469 - val_loss: 99.7188\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 133511.3906 - val_loss: 102.1579\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 224295.3750 - val_loss: 101.8928\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5a001d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 73 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 51138.3945 - val_loss: 98.7028\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 53283.5508 - val_loss: 99.5509\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47744.7109 - val_loss: 94.2736\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 106664.8906 - val_loss: 95.0191\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 78148.0469 - val_loss: 99.2572\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 105326.9219 - val_loss: 101.0153\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 32430.8809 - val_loss: 97.7094\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15744.3604 - val_loss: 95.8270\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 67694.4297 - val_loss: 95.8385\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16963.2754 - val_loss: 97.7789\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 30101.4238 - val_loss: 98.7980\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 38705.3164 - val_loss: 97.6728\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 24271.3262 - val_loss: 97.4684\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 20173.1289 - val_loss: 97.5549\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19864.1348 - val_loss: 98.1320\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9557.6846 - val_loss: 97.4199\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 50246.5352 - val_loss: 97.7251\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 23294.2773 - val_loss: 97.7780\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19967.5410 - val_loss: 96.1611\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 28068.6484 - val_loss: 95.6926\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 88779.8750 - val_loss: 98.1477\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26009.4238 - val_loss: 99.3758\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8429.3604 - val_loss: 97.0912\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 18233.9434 - val_loss: 94.3393\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 183408.1875 - val_loss: 94.0727\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 135450.4375 - val_loss: 95.5628\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 77728.7656 - val_loss: 98.4372\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 26810.7070 - val_loss: 99.2143\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 45828.4102 - val_loss: 98.1749\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 60484.3242 - val_loss: 97.2847\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 58092.5977 - val_loss: 99.0104\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 105166.9609 - val_loss: 99.0503\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7211.6924 - val_loss: 98.6183\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7801.2739 - val_loss: 95.8002\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 125336.3047 - val_loss: 95.2999\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 112170.5938 - val_loss: 96.2567\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7093.1240 - val_loss: 98.7947\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28734.5098 - val_loss: 100.4821\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 63528.0469 - val_loss: 100.4095\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11875.3818 - val_loss: 98.2430\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 62892.3672 - val_loss: 97.4353\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 84944.3672 - val_loss: 97.8357\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12852.0635 - val_loss: 99.3432\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8017.0518 - val_loss: 100.6987\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 119524.3984 - val_loss: 101.4086\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 81051.4219 - val_loss: 100.0966\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17743.2090 - val_loss: 98.9070\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 20513.8242 - val_loss: 98.4768\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 66744.4766 - val_loss: 99.1281\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1825.1906 - val_loss: 100.4045\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdff06155e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 74 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 80.2054 - val_loss: 52.2829\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 49.3852 - val_loss: 27.1570\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 40.9328 - val_loss: 44.5204\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 37.3410 - val_loss: 42.4848\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 32.5111 - val_loss: 25.4641\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 29.1441 - val_loss: 20.1359\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 25.8130 - val_loss: 28.2470\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 20.8442 - val_loss: 13.4732\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17.0939 - val_loss: 11.4440\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.7026 - val_loss: 3.4614\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.4711 - val_loss: 6.1782\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.2551 - val_loss: 7.0325\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.0216 - val_loss: 5.9889\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.2956 - val_loss: 8.0087\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.8201 - val_loss: 3.4754\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.3673 - val_loss: 5.2815\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.9567 - val_loss: 6.2628\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.3161 - val_loss: 3.5295\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.5737 - val_loss: 6.6693\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.6135 - val_loss: 5.9307\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.4648 - val_loss: 6.7827\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.5436 - val_loss: 3.8294\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.4357 - val_loss: 6.4167\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.4151 - val_loss: 7.0364\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.4441 - val_loss: 3.3220\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.6713 - val_loss: 5.1457\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.3558 - val_loss: 5.1909\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.4667 - val_loss: 8.5792\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.5372 - val_loss: 5.9011\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.1314 - val_loss: 8.0297\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.6628 - val_loss: 4.2973\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8745 - val_loss: 6.5860\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.2282 - val_loss: 4.0178\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.2934 - val_loss: 7.0068\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.0698 - val_loss: 6.9474\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.8394 - val_loss: 4.3307\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.9036 - val_loss: 5.5240\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.0299 - val_loss: 6.8782\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6010 - val_loss: 7.8048\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.3101 - val_loss: 4.4268\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.8441 - val_loss: 3.7609\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.8364 - val_loss: 4.9794\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.3438 - val_loss: 6.4210\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.4994 - val_loss: 4.6182\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.8475 - val_loss: 3.4242\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.1841 - val_loss: 6.6823\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4099 - val_loss: 5.1304\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.8367 - val_loss: 6.8753\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.7135 - val_loss: 5.9020\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.8418 - val_loss: 6.4915\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf3f70c1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 75 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 81.3755 - val_loss: 61.2484\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 42.0402 - val_loss: 35.8298\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 40.3725 - val_loss: 50.5140\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 35.5126 - val_loss: 49.9919\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 31.0492 - val_loss: 37.5308\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 29.4242 - val_loss: 26.9952\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25.9462 - val_loss: 31.6663\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25.0300 - val_loss: 24.5510\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 21.2679 - val_loss: 12.0712\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 19.0036 - val_loss: 17.7388\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17.9874 - val_loss: 15.2438\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.2139 - val_loss: 9.4865\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.5693 - val_loss: 6.3689\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.2552 - val_loss: 5.8010\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.6767 - val_loss: 9.2696\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.7790 - val_loss: 3.8536\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.4952 - val_loss: 6.4489\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 13.6989 - val_loss: 4.7049\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 13.9776 - val_loss: 7.0935\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 14.1586 - val_loss: 4.7053\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.3310 - val_loss: 7.5785\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.0477 - val_loss: 6.2282\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.8645 - val_loss: 4.8246\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.6772 - val_loss: 6.2063\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.1666 - val_loss: 4.5403\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 13.3707 - val_loss: 6.6740\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 12.7016 - val_loss: 4.6972\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 10.9992 - val_loss: 7.2726\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 12.2739 - val_loss: 4.6572\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 12.2837 - val_loss: 5.2758\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 12.6423 - val_loss: 4.2123\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.4211 - val_loss: 6.8117\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 11.9277 - val_loss: 4.2982\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 12.5191 - val_loss: 5.0295\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.1723 - val_loss: 5.7387\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.1501 - val_loss: 3.6468\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.3620 - val_loss: 5.7160\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 10.7302 - val_loss: 3.2989\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.3269 - val_loss: 4.8753\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.9651 - val_loss: 3.6023\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.2126 - val_loss: 4.7805\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.4894 - val_loss: 3.5987\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.5410 - val_loss: 3.6558\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.0033 - val_loss: 3.4865\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.1262 - val_loss: 5.7783\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 9.1987 - val_loss: 4.9659\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.5836 - val_loss: 4.6578\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.0188 - val_loss: 3.0711\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.5882 - val_loss: 3.6744\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.8646 - val_loss: 5.1384\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf20a20af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 76 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 103173.6562 - val_loss: 109.3998\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 274964.7500 - val_loss: 114.9919\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 222074.7969 - val_loss: 104.2071\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 38430.6055 - val_loss: 100.7654\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7286.5781 - val_loss: 105.1508\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 87344.2344 - val_loss: 105.6632\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 74029.6016 - val_loss: 102.9234\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 35073.5703 - val_loss: 97.5030\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 110725.1719 - val_loss: 97.4018\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 113132.9062 - val_loss: 98.7389\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 45042.7930 - val_loss: 101.9892\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 5687.0693 - val_loss: 106.5343\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 111021.8828 - val_loss: 106.3553\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 81778.5312 - val_loss: 104.0302\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 46935.8164 - val_loss: 100.0574\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 52565.0391 - val_loss: 99.6752\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28115.3262 - val_loss: 101.5283\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 55317.5391 - val_loss: 102.1999\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 41198.4531 - val_loss: 102.1127\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11302.5625 - val_loss: 101.6513\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7580.6313 - val_loss: 100.6627\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 30086.2559 - val_loss: 100.2682\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 62504.2969 - val_loss: 100.8179\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 68228.1562 - val_loss: 102.8292\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15513.1270 - val_loss: 101.0422\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 52000.3789 - val_loss: 100.4551\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 33507.3672 - val_loss: 103.1340\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 28958.7441 - val_loss: 104.1710\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 22540.8105 - val_loss: 102.6128\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 4266.7466 - val_loss: 98.1205\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 96331.7812 - val_loss: 97.4899\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 70681.6406 - val_loss: 98.4212\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8671.3623 - val_loss: 101.2146\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1074.1578 - val_loss: 102.8925\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15407.0098 - val_loss: 104.8236\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 81954.6875 - val_loss: 103.7845\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 50581.0859 - val_loss: 100.3160\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 134209.0469 - val_loss: 97.9841\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27054.6191 - val_loss: 101.5969\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 35830.0156 - val_loss: 103.0011\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 16761.9004 - val_loss: 101.4764\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12507.1309 - val_loss: 99.9249\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 19938.7949 - val_loss: 101.0076\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5517.9941 - val_loss: 103.9430\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 124528.3984 - val_loss: 103.7957\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9609.8125 - val_loss: 101.6422\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13092.3662 - val_loss: 98.9758\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 33920.6562 - val_loss: 98.8191\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 65856.0625 - val_loss: 100.8239\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 24321.7559 - val_loss: 103.3480\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdefe087dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 77 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 83.3915 - val_loss: 64.7729\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 69.9032 - val_loss: 58.7929\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 55.5089 - val_loss: 60.4050\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 46.7006 - val_loss: 31.8026\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 41.6808 - val_loss: 27.8778\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 38.0199 - val_loss: 35.1410\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 35.6746 - val_loss: 23.1390\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29.6269 - val_loss: 18.1335\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 28.0034 - val_loss: 20.9148\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 24.6967 - val_loss: 11.2568\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 22.8546 - val_loss: 7.7581\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.1122 - val_loss: 4.9234\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 20.6231 - val_loss: 5.6822\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 22.2401 - val_loss: 4.7695\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 21.2912 - val_loss: 4.5730\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 20.2814 - val_loss: 6.1853\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 20.2305 - val_loss: 5.8777\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.5329 - val_loss: 5.2487\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18.3733 - val_loss: 4.5899\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 19.1323 - val_loss: 5.1528\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20.1964 - val_loss: 4.3488\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19.3906 - val_loss: 3.7534\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.5657 - val_loss: 4.9492\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 18.6990 - val_loss: 5.8796\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 18.0515 - val_loss: 3.9126\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16.2962 - val_loss: 6.2384\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15.0015 - val_loss: 4.5139\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.7201 - val_loss: 5.6692\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.4864 - val_loss: 4.8279\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.1422 - val_loss: 5.1876\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.9370 - val_loss: 6.0130\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.5231 - val_loss: 4.1990\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15.2749 - val_loss: 5.0736\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.9149 - val_loss: 5.2982\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.0890 - val_loss: 7.1195\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 13.1143 - val_loss: 4.0966\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12.2436 - val_loss: 6.8828\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.2627 - val_loss: 7.6852\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.6076 - val_loss: 3.5648\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.6086 - val_loss: 7.2050\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.3448 - val_loss: 5.4070\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.5512 - val_loss: 5.5786\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.8441 - val_loss: 8.8560\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 13.1834 - val_loss: 3.6654\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.3534 - val_loss: 7.3883\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.0269 - val_loss: 3.7522\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.5773 - val_loss: 4.5810\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.0283 - val_loss: 6.4749\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.6119 - val_loss: 6.9945\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.7876 - val_loss: 3.5846\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf075641f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 78 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 101.9453 - val_loss: 83.0481\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 53.6280 - val_loss: 39.2126\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38.9814 - val_loss: 18.2568\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 30.3947 - val_loss: 37.2491\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 27.9391 - val_loss: 38.6612\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 25.9624 - val_loss: 25.0659\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 22.1591 - val_loss: 16.5072\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 20.0594 - val_loss: 19.0651\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18.6790 - val_loss: 14.0811\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.5614 - val_loss: 7.4753\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.8965 - val_loss: 3.0309\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.5720 - val_loss: 3.1635\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.1970 - val_loss: 2.7955\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.8805 - val_loss: 4.2290\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12.3628 - val_loss: 5.7819\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.9059 - val_loss: 6.4578\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.3580 - val_loss: 2.6915\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.3295 - val_loss: 3.4697\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.8019 - val_loss: 8.6230\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.1183 - val_loss: 3.4595\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.1921 - val_loss: 5.7309\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.6509 - val_loss: 3.3609\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.7494 - val_loss: 3.0935\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.0738 - val_loss: 4.0046\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.1771 - val_loss: 4.5184\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.3641 - val_loss: 7.8785\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.8068 - val_loss: 3.4301\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6015 - val_loss: 4.4242\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.0429 - val_loss: 3.6094\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.4037 - val_loss: 4.8452\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.3540 - val_loss: 4.0531\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.2643 - val_loss: 5.4383\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.0283 - val_loss: 4.9528\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.6477 - val_loss: 4.4842\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.7973 - val_loss: 3.8035\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.1910 - val_loss: 4.7141\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.8142 - val_loss: 4.4792\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.9832 - val_loss: 6.5199\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.0316 - val_loss: 3.4440\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.9503 - val_loss: 5.8256\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.6623 - val_loss: 3.9176\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.1411 - val_loss: 4.8455\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3650 - val_loss: 4.6612\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.9201 - val_loss: 3.5016\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.8628 - val_loss: 6.9600\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.7463 - val_loss: 3.9654\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.3954 - val_loss: 3.9888\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.0254 - val_loss: 6.3105\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.2307 - val_loss: 4.1809\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.9899 - val_loss: 4.9351\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdeef5898b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 79 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 6459354.5000 - val_loss: 98.8409\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5265718.0000 - val_loss: 98.1018\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3803390.0000 - val_loss: 98.3467\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2865185.2500 - val_loss: 98.5577\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 2343087.2500 - val_loss: 98.8280\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1841796.6250 - val_loss: 98.7578\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1352452.6250 - val_loss: 98.3188\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1006625.2500 - val_loss: 98.0711\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 758400.1875 - val_loss: 97.9004\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 502565.1562 - val_loss: 97.7383\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 385510.8125 - val_loss: 97.6066\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 281191.4062 - val_loss: 97.5263\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 359938.2188 - val_loss: 97.4644\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 357574.7500 - val_loss: 97.3722\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 253573.0469 - val_loss: 97.2609\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 208137.1406 - val_loss: 97.1487\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 170110.3281 - val_loss: 97.0364\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 181205.2031 - val_loss: 96.9324\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 189129.7031 - val_loss: 96.8274\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 290726.3750 - val_loss: 96.7135\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 170304.8750 - val_loss: 96.6041\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 176860.3125 - val_loss: 96.4714\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 158435.9062 - val_loss: 96.3478\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 244205.4219 - val_loss: 96.2335\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 253209.5000 - val_loss: 96.0818\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 235622.2969 - val_loss: 95.9220\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 268306.1875 - val_loss: 95.8020\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 338723.0000 - val_loss: 95.7526\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 438834.5938 - val_loss: 95.6053\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 252483.2656 - val_loss: 95.4715\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 170291.6250 - val_loss: 95.3704\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 170669.3750 - val_loss: 95.2516\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 215352.0469 - val_loss: 95.1437\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 256464.4531 - val_loss: 95.0141\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 245631.7031 - val_loss: 94.8854\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 235759.6875 - val_loss: 94.7801\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 254295.7969 - val_loss: 94.6367\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 263906.6250 - val_loss: 94.4985\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 224165.1250 - val_loss: 94.4274\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 114340.9219 - val_loss: 94.3158\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 135366.7031 - val_loss: 94.1868\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 129542.2266 - val_loss: 94.0482\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 157535.5469 - val_loss: 93.9364\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 211265.9688 - val_loss: 93.7980\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 275082.0938 - val_loss: 93.7320\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 222495.8125 - val_loss: 93.6603\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 246094.5312 - val_loss: 93.5203\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 435218.8125 - val_loss: 93.3548\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 527570.4375 - val_loss: 93.3778\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 307071.1562 - val_loss: 93.3382\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdef4f6ef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 80 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 72.5927 - val_loss: 43.1565\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 41.6728 - val_loss: 13.4818\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 34.6880 - val_loss: 40.9806\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31.3216 - val_loss: 45.0117\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 29.2315 - val_loss: 31.6774\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 26.3075 - val_loss: 20.6773\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 25.5734 - val_loss: 21.9321\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23.0357 - val_loss: 29.0161\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21.5244 - val_loss: 18.7881\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 19.5961 - val_loss: 11.8742\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 16.1635 - val_loss: 18.4357\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 15.8965 - val_loss: 3.0158\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 15.7598 - val_loss: 10.8739\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.5788 - val_loss: 3.4759\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.2285 - val_loss: 6.3855\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 12.6262 - val_loss: 6.1356\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 12.6400 - val_loss: 2.8983\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 12.8229 - val_loss: 5.3471\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 12.4141 - val_loss: 3.4420\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10.7738 - val_loss: 4.2192\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.3033 - val_loss: 3.5460\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.6459 - val_loss: 4.0113\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.3846 - val_loss: 5.2430\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 12.4542 - val_loss: 4.0070\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.8594 - val_loss: 3.8680\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 11.5225 - val_loss: 3.3874\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.1360 - val_loss: 3.3039\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.8257 - val_loss: 3.0686\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.0427 - val_loss: 4.3141\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.2612 - val_loss: 6.4013\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.6297 - val_loss: 8.8592\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.4958 - val_loss: 9.1475\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.4670 - val_loss: 5.6337\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.0695 - val_loss: 5.1885\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.5036 - val_loss: 3.8854\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.9323 - val_loss: 2.8228\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.5923 - val_loss: 3.5088\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.8046 - val_loss: 3.6356\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.5737 - val_loss: 3.0933\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.9650 - val_loss: 2.8518\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.1848 - val_loss: 4.2494\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.7588 - val_loss: 3.2632\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.8135 - val_loss: 3.0925\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.3374 - val_loss: 3.2312\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.6043 - val_loss: 2.4903\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.0616 - val_loss: 4.8402\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.9017 - val_loss: 4.5070\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.0155 - val_loss: 4.3009\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.2204 - val_loss: 3.3738\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.2143 - val_loss: 3.1933\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf532b4160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 81 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 8054326.5000 - val_loss: 102.3190\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6661578.0000 - val_loss: 101.7867\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4851765.0000 - val_loss: 102.0416\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2861010.0000 - val_loss: 101.3680\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2183920.7500 - val_loss: 100.9449\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 2036151.7500 - val_loss: 100.3742\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1802431.3750 - val_loss: 100.1213\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1599486.7500 - val_loss: 99.4731\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1326313.5000 - val_loss: 99.2337\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 799150.1875 - val_loss: 98.9223\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 522089.5312 - val_loss: 98.7005\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 452648.0000 - val_loss: 98.4891\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 333458.7812 - val_loss: 98.2725\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 367438.6875 - val_loss: 98.1100\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 402588.0938 - val_loss: 97.9797\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 251471.6875 - val_loss: 97.8374\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 212369.9375 - val_loss: 97.7171\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 183480.3125 - val_loss: 97.5846\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 180776.5312 - val_loss: 97.4398\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 203181.2344 - val_loss: 97.2584\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 222761.8125 - val_loss: 97.1264\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 761830.5000 - val_loss: 97.0449\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 531186.1875 - val_loss: 96.9831\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 619035.6250 - val_loss: 96.9373\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 501820.4062 - val_loss: 96.8476\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 328408.0312 - val_loss: 96.7476\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 329681.9375 - val_loss: 96.6402\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 427112.9688 - val_loss: 96.5612\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 434186.9375 - val_loss: 96.4906\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 203622.0625 - val_loss: 96.4255\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 405337.2812 - val_loss: 96.3419\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 283463.7500 - val_loss: 96.2644\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 384457.1562 - val_loss: 96.2044\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 426808.2500 - val_loss: 96.1501\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 372907.2500 - val_loss: 96.1001\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 288535.3125 - val_loss: 96.0429\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 310662.7188 - val_loss: 95.9897\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 349850.3438 - val_loss: 95.9219\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 216015.0781 - val_loss: 95.8605\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 275503.9688 - val_loss: 95.7841\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 231171.1094 - val_loss: 95.7322\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 347035.1562 - val_loss: 95.6899\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 302380.9062 - val_loss: 95.6621\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 300019.7812 - val_loss: 95.6401\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 677531.6875 - val_loss: 95.6020\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 548111.8125 - val_loss: 95.6348\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 536545.1875 - val_loss: 95.6857\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 660960.0625 - val_loss: 95.6822\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 461599.2188 - val_loss: 95.6719\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 371262.7812 - val_loss: 95.6883\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdfdd73bee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 82 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 13539.0469 - val_loss: 107.3830\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 317687.5938 - val_loss: 104.0894\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 135057.1562 - val_loss: 97.7293\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4424.2207 - val_loss: 98.3509\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 80636.6484 - val_loss: 95.9927\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21431.0371 - val_loss: 92.0862\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 133458.8750 - val_loss: 91.6001\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 112956.9219 - val_loss: 94.6859\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 41954.2812 - val_loss: 95.7604\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24913.5996 - val_loss: 95.8317\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11396.9873 - val_loss: 94.9843\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 43553.3867 - val_loss: 96.3098\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 26629.9766 - val_loss: 96.0415\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8699.1865 - val_loss: 93.5729\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 130461.4453 - val_loss: 92.1043\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 104776.8984 - val_loss: 94.4186\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 61169.4805 - val_loss: 97.7599\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 97745.4688 - val_loss: 99.3858\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 34120.4375 - val_loss: 97.1653\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17358.4844 - val_loss: 93.3549\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 138198.4219 - val_loss: 91.6232\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 112004.9062 - val_loss: 94.7384\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 42280.9336 - val_loss: 97.7619\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 46065.2266 - val_loss: 98.4220\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 43317.1406 - val_loss: 97.9357\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15472.9707 - val_loss: 97.1358\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 28409.0918 - val_loss: 95.4833\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 67503.9453 - val_loss: 95.2560\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34085.5117 - val_loss: 97.1645\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27303.4609 - val_loss: 97.0928\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 903.1060 - val_loss: 96.2593\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 85700.3047 - val_loss: 96.1631\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 31465.4531 - val_loss: 97.4302\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12435.5801 - val_loss: 97.1958\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9243.8965 - val_loss: 98.1343\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8123.8569 - val_loss: 97.7893\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1427.1293 - val_loss: 96.7631\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 129.0876 - val_loss: 97.4055\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 34892.6445 - val_loss: 97.3117\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3929.0588 - val_loss: 94.2124\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 86359.7188 - val_loss: 93.2849\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 124975.2109 - val_loss: 93.8662\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 98897.0859 - val_loss: 96.9430\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 32972.1133 - val_loss: 98.8235\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 54027.6758 - val_loss: 97.3827\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19714.1719 - val_loss: 97.9457\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 65778.6016 - val_loss: 99.6638\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 48935.8945 - val_loss: 99.7874\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6344.6562 - val_loss: 97.8412\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 41274.7539 - val_loss: 97.0194\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf14f98430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 83 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 80.6944 - val_loss: 48.0055\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 25.3164 - val_loss: 12.9324\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 22.5758 - val_loss: 15.3620\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 16.4299 - val_loss: 25.4004\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.9388 - val_loss: 11.8965\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 13.5318 - val_loss: 9.0640\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 12.5147 - val_loss: 15.0110\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 13.4180 - val_loss: 17.8277\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 13.5922 - val_loss: 10.3215\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.4657 - val_loss: 10.5910\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.9135 - val_loss: 12.1195\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.3251 - val_loss: 12.1590\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.3084 - val_loss: 7.8561\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.7319 - val_loss: 12.6801\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 9.1365 - val_loss: 5.4132\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 9.4753 - val_loss: 12.3016\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.9191 - val_loss: 7.5301\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.2693 - val_loss: 8.4510\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 7.9790 - val_loss: 4.0427\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.5903 - val_loss: 8.5714\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.7149 - val_loss: 7.8297\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.6369 - val_loss: 5.2811\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 8.1675 - val_loss: 5.6107\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.0711 - val_loss: 3.8175\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.8455 - val_loss: 9.0666\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.3014 - val_loss: 4.3701\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.1852 - val_loss: 10.5510\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.7220 - val_loss: 4.2576\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.2998 - val_loss: 8.9921\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.4484 - val_loss: 4.5395\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.8977 - val_loss: 6.8151\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.4078 - val_loss: 5.2584\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.7268 - val_loss: 4.6379\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.2061 - val_loss: 6.9284\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 7.5637 - val_loss: 4.7624\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.6296 - val_loss: 6.9306\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.6334 - val_loss: 6.0897\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.4904 - val_loss: 3.5927\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 7.9507 - val_loss: 6.6278\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.0181 - val_loss: 3.6150\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.9837 - val_loss: 3.9374\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 6.4737 - val_loss: 5.8132\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.9479 - val_loss: 3.6237\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.6377 - val_loss: 7.0527\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.6695 - val_loss: 3.6572\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.5692 - val_loss: 5.2821\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.1398 - val_loss: 3.8428\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 6.3050 - val_loss: 6.3418\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.6537 - val_loss: 4.3049\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.2487 - val_loss: 4.0509\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf3f70c670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 84 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 71.7467 - val_loss: 48.3032\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 39.3718 - val_loss: 25.2577\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 37.7416 - val_loss: 33.5647\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 34.2266 - val_loss: 36.0725\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32.6374 - val_loss: 24.0986\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29.1289 - val_loss: 12.4256\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 24.8850 - val_loss: 23.7130\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 23.8535 - val_loss: 19.9177\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 20.8703 - val_loss: 8.3191\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20.7561 - val_loss: 12.7373\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 18.6871 - val_loss: 9.2495\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 18.3046 - val_loss: 9.3217\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19.4876 - val_loss: 14.0977\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18.0078 - val_loss: 9.5101\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.0552 - val_loss: 12.1557\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.8057 - val_loss: 9.4191\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.0802 - val_loss: 9.2694\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17.5023 - val_loss: 9.0552\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.9213 - val_loss: 9.3071\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 17.6587 - val_loss: 11.8005\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.4115 - val_loss: 9.3000\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.2038 - val_loss: 14.0210\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.5106 - val_loss: 10.1289\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 17.5258 - val_loss: 8.6308\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.2693 - val_loss: 10.1522\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.8250 - val_loss: 9.4869\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.2183 - val_loss: 9.3500\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.1798 - val_loss: 9.7320\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.4601 - val_loss: 9.3810\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18.0743 - val_loss: 10.2366\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.5886 - val_loss: 9.4907\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.9609 - val_loss: 10.3263\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 17.6592 - val_loss: 9.7642\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.1394 - val_loss: 9.2139\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.6656 - val_loss: 9.3835\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.5245 - val_loss: 9.7263\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.7015 - val_loss: 9.6207\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 15.3277 - val_loss: 9.7993\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.4116 - val_loss: 9.4560\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.0703 - val_loss: 9.3246\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.1888 - val_loss: 9.7028\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.3308 - val_loss: 9.7972\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16.5637 - val_loss: 9.7779\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.5369 - val_loss: 9.5397\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15.7961 - val_loss: 9.2458\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.5050 - val_loss: 9.6020\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.5293 - val_loss: 9.0896\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.5866 - val_loss: 9.1995\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.4803 - val_loss: 9.4183\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.0434 - val_loss: 9.8971\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf82358dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 85 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 68.7416 - val_loss: 32.7931\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 32.4284 - val_loss: 8.8902\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 24.4543 - val_loss: 29.8832\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24.4817 - val_loss: 29.3095\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19.6976 - val_loss: 12.7354\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 20.6229 - val_loss: 11.0303\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17.5315 - val_loss: 22.3412\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 17.3518 - val_loss: 15.9853\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.5868 - val_loss: 9.4099\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.6081 - val_loss: 13.5357\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.9094 - val_loss: 10.2756\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.8399 - val_loss: 6.1376\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.9215 - val_loss: 6.3915\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.1359 - val_loss: 6.2658\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.0873 - val_loss: 6.4491\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.7816 - val_loss: 9.7460\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.0494 - val_loss: 9.9312\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.0644 - val_loss: 8.8407\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.0689 - val_loss: 6.5103\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.4383 - val_loss: 8.1130\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2158 - val_loss: 6.0002\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9345 - val_loss: 6.8583\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.6063 - val_loss: 6.8713\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.5610 - val_loss: 6.0872\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.4673 - val_loss: 6.6408\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.5592 - val_loss: 7.5020\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.4101 - val_loss: 6.9977\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.1613 - val_loss: 7.2086\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.0146 - val_loss: 6.0326\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.6226 - val_loss: 6.2877\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.0224 - val_loss: 8.3881\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.4625 - val_loss: 6.5215\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.9157 - val_loss: 6.6437\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.6588 - val_loss: 6.1381\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.0800 - val_loss: 6.3521\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4838 - val_loss: 6.5563\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.2157 - val_loss: 5.9930\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.1934 - val_loss: 6.3087\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.8494 - val_loss: 6.9719\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.7498 - val_loss: 6.0132\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.6204 - val_loss: 6.1454\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.3723 - val_loss: 7.6120\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.4062 - val_loss: 5.9252\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 7.4674 - val_loss: 5.9391\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.9160 - val_loss: 6.2223\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.6734 - val_loss: 6.1357\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.4795 - val_loss: 6.5115\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.0902 - val_loss: 6.4584\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.3023 - val_loss: 7.6441\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.8572 - val_loss: 6.1609\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf1e002790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 86 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 52.8481 - val_loss: 14.4488\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 32.7463 - val_loss: 11.9233\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 23.6795 - val_loss: 31.7241\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 22.8406 - val_loss: 23.4960\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 19.9280 - val_loss: 12.0681\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17.9761 - val_loss: 18.3558\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.0981 - val_loss: 15.0109\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.8224 - val_loss: 6.7240\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.7206 - val_loss: 11.7327\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.1656 - val_loss: 6.6929\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.9450 - val_loss: 12.2298\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.4414 - val_loss: 7.2193\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.5671 - val_loss: 12.5084\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.6229 - val_loss: 7.0003\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.6220 - val_loss: 6.7173\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.6195 - val_loss: 8.8070\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12.2256 - val_loss: 6.6540\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4646 - val_loss: 6.9748\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.5861 - val_loss: 7.0705\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.2643 - val_loss: 7.1805\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.1044 - val_loss: 6.8554\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.5309 - val_loss: 6.7372\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.9552 - val_loss: 7.5351\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.4589 - val_loss: 6.6871\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.2156 - val_loss: 6.7400\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.9009 - val_loss: 6.5938\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.1377 - val_loss: 6.3824\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.1675 - val_loss: 6.7458\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.3474 - val_loss: 7.0342\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.3560 - val_loss: 6.8473\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.9518 - val_loss: 6.5120\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5366 - val_loss: 6.2861\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.4257 - val_loss: 6.5359\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.3331 - val_loss: 6.5142\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.4465 - val_loss: 6.3511\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.9990 - val_loss: 6.3320\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.4713 - val_loss: 6.5962\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.7667 - val_loss: 6.0832\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.2165 - val_loss: 6.9732\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.2267 - val_loss: 6.9469\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.7917 - val_loss: 5.9609\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.7061 - val_loss: 6.4749\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.7783 - val_loss: 6.3610\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.2659 - val_loss: 6.5923\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.4375 - val_loss: 6.0074\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.7288 - val_loss: 5.9274\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.0446 - val_loss: 7.1040\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.3073 - val_loss: 5.9668\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.7336 - val_loss: 5.9448\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.9095 - val_loss: 5.8041\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf0807eca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 87 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 207367.2500 - val_loss: 85.2758\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 50535.5391 - val_loss: 95.6717\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8138.4531 - val_loss: 95.9628\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50754.1914 - val_loss: 94.3641\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7794.7773 - val_loss: 98.5340\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 66760.2578 - val_loss: 97.6832\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 51355.2031 - val_loss: 90.8058\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 119756.8828 - val_loss: 90.3153\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 101581.7188 - val_loss: 94.6809\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14265.2285 - val_loss: 95.7998\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8581.5352 - val_loss: 98.2812\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 60827.3438 - val_loss: 99.2939\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 63837.7500 - val_loss: 93.2620\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 76934.7656 - val_loss: 92.3974\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 70456.5625 - val_loss: 96.6292\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 39225.8906 - val_loss: 97.3409\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15507.1465 - val_loss: 94.2264\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 55965.3828 - val_loss: 93.5820\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 30625.1406 - val_loss: 96.1700\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17240.5488 - val_loss: 96.3388\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 22736.6680 - val_loss: 97.3107\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 45097.2812 - val_loss: 95.8721\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4440.4624 - val_loss: 97.2106\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15240.8604 - val_loss: 96.0037\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20582.7207 - val_loss: 96.3847\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21720.3828 - val_loss: 96.5044\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 48819.9570 - val_loss: 96.2341\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 63241.2109 - val_loss: 97.3434\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 63900.2773 - val_loss: 95.7252\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 25578.7500 - val_loss: 95.9289\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9041.6289 - val_loss: 95.6053\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 48365.3711 - val_loss: 95.4908\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 30661.7559 - val_loss: 98.4979\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 63103.1836 - val_loss: 99.8632\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 36072.4102 - val_loss: 98.6258\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 21009.4316 - val_loss: 95.7075\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 46022.5469 - val_loss: 95.7084\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 34343.5625 - val_loss: 96.4451\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 3265.4268 - val_loss: 100.3949\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 81322.0234 - val_loss: 102.7250\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 86233.5156 - val_loss: 100.4771\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 91241.3672 - val_loss: 97.7099\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13252.8320 - val_loss: 96.5261\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15623.2842 - val_loss: 98.7077\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 20527.7363 - val_loss: 101.9966\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 75463.2031 - val_loss: 102.7126\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 121682.2734 - val_loss: 101.0488\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 78155.0391 - val_loss: 97.8609\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17658.9785 - val_loss: 96.8737\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16599.2246 - val_loss: 97.7280\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf1111f670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 88 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 111543.8672 - val_loss: 79.2709\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 228839.5781 - val_loss: 86.9849\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 107087.7969 - val_loss: 83.3742\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14426.1416 - val_loss: 83.5982\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19970.3828 - val_loss: 86.4137\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 111955.4062 - val_loss: 89.1227\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 62255.8828 - val_loss: 87.5637\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 55786.1250 - val_loss: 82.5385\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 128176.7109 - val_loss: 81.9631\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 78216.3203 - val_loss: 85.7725\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12896.2275 - val_loss: 86.0665\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28244.3027 - val_loss: 87.3061\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17693.3516 - val_loss: 86.7819\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 48965.6289 - val_loss: 87.3529\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13979.8145 - val_loss: 86.6893\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42041.6016 - val_loss: 87.0943\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5306.9141 - val_loss: 90.2327\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 132301.8594 - val_loss: 90.7578\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 52790.8711 - val_loss: 88.3709\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15051.5498 - val_loss: 84.4678\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 147674.3750 - val_loss: 82.9605\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 43840.8125 - val_loss: 87.0818\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 56218.8867 - val_loss: 92.5079\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 158538.4531 - val_loss: 94.4371\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 160531.0625 - val_loss: 93.7934\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 151852.9844 - val_loss: 91.9942\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8427.6836 - val_loss: 88.9984\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 134045.2344 - val_loss: 87.6446\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 131359.7344 - val_loss: 89.9952\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 65334.6055 - val_loss: 94.0941\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 144307.7188 - val_loss: 96.4157\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 85431.8672 - val_loss: 95.0233\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3404.6526 - val_loss: 93.9558\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 24133.2324 - val_loss: 94.1983\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10607.1875 - val_loss: 93.0261\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 103060.4219 - val_loss: 92.0423\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 28354.6680 - val_loss: 93.5582\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19695.6113 - val_loss: 94.3985\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3325.0593 - val_loss: 94.5555\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3985.6401 - val_loss: 94.8393\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 77946.5547 - val_loss: 94.6151\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4788.1128 - val_loss: 93.8229\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 56355.1562 - val_loss: 93.6468\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 20793.0195 - val_loss: 94.7475\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24613.9375 - val_loss: 94.9349\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4014.7754 - val_loss: 95.5061\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 40478.0000 - val_loss: 95.4991\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 21464.2656 - val_loss: 94.0141\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 89434.9375 - val_loss: 93.0052\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 59287.6172 - val_loss: 93.7040\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdef6bfcd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 89 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 86.4304 - val_loss: 58.8746\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 41.8005 - val_loss: 13.4001\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 36.7826 - val_loss: 33.0355\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29.4614 - val_loss: 40.9396\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 28.5918 - val_loss: 28.9111\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25.2076 - val_loss: 15.0247\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 23.3780 - val_loss: 16.7659\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 20.2610 - val_loss: 18.7352\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 17.5374 - val_loss: 8.6563\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.6689 - val_loss: 10.4911\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.2461 - val_loss: 10.0704\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 17.3226 - val_loss: 8.2926\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15.7682 - val_loss: 7.7048\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.4082 - val_loss: 9.1750\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.8226 - val_loss: 7.3104\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.4560 - val_loss: 9.3049\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.3326 - val_loss: 9.6575\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.9920 - val_loss: 8.9481\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.1667 - val_loss: 7.9874\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.9161 - val_loss: 10.1287\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.4588 - val_loss: 7.7172\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.0043 - val_loss: 8.7481\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.2681 - val_loss: 5.9150\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.6923 - val_loss: 8.2912\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.6362 - val_loss: 6.3697\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.7628 - val_loss: 9.9452\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.9207 - val_loss: 8.0070\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.9597 - val_loss: 7.5506\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.9878 - val_loss: 8.7124\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.3646 - val_loss: 6.6903\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.8258 - val_loss: 9.7667\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.0649 - val_loss: 6.0726\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.7078 - val_loss: 7.4653\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.8492 - val_loss: 7.5471\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.8467 - val_loss: 7.7287\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.5932 - val_loss: 6.0147\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.8170 - val_loss: 9.8311\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.6605 - val_loss: 5.1830\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.7293 - val_loss: 9.3229\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.6300 - val_loss: 5.1591\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.0621 - val_loss: 7.7215\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.3654 - val_loss: 6.5336\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.3806 - val_loss: 5.6597\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.5618 - val_loss: 6.0297\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.5463 - val_loss: 5.6183\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.7180 - val_loss: 5.6901\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.7077 - val_loss: 6.4451\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.9269 - val_loss: 5.2006\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.4218 - val_loss: 5.8547\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.5204 - val_loss: 6.7962\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdefbdcf040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 90 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 3s 648ms/step - loss: 154766.9531 - val_loss: 106.2563\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 244247.1562 - val_loss: 109.6182\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 112394.2109 - val_loss: 101.2346\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 28421.2754 - val_loss: 91.0675\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 260614.7031 - val_loss: 88.1549\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 198854.9844 - val_loss: 91.8280\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 66577.7734 - val_loss: 97.7760\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23753.7207 - val_loss: 105.3035\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 188420.6719 - val_loss: 108.4038\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 142721.5156 - val_loss: 104.0556\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 25246.8613 - val_loss: 97.6613\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12174.8535 - val_loss: 96.9621\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 62853.5508 - val_loss: 97.8540\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 2324.0386 - val_loss: 98.9156\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 54218.0820 - val_loss: 98.8225\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 21750.2129 - val_loss: 100.9378\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32884.1055 - val_loss: 101.4812\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 31874.0195 - val_loss: 99.6279\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 49072.4336 - val_loss: 98.4540\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 38169.9648 - val_loss: 98.3335\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 48284.0586 - val_loss: 98.2599\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 31290.1289 - val_loss: 100.2751\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 52863.7188 - val_loss: 100.0686\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 21011.5391 - val_loss: 98.0630\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 63856.5859 - val_loss: 97.2504\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 62944.6133 - val_loss: 99.6089\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 13192.7627 - val_loss: 99.8943\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 4453.9321 - val_loss: 98.9927\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 38611.1719 - val_loss: 97.4820\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 49045.4727 - val_loss: 98.6665\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 18238.2422 - val_loss: 101.9287\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 54804.6367 - val_loss: 103.3707\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 97315.3984 - val_loss: 100.5201\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 74092.9844 - val_loss: 97.6166\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 35399.0078 - val_loss: 97.5117\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 36093.1484 - val_loss: 99.0499\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 22811.4316 - val_loss: 100.3435\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 49529.3594 - val_loss: 101.5145\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 67069.6094 - val_loss: 99.8661\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 13258.6064 - val_loss: 100.1521\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12637.0752 - val_loss: 100.1430\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 21964.1270 - val_loss: 99.3526\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 37010.0742 - val_loss: 100.0661\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 31117.4961 - val_loss: 97.2319\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 59109.3281 - val_loss: 97.1059\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 64958.0977 - val_loss: 99.0267\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 276.5532 - val_loss: 99.4629\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 26882.9727 - val_loss: 99.4629\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 2425.3542 - val_loss: 102.4054\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 62691.6055 - val_loss: 103.2469\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdeef87d550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 91 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 68.5531 - val_loss: 56.2214\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 52.5624 - val_loss: 51.1931\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 42.7772 - val_loss: 39.7796\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 32.1785 - val_loss: 16.7600\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21.6236 - val_loss: 9.2827\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18.3056 - val_loss: 8.0453\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21.5519 - val_loss: 7.5389\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 17.8160 - val_loss: 10.0956\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 21.4875 - val_loss: 15.1966\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 18.2537 - val_loss: 6.7616\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 16.8077 - val_loss: 7.0430\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.6751 - val_loss: 7.5544\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.4257 - val_loss: 7.9237\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 16.9557 - val_loss: 6.7261\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 17.8283 - val_loss: 7.1438\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.1650 - val_loss: 6.7672\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.7930 - val_loss: 6.5901\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 15.3345 - val_loss: 6.6101\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15.3518 - val_loss: 8.8403\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.6446 - val_loss: 6.4636\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19.2462 - val_loss: 6.3025\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.8575 - val_loss: 6.8734\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.6547 - val_loss: 8.3834\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16.9406 - val_loss: 6.5557\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.6620 - val_loss: 6.0725\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 15.5376 - val_loss: 6.4102\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.4704 - val_loss: 6.2027\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.3979 - val_loss: 7.7636\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.3077 - val_loss: 6.5751\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.8458 - val_loss: 5.9649\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.1051 - val_loss: 6.2561\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.0705 - val_loss: 8.5899\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.9637 - val_loss: 5.9431\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.6284 - val_loss: 5.6977\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.5143 - val_loss: 8.3222\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15.2419 - val_loss: 5.8986\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 13.3873 - val_loss: 5.7134\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.3427 - val_loss: 7.5800\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.5118 - val_loss: 5.5529\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.0264 - val_loss: 6.7812\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.9009 - val_loss: 6.1665\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.8488 - val_loss: 6.6641\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.4021 - val_loss: 8.3698\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.2779 - val_loss: 10.0403\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.8067 - val_loss: 7.2564\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.7064 - val_loss: 9.9151\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.2998 - val_loss: 5.6050\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18.2297 - val_loss: 8.1083\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.1335 - val_loss: 5.0257\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16.0841 - val_loss: 4.9619\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdeef310670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 92 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 76.3205 - val_loss: 38.4583\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 32.3795 - val_loss: 3.8235\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 31.8830 - val_loss: 23.1068\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 25.1116 - val_loss: 30.5734\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 22.6249 - val_loss: 18.2192\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21.0687 - val_loss: 12.4675\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21.2329 - val_loss: 16.4084\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 18.1115 - val_loss: 10.3039\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 18.0836 - val_loss: 10.5908\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.6990 - val_loss: 6.9708\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 15.2942 - val_loss: 8.3259\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.0298 - val_loss: 4.1406\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.9113 - val_loss: 4.2236\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 13.4872 - val_loss: 4.3844\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.6212 - val_loss: 4.7336\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.3022 - val_loss: 6.1245\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.7880 - val_loss: 5.1967\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.9243 - val_loss: 6.4900\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.9414 - val_loss: 4.8238\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.1130 - val_loss: 4.7557\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.0089 - val_loss: 4.9321\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.1645 - val_loss: 5.4377\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.2738 - val_loss: 4.6719\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.2942 - val_loss: 5.4168\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.8854 - val_loss: 5.2827\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.9034 - val_loss: 4.8946\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.8081 - val_loss: 4.7714\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.6309 - val_loss: 6.8035\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.4207 - val_loss: 5.1185\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.1158 - val_loss: 5.0074\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.4300 - val_loss: 4.7999\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.0185 - val_loss: 4.8205\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.8760 - val_loss: 4.7571\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.0127 - val_loss: 5.4218\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8814 - val_loss: 4.7486\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.2661 - val_loss: 5.0579\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.4562 - val_loss: 4.7290\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.9459 - val_loss: 4.9296\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.2044 - val_loss: 5.9377\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.0751 - val_loss: 5.0220\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.7521 - val_loss: 6.4811\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.1589 - val_loss: 4.6360\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.2359 - val_loss: 5.6717\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.5764 - val_loss: 4.2694\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.5171 - val_loss: 4.3750\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.4165 - val_loss: 4.7227\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.7467 - val_loss: 5.5251\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.3270 - val_loss: 3.9878\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.3780 - val_loss: 6.5393\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.5903 - val_loss: 4.0746\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdefea1e1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 93 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 88.3450 - val_loss: 58.7157\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 60.9775 - val_loss: 46.4672\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 47.6138 - val_loss: 57.1152\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43.1708 - val_loss: 50.1518\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 37.3134 - val_loss: 33.4408\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 32.9213 - val_loss: 24.9989\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 29.0020 - val_loss: 28.2794\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 25.4636 - val_loss: 12.0368\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 24.3851 - val_loss: 8.7621\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 23.2410 - val_loss: 13.1455\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 21.2059 - val_loss: 7.4898\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.1555 - val_loss: 10.3540\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19.7499 - val_loss: 8.8972\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21.4160 - val_loss: 4.6518\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.5599 - val_loss: 5.9174\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 18.8614 - val_loss: 3.7627\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.9997 - val_loss: 13.8163\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.8045 - val_loss: 3.7848\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 17.8982 - val_loss: 7.7893\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 16.8037 - val_loss: 4.5089\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19.8266 - val_loss: 4.1752\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.8758 - val_loss: 8.2425\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.0108 - val_loss: 4.8168\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.0145 - val_loss: 3.9614\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.2023 - val_loss: 5.1641\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.2843 - val_loss: 4.1447\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.1782 - val_loss: 3.5940\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.7200 - val_loss: 3.5899\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.1055 - val_loss: 6.3339\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.4269 - val_loss: 3.7289\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.0042 - val_loss: 3.6817\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.4327 - val_loss: 3.3511\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.0296 - val_loss: 3.3971\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.1242 - val_loss: 7.4875\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.0237 - val_loss: 3.2954\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.4208 - val_loss: 2.9388\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.9237 - val_loss: 5.6419\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.2392 - val_loss: 3.2239\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.4850 - val_loss: 2.8027\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.5361 - val_loss: 3.8214\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.8455 - val_loss: 8.3952\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.3413 - val_loss: 5.3400\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.3338 - val_loss: 3.0038\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.6457 - val_loss: 3.8526\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.8850 - val_loss: 7.1671\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.7809 - val_loss: 3.6143\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.5884 - val_loss: 3.5722\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7411 - val_loss: 5.5173\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.1412 - val_loss: 5.6313\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7996 - val_loss: 3.6161\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf0bd1e280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 94 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 88.7649 - val_loss: 61.2319\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 39.5512 - val_loss: 8.1343\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 38.3622 - val_loss: 17.4569\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29.0678 - val_loss: 31.0039\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 26.8174 - val_loss: 18.3528\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 21.6152 - val_loss: 6.5441\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 21.6224 - val_loss: 6.8669\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 20.1102 - val_loss: 13.4186\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.4056 - val_loss: 9.0769\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.3684 - val_loss: 7.1297\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.9076 - val_loss: 7.2260\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.1499 - val_loss: 7.3264\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.6635 - val_loss: 7.0857\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.2812 - val_loss: 7.1351\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.4759 - val_loss: 7.2492\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.9612 - val_loss: 6.2678\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.7340 - val_loss: 7.7843\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.0366 - val_loss: 5.9726\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.1309 - val_loss: 6.4390\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.8011 - val_loss: 5.9001\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.6088 - val_loss: 5.4222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.7675 - val_loss: 5.3333\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.6448 - val_loss: 5.2647\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.9957 - val_loss: 5.1689\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1796 - val_loss: 7.5100\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8433 - val_loss: 5.3335\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.1401 - val_loss: 5.7490\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.1462 - val_loss: 5.0273\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.9457 - val_loss: 4.9434\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.3527 - val_loss: 6.3973\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.5684 - val_loss: 4.8777\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.5036 - val_loss: 6.4630\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.4383 - val_loss: 4.7382\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.2660 - val_loss: 6.1259\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.6141 - val_loss: 4.7788\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.9135 - val_loss: 5.3900\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.8273 - val_loss: 4.7614\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.4863 - val_loss: 10.5030\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.5316 - val_loss: 5.1634\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.5923 - val_loss: 6.2209\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.8861 - val_loss: 4.9477\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.5828 - val_loss: 4.7644\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.7020 - val_loss: 4.3485\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.0418 - val_loss: 5.4728\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.0126 - val_loss: 4.3595\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.9392 - val_loss: 4.3225\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.3626 - val_loss: 4.6914\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.7268 - val_loss: 4.3104\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.5297 - val_loss: 4.3841\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.0388 - val_loss: 5.1489\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf7eae7e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 95 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 61.7129 - val_loss: 29.9453\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 46.0000 - val_loss: 35.9766\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 37.5219 - val_loss: 44.2215\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33.7716 - val_loss: 27.9204\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31.1153 - val_loss: 23.7279\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 25.3576 - val_loss: 29.0801\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 24.2429 - val_loss: 10.8304\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 21.5565 - val_loss: 13.9475\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20.9879 - val_loss: 8.8965\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19.5593 - val_loss: 11.2039\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 20.1751 - val_loss: 6.5840\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.8283 - val_loss: 9.0522\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.0630 - val_loss: 8.7516\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.8059 - val_loss: 6.4291\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.7072 - val_loss: 10.9250\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.6121 - val_loss: 6.2391\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 16.0382 - val_loss: 8.4194\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 17.0063 - val_loss: 5.1469\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.8477 - val_loss: 8.4501\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.4261 - val_loss: 5.4694\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.2921 - val_loss: 8.1524\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 16.2540 - val_loss: 5.4555\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.3748 - val_loss: 7.0926\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 14.9272 - val_loss: 5.6562\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.8882 - val_loss: 6.4356\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.8692 - val_loss: 6.4306\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.6522 - val_loss: 5.8955\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15.3099 - val_loss: 6.4145\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.5150 - val_loss: 8.3094\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.2251 - val_loss: 5.0441\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.7504 - val_loss: 6.8177\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.4965 - val_loss: 6.8472\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.7227 - val_loss: 5.3933\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.7608 - val_loss: 8.8804\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.1486 - val_loss: 5.9523\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.0260 - val_loss: 6.8180\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.5203 - val_loss: 5.4956\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.8726 - val_loss: 6.7402\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.8858 - val_loss: 6.5207\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.6475 - val_loss: 7.4528\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.3164 - val_loss: 5.8791\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.9755 - val_loss: 6.7572\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.7545 - val_loss: 5.0152\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.5061 - val_loss: 7.1415\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.9395 - val_loss: 6.8691\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.8385 - val_loss: 4.8473\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.6520 - val_loss: 6.5824\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 14.7755 - val_loss: 6.3492\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 13.2421 - val_loss: 4.4395\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.2260 - val_loss: 7.1866\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf9948a160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 96 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 81.5814 - val_loss: 51.2340\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 30.1931 - val_loss: 4.3235\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 29.9145 - val_loss: 21.9460\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.6521 - val_loss: 33.2774\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 17.9603 - val_loss: 21.6721\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.3240 - val_loss: 14.5141\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16.5866 - val_loss: 21.6613\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.4011 - val_loss: 23.0723\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 14.7140 - val_loss: 13.4363\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.9473 - val_loss: 17.5033\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.6313 - val_loss: 14.9250\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.7512 - val_loss: 8.5050\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.2389 - val_loss: 12.2697\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.9744 - val_loss: 3.6308\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.6544 - val_loss: 9.8050\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.3588 - val_loss: 3.8421\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.7542 - val_loss: 9.3478\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 9.5931 - val_loss: 6.0927\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.5662 - val_loss: 4.4685\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.8177 - val_loss: 3.5467\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.1433 - val_loss: 6.0930\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.5640 - val_loss: 3.3837\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.1037 - val_loss: 5.3576\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.4183 - val_loss: 5.2620\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4804 - val_loss: 8.8537\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.6370 - val_loss: 2.9842\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.1350 - val_loss: 5.7264\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.3680 - val_loss: 3.5442\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.9942 - val_loss: 3.2156\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 8.8066 - val_loss: 4.5539\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.4003 - val_loss: 3.3364\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.0532 - val_loss: 3.9930\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2211 - val_loss: 3.3580\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.9212 - val_loss: 3.5523\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.5517 - val_loss: 5.4707\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3716 - val_loss: 4.2738\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.2327 - val_loss: 6.8170\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.1917 - val_loss: 4.6476\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.7552 - val_loss: 7.9297\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.6396 - val_loss: 3.7490\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4159 - val_loss: 7.8256\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4393 - val_loss: 4.2349\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.8085 - val_loss: 6.7215\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.3711 - val_loss: 4.1877\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.1547 - val_loss: 3.0456\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.0574 - val_loss: 4.9363\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1107 - val_loss: 6.8971\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.9953 - val_loss: 3.5031\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.2220 - val_loss: 7.1486\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.2528 - val_loss: 2.9207\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf17065820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 97 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 76.3011 - val_loss: 45.2066\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 29.4350 - val_loss: 10.3331\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 27.7619 - val_loss: 17.6489\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22.8819 - val_loss: 30.6662\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 22.1323 - val_loss: 17.0125\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 21.2381 - val_loss: 2.3547\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19.8396 - val_loss: 13.2636\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 16.1568 - val_loss: 18.1654\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 16.4838 - val_loss: 6.9165\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.9181 - val_loss: 2.1165\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.8749 - val_loss: 11.5723\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.2927 - val_loss: 3.6678\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9152 - val_loss: 2.9779\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.9563 - val_loss: 3.5204\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.7332 - val_loss: 5.3807\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.1771 - val_loss: 5.7425\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.2585 - val_loss: 8.5083\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.6065 - val_loss: 5.2229\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.7551 - val_loss: 8.6569\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6719 - val_loss: 3.4078\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.4655 - val_loss: 2.9344\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.0208 - val_loss: 2.8924\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.1105 - val_loss: 5.2398\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.2608 - val_loss: 2.7333\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.2996 - val_loss: 3.0064\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.1338 - val_loss: 2.4828\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.9780 - val_loss: 2.9201\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.8017 - val_loss: 2.8251\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.0154 - val_loss: 3.6886\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.1247 - val_loss: 2.6282\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.1539 - val_loss: 6.4910\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.8835 - val_loss: 2.8136\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.3526 - val_loss: 3.9992\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.9068 - val_loss: 3.8442\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.2899 - val_loss: 3.8954\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.0735 - val_loss: 3.9129\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.1113 - val_loss: 3.0664\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.5737 - val_loss: 4.1398\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.5127 - val_loss: 2.7694\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.3061 - val_loss: 3.8611\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.7060 - val_loss: 4.4122\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.2874 - val_loss: 4.5287\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.2323 - val_loss: 3.7863\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.8475 - val_loss: 4.5268\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.6637 - val_loss: 4.4076\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.2375 - val_loss: 7.6200\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.5068 - val_loss: 2.7669\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.7167 - val_loss: 2.8766\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.2435 - val_loss: 2.7006\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.5938 - val_loss: 2.7627\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf71e3fca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 98 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 93.7874 - val_loss: 59.2670\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 54.7956 - val_loss: 24.2423\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 41.4746 - val_loss: 29.2719\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 31.4497 - val_loss: 33.0284\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 27.7498 - val_loss: 17.9869\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 23.3751 - val_loss: 16.0956\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 19.3008 - val_loss: 16.0460\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 20.6829 - val_loss: 12.3896\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.1165 - val_loss: 14.6984\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17.7455 - val_loss: 11.8891\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 17.7315 - val_loss: 12.6152\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 17.2038 - val_loss: 13.1064\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 18.0705 - val_loss: 13.0432\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 18.1780 - val_loss: 15.1350\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 18.6142 - val_loss: 12.9262\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.9169 - val_loss: 11.8965\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.1188 - val_loss: 11.7507\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 16.2234 - val_loss: 11.4271\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 17.0989 - val_loss: 11.1659\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 15.9901 - val_loss: 12.2169\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.2673 - val_loss: 12.3140\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.2273 - val_loss: 11.7017\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.1705 - val_loss: 11.0067\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 15.6464 - val_loss: 10.7868\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 14.6173 - val_loss: 11.7671\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 16.1580 - val_loss: 11.1455\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.5187 - val_loss: 11.4925\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.9892 - val_loss: 10.6829\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.1979 - val_loss: 11.3008\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.6812 - val_loss: 11.2780\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 15.2703 - val_loss: 10.6944\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.0521 - val_loss: 10.7407\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15.2737 - val_loss: 10.8558\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 15.8720 - val_loss: 14.5759\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 14.5814 - val_loss: 10.3281\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 14.1438 - val_loss: 11.5003\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.1047 - val_loss: 10.3958\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 14.0877 - val_loss: 12.1562\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 14.2078 - val_loss: 10.4555\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 14.3325 - val_loss: 12.0436\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 14.5484 - val_loss: 11.2143\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 12.5055 - val_loss: 10.6928\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 13.2839 - val_loss: 10.5169\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.6227 - val_loss: 10.2511\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.0634 - val_loss: 11.3193\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 12.2358 - val_loss: 9.6571\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 14.0338 - val_loss: 12.6874\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 13.9403 - val_loss: 10.5133\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.6770 - val_loss: 9.8328\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.1337 - val_loss: 9.7251\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdeff70a940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 99 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 11941.4922 - val_loss: 124.7377\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 503819.4062 - val_loss: 128.1171\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 440598.2500 - val_loss: 113.2478\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 30665.4766 - val_loss: 103.4814\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 45320.2500 - val_loss: 100.3185\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 83044.5000 - val_loss: 101.2109\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 60029.2891 - val_loss: 110.3010\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 137616.1250 - val_loss: 110.3566\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 170117.3281 - val_loss: 106.6083\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7429.8535 - val_loss: 102.8541\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 77282.1484 - val_loss: 100.7460\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 46067.6680 - val_loss: 104.8007\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 87700.8516 - val_loss: 104.9301\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 43471.8398 - val_loss: 103.7128\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 26236.5898 - val_loss: 97.9422\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 153232.4062 - val_loss: 97.0738\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 139898.9219 - val_loss: 97.7931\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 55306.4883 - val_loss: 101.6927\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 27294.2676 - val_loss: 103.1012\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 2507.7051 - val_loss: 101.9879\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12488.4453 - val_loss: 100.6452\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5759.4541 - val_loss: 99.3956\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 58588.3359 - val_loss: 98.5761\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 78111.6875 - val_loss: 100.7473\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 23372.4219 - val_loss: 104.2036\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 93499.4609 - val_loss: 104.3575\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 68477.5156 - val_loss: 102.3048\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 68634.9453 - val_loss: 98.9298\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 81614.3906 - val_loss: 99.5933\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 64502.0508 - val_loss: 100.9096\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6905.0024 - val_loss: 102.0799\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4362.2451 - val_loss: 99.9542\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 51883.5977 - val_loss: 99.6397\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55543.7031 - val_loss: 100.6973\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 80138.1328 - val_loss: 102.9850\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 48113.3242 - val_loss: 103.6450\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 56063.7812 - val_loss: 101.1264\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 38598.1094 - val_loss: 99.9220\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6513.1714 - val_loss: 100.2420\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4649.7769 - val_loss: 102.9914\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 31529.4414 - val_loss: 102.9865\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 69366.9375 - val_loss: 100.8448\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3189.9512 - val_loss: 101.7499\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 56755.7578 - val_loss: 101.8286\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 34201.4258 - val_loss: 98.4926\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 52429.3281 - val_loss: 97.3242\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 112206.4375 - val_loss: 99.6582\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14498.9277 - val_loss: 102.9770\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 93511.0312 - val_loss: 104.2697\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 86307.2734 - val_loss: 103.1500\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdee3e6f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 100 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 92.5142 - val_loss: 52.8978\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 26.8485 - val_loss: 8.2037\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 23.5167 - val_loss: 20.4033\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 17.1931 - val_loss: 30.2084\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 17.3237 - val_loss: 16.5814\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.0399 - val_loss: 9.1590\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.9925 - val_loss: 16.5656\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.6041 - val_loss: 18.3110\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.4313 - val_loss: 10.0816\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.0824 - val_loss: 10.1053\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.1770 - val_loss: 17.1710\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.8409 - val_loss: 9.0802\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.5896 - val_loss: 9.3818\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.5140 - val_loss: 10.5537\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.1447 - val_loss: 5.7773\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8.8681 - val_loss: 6.9255\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.3625 - val_loss: 7.6428\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.2844 - val_loss: 4.0838\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.7029 - val_loss: 5.1053\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4743 - val_loss: 6.3380\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.9349 - val_loss: 4.5217\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.3759 - val_loss: 5.3848\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.0151 - val_loss: 4.6625\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.9541 - val_loss: 4.4528\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.8793 - val_loss: 7.7537\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.7080 - val_loss: 4.3114\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.1292 - val_loss: 5.8842\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.9221 - val_loss: 4.5424\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.2551 - val_loss: 4.4505\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.4482 - val_loss: 4.1937\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.9310 - val_loss: 4.3732\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.3870 - val_loss: 5.8320\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.0279 - val_loss: 4.3704\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.5608 - val_loss: 6.5514\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.5052 - val_loss: 4.8555\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.8885 - val_loss: 8.0780\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.5605 - val_loss: 5.9406\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.8473 - val_loss: 10.3147\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.7119 - val_loss: 4.8227\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.6791 - val_loss: 8.3861\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.8647 - val_loss: 5.3722\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.5377 - val_loss: 8.1707\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.2425 - val_loss: 4.4907\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.6845 - val_loss: 6.2175\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.5743 - val_loss: 4.1925\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.1453 - val_loss: 4.7953\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.0724 - val_loss: 4.0331\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.6432 - val_loss: 5.1580\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.3355 - val_loss: 4.0738\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.4124 - val_loss: 4.1730\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdee9f13700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 101 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 51.9894 - val_loss: 15.8365\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 45.2195 - val_loss: 22.2104\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 30.4880 - val_loss: 38.3210\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29.1427 - val_loss: 33.6631\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24.7750 - val_loss: 19.7011\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 20.7428 - val_loss: 15.0728\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 17.4518 - val_loss: 12.1824\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 16.1345 - val_loss: 6.8295\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15.1583 - val_loss: 3.5089\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.7934 - val_loss: 9.3930\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 14.9151 - val_loss: 6.3131\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.0253 - val_loss: 6.2702\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.0795 - val_loss: 6.6029\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.9282 - val_loss: 2.9689\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.3499 - val_loss: 4.2841\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.2398 - val_loss: 2.2150\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.5252 - val_loss: 4.1588\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 15.3683 - val_loss: 7.3260\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.0904 - val_loss: 3.2100\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.7844 - val_loss: 5.4210\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.5853 - val_loss: 2.5623\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.6759 - val_loss: 2.3417\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.4105 - val_loss: 2.8900\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.1705 - val_loss: 3.4529\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.2032 - val_loss: 2.4197\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.8674 - val_loss: 4.6146\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12.0684 - val_loss: 2.7400\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.6882 - val_loss: 5.7813\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 12.0501 - val_loss: 5.4342\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.9844 - val_loss: 4.1720\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.0246 - val_loss: 3.8830\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.9716 - val_loss: 2.1796\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.5799 - val_loss: 3.9386\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.0398 - val_loss: 5.6540\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.9394 - val_loss: 5.4793\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10.4098 - val_loss: 5.0630\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.4412 - val_loss: 4.7477\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.9994 - val_loss: 4.4072\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.3416 - val_loss: 1.7144\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.3345 - val_loss: 2.2964\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.9349 - val_loss: 2.3348\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.7813 - val_loss: 4.4194\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.0356 - val_loss: 2.0708\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.4185 - val_loss: 2.3249\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.9149 - val_loss: 1.9535\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.2796 - val_loss: 1.3887\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.4066 - val_loss: 3.8747\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.0650 - val_loss: 4.6701\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.9444 - val_loss: 8.4557\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.8674 - val_loss: 5.8345\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdf5eb253a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 102 finished\n"
     ]
    }
   ],
   "source": [
    "zipcodes = nv_zipcodes\n",
    "dict_mape4 = {}\n",
    "dict_pred4 = {}\n",
    "\n",
    "for zipcode in range(len(zipcodes)):\n",
    "\n",
    "    # init a RMM model\n",
    "    rnn_model = Sequential()\n",
    "    # add 4 layers of RNN and a last layer\n",
    "\n",
    "    # we define shape on first layer, (60,1) because we use 60 inputs per prediction\n",
    "    rnn_model.add(LSTM(units= 60, return_sequences = True, input_shape=((60,1))))\n",
    "    rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # another layer\n",
    "    rnn_model.add(LSTM(units= 30, return_sequences = False))\n",
    "    rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # return_sequence is False because we want only 1 output after this layer\n",
    "    #rnn_model.add(LSTM(units= 60, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # last layer \n",
    "\n",
    "    rnn_model.add(Dense(units=1))\n",
    "\n",
    "    # compile - because this is a regression model we want to minimize MSE\n",
    "\n",
    "    rnn_model.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "\n",
    "    # We get only the specific column(Zipcode from our train and test datas)\n",
    "    train_data = train.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    test_data = test.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # We are using normalizaion rather than standascaler. \n",
    "    # In a upward trending timeseries it is better to not start from negative\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Because we are using 60 previous values to model and predict the next value, \n",
    "    # We set X_train from arrays of 60 for each y_train value\n",
    "    # Same idea for test data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(train_data_scaled)):\n",
    "        X_train.append(train_data_scaled[i-60:i])\n",
    "        y_train.append(train_data_scaled[i])\n",
    "\n",
    "    data_total = pd.concat((train.iloc[:,zipcode:zipcode+1], test.iloc[:,zipcode:zipcode+1]),axis=0)\n",
    "    inputs = data_total[len(train)-60:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(60,len(inputs)):\n",
    "        X_test.append(inputs[i-60:i])\n",
    "        y_test.append(inputs[i])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(test_data)\n",
    "\n",
    "    # We need numpy arrays for our model\n",
    "    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # We fit our data to our zipcode specific data\n",
    "    rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, scaler.transform(y_test)))\n",
    "\n",
    "    # Make predictions on the data\n",
    "\n",
    "    y_hat_raw = rnn_model.predict(X_test)\n",
    "    y_hat = scaler.inverse_transform(y_hat_raw)\n",
    "\n",
    "    # Use the score on unseen test data to calculate the MAPE\n",
    "\n",
    "    dict_mape4[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_test)/y_test))      \n",
    "\n",
    "    # We get the last 60 values from our test data which is basically last 60 values in the data set\n",
    "    last_60 = df_time_series.iloc[-60:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # Before we use our data we scale it\n",
    "    last_60 = scaler.transform(last_60)\n",
    "    \n",
    "    # Our input should be in (x,60,1) format\n",
    "    x_new_pred = last_60[-60:].reshape(1,60,1)\n",
    "\n",
    "    # make a prediction, add to the last_60 for the next prediction and \n",
    "    y_pred = rnn_model.predict(x_new_pred)\n",
    "\n",
    "    # We add our predition to our list of predictions for zipcode specific predictions list\n",
    "    dict_pred4[zipcodes[zipcode]]=scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(f'Iteration number {zipcode} finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_keys4 = list(dict_mape4.keys())\n",
    "rnn_mape4 = list(dict_mape4.values())\n",
    "rnn_pred4 = []\n",
    "rnn_dict4 = {}\n",
    "for zipcode in dict_pred4.keys():\n",
    "    rnn_pred4.append(dict_pred3[zipcode].astype(int)[0][0])\n",
    "for zc in rnn_keys4:\n",
    "    a = []\n",
    "    a.append(dict_mape4[zc])\n",
    "    a.append(dict_pred4[zc].astype(float)[0][0])\n",
    "    a.append('RNN_2_layer_w/_D.o.')\n",
    "    rnn_dict4[zc] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2119248143820323"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_mape4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rnn_dict, rnn_dict2, rnn_dict3, rnn_dict4]\n",
    "best_model_dict = {}\n",
    "for zipcode in dict_pred.keys():\n",
    "    best_model = [1,1]\n",
    "    for model in models:\n",
    "        if model[zipcode][0]<best_model[0]:\n",
    "            best_model = model[zipcode]\n",
    "    best_model_dict[zipcode] = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95804: [0.514447689112919, 75282.640625, 'RNN_2_Layers'],\n",
       " 95817: [0.47909724302998, 82791.890625, 'RNN_2_layer_w/_D.o.'],\n",
       " 95813: [0.010808055744779672, 343835.59375, 'RNN_2_Layers'],\n",
       " 95785: [0.010358055443760965, 421466.875, 'RNN_w/_D.o.'],\n",
       " 95819: [0.011060594461016884, 303811.84375, 'RNN_w/_D.o.'],\n",
       " 95770: [0.42153780511040634, 111346.015625, 'RNN_w/_D.o.'],\n",
       " 95806: [0.4930118207021053, 75971.6328125, 'RNN_w/_D.o.'],\n",
       " 95790: [0.007388430655138559, 312865.75, 'RNN'],\n",
       " 95799: [0.4047415036243203, 114340.0, 'RNN_w/_D.o.'],\n",
       " 95844: [0.009709705808756491, 305326.5625, 'RNN_w/_D.o.'],\n",
       " 95843: [0.3900965326459336, 134520.515625, 'RNN_2_layer_w/_D.o.'],\n",
       " 95815: [0.46526802172140347, 94239.34375, 'RNN_2_layer_w/_D.o.'],\n",
       " 95825: [0.38387902090114595, 142043.46875, 'RNN'],\n",
       " 95818: [0.42562386145039116, 97351.484375, 'RNN_2_layer_w/_D.o.'],\n",
       " 95811: [0.46491245082909255, 74676.609375, 'RNN'],\n",
       " 95931: [0.42526985473181134, 123504.640625, 'RNN_w/_D.o.'],\n",
       " 95753: [0.3965936438523714, 141604.265625, 'RNN'],\n",
       " 95827: [0.007603622823857905, 336967.1875, 'RNN_w/_D.o.'],\n",
       " 95937: [0.010482319800557482, 444971.84375, 'RNN'],\n",
       " 95914: [0.42236398089775723, 174242.109375, 'RNN_2_Layers'],\n",
       " 95754: [0.40541718141738725, 117087.3046875, 'RNN_w/_D.o.'],\n",
       " 95824: [0.3774964689018774, 143480.625, 'RNN'],\n",
       " 95945: [0.009420181348985288, 393342.9375, 'RNN'],\n",
       " 95800: [0.4718195009651555, 84472.21875, 'RNN'],\n",
       " 95751: [0.006466971191703606, 348101.21875, 'RNN_w/_D.o.'],\n",
       " 95769: [0.20977313408814366, 84078.21875, 'RNN_w/_D.o.'],\n",
       " 95909: [0.4408909816535858, 112772.4296875, 'RNN_w/_D.o.'],\n",
       " 95771: [0.4449168818684283, 96661.84375, 'RNN'],\n",
       " 95935: [0.45576855675063266, 119608.140625, 'RNN_2_layer_w/_D.o.'],\n",
       " 95798: [0.49470465844168654, 83719.421875, 'RNN'],\n",
       " 95835: [0.37012083339406066, 148331.453125, 'RNN_2_layer_w/_D.o.'],\n",
       " 95845: [0.3527866797556514, 166657.90625, 'RNN'],\n",
       " 95865: [0.0060464769748770665, 294301.125, 'RNN'],\n",
       " 95809: [0.008562374309784411, 308646.96875, 'RNN_2_Layers'],\n",
       " 95944: [0.00899301301814151, 411977.78125, 'RNN_2_Layers'],\n",
       " 399671: [0.39671479526227116, 129585.75, 'RNN_2_Layers'],\n",
       " 95831: [0.010588402896257164, 421104.15625, 'RNN_2_Layers'],\n",
       " 95803: [0.5113337512624517, 72683.21875, 'RNN_w/_D.o.'],\n",
       " 95939: [0.012545132723112445, 653071.75, 'RNN_w/_D.o.'],\n",
       " 399665: [0.014149467428044914, 302807.65625, 'RNN'],\n",
       " 95826: [0.39557817802969253, 130099.0078125, 'RNN_2_Layers'],\n",
       " 95830: [0.010556710001477967, 318089.5, 'RNN_2_Layers'],\n",
       " 95932: [0.41069818420484944, 147422.921875, 'RNN'],\n",
       " 95792: [0.39536266368264517, 120747.5, 'RNN_w/_D.o.'],\n",
       " 95837: [0.007663622906824243, 320045.84375, 'RNN_w/_D.o.'],\n",
       " 95750: [0.012161211967476323, 269634.9375, 'RNN_2_Layers'],\n",
       " 95838: [0.4022623108188854, 102916.2578125, 'RNN'],\n",
       " 95912: [0.41581828152395867, 145191.703125, 'RNN_w/_D.o.'],\n",
       " 95940: [0.28050054567188604, 115600.046875, 'RNN'],\n",
       " 95841: [0.3897281475301448, 120660.484375, 'RNN'],\n",
       " 95793: [0.009597087395329643, 296469.84375, 'RNN'],\n",
       " 95952: [0.009495231708585497, 266254.875, 'RNN'],\n",
       " 95963: [0.10176629964979514, 209590.125, 'RNN'],\n",
       " 95816: [0.4315038321521024, 116423.96875, 'RNN'],\n",
       " 95779: [0.010431262544918843, 354796.84375, 'RNN_2_Layers'],\n",
       " 95852: [0.46973642009308786, 84205.7265625, 'RNN'],\n",
       " 95783: [0.29514574011960526, 116132.4609375, 'RNN_w/_D.o.'],\n",
       " 95814: [0.38382792279041755, 134058.5, 'RNN'],\n",
       " 95957: [0.012981924290519522, 267417.28125, 'RNN'],\n",
       " 95888: [0.18024022600261902, 144912.828125, 'RNN_w/_D.o.'],\n",
       " 95861: [0.008910244261769715, 292220.53125, 'RNN_2_Layers'],\n",
       " 95840: [0.01030218372133625, 347827.71875, 'RNN'],\n",
       " 95842: [0.36788399256165016, 167712.90625, 'RNN'],\n",
       " 95766: [0.00854011861571219, 239586.078125, 'RNN'],\n",
       " 95883: [0.1520333966450159, 175152.21875, 'RNN'],\n",
       " 95911: [0.42992650802064086, 126064.5390625, 'RNN_w/_D.o.'],\n",
       " 95744: [0.00984138429584488, 318896.78125, 'RNN'],\n",
       " 95834: [0.010040520321775439, 439585.46875, 'RNN_2_Layers'],\n",
       " 95928: [0.021741427708519265, 318965.125, 'RNN'],\n",
       " 95901: [0.015790881595813135, 398780.40625, 'RNN'],\n",
       " 95890: [0.01847956218986767, 367463.875, 'RNN'],\n",
       " 95966: [0.07944586290889326, 216266.828125, 'RNN'],\n",
       " 95768: [0.16659501239545244, 133545.65625, 'RNN'],\n",
       " 95805: [0.3309421671862406, 162035.734375, 'RNN'],\n",
       " 399673: [0.39168266938519675, 150949.6875, 'RNN_w/_D.o.'],\n",
       " 95954: [0.010090192830097204, 399326.6875, 'RNN'],\n",
       " 399672: [0.012774884508413867, 423790.8125, 'RNN_w/_D.o.'],\n",
       " 95787: [0.32292317749437116, 81608.4609375, 'RNN'],\n",
       " 95839: [0.013403365697682666, 286015.15625, 'RNN_2_layer_w/_D.o.'],\n",
       " 399674: [0.013792924062759431, 540005.875, 'RNN'],\n",
       " 95922: [0.10331362132064165, 118700.0390625, 'RNN_w/_D.o.'],\n",
       " 95866: [0.006428252410216056, 306795.75, 'RNN_w/_D.o.'],\n",
       " 95907: [0.16190199699180186, 109896.9765625, 'RNN_w/_D.o.'],\n",
       " 95788: [0.3864293493042555, 106712.0703125, 'RNN_2_layer_w/_D.o.'],\n",
       " 95926: [0.018112257056903527, 924405.6875, 'RNN_w/_D.o.'],\n",
       " 95930: [0.03876847845117795, 338159.3125, 'RNN'],\n",
       " 95956: [0.02446487880320502, 315065.6875, 'RNN'],\n",
       " 95938: [0.023540595917550224, 426174.78125, 'RNN_w/_D.o.'],\n",
       " 95795: [0.3838596467150377, 137223.53125, 'RNN'],\n",
       " 95923: [0.29980676589630256, 436290.5625, 'RNN_2_Layers'],\n",
       " 95955: [0.02124960986573491, 423724.21875, 'RNN'],\n",
       " 95924: [0.23029241142242796, 260255.78125, 'RNN'],\n",
       " 95775: [0.01355241057158235, 208000.671875, 'RNN_w/_D.o.'],\n",
       " 95919: [0.018229440515598945, 279638.8125, 'RNN_2_Layers'],\n",
       " 95794: [0.008400510030956663, 329596.03125, 'RNN_w/_D.o.'],\n",
       " 399666: [0.011334145489822915, 327640.78125, 'RNN_2_Layers'],\n",
       " 95760: [0.012560150497267532, 306605.96875, 'RNN_w/_D.o.'],\n",
       " 95916: [0.010913525910615451, 453697.84375, 'RNN_w/_D.o.'],\n",
       " 95891: [0.012681091978175376, 653999.0, 'RNN_w/_D.o.'],\n",
       " 95820: [0.026793016022013318, 333740.6875, 'RNN'],\n",
       " 95917: [0.3900096034494574, 109275.640625, 'RNN_2_Layers'],\n",
       " 95893: [0.023259901004509066, 2082682.875, 'RNN_2_Layers'],\n",
       " 95851: [0.00911636346264891, 361679.90625, 'RNN_2_Layers']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'RNN', 'RNN_2_Layers', 'RNN_2_layer_w/_D.o.', 'RNN_w/_D.o.'},\n",
       " [44, 32, 19, 8])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_types = []\n",
    "for item in best_model_dict.values():\n",
    "    model_types.append([item[2]])\n",
    "list = []\n",
    "for item in model_types:\n",
    "    list.append(item[0])\n",
    "labels = set(list)\n",
    "sizes = []\n",
    "#list.count(labels[0])\n",
    "for i in labels:\n",
    "    sizes.append(list.count(i))\n",
    "labels, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explode = (0., 0.2, 0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_05_18 = []\n",
    "for zipcode in df_time_series.columns:\n",
    "    predictions_05_18.append(best_model_dict[zipcode][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_05_18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding our best predictions to the Nevada DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ferityikar/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df_time_series.loc['2018-05-01_pred'] = predictions_05_18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>95804</th>\n",
       "      <th>95817</th>\n",
       "      <th>95813</th>\n",
       "      <th>95785</th>\n",
       "      <th>95819</th>\n",
       "      <th>95770</th>\n",
       "      <th>95806</th>\n",
       "      <th>95790</th>\n",
       "      <th>95799</th>\n",
       "      <th>95844</th>\n",
       "      <th>...</th>\n",
       "      <th>95919</th>\n",
       "      <th>95794</th>\n",
       "      <th>399666</th>\n",
       "      <th>95760</th>\n",
       "      <th>95916</th>\n",
       "      <th>95891</th>\n",
       "      <th>95820</th>\n",
       "      <th>95917</th>\n",
       "      <th>95893</th>\n",
       "      <th>95851</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>106800.000000</td>\n",
       "      <td>165100.00000</td>\n",
       "      <td>185700.000</td>\n",
       "      <td>144000.00000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>148000.00</td>\n",
       "      <td>118900.0</td>\n",
       "      <td>157300.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>116800.0000</td>\n",
       "      <td>170900.00000</td>\n",
       "      <td>196000.00000</td>\n",
       "      <td>153200.00000</td>\n",
       "      <td>184200.00000</td>\n",
       "      <td>299200.0</td>\n",
       "      <td>166100.0000</td>\n",
       "      <td>293200.000000</td>\n",
       "      <td>562400.000</td>\n",
       "      <td>176400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107000.000000</td>\n",
       "      <td>164500.00000</td>\n",
       "      <td>186300.000</td>\n",
       "      <td>143500.00000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147800.00</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>156000.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117000.0000</td>\n",
       "      <td>170800.00000</td>\n",
       "      <td>196000.00000</td>\n",
       "      <td>153700.00000</td>\n",
       "      <td>185000.00000</td>\n",
       "      <td>299600.0</td>\n",
       "      <td>166600.0000</td>\n",
       "      <td>293200.000000</td>\n",
       "      <td>562800.000</td>\n",
       "      <td>176300.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107200.000000</td>\n",
       "      <td>164000.00000</td>\n",
       "      <td>186900.000</td>\n",
       "      <td>143100.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147600.00</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>154700.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117200.0000</td>\n",
       "      <td>170700.00000</td>\n",
       "      <td>195900.00000</td>\n",
       "      <td>154100.00000</td>\n",
       "      <td>185800.00000</td>\n",
       "      <td>299900.0</td>\n",
       "      <td>167300.0000</td>\n",
       "      <td>293200.000000</td>\n",
       "      <td>562700.000</td>\n",
       "      <td>176100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01 00:00:00</th>\n",
       "      <td>102600.000000</td>\n",
       "      <td>107400.000000</td>\n",
       "      <td>163500.00000</td>\n",
       "      <td>187400.000</td>\n",
       "      <td>142700.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95900.000000</td>\n",
       "      <td>147300.00</td>\n",
       "      <td>119100.0</td>\n",
       "      <td>153500.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117400.0000</td>\n",
       "      <td>170700.00000</td>\n",
       "      <td>195700.00000</td>\n",
       "      <td>154400.00000</td>\n",
       "      <td>186400.00000</td>\n",
       "      <td>300200.0</td>\n",
       "      <td>167900.0000</td>\n",
       "      <td>293200.000000</td>\n",
       "      <td>562400.000</td>\n",
       "      <td>176000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01 00:00:00</th>\n",
       "      <td>102700.000000</td>\n",
       "      <td>107600.000000</td>\n",
       "      <td>163200.00000</td>\n",
       "      <td>187700.000</td>\n",
       "      <td>142400.00000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>96100.000000</td>\n",
       "      <td>147100.00</td>\n",
       "      <td>119200.0</td>\n",
       "      <td>152600.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>117600.0000</td>\n",
       "      <td>170700.00000</td>\n",
       "      <td>195400.00000</td>\n",
       "      <td>154700.00000</td>\n",
       "      <td>186900.00000</td>\n",
       "      <td>300500.0</td>\n",
       "      <td>168600.0000</td>\n",
       "      <td>293200.000000</td>\n",
       "      <td>562300.000</td>\n",
       "      <td>175900.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>200700.000000</td>\n",
       "      <td>201500.000000</td>\n",
       "      <td>330700.00000</td>\n",
       "      <td>407300.000</td>\n",
       "      <td>294300.00000</td>\n",
       "      <td>234600.000000</td>\n",
       "      <td>189200.000000</td>\n",
       "      <td>303500.00</td>\n",
       "      <td>243700.0</td>\n",
       "      <td>294100.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>270000.0000</td>\n",
       "      <td>316500.00000</td>\n",
       "      <td>315500.00000</td>\n",
       "      <td>299900.00000</td>\n",
       "      <td>449500.00000</td>\n",
       "      <td>642500.0</td>\n",
       "      <td>317600.0000</td>\n",
       "      <td>201600.000000</td>\n",
       "      <td>2121300.000</td>\n",
       "      <td>350400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>203500.000000</td>\n",
       "      <td>204000.000000</td>\n",
       "      <td>334600.00000</td>\n",
       "      <td>410400.000</td>\n",
       "      <td>297400.00000</td>\n",
       "      <td>237200.000000</td>\n",
       "      <td>191700.000000</td>\n",
       "      <td>306700.00</td>\n",
       "      <td>246300.0</td>\n",
       "      <td>296900.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>275600.0000</td>\n",
       "      <td>319500.00000</td>\n",
       "      <td>319500.00000</td>\n",
       "      <td>302500.00000</td>\n",
       "      <td>450100.00000</td>\n",
       "      <td>653800.0</td>\n",
       "      <td>323400.0000</td>\n",
       "      <td>207000.000000</td>\n",
       "      <td>2153600.000</td>\n",
       "      <td>353000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>206600.000000</td>\n",
       "      <td>206700.000000</td>\n",
       "      <td>338800.00000</td>\n",
       "      <td>413700.000</td>\n",
       "      <td>300200.00000</td>\n",
       "      <td>239800.000000</td>\n",
       "      <td>194500.000000</td>\n",
       "      <td>309800.00</td>\n",
       "      <td>249500.0</td>\n",
       "      <td>299400.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>282100.0000</td>\n",
       "      <td>322400.00000</td>\n",
       "      <td>323600.00000</td>\n",
       "      <td>305700.00000</td>\n",
       "      <td>451100.00000</td>\n",
       "      <td>666000.0</td>\n",
       "      <td>334700.0000</td>\n",
       "      <td>216500.000000</td>\n",
       "      <td>2167100.000</td>\n",
       "      <td>356000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>209300.000000</td>\n",
       "      <td>208600.000000</td>\n",
       "      <td>342000.00000</td>\n",
       "      <td>416100.000</td>\n",
       "      <td>302400.00000</td>\n",
       "      <td>241900.000000</td>\n",
       "      <td>196600.000000</td>\n",
       "      <td>312200.00</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>300800.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>286000.0000</td>\n",
       "      <td>324700.00000</td>\n",
       "      <td>326600.00000</td>\n",
       "      <td>307800.00000</td>\n",
       "      <td>455300.00000</td>\n",
       "      <td>672600.0</td>\n",
       "      <td>344300.0000</td>\n",
       "      <td>222800.000000</td>\n",
       "      <td>2161900.000</td>\n",
       "      <td>357200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01_pred</th>\n",
       "      <td>75282.640625</td>\n",
       "      <td>82791.890625</td>\n",
       "      <td>343835.59375</td>\n",
       "      <td>421466.875</td>\n",
       "      <td>303811.84375</td>\n",
       "      <td>111346.015625</td>\n",
       "      <td>75971.632812</td>\n",
       "      <td>312865.75</td>\n",
       "      <td>114340.0</td>\n",
       "      <td>305326.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>279638.8125</td>\n",
       "      <td>329596.03125</td>\n",
       "      <td>327640.78125</td>\n",
       "      <td>306605.96875</td>\n",
       "      <td>453697.84375</td>\n",
       "      <td>653999.0</td>\n",
       "      <td>333740.6875</td>\n",
       "      <td>109275.640625</td>\n",
       "      <td>2082682.875</td>\n",
       "      <td>361679.90625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            95804          95817         95813       95785   \\\n",
       "1996-04-01 00:00:00  102500.000000  106800.000000  165100.00000  185700.000   \n",
       "1996-05-01 00:00:00  102500.000000  107000.000000  164500.00000  186300.000   \n",
       "1996-06-01 00:00:00  102500.000000  107200.000000  164000.00000  186900.000   \n",
       "1996-07-01 00:00:00  102600.000000  107400.000000  163500.00000  187400.000   \n",
       "1996-08-01 00:00:00  102700.000000  107600.000000  163200.00000  187700.000   \n",
       "...                            ...            ...           ...         ...   \n",
       "2018-01-01 00:00:00  200700.000000  201500.000000  330700.00000  407300.000   \n",
       "2018-02-01 00:00:00  203500.000000  204000.000000  334600.00000  410400.000   \n",
       "2018-03-01 00:00:00  206600.000000  206700.000000  338800.00000  413700.000   \n",
       "2018-04-01 00:00:00  209300.000000  208600.000000  342000.00000  416100.000   \n",
       "2018-05-01_pred       75282.640625   82791.890625  343835.59375  421466.875   \n",
       "\n",
       "                           95819          95770          95806      95790   \\\n",
       "1996-04-01 00:00:00  144000.00000  122800.000000   95800.000000  148000.00   \n",
       "1996-05-01 00:00:00  143500.00000  122800.000000   95800.000000  147800.00   \n",
       "1996-06-01 00:00:00  143100.00000  122700.000000   95800.000000  147600.00   \n",
       "1996-07-01 00:00:00  142700.00000  122700.000000   95900.000000  147300.00   \n",
       "1996-08-01 00:00:00  142400.00000  122700.000000   96100.000000  147100.00   \n",
       "...                           ...            ...            ...        ...   \n",
       "2018-01-01 00:00:00  294300.00000  234600.000000  189200.000000  303500.00   \n",
       "2018-02-01 00:00:00  297400.00000  237200.000000  191700.000000  306700.00   \n",
       "2018-03-01 00:00:00  300200.00000  239800.000000  194500.000000  309800.00   \n",
       "2018-04-01 00:00:00  302400.00000  241900.000000  196600.000000  312200.00   \n",
       "2018-05-01_pred      303811.84375  111346.015625   75971.632812  312865.75   \n",
       "\n",
       "                       95799        95844   ...       95919         95794   \\\n",
       "1996-04-01 00:00:00  118900.0  157300.0000  ...  116800.0000  170900.00000   \n",
       "1996-05-01 00:00:00  119000.0  156000.0000  ...  117000.0000  170800.00000   \n",
       "1996-06-01 00:00:00  119000.0  154700.0000  ...  117200.0000  170700.00000   \n",
       "1996-07-01 00:00:00  119100.0  153500.0000  ...  117400.0000  170700.00000   \n",
       "1996-08-01 00:00:00  119200.0  152600.0000  ...  117600.0000  170700.00000   \n",
       "...                       ...          ...  ...          ...           ...   \n",
       "2018-01-01 00:00:00  243700.0  294100.0000  ...  270000.0000  316500.00000   \n",
       "2018-02-01 00:00:00  246300.0  296900.0000  ...  275600.0000  319500.00000   \n",
       "2018-03-01 00:00:00  249500.0  299400.0000  ...  282100.0000  322400.00000   \n",
       "2018-04-01 00:00:00  252000.0  300800.0000  ...  286000.0000  324700.00000   \n",
       "2018-05-01_pred      114340.0  305326.5625  ...  279638.8125  329596.03125   \n",
       "\n",
       "                           399666        95760         95916     95891   \\\n",
       "1996-04-01 00:00:00  196000.00000  153200.00000  184200.00000  299200.0   \n",
       "1996-05-01 00:00:00  196000.00000  153700.00000  185000.00000  299600.0   \n",
       "1996-06-01 00:00:00  195900.00000  154100.00000  185800.00000  299900.0   \n",
       "1996-07-01 00:00:00  195700.00000  154400.00000  186400.00000  300200.0   \n",
       "1996-08-01 00:00:00  195400.00000  154700.00000  186900.00000  300500.0   \n",
       "...                           ...           ...           ...       ...   \n",
       "2018-01-01 00:00:00  315500.00000  299900.00000  449500.00000  642500.0   \n",
       "2018-02-01 00:00:00  319500.00000  302500.00000  450100.00000  653800.0   \n",
       "2018-03-01 00:00:00  323600.00000  305700.00000  451100.00000  666000.0   \n",
       "2018-04-01 00:00:00  326600.00000  307800.00000  455300.00000  672600.0   \n",
       "2018-05-01_pred      327640.78125  306605.96875  453697.84375  653999.0   \n",
       "\n",
       "                          95820          95917        95893         95851   \n",
       "1996-04-01 00:00:00  166100.0000  293200.000000   562400.000  176400.00000  \n",
       "1996-05-01 00:00:00  166600.0000  293200.000000   562800.000  176300.00000  \n",
       "1996-06-01 00:00:00  167300.0000  293200.000000   562700.000  176100.00000  \n",
       "1996-07-01 00:00:00  167900.0000  293200.000000   562400.000  176000.00000  \n",
       "1996-08-01 00:00:00  168600.0000  293200.000000   562300.000  175900.00000  \n",
       "...                          ...            ...          ...           ...  \n",
       "2018-01-01 00:00:00  317600.0000  201600.000000  2121300.000  350400.00000  \n",
       "2018-02-01 00:00:00  323400.0000  207000.000000  2153600.000  353000.00000  \n",
       "2018-03-01 00:00:00  334700.0000  216500.000000  2167100.000  356000.00000  \n",
       "2018-04-01 00:00:00  344300.0000  222800.000000  2161900.000  357200.00000  \n",
       "2018-05-01_pred      333740.6875  109275.640625  2082682.875  361679.90625  \n",
       "\n",
       "[266 rows x 103 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_return = {}\n",
    "for i in df_time_series.columns:\n",
    "    investment_return[i] = (df_time_series[i][-1]-df_time_series[i][-2])/df_time_series[i][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95804: -0.6403122760391782,\n",
       " 95803: -0.6295452663098878,\n",
       " 95798: -0.6177195348173516,\n",
       " 95806: -0.613572569621058,\n",
       " 95817: -0.6031069481064237,\n",
       " 95815: -0.6021977891515408,\n",
       " 95800: -0.5948574640287769,\n",
       " 95852: -0.5884373090786901,\n",
       " 95771: -0.5782642070244328,\n",
       " 95811: -0.575701083096591,\n",
       " 95935: -0.5719107350572655,\n",
       " 95931: -0.5607943078769559,\n",
       " 95816: -0.5581633064516129,\n",
       " 95909: -0.550528379085293,\n",
       " 95799: -0.5462698412698412,\n",
       " 95818: -0.5440211504683841,\n",
       " 95770: -0.5397022917527904,\n",
       " 95911: -0.5375475456254586,\n",
       " 95754: -0.5333307904045437,\n",
       " 95914: -0.5286932394509062,\n",
       " 95932: -0.5247488011766602,\n",
       " 399671: -0.5232312362030905,\n",
       " 95826: -0.5208139675414365,\n",
       " 95912: -0.5185951487897879,\n",
       " 95788: -0.517139953337104,\n",
       " 95792: -0.51701,\n",
       " 95838: -0.5127071126302083,\n",
       " 95805: -0.510909343872623,\n",
       " 95917: -0.5095348266382406,\n",
       " 95753: -0.50763468141516,\n",
       " 95814: -0.5049538404726736,\n",
       " 95841: -0.5032503730959242,\n",
       " 95940: -0.5021531142334195,\n",
       " 95843: -0.5010366631120178,\n",
       " 95795: -0.49936690532652317,\n",
       " 95825: -0.49807961572438164,\n",
       " 399673: -0.49649870747164776,\n",
       " 95824: -0.48665250447227193,\n",
       " 95835: -0.4793560788873289,\n",
       " 95842: -0.471770374015748,\n",
       " 95787: -0.4609744984313078,\n",
       " 95845: -0.4508800453047776,\n",
       " 95769: -0.44429465465961665,\n",
       " 95783: -0.42193896994773517,\n",
       " 95923: -0.41105485623650106,\n",
       " 95907: -0.4104239454801502,\n",
       " 95888: -0.40266764993816984,\n",
       " 95883: -0.368137738997114,\n",
       " 95924: -0.32663445989650713,\n",
       " 95922: -0.29554872959940653,\n",
       " 95768: -0.26299306705298015,\n",
       " 95963: -0.14172757985257986,\n",
       " 95966: -0.10854563839653751,\n",
       " 95893: -0.03664236319903788,\n",
       " 95820: -0.030668929712460064,\n",
       " 95891: -0.027655367231638417,\n",
       " 95926: -0.02755555701662108,\n",
       " 95890: -0.024777401804670914,\n",
       " 95919: -0.022241914335664335,\n",
       " 95901: -0.01899039052890529,\n",
       " 95939: -0.018232486470234517,\n",
       " 95954: -0.016678927604038413,\n",
       " 95937: -0.01620198153880168,\n",
       " 95952: -0.016057372505543236,\n",
       " 399674: -0.013868014974433893,\n",
       " 95956: -0.013570170632435817,\n",
       " 95928: -0.010960852713178294,\n",
       " 95944: -0.010857668067226892,\n",
       " 95840: -0.009602167568337129,\n",
       " 95957: -0.0077280844155844155,\n",
       " 95945: -0.0052024848254931715,\n",
       " 95760: -0.003879243827160494,\n",
       " 95955: -0.0037051052198448153,\n",
       " 95916: -0.0035189023720623765,\n",
       " 95830: 0.0002814465408805031,\n",
       " 95831: 0.0007228047766159696,\n",
       " 95930: 0.0007674237940218999,\n",
       " 95790: 0.0021324471492632927,\n",
       " 399666: 0.0031867154011022657,\n",
       " 95834: 0.0033907070303583657,\n",
       " 95775: 0.003864246500965251,\n",
       " 95819: 0.004668795469576719,\n",
       " 95793: 0.004982521186440678,\n",
       " 95813: 0.005367233187134503,\n",
       " 399665: 0.006339834662678631,\n",
       " 399672: 0.007586334997622444,\n",
       " 95779: 0.007659311985231469,\n",
       " 95827: 0.007676996112440191,\n",
       " 95865: 0.00960934819897084,\n",
       " 95809: 0.011957274590163934,\n",
       " 95851: 0.012541730823068309,\n",
       " 95785: 0.012898041336217256,\n",
       " 95837: 0.014408379556259905,\n",
       " 95866: 0.014536210317460318,\n",
       " 95766: 0.014765261012282932,\n",
       " 95844: 0.015048412566489361,\n",
       " 95794: 0.015078630274099168,\n",
       " 95751: 0.015464465431738622,\n",
       " 95744: 0.022760683932007697,\n",
       " 95750: 0.022894300075872533,\n",
       " 95839: 0.023676292949176808,\n",
       " 95861: 0.02389814733707078,\n",
       " 95938: 0.025691410950661853}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_return = dict(sorted(investment_return.items(), key=lambda item: item[1]))\n",
    "investment_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in investment_return.keys():\n",
    "    list.append(i)\n",
    "best_5_investments = list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95744, 95750, 95839, 95861, 95938]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_5_investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>95744</th>\n",
       "      <th>95750</th>\n",
       "      <th>95839</th>\n",
       "      <th>95861</th>\n",
       "      <th>95938</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-01 00:00:00</th>\n",
       "      <td>281800.00000</td>\n",
       "      <td>236300.0000</td>\n",
       "      <td>244600.00000</td>\n",
       "      <td>255300.00000</td>\n",
       "      <td>400200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01 00:00:00</th>\n",
       "      <td>284300.00000</td>\n",
       "      <td>239400.0000</td>\n",
       "      <td>247300.00000</td>\n",
       "      <td>258600.00000</td>\n",
       "      <td>408000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01 00:00:00</th>\n",
       "      <td>287000.00000</td>\n",
       "      <td>242400.0000</td>\n",
       "      <td>250700.00000</td>\n",
       "      <td>262000.00000</td>\n",
       "      <td>412500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01 00:00:00</th>\n",
       "      <td>290100.00000</td>\n",
       "      <td>245400.0000</td>\n",
       "      <td>255000.00000</td>\n",
       "      <td>265800.00000</td>\n",
       "      <td>415700.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 00:00:00</th>\n",
       "      <td>294100.00000</td>\n",
       "      <td>248600.0000</td>\n",
       "      <td>259500.00000</td>\n",
       "      <td>270100.00000</td>\n",
       "      <td>415100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 00:00:00</th>\n",
       "      <td>297300.00000</td>\n",
       "      <td>251300.0000</td>\n",
       "      <td>262500.00000</td>\n",
       "      <td>273500.00000</td>\n",
       "      <td>416500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:00:00</th>\n",
       "      <td>300900.00000</td>\n",
       "      <td>254200.0000</td>\n",
       "      <td>265500.00000</td>\n",
       "      <td>276500.00000</td>\n",
       "      <td>419500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>304400.00000</td>\n",
       "      <td>257100.0000</td>\n",
       "      <td>268500.00000</td>\n",
       "      <td>279200.00000</td>\n",
       "      <td>421800.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>307500.00000</td>\n",
       "      <td>259500.0000</td>\n",
       "      <td>271700.00000</td>\n",
       "      <td>281700.00000</td>\n",
       "      <td>420600.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>310200.00000</td>\n",
       "      <td>261800.0000</td>\n",
       "      <td>275800.00000</td>\n",
       "      <td>283900.00000</td>\n",
       "      <td>418300.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>311800.00000</td>\n",
       "      <td>263600.0000</td>\n",
       "      <td>279400.00000</td>\n",
       "      <td>285400.00000</td>\n",
       "      <td>415500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01_pred</th>\n",
       "      <td>318896.78125</td>\n",
       "      <td>269634.9375</td>\n",
       "      <td>286015.15625</td>\n",
       "      <td>292220.53125</td>\n",
       "      <td>426174.78125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            95744        95750         95839         95861  \\\n",
       "2017-06-01 00:00:00  281800.00000  236300.0000  244600.00000  255300.00000   \n",
       "2017-07-01 00:00:00  284300.00000  239400.0000  247300.00000  258600.00000   \n",
       "2017-08-01 00:00:00  287000.00000  242400.0000  250700.00000  262000.00000   \n",
       "2017-09-01 00:00:00  290100.00000  245400.0000  255000.00000  265800.00000   \n",
       "2017-10-01 00:00:00  294100.00000  248600.0000  259500.00000  270100.00000   \n",
       "2017-11-01 00:00:00  297300.00000  251300.0000  262500.00000  273500.00000   \n",
       "2017-12-01 00:00:00  300900.00000  254200.0000  265500.00000  276500.00000   \n",
       "2018-01-01 00:00:00  304400.00000  257100.0000  268500.00000  279200.00000   \n",
       "2018-02-01 00:00:00  307500.00000  259500.0000  271700.00000  281700.00000   \n",
       "2018-03-01 00:00:00  310200.00000  261800.0000  275800.00000  283900.00000   \n",
       "2018-04-01 00:00:00  311800.00000  263600.0000  279400.00000  285400.00000   \n",
       "2018-05-01_pred      318896.78125  269634.9375  286015.15625  292220.53125   \n",
       "\n",
       "                            95938  \n",
       "2017-06-01 00:00:00  400200.00000  \n",
       "2017-07-01 00:00:00  408000.00000  \n",
       "2017-08-01 00:00:00  412500.00000  \n",
       "2017-09-01 00:00:00  415700.00000  \n",
       "2017-10-01 00:00:00  415100.00000  \n",
       "2017-11-01 00:00:00  416500.00000  \n",
       "2017-12-01 00:00:00  419500.00000  \n",
       "2018-01-01 00:00:00  421800.00000  \n",
       "2018-02-01 00:00:00  420600.00000  \n",
       "2018-03-01 00:00:00  418300.00000  \n",
       "2018-04-01 00:00:00  415500.00000  \n",
       "2018-05-01_pred      426174.78125  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_chart_data = df_time_series[best_5_investments][-12:]\n",
    "investment_chart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "months = [\"June '17\", \"July '17\",\"Aug '17\",\"Sep '17\",\"Oct '17\",\"Nov '17\",\"Dec '18\",\"Jan '18\",\"Feb '18\",\"Mar '18\",\"Apr '18\", \"May '18\"]\n",
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "fig = plt.figure()\n",
    "\n",
    "ax.plot(months, investment_chart_data[95744])\n",
    "ax.plot(months, investment_chart_data[95750])\n",
    "ax.plot(months, investment_chart_data[95839])\n",
    "ax.plot(months, investment_chart_data[95861])\n",
    "ax.plot(months, investment_chart_data[95938])\n",
    "\n",
    "\n",
    "\n",
    "ax.set_title('Top 5 Profitable Zipcodes')\n",
    "ax.legend(['95744','95750','95839','95861','95938'], loc=('upper left'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('rnn_mape.pickle','wb')\n",
    "pickle.dump(rnn_mape, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('rnn_dict.pickle','wb')\n",
    "pickle.dump(rnn_dict, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('rnn_pred.pickle','wb')\n",
    "pickle.dump(rnn_pred, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('rnn_mape2.pickle','wb')\n",
    "pickle.dump(rnn_mape2, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out = open('rnn_dict2.pickle','wb')\n",
    "pickle.dump(rnn_dict2, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out = open('rnn_pred2.pickle','wb')\n",
    "pickle.dump(rnn_pred2, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('rnn_mape3.pickle','wb')\n",
    "pickle.dump(rnn_mape3, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out = open('rnn_dict3.pickle','wb')\n",
    "pickle.dump(rnn_dict3, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out = open('rnn_pred3.pickle','wb')\n",
    "pickle.dump(rnn_pred3, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open('rnn_mape4.pickle','wb')\n",
    "pickle.dump(rnn_mape4, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out = open('rnn_dict4.pickle','wb')\n",
    "pickle.dump(rnn_dict4, pickle_out)\n",
    "pickle_out.close()\n",
    "pickle_out = open('rnn_pred4.pickle','wb')\n",
    "pickle.dump(rnn_pred4, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e81d9768a2937af9514d7fa33aa30feb69a40df5b58c34cfa60b871c6c10885"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
