{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Metro</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>1996-04</th>\n",
       "      <th>1996-05</th>\n",
       "      <th>1996-06</th>\n",
       "      <th>...</th>\n",
       "      <th>2017-07</th>\n",
       "      <th>2017-08</th>\n",
       "      <th>2017-09</th>\n",
       "      <th>2017-10</th>\n",
       "      <th>2017-11</th>\n",
       "      <th>2017-12</th>\n",
       "      <th>2018-01</th>\n",
       "      <th>2018-02</th>\n",
       "      <th>2018-03</th>\n",
       "      <th>2018-04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>334200.0</td>\n",
       "      <td>335400.0</td>\n",
       "      <td>336500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1005500</td>\n",
       "      <td>1007500</td>\n",
       "      <td>1007800</td>\n",
       "      <td>1009600</td>\n",
       "      <td>1013300</td>\n",
       "      <td>1018700</td>\n",
       "      <td>1024400</td>\n",
       "      <td>1030700</td>\n",
       "      <td>1033800</td>\n",
       "      <td>1030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90668</td>\n",
       "      <td>75070</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>Collin</td>\n",
       "      <td>2</td>\n",
       "      <td>235700.0</td>\n",
       "      <td>236900.0</td>\n",
       "      <td>236700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>308000</td>\n",
       "      <td>310000</td>\n",
       "      <td>312500</td>\n",
       "      <td>314100</td>\n",
       "      <td>315000</td>\n",
       "      <td>316600</td>\n",
       "      <td>318100</td>\n",
       "      <td>319600</td>\n",
       "      <td>321100</td>\n",
       "      <td>321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Katy</td>\n",
       "      <td>TX</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Harris</td>\n",
       "      <td>3</td>\n",
       "      <td>210400.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>212200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>321000</td>\n",
       "      <td>320600</td>\n",
       "      <td>320200</td>\n",
       "      <td>320400</td>\n",
       "      <td>320800</td>\n",
       "      <td>321200</td>\n",
       "      <td>321200</td>\n",
       "      <td>323000</td>\n",
       "      <td>326900</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Cook</td>\n",
       "      <td>4</td>\n",
       "      <td>498100.0</td>\n",
       "      <td>500900.0</td>\n",
       "      <td>503100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1289800</td>\n",
       "      <td>1287700</td>\n",
       "      <td>1287400</td>\n",
       "      <td>1291500</td>\n",
       "      <td>1296600</td>\n",
       "      <td>1299000</td>\n",
       "      <td>1302700</td>\n",
       "      <td>1306400</td>\n",
       "      <td>1308500</td>\n",
       "      <td>1307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93144</td>\n",
       "      <td>79936</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>5</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>77300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119100</td>\n",
       "      <td>119400</td>\n",
       "      <td>120000</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120300</td>\n",
       "      <td>120500</td>\n",
       "      <td>121000</td>\n",
       "      <td>121500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14718</th>\n",
       "      <td>58333</td>\n",
       "      <td>1338</td>\n",
       "      <td>Ashfield</td>\n",
       "      <td>MA</td>\n",
       "      <td>Greenfield Town</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>14719</td>\n",
       "      <td>94600.0</td>\n",
       "      <td>94300.0</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>216800</td>\n",
       "      <td>217700</td>\n",
       "      <td>218600</td>\n",
       "      <td>218500</td>\n",
       "      <td>218100</td>\n",
       "      <td>216400</td>\n",
       "      <td>213100</td>\n",
       "      <td>209800</td>\n",
       "      <td>209200</td>\n",
       "      <td>209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14719</th>\n",
       "      <td>59107</td>\n",
       "      <td>3293</td>\n",
       "      <td>Woodstock</td>\n",
       "      <td>NH</td>\n",
       "      <td>Claremont</td>\n",
       "      <td>Grafton</td>\n",
       "      <td>14720</td>\n",
       "      <td>92700.0</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>92400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>202100</td>\n",
       "      <td>208400</td>\n",
       "      <td>212200</td>\n",
       "      <td>215200</td>\n",
       "      <td>214300</td>\n",
       "      <td>213100</td>\n",
       "      <td>213700</td>\n",
       "      <td>218300</td>\n",
       "      <td>222700</td>\n",
       "      <td>225800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14720</th>\n",
       "      <td>75672</td>\n",
       "      <td>40404</td>\n",
       "      <td>Berea</td>\n",
       "      <td>KY</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Madison</td>\n",
       "      <td>14721</td>\n",
       "      <td>57100.0</td>\n",
       "      <td>57300.0</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121800</td>\n",
       "      <td>122800</td>\n",
       "      <td>124600</td>\n",
       "      <td>126700</td>\n",
       "      <td>128800</td>\n",
       "      <td>130600</td>\n",
       "      <td>131700</td>\n",
       "      <td>132500</td>\n",
       "      <td>133000</td>\n",
       "      <td>133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14721</th>\n",
       "      <td>93733</td>\n",
       "      <td>81225</td>\n",
       "      <td>Mount Crested Butte</td>\n",
       "      <td>CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gunnison</td>\n",
       "      <td>14722</td>\n",
       "      <td>191100.0</td>\n",
       "      <td>192400.0</td>\n",
       "      <td>193700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>662800</td>\n",
       "      <td>671200</td>\n",
       "      <td>682400</td>\n",
       "      <td>695600</td>\n",
       "      <td>695500</td>\n",
       "      <td>694700</td>\n",
       "      <td>706400</td>\n",
       "      <td>705300</td>\n",
       "      <td>681500</td>\n",
       "      <td>664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14722</th>\n",
       "      <td>95851</td>\n",
       "      <td>89155</td>\n",
       "      <td>Mesquite</td>\n",
       "      <td>NV</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Clark</td>\n",
       "      <td>14723</td>\n",
       "      <td>176400.0</td>\n",
       "      <td>176300.0</td>\n",
       "      <td>176100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>333800</td>\n",
       "      <td>336400</td>\n",
       "      <td>339700</td>\n",
       "      <td>343800</td>\n",
       "      <td>346800</td>\n",
       "      <td>348900</td>\n",
       "      <td>350400</td>\n",
       "      <td>353000</td>\n",
       "      <td>356000</td>\n",
       "      <td>357200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14723 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RegionID  RegionName                 City State              Metro  \\\n",
       "0         84654       60657              Chicago    IL            Chicago   \n",
       "1         90668       75070             McKinney    TX  Dallas-Fort Worth   \n",
       "2         91982       77494                 Katy    TX            Houston   \n",
       "3         84616       60614              Chicago    IL            Chicago   \n",
       "4         93144       79936              El Paso    TX            El Paso   \n",
       "...         ...         ...                  ...   ...                ...   \n",
       "14718     58333        1338             Ashfield    MA    Greenfield Town   \n",
       "14719     59107        3293            Woodstock    NH          Claremont   \n",
       "14720     75672       40404                Berea    KY           Richmond   \n",
       "14721     93733       81225  Mount Crested Butte    CO                NaN   \n",
       "14722     95851       89155             Mesquite    NV          Las Vegas   \n",
       "\n",
       "      CountyName  SizeRank   1996-04   1996-05   1996-06  ...  2017-07  \\\n",
       "0           Cook         1  334200.0  335400.0  336500.0  ...  1005500   \n",
       "1         Collin         2  235700.0  236900.0  236700.0  ...   308000   \n",
       "2         Harris         3  210400.0  212200.0  212200.0  ...   321000   \n",
       "3           Cook         4  498100.0  500900.0  503100.0  ...  1289800   \n",
       "4        El Paso         5   77300.0   77300.0   77300.0  ...   119100   \n",
       "...          ...       ...       ...       ...       ...  ...      ...   \n",
       "14718   Franklin     14719   94600.0   94300.0   94000.0  ...   216800   \n",
       "14719    Grafton     14720   92700.0   92500.0   92400.0  ...   202100   \n",
       "14720    Madison     14721   57100.0   57300.0   57500.0  ...   121800   \n",
       "14721   Gunnison     14722  191100.0  192400.0  193700.0  ...   662800   \n",
       "14722      Clark     14723  176400.0  176300.0  176100.0  ...   333800   \n",
       "\n",
       "       2017-08  2017-09  2017-10  2017-11  2017-12  2018-01  2018-02  2018-03  \\\n",
       "0      1007500  1007800  1009600  1013300  1018700  1024400  1030700  1033800   \n",
       "1       310000   312500   314100   315000   316600   318100   319600   321100   \n",
       "2       320600   320200   320400   320800   321200   321200   323000   326900   \n",
       "3      1287700  1287400  1291500  1296600  1299000  1302700  1306400  1308500   \n",
       "4       119400   120000   120300   120300   120300   120300   120500   121000   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "14718   217700   218600   218500   218100   216400   213100   209800   209200   \n",
       "14719   208400   212200   215200   214300   213100   213700   218300   222700   \n",
       "14720   122800   124600   126700   128800   130600   131700   132500   133000   \n",
       "14721   671200   682400   695600   695500   694700   706400   705300   681500   \n",
       "14722   336400   339700   343800   346800   348900   350400   353000   356000   \n",
       "\n",
       "       2018-04  \n",
       "0      1030600  \n",
       "1       321800  \n",
       "2       329900  \n",
       "3      1307000  \n",
       "4       121500  \n",
       "...        ...  \n",
       "14718   209300  \n",
       "14719   225800  \n",
       "14720   133400  \n",
       "14721   664400  \n",
       "14722   357200  \n",
       "\n",
       "[14723 rows x 272 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/zillow_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>84654</th>\n",
       "      <th>90668</th>\n",
       "      <th>91982</th>\n",
       "      <th>84616</th>\n",
       "      <th>93144</th>\n",
       "      <th>91733</th>\n",
       "      <th>61807</th>\n",
       "      <th>84640</th>\n",
       "      <th>91940</th>\n",
       "      <th>97564</th>\n",
       "      <th>...</th>\n",
       "      <th>59187</th>\n",
       "      <th>94711</th>\n",
       "      <th>62556</th>\n",
       "      <th>99032</th>\n",
       "      <th>62697</th>\n",
       "      <th>58333</th>\n",
       "      <th>59107</th>\n",
       "      <th>75672</th>\n",
       "      <th>93733</th>\n",
       "      <th>95851</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01</th>\n",
       "      <td>334200</td>\n",
       "      <td>235700</td>\n",
       "      <td>210400</td>\n",
       "      <td>498100</td>\n",
       "      <td>77300</td>\n",
       "      <td>95000</td>\n",
       "      <td>152900</td>\n",
       "      <td>216500</td>\n",
       "      <td>95400</td>\n",
       "      <td>766000</td>\n",
       "      <td>...</td>\n",
       "      <td>80800</td>\n",
       "      <td>135900</td>\n",
       "      <td>78300</td>\n",
       "      <td>136200</td>\n",
       "      <td>62500</td>\n",
       "      <td>94600</td>\n",
       "      <td>92700</td>\n",
       "      <td>57100</td>\n",
       "      <td>191100</td>\n",
       "      <td>176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01</th>\n",
       "      <td>335400</td>\n",
       "      <td>236900</td>\n",
       "      <td>212200</td>\n",
       "      <td>500900</td>\n",
       "      <td>77300</td>\n",
       "      <td>95200</td>\n",
       "      <td>152700</td>\n",
       "      <td>216700</td>\n",
       "      <td>95600</td>\n",
       "      <td>771100</td>\n",
       "      <td>...</td>\n",
       "      <td>80100</td>\n",
       "      <td>136300</td>\n",
       "      <td>78300</td>\n",
       "      <td>136600</td>\n",
       "      <td>62600</td>\n",
       "      <td>94300</td>\n",
       "      <td>92500</td>\n",
       "      <td>57300</td>\n",
       "      <td>192400</td>\n",
       "      <td>176300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01</th>\n",
       "      <td>336500</td>\n",
       "      <td>236700</td>\n",
       "      <td>212200</td>\n",
       "      <td>503100</td>\n",
       "      <td>77300</td>\n",
       "      <td>95400</td>\n",
       "      <td>152600</td>\n",
       "      <td>216900</td>\n",
       "      <td>95800</td>\n",
       "      <td>776500</td>\n",
       "      <td>...</td>\n",
       "      <td>79400</td>\n",
       "      <td>136600</td>\n",
       "      <td>78200</td>\n",
       "      <td>136800</td>\n",
       "      <td>62700</td>\n",
       "      <td>94000</td>\n",
       "      <td>92400</td>\n",
       "      <td>57500</td>\n",
       "      <td>193700</td>\n",
       "      <td>176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01</th>\n",
       "      <td>337600</td>\n",
       "      <td>235400</td>\n",
       "      <td>210700</td>\n",
       "      <td>504600</td>\n",
       "      <td>77300</td>\n",
       "      <td>95700</td>\n",
       "      <td>152400</td>\n",
       "      <td>217000</td>\n",
       "      <td>96100</td>\n",
       "      <td>781900</td>\n",
       "      <td>...</td>\n",
       "      <td>78600</td>\n",
       "      <td>136900</td>\n",
       "      <td>78200</td>\n",
       "      <td>136800</td>\n",
       "      <td>62700</td>\n",
       "      <td>93700</td>\n",
       "      <td>92200</td>\n",
       "      <td>57700</td>\n",
       "      <td>195000</td>\n",
       "      <td>176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01</th>\n",
       "      <td>338500</td>\n",
       "      <td>233300</td>\n",
       "      <td>208300</td>\n",
       "      <td>505500</td>\n",
       "      <td>77400</td>\n",
       "      <td>95900</td>\n",
       "      <td>152300</td>\n",
       "      <td>217100</td>\n",
       "      <td>96400</td>\n",
       "      <td>787300</td>\n",
       "      <td>...</td>\n",
       "      <td>77900</td>\n",
       "      <td>137100</td>\n",
       "      <td>78100</td>\n",
       "      <td>136700</td>\n",
       "      <td>62700</td>\n",
       "      <td>93400</td>\n",
       "      <td>92100</td>\n",
       "      <td>58000</td>\n",
       "      <td>196300</td>\n",
       "      <td>175900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>1018700</td>\n",
       "      <td>316600</td>\n",
       "      <td>321200</td>\n",
       "      <td>1299000</td>\n",
       "      <td>120300</td>\n",
       "      <td>162800</td>\n",
       "      <td>414300</td>\n",
       "      <td>777900</td>\n",
       "      <td>172300</td>\n",
       "      <td>3778700</td>\n",
       "      <td>...</td>\n",
       "      <td>123400</td>\n",
       "      <td>257600</td>\n",
       "      <td>171300</td>\n",
       "      <td>341000</td>\n",
       "      <td>122800</td>\n",
       "      <td>216400</td>\n",
       "      <td>213100</td>\n",
       "      <td>130600</td>\n",
       "      <td>694700</td>\n",
       "      <td>348900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>1024400</td>\n",
       "      <td>318100</td>\n",
       "      <td>321200</td>\n",
       "      <td>1302700</td>\n",
       "      <td>120300</td>\n",
       "      <td>162800</td>\n",
       "      <td>413900</td>\n",
       "      <td>778500</td>\n",
       "      <td>173300</td>\n",
       "      <td>3770800</td>\n",
       "      <td>...</td>\n",
       "      <td>124400</td>\n",
       "      <td>258000</td>\n",
       "      <td>172400</td>\n",
       "      <td>342300</td>\n",
       "      <td>123200</td>\n",
       "      <td>213100</td>\n",
       "      <td>213700</td>\n",
       "      <td>131700</td>\n",
       "      <td>706400</td>\n",
       "      <td>350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>1030700</td>\n",
       "      <td>319600</td>\n",
       "      <td>323000</td>\n",
       "      <td>1306400</td>\n",
       "      <td>120500</td>\n",
       "      <td>162900</td>\n",
       "      <td>411400</td>\n",
       "      <td>780500</td>\n",
       "      <td>174200</td>\n",
       "      <td>3763100</td>\n",
       "      <td>...</td>\n",
       "      <td>125500</td>\n",
       "      <td>260600</td>\n",
       "      <td>173600</td>\n",
       "      <td>345000</td>\n",
       "      <td>123200</td>\n",
       "      <td>209800</td>\n",
       "      <td>218300</td>\n",
       "      <td>132500</td>\n",
       "      <td>705300</td>\n",
       "      <td>353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>1033800</td>\n",
       "      <td>321100</td>\n",
       "      <td>326900</td>\n",
       "      <td>1308500</td>\n",
       "      <td>121000</td>\n",
       "      <td>163500</td>\n",
       "      <td>413200</td>\n",
       "      <td>782800</td>\n",
       "      <td>175400</td>\n",
       "      <td>3779800</td>\n",
       "      <td>...</td>\n",
       "      <td>126600</td>\n",
       "      <td>264700</td>\n",
       "      <td>175800</td>\n",
       "      <td>348000</td>\n",
       "      <td>120700</td>\n",
       "      <td>209200</td>\n",
       "      <td>222700</td>\n",
       "      <td>133000</td>\n",
       "      <td>681500</td>\n",
       "      <td>356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>1030600</td>\n",
       "      <td>321800</td>\n",
       "      <td>329900</td>\n",
       "      <td>1307000</td>\n",
       "      <td>121500</td>\n",
       "      <td>164300</td>\n",
       "      <td>417900</td>\n",
       "      <td>782800</td>\n",
       "      <td>176200</td>\n",
       "      <td>3813500</td>\n",
       "      <td>...</td>\n",
       "      <td>127500</td>\n",
       "      <td>266800</td>\n",
       "      <td>177500</td>\n",
       "      <td>349300</td>\n",
       "      <td>117700</td>\n",
       "      <td>209300</td>\n",
       "      <td>225800</td>\n",
       "      <td>133400</td>\n",
       "      <td>664400</td>\n",
       "      <td>357200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 14723 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              84654   90668   91982    84616   93144   91733   61807   84640  \\\n",
       "1996-04-01   334200  235700  210400   498100   77300   95000  152900  216500   \n",
       "1996-05-01   335400  236900  212200   500900   77300   95200  152700  216700   \n",
       "1996-06-01   336500  236700  212200   503100   77300   95400  152600  216900   \n",
       "1996-07-01   337600  235400  210700   504600   77300   95700  152400  217000   \n",
       "1996-08-01   338500  233300  208300   505500   77400   95900  152300  217100   \n",
       "...             ...     ...     ...      ...     ...     ...     ...     ...   \n",
       "2017-12-01  1018700  316600  321200  1299000  120300  162800  414300  777900   \n",
       "2018-01-01  1024400  318100  321200  1302700  120300  162800  413900  778500   \n",
       "2018-02-01  1030700  319600  323000  1306400  120500  162900  411400  780500   \n",
       "2018-03-01  1033800  321100  326900  1308500  121000  163500  413200  782800   \n",
       "2018-04-01  1030600  321800  329900  1307000  121500  164300  417900  782800   \n",
       "\n",
       "             91940    97564  ...   59187   94711   62556   99032   62697  \\\n",
       "1996-04-01   95400   766000  ...   80800  135900   78300  136200   62500   \n",
       "1996-05-01   95600   771100  ...   80100  136300   78300  136600   62600   \n",
       "1996-06-01   95800   776500  ...   79400  136600   78200  136800   62700   \n",
       "1996-07-01   96100   781900  ...   78600  136900   78200  136800   62700   \n",
       "1996-08-01   96400   787300  ...   77900  137100   78100  136700   62700   \n",
       "...            ...      ...  ...     ...     ...     ...     ...     ...   \n",
       "2017-12-01  172300  3778700  ...  123400  257600  171300  341000  122800   \n",
       "2018-01-01  173300  3770800  ...  124400  258000  172400  342300  123200   \n",
       "2018-02-01  174200  3763100  ...  125500  260600  173600  345000  123200   \n",
       "2018-03-01  175400  3779800  ...  126600  264700  175800  348000  120700   \n",
       "2018-04-01  176200  3813500  ...  127500  266800  177500  349300  117700   \n",
       "\n",
       "             58333   59107   75672   93733   95851  \n",
       "1996-04-01   94600   92700   57100  191100  176400  \n",
       "1996-05-01   94300   92500   57300  192400  176300  \n",
       "1996-06-01   94000   92400   57500  193700  176100  \n",
       "1996-07-01   93700   92200   57700  195000  176000  \n",
       "1996-08-01   93400   92100   58000  196300  175900  \n",
       "...            ...     ...     ...     ...     ...  \n",
       "2017-12-01  216400  213100  130600  694700  348900  \n",
       "2018-01-01  213100  213700  131700  706400  350400  \n",
       "2018-02-01  209800  218300  132500  705300  353000  \n",
       "2018-03-01  209200  222700  133000  681500  356000  \n",
       "2018-04-01  209300  225800  133400  664400  357200  \n",
       "\n",
       "[265 rows x 14723 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series = pd.DataFrame(index=pd.to_datetime(df.columns[7:]), data=np.ones(len(df.columns)-7))\n",
    "for i in range(df.shape[0]):\n",
    "    df_time_series[df['RegionID'][i]] = df.iloc[i,7:]\n",
    "df_time_series.drop(df_time_series.columns[0],axis=1, inplace=True)\n",
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95804"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nv = df[df['State'] == 'NV']\n",
    "nv_zipcodes = list(df_nv.RegionID)\n",
    "nv_zipcodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_time_series.iloc[:,0].plot(figsize=(16,9))\n",
    "df_time_series.iloc[:,1].plot()\n",
    "df_time_series.iloc[:,2].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(df_time_series)*.8)\n",
    "train = df_time_series.iloc[:size]\n",
    "test = df_time_series.iloc[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = df_time_series[nv_zipcodes]\n",
    "train = train[nv_zipcodes]\n",
    "test = test[nv_zipcodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are trying a RNN model to see how it does on our first zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "train_data = train.iloc[:,x:x+1].values.astype(int)\n",
    "test_data = test.iloc[:,x:x+1].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataset with 60 timesteps (5 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60,len(train_data_scaled)):\n",
    "    X_train.append(train_data_scaled[i-60:i])\n",
    "    y_train.append(train_data_scaled[i])\n",
    "\n",
    "data_total = pd.concat((train.iloc[:,x:x+1], test.iloc[:,x:x+1]),axis=0)\n",
    "inputs = data_total[len(train)-60:].values\n",
    "inputs = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(60,len(inputs)):\n",
    "    X_test.append(inputs[i-60:i])\n",
    "    y_test.append(inputs[i])\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn data into arrays for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.add(LSTM(units= 60, return_sequences = False, input_shape=((60,1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.add(Dense(units=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 60)                14880     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 14,941\n",
      "Trainable params: 14,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1311\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0270\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0319\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0150\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0158\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0124\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0097\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0089\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0069\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0058\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0046\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0035\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0025\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0018\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0013\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0012\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.0012\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.6893e-04\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.5870e-04\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.5507e-04\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.2414e-04\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.1414e-04\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 9.0132e-04\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.8890e-04\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 9.0781e-04\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.9951e-04\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.8054e-04\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.7416e-04\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6825e-04\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.5362e-04\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.3642e-04\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.4454e-04\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.5379e-04\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.0805e-04\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.8594e-04\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.8238e-04\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.7900e-04\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.0008e-04\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.6262e-04\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.5302e-04\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.3888e-04\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.4094e-04\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.2216e-04\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.2049e-04\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.0803e-04\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.0297e-04\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 6.9462e-04\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.0481e-04\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.1840e-04\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.7931e-04\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.2525e-04\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.8654e-04\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.9563e-04\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.7364e-04\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 8.0707e-04\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 8.3095e-04\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 7.1224e-04\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.1344e-04\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 7.1230e-04\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.6016e-04\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.5586e-04\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.2557e-04\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.0302e-04\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.9557e-04\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.7927e-04\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.7329e-04\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.5628e-04\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.5365e-04\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.6461e-04\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.6122e-04\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.8291e-04\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.5701e-04\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.4153e-04\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.4886e-04\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.6281e-04\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 5.1811e-04\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.1544e-04\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.0323e-04\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.2730e-04\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.6003e-04\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 6.0430e-04\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.6342e-04\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.3189e-04\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 5.2040e-04\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.8074e-04\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5256e-04\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.9979e-04\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.7825e-04\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.5672e-04\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 4.3792e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff41a167370>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(X_train, y_train, epochs=100, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_raw = rnn_model.predict(X_test)\n",
    "y_hat = scaler.inverse_transform(y_hat_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test, color='red', label='Real Prices')\n",
    "plt.plot(y_hat, color='blue', label='Predicted Prices')\n",
    "plt.title('Unseen Data Predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Our RNN model on all NV Zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 24838.7852 - val_loss: 114.0518\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 346162.7188 - val_loss: 119.8761\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 311825.0938 - val_loss: 110.4996\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 112270.8281 - val_loss: 104.1052\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7280.6343 - val_loss: 98.2523\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 161654.6094 - val_loss: 95.9728\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 156434.8594 - val_loss: 96.8727\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 106218.5703 - val_loss: 99.1697\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 59663.7812 - val_loss: 102.5557\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 65514.2031 - val_loss: 104.2361\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49314.8750 - val_loss: 102.9912\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26282.5840 - val_loss: 100.2605\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46775.3828 - val_loss: 100.1188\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 54399.0781 - val_loss: 100.9972\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17676.0156 - val_loss: 102.6530\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25443.4121 - val_loss: 103.4435\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24248.5488 - val_loss: 102.7808\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15171.1250 - val_loss: 102.0899\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10781.4951 - val_loss: 102.5933\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12842.5684 - val_loss: 102.1789\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3795.7891 - val_loss: 103.6582\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 54611.8008 - val_loss: 104.3329\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48536.1758 - val_loss: 102.2517\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4756.2549 - val_loss: 102.2203\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5071.3008 - val_loss: 103.3382\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25268.1562 - val_loss: 102.8724\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12793.6064 - val_loss: 101.4807\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43727.4805 - val_loss: 101.0180\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21902.0273 - val_loss: 102.3960\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 256.8121 - val_loss: 104.8539\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 76480.1250 - val_loss: 105.3915\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 81965.6406 - val_loss: 104.6479\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 52256.1172 - val_loss: 103.3673\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4538.2031 - val_loss: 101.8034\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45191.3438 - val_loss: 100.8121\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46073.8789 - val_loss: 101.6135\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9514.6367 - val_loss: 102.5561\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12231.3936 - val_loss: 103.2628\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21492.2891 - val_loss: 102.5592\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7062.0674 - val_loss: 102.4485\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 427.6256 - val_loss: 104.2701\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49941.8789 - val_loss: 104.3903\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54965.7930 - val_loss: 104.0227\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43726.9102 - val_loss: 102.3913\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13278.7939 - val_loss: 102.0258\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10103.2490 - val_loss: 102.8505\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21145.4668 - val_loss: 102.8957\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10918.0234 - val_loss: 102.0490\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24175.6523 - val_loss: 101.6560\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17189.4785 - val_loss: 102.4600\n",
      "Iteration number 0 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 268793.5625 - val_loss: 107.8876\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 324962.4688 - val_loss: 103.8027\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 133010.9375 - val_loss: 95.8391\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 186988.8125 - val_loss: 95.0804\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 105624.4219 - val_loss: 98.0977\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25004.0469 - val_loss: 97.1603\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57659.8164 - val_loss: 96.0662\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 62909.1641 - val_loss: 98.2646\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32295.8320 - val_loss: 96.8784\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 86009.8984 - val_loss: 96.1622\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46065.5000 - val_loss: 99.6176\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 135721.8281 - val_loss: 99.7598\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 98273.1406 - val_loss: 96.2929\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 123782.0391 - val_loss: 95.6046\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 84742.1875 - val_loss: 98.1429\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 53792.3594 - val_loss: 97.0713\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 38978.9062 - val_loss: 96.3722\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13146.8486 - val_loss: 96.3457\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21098.2539 - val_loss: 97.1059\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37116.3320 - val_loss: 96.3205\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 56905.4609 - val_loss: 98.8392\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23190.2441 - val_loss: 98.3577\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45698.4922 - val_loss: 98.3984\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34826.1367 - val_loss: 100.1853\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 55900.5781 - val_loss: 98.6750\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11898.1699 - val_loss: 98.9565\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21238.5840 - val_loss: 97.3137\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 82286.3359 - val_loss: 97.5861\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28287.2246 - val_loss: 98.7551\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25781.6777 - val_loss: 97.2017\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46702.8555 - val_loss: 98.1448\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17254.8574 - val_loss: 97.7916\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10669.5664 - val_loss: 98.8880\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 60030.6172 - val_loss: 98.0532\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29956.7246 - val_loss: 97.1183\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35400.5273 - val_loss: 99.0474\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 99446.5156 - val_loss: 98.7464\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34666.5195 - val_loss: 97.6864\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27231.9023 - val_loss: 99.0578\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 58900.3281 - val_loss: 99.0621\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18682.2422 - val_loss: 97.3974\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 67909.5625 - val_loss: 97.9396\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27427.7305 - val_loss: 99.6859\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 81893.5703 - val_loss: 98.9188\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17031.6992 - val_loss: 98.1054\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23501.9746 - val_loss: 99.0219\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43670.6562 - val_loss: 97.7318\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 76421.0625 - val_loss: 97.7234\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 57141.2969 - val_loss: 99.6379\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 83660.1016 - val_loss: 99.2004\n",
      "Iteration number 1 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 93.2317 - val_loss: 76.5660\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 58.9534 - val_loss: 44.1831\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49.3276 - val_loss: 43.7206\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39.9171 - val_loss: 42.6268\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.6723 - val_loss: 29.1006\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.2270 - val_loss: 25.0373\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.0174 - val_loss: 15.5465\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22.9553 - val_loss: 10.4820\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21.1223 - val_loss: 8.2957\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.1191 - val_loss: 5.9220\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18.2885 - val_loss: 6.3876\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17.6843 - val_loss: 4.7845\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15.8290 - val_loss: 6.6585\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15.0843 - val_loss: 3.1527\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.3578 - val_loss: 6.1350\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4453 - val_loss: 3.8343\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.1142 - val_loss: 4.0679\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.6195 - val_loss: 3.5374\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.2297 - val_loss: 3.8849\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.8529 - val_loss: 4.2058\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.2785 - val_loss: 3.2951\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.1698 - val_loss: 2.3610\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.8212 - val_loss: 6.3622\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.6943 - val_loss: 2.9470\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.7467 - val_loss: 4.6511\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.9678 - val_loss: 4.5303\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.6682 - val_loss: 3.0352\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.5637 - val_loss: 4.7320\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2355 - val_loss: 3.8005\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.0928 - val_loss: 4.2255\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3962 - val_loss: 1.5539\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.4079 - val_loss: 6.1035\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2227 - val_loss: 3.0013\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6675 - val_loss: 3.7166\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3039 - val_loss: 3.9412\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.0770 - val_loss: 2.7851\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.6240 - val_loss: 5.2018\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3918 - val_loss: 1.5008\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3732 - val_loss: 6.4641\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.8720 - val_loss: 2.0780\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6296 - val_loss: 3.3490\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.5911 - val_loss: 1.9272\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3429 - val_loss: 3.9800\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3404 - val_loss: 2.0160\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.2166 - val_loss: 3.7384\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0413 - val_loss: 2.0357\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0443 - val_loss: 4.7039\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3373 - val_loss: 1.8674\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.9939 - val_loss: 4.3515\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3974 - val_loss: 1.9575\n",
      "Iteration number 2 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 94.3975 - val_loss: 75.6122\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48.6399 - val_loss: 29.2796\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31.0070 - val_loss: 8.6624\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.4855 - val_loss: 26.5157\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20.7120 - val_loss: 32.3182\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.8412 - val_loss: 23.2021\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16.5108 - val_loss: 13.1432\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.2429 - val_loss: 11.6700\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.6157 - val_loss: 15.2052\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.0968 - val_loss: 8.0460\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5467 - val_loss: 8.1722\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8932 - val_loss: 3.9159\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6794 - val_loss: 3.4034\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5282 - val_loss: 4.0856\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1746 - val_loss: 5.1783\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.8943 - val_loss: 3.9697\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.5577 - val_loss: 3.2157\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.4079 - val_loss: 4.7376\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.5790 - val_loss: 2.5378\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3022 - val_loss: 4.5564\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3945 - val_loss: 4.0015\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.2289 - val_loss: 2.6805\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.5782 - val_loss: 3.8626\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6155 - val_loss: 2.4524\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.2438 - val_loss: 4.5444\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.4712 - val_loss: 2.1704\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1008 - val_loss: 3.9386\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0750 - val_loss: 2.2376\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8549 - val_loss: 4.3696\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8617 - val_loss: 2.6557\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.9726 - val_loss: 3.8689\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.6646 - val_loss: 2.2364\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.5498 - val_loss: 2.6542\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.2837 - val_loss: 2.2365\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.2649 - val_loss: 3.2650\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.1281 - val_loss: 2.5034\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.4272 - val_loss: 2.5854\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0076 - val_loss: 2.1888\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0605 - val_loss: 2.3920\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0556 - val_loss: 3.5860\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0030 - val_loss: 2.6175\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.7464 - val_loss: 2.5201\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5560 - val_loss: 2.7933\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3045 - val_loss: 2.2013\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.2488 - val_loss: 2.1382\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2999 - val_loss: 3.2683\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3116 - val_loss: 2.5030\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.8533 - val_loss: 2.7266\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.1437 - val_loss: 2.3549\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.6247 - val_loss: 2.8298\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4155cc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 3 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 90.9949 - val_loss: 77.4082\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61.5958 - val_loss: 48.0451\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 52.4791 - val_loss: 44.9626\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.2448 - val_loss: 42.2587\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.1791 - val_loss: 26.4846\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.2185 - val_loss: 19.9978\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.3263 - val_loss: 17.7933\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20.0744 - val_loss: 8.8582\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.3553 - val_loss: 8.0144\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.5040 - val_loss: 4.5631\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.5819 - val_loss: 7.2251\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.7858 - val_loss: 4.0676\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.0553 - val_loss: 7.0830\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4759 - val_loss: 3.8545\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4829 - val_loss: 7.2044\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.3860 - val_loss: 3.7891\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.4093 - val_loss: 4.7412\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9797 - val_loss: 5.4727\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5296 - val_loss: 4.3518\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5056 - val_loss: 3.7620\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3221 - val_loss: 4.5898\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2698 - val_loss: 4.0627\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9723 - val_loss: 4.6971\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9344 - val_loss: 3.3577\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0469 - val_loss: 4.3336\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0379 - val_loss: 5.3425\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9995 - val_loss: 2.9787\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2759 - val_loss: 4.5560\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9884 - val_loss: 3.7036\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5861 - val_loss: 3.9478\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4213 - val_loss: 3.1628\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8421 - val_loss: 4.9842\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4700 - val_loss: 3.1890\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0082 - val_loss: 3.6137\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9204 - val_loss: 5.5640\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3060 - val_loss: 2.9091\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5536 - val_loss: 3.1294\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1105 - val_loss: 3.8857\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3412 - val_loss: 3.6783\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9411 - val_loss: 3.0251\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8108 - val_loss: 3.6026\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3590 - val_loss: 3.4154\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1968 - val_loss: 3.0963\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9315 - val_loss: 3.4590\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2801 - val_loss: 3.2282\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8904 - val_loss: 3.0319\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8948 - val_loss: 4.0032\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0589 - val_loss: 3.3501\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3740 - val_loss: 2.8126\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7534 - val_loss: 4.6785\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e8cb93a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 4 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 16746.0098 - val_loss: 90.2023\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 365382.3438 - val_loss: 86.4016\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 285687.4062 - val_loss: 95.8542\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 124583.5547 - val_loss: 104.6404\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57159.3359 - val_loss: 108.1533\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 50139.4375 - val_loss: 106.4412\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9629.9883 - val_loss: 101.4708\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 121036.0625 - val_loss: 99.0104\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 100551.6875 - val_loss: 101.7789\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22949.3887 - val_loss: 105.1495\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55775.1172 - val_loss: 107.2043\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 56521.3086 - val_loss: 106.0760\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36736.4609 - val_loss: 102.1262\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 74900.5625 - val_loss: 100.5072\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 68347.4375 - val_loss: 103.6302\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10190.1904 - val_loss: 104.0902\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4174.7134 - val_loss: 101.7766\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 56334.9414 - val_loss: 101.2506\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35487.1172 - val_loss: 102.5091\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9061.6836 - val_loss: 106.4903\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 93833.2344 - val_loss: 108.2439\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 94770.8125 - val_loss: 106.4451\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 56340.0469 - val_loss: 103.9976\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5399.2349 - val_loss: 100.9433\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47520.0117 - val_loss: 100.5295\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54548.9453 - val_loss: 101.8203\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18758.7949 - val_loss: 103.5033\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18107.1816 - val_loss: 103.7469\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15193.3096 - val_loss: 102.9872\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11464.0518 - val_loss: 102.7078\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 978.3833 - val_loss: 102.5644\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29050.3418 - val_loss: 101.7048\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25878.8594 - val_loss: 103.3492\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9567.4805 - val_loss: 102.9263\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1925.2451 - val_loss: 103.5831\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23572.3691 - val_loss: 103.5205\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13854.6660 - val_loss: 101.6474\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46296.3164 - val_loss: 100.9735\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35315.1602 - val_loss: 103.0343\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25675.6191 - val_loss: 103.8382\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19754.3379 - val_loss: 103.0018\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12071.1025 - val_loss: 102.4063\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5891.2158 - val_loss: 103.7906\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42337.2031 - val_loss: 104.3968\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23667.0645 - val_loss: 102.9013\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24175.3691 - val_loss: 101.7563\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14984.4297 - val_loss: 103.0720\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9368.6523 - val_loss: 103.0601\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9535.2871 - val_loss: 102.5110\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20555.5527 - val_loss: 101.9347\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40fad7d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 5 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 184156.8750 - val_loss: 92.4616\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 68931.5625 - val_loss: 103.5420\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42034.1367 - val_loss: 105.6473\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 75056.0469 - val_loss: 105.2328\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42724.5117 - val_loss: 100.8664\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 67663.6172 - val_loss: 99.3773\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47288.7266 - val_loss: 101.2081\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9882.5166 - val_loss: 103.6274\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9756.5117 - val_loss: 102.6049\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16889.8164 - val_loss: 102.6165\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6700.4824 - val_loss: 104.7424\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49848.0469 - val_loss: 105.3316\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35035.1055 - val_loss: 103.1194\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27266.7578 - val_loss: 101.7486\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21041.4648 - val_loss: 104.8019\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36643.3047 - val_loss: 104.7020\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34641.2266 - val_loss: 104.0506\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23532.4727 - val_loss: 100.1344\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 69613.8438 - val_loss: 99.0375\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 70497.5547 - val_loss: 100.4444\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27230.9844 - val_loss: 102.0333\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14341.6875 - val_loss: 105.9910\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 61883.2109 - val_loss: 106.8150\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 78188.4844 - val_loss: 106.1087\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48536.8984 - val_loss: 105.0537\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18701.3906 - val_loss: 102.2935\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20635.2617 - val_loss: 101.5331\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43765.5039 - val_loss: 101.4949\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30347.9121 - val_loss: 103.6949\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35565.2383 - val_loss: 104.7159\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26566.8379 - val_loss: 103.2123\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7958.0840 - val_loss: 102.7468\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4906.6362 - val_loss: 104.1023\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33046.2734 - val_loss: 104.3760\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27524.9629 - val_loss: 102.8568\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14117.9883 - val_loss: 102.6776\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5729.8330 - val_loss: 103.4296\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24767.4766 - val_loss: 104.1015\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11333.9609 - val_loss: 102.9594\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16299.2070 - val_loss: 102.4161\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15367.9375 - val_loss: 102.9175\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 523.8347 - val_loss: 104.6092\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43384.8789 - val_loss: 105.0984\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41041.0000 - val_loss: 104.7156\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33747.7188 - val_loss: 102.5310\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21024.1523 - val_loss: 102.0674\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24422.9766 - val_loss: 102.8938\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6433.6060 - val_loss: 104.3008\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33068.6250 - val_loss: 104.5182\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27380.2246 - val_loss: 103.7349\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3edba9ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 6 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 68.8157 - val_loss: 49.7097\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55.1544 - val_loss: 33.7150\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42.3580 - val_loss: 38.8571\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.7931 - val_loss: 30.5850\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.1232 - val_loss: 18.1364\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23.7810 - val_loss: 17.1141\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21.1748 - val_loss: 8.4967\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.1420 - val_loss: 3.7586\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.4150 - val_loss: 7.9032\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.9031 - val_loss: 2.4242\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.5196 - val_loss: 6.8428\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.6553 - val_loss: 3.9223\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.7855 - val_loss: 7.3109\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4104 - val_loss: 4.0118\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.8508 - val_loss: 5.4146\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4571 - val_loss: 3.3562\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.6574 - val_loss: 3.5529\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.5497 - val_loss: 5.3169\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.8237 - val_loss: 6.9003\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1172 - val_loss: 2.6028\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.5413 - val_loss: 5.7924\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.4589 - val_loss: 3.6637\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.3619 - val_loss: 5.7070\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.5507 - val_loss: 4.8827\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7036 - val_loss: 3.4227\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3764 - val_loss: 4.9681\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.9381 - val_loss: 5.4014\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7088 - val_loss: 3.6957\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3593 - val_loss: 5.1057\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.4413 - val_loss: 3.8805\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.4199 - val_loss: 4.3335\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1002 - val_loss: 3.9791\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.0969 - val_loss: 2.8579\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7984 - val_loss: 4.8239\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3316 - val_loss: 4.2131\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8356 - val_loss: 2.9399\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9479 - val_loss: 3.2366\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6905 - val_loss: 4.4456\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6161 - val_loss: 3.4046\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.4595 - val_loss: 4.2415\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6810 - val_loss: 1.8278\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9398 - val_loss: 5.3357\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.1821 - val_loss: 1.9469\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8552 - val_loss: 3.3681\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4486 - val_loss: 3.3560\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3460 - val_loss: 3.4530\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3302 - val_loss: 2.7811\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1702 - val_loss: 3.8299\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.5538 - val_loss: 2.1897\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4328 - val_loss: 5.5243\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f2187ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 7 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 94501.9922 - val_loss: 106.3934\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 166119.7969 - val_loss: 110.1455\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 121373.0781 - val_loss: 102.3081\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7540.1499 - val_loss: 94.0519\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 91462.8750 - val_loss: 93.1795\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 102617.1875 - val_loss: 93.6964\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 60245.6641 - val_loss: 98.6627\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2060.1692 - val_loss: 104.6351\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 116038.3672 - val_loss: 105.9718\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 125467.3047 - val_loss: 105.6482\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 75353.8516 - val_loss: 102.8478\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13472.7002 - val_loss: 98.6497\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54878.8789 - val_loss: 96.5787\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 70493.9844 - val_loss: 97.3597\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45154.8047 - val_loss: 99.5722\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6582.6733 - val_loss: 102.8662\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 63562.5312 - val_loss: 103.8023\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 60352.5000 - val_loss: 103.1123\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25009.7754 - val_loss: 100.3335\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11251.4482 - val_loss: 99.2939\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19917.5527 - val_loss: 100.4790\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7136.8750 - val_loss: 100.1902\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4236.8335 - val_loss: 100.9942\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16311.5771 - val_loss: 100.7771\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6662.0913 - val_loss: 98.3768\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49009.9375 - val_loss: 97.9275\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42591.3867 - val_loss: 99.0925\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17110.0605 - val_loss: 101.3579\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46431.6055 - val_loss: 102.4871\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33717.6562 - val_loss: 101.2999\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10603.9180 - val_loss: 98.9280\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 52950.8438 - val_loss: 97.9238\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51792.0195 - val_loss: 98.8430\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30421.1836 - val_loss: 100.8477\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3834.3313 - val_loss: 100.9499\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7323.3218 - val_loss: 100.6151\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12894.6240 - val_loss: 99.9903\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11468.0234 - val_loss: 100.5593\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4344.6646 - val_loss: 100.5487\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2378.2688 - val_loss: 101.1100\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17634.0469 - val_loss: 101.0751\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3358.2461 - val_loss: 100.3007\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5526.3926 - val_loss: 99.8373\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16165.7998 - val_loss: 100.5027\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8689.6670 - val_loss: 100.7160\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6384.3564 - val_loss: 100.4555\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 837.9638 - val_loss: 100.1646\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8273.7461 - val_loss: 100.5027\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2251.1084 - val_loss: 100.3455\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10578.4092 - val_loss: 100.0691\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4153818b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 8 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 77.8325 - val_loss: 58.8147\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54.2082 - val_loss: 43.8562\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41.6269 - val_loss: 41.9078\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.1232 - val_loss: 24.2896\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29.0050 - val_loss: 18.7123\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23.8964 - val_loss: 13.3148\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20.6261 - val_loss: 8.3148\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19.8088 - val_loss: 5.4476\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17.3695 - val_loss: 5.1937\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17.2539 - val_loss: 4.7744\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15.8645 - val_loss: 5.1090\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.2397 - val_loss: 4.4954\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.6310 - val_loss: 3.8156\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.4391 - val_loss: 3.8449\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.6700 - val_loss: 4.9514\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.1909 - val_loss: 4.6557\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.2321 - val_loss: 3.9870\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.9163 - val_loss: 4.8898\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.8781 - val_loss: 4.2301\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.0170 - val_loss: 5.9639\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.0179 - val_loss: 4.6966\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.8724 - val_loss: 4.7735\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.2764 - val_loss: 3.2220\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.0798 - val_loss: 5.1215\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.2400 - val_loss: 3.6771\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.3791 - val_loss: 5.8917\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.6146 - val_loss: 6.6860\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.2502 - val_loss: 3.1856\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.9877 - val_loss: 3.1950\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7970 - val_loss: 2.6341\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.9601 - val_loss: 2.4744\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7541 - val_loss: 2.8508\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.8134 - val_loss: 2.9079\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7688 - val_loss: 2.5349\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4103 - val_loss: 2.5913\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3810 - val_loss: 3.1807\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.9575 - val_loss: 2.5548\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.1371 - val_loss: 2.3653\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.1072 - val_loss: 2.2186\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.0316 - val_loss: 2.5104\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8592 - val_loss: 2.1622\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8659 - val_loss: 2.1643\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8203 - val_loss: 2.5013\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.5794 - val_loss: 2.5093\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6455 - val_loss: 1.9915\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8992 - val_loss: 3.1347\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6522 - val_loss: 1.9575\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.4109 - val_loss: 2.7224\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1336 - val_loss: 2.1277\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1245 - val_loss: 3.4265\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f3b04040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 9 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 41561.6602 - val_loss: 92.6282\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 84492.6016 - val_loss: 98.5488\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 76656.4766 - val_loss: 96.3893\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28506.2207 - val_loss: 89.6124\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 59730.7305 - val_loss: 89.3283\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 67366.2031 - val_loss: 90.2365\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25549.3965 - val_loss: 95.7124\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 74905.6328 - val_loss: 98.5443\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 74560.1641 - val_loss: 97.2130\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28217.2930 - val_loss: 94.6917\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10415.1504 - val_loss: 93.9473\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14391.4131 - val_loss: 95.6241\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24471.3301 - val_loss: 95.6614\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4250.5225 - val_loss: 94.1210\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25343.1270 - val_loss: 93.8357\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22898.7812 - val_loss: 95.9158\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13523.0049 - val_loss: 95.2901\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 906.1572 - val_loss: 93.0646\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46458.0742 - val_loss: 93.3749\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32212.1504 - val_loss: 95.1030\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7884.9302 - val_loss: 95.5727\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 169.0546 - val_loss: 96.7175\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29995.5723 - val_loss: 96.5518\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14598.5430 - val_loss: 94.4558\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41451.3047 - val_loss: 93.7701\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36190.5312 - val_loss: 96.0475\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4219.9131 - val_loss: 95.7795\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2965.7896 - val_loss: 97.1861\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33134.1094 - val_loss: 97.3233\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17353.3516 - val_loss: 95.6180\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30492.1680 - val_loss: 94.8316\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23016.2188 - val_loss: 95.9080\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15041.8311 - val_loss: 96.8820\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10131.0010 - val_loss: 94.6368\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42144.7617 - val_loss: 94.5584\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37249.2148 - val_loss: 95.4034\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18149.4531 - val_loss: 97.7506\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21421.4004 - val_loss: 98.0919\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25847.2578 - val_loss: 97.1066\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5893.7915 - val_loss: 97.0877\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7115.6084 - val_loss: 96.9413\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7872.9312 - val_loss: 97.2443\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10582.6748 - val_loss: 97.2865\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 273.7409 - val_loss: 97.6704\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12670.6797 - val_loss: 97.1169\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4419.0430 - val_loss: 97.5856\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7844.8174 - val_loss: 96.9018\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11278.5908 - val_loss: 97.2711\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 275.5706 - val_loss: 96.7355\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14816.1484 - val_loss: 97.1922\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415518820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 10 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 89021.9375 - val_loss: 125.7342\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 433347.1562 - val_loss: 124.8131\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 293531.7188 - val_loss: 114.8028\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64071.6328 - val_loss: 108.2047\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 135795.7656 - val_loss: 108.7858\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58388.9805 - val_loss: 114.7564\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 159044.1250 - val_loss: 115.7119\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 122556.9766 - val_loss: 113.0206\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45541.6445 - val_loss: 109.0115\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 84326.3125 - val_loss: 109.4514\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33725.8086 - val_loss: 112.9047\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 119446.1484 - val_loss: 113.3007\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 82135.5312 - val_loss: 111.0058\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44044.0312 - val_loss: 109.2929\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30593.6309 - val_loss: 111.2118\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28816.3281 - val_loss: 109.2345\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 59647.6758 - val_loss: 109.1364\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35012.4062 - val_loss: 112.0527\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 112113.5234 - val_loss: 113.4169\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 77535.5391 - val_loss: 111.1605\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18482.5273 - val_loss: 106.8288\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 182361.5781 - val_loss: 105.5270\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 171902.6562 - val_loss: 106.6499\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 120099.6562 - val_loss: 109.8810\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32515.7363 - val_loss: 110.5785\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37407.0156 - val_loss: 109.7266\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22089.3047 - val_loss: 109.4159\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6625.1519 - val_loss: 109.5091\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11104.1885 - val_loss: 109.0279\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8606.7588 - val_loss: 108.3722\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19428.9199 - val_loss: 108.5745\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2786.2090 - val_loss: 107.9657\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27716.2129 - val_loss: 108.1098\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2944.7373 - val_loss: 108.8437\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9373.6602 - val_loss: 108.7705\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9403.8330 - val_loss: 108.5622\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7760.4316 - val_loss: 107.2415\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37264.8320 - val_loss: 108.0114\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12307.2070 - val_loss: 107.5783\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11861.3340 - val_loss: 107.9091\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5936.8667 - val_loss: 107.0132\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31427.7598 - val_loss: 107.7702\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3168.5623 - val_loss: 108.0881\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22007.6543 - val_loss: 107.4391\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34991.6172 - val_loss: 106.7702\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5640.0737 - val_loss: 108.0773\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 69423.6641 - val_loss: 108.6654\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 52851.8125 - val_loss: 107.8578\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17089.7773 - val_loss: 105.6150\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 72318.6484 - val_loss: 105.4431\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f09094c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 11 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 254357.5781 - val_loss: 91.1922\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 229051.4219 - val_loss: 98.4472\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42187.4062 - val_loss: 108.3225\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 174027.5000 - val_loss: 106.8618\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 104286.8906 - val_loss: 101.9218\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50597.0039 - val_loss: 102.5026\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19483.3945 - val_loss: 103.2813\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20267.8379 - val_loss: 101.5109\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16961.2520 - val_loss: 102.0849\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25518.0879 - val_loss: 100.5036\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28955.4805 - val_loss: 103.0907\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 76147.4219 - val_loss: 102.3781\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19986.5781 - val_loss: 100.6331\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11929.6123 - val_loss: 100.4329\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11549.7969 - val_loss: 100.7519\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30639.0664 - val_loss: 99.4822\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15355.2793 - val_loss: 100.1958\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 82229.8750 - val_loss: 101.0455\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13879.5674 - val_loss: 98.5123\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27683.8594 - val_loss: 99.7580\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34048.4453 - val_loss: 100.5325\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15626.1943 - val_loss: 97.0745\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 119209.0547 - val_loss: 97.3362\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 89108.5859 - val_loss: 99.4987\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8794.6025 - val_loss: 100.2623\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10518.0859 - val_loss: 100.9945\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37630.2070 - val_loss: 100.6701\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15652.9443 - val_loss: 99.6488\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24509.9316 - val_loss: 101.0518\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43908.4414 - val_loss: 101.8207\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22384.3145 - val_loss: 99.7001\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49529.6289 - val_loss: 99.7087\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34603.3750 - val_loss: 101.5117\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 43016.0508 - val_loss: 101.3280\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6400.6714 - val_loss: 99.7340\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41412.8672 - val_loss: 99.9157\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18518.0566 - val_loss: 101.4138\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29218.1543 - val_loss: 100.9088\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6963.5640 - val_loss: 100.1880\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14713.6904 - val_loss: 100.3641\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21050.7207 - val_loss: 99.0363\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 38492.2852 - val_loss: 100.1292\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23156.2324 - val_loss: 100.2534\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32607.0332 - val_loss: 98.5440\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45360.1016 - val_loss: 100.0175\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19344.4727 - val_loss: 99.6112\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4164.1299 - val_loss: 99.1772\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10400.9736 - val_loss: 99.9707\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44017.1367 - val_loss: 99.6532\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21965.3398 - val_loss: 98.1631\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f492e310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 12 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 5530.2983 - val_loss: 80.8033\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 507842.3125 - val_loss: 83.1147\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 286532.7500 - val_loss: 90.1178\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 82042.9766 - val_loss: 97.3216\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 65449.3828 - val_loss: 95.9362\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2976.9995 - val_loss: 96.4362\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 70490.2109 - val_loss: 97.4549\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48167.3359 - val_loss: 94.9179\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40713.2148 - val_loss: 96.3729\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9128.3174 - val_loss: 95.5966\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9730.0967 - val_loss: 96.8274\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32646.1289 - val_loss: 95.9054\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7832.1528 - val_loss: 95.9645\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11174.2207 - val_loss: 97.4435\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 53408.6914 - val_loss: 97.5840\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12662.0596 - val_loss: 96.0917\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43122.2773 - val_loss: 96.4995\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 38994.8320 - val_loss: 98.8753\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 100115.7656 - val_loss: 98.6730\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47011.3008 - val_loss: 95.0749\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 59234.7812 - val_loss: 94.6581\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 78442.3125 - val_loss: 95.3837\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44053.5938 - val_loss: 97.7739\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46748.5508 - val_loss: 97.1968\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20155.6543 - val_loss: 95.5194\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 60551.7812 - val_loss: 96.3456\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7629.6909 - val_loss: 98.7647\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 105248.1016 - val_loss: 98.9331\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 84609.8125 - val_loss: 97.0285\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21538.0059 - val_loss: 95.4693\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42503.6758 - val_loss: 96.3157\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35688.5664 - val_loss: 98.3189\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40191.7148 - val_loss: 97.6780\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19884.9180 - val_loss: 96.7008\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 57046.4688 - val_loss: 97.6751\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2205.0859 - val_loss: 99.4727\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 90351.2500 - val_loss: 100.1141\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 70670.9844 - val_loss: 98.4656\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10753.9971 - val_loss: 97.1481\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45188.1016 - val_loss: 97.5247\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16801.5664 - val_loss: 99.7735\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 103052.4141 - val_loss: 100.5329\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 78945.6719 - val_loss: 99.4522\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29378.2070 - val_loss: 97.6545\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34388.1406 - val_loss: 97.9910\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7060.5796 - val_loss: 97.7692\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20128.4941 - val_loss: 97.9023\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5747.9292 - val_loss: 97.6926\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29498.2793 - val_loss: 97.3793\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9933.0723 - val_loss: 97.7246\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415518d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 13 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 162936.0000 - val_loss: 65.3446\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22051.6094 - val_loss: 71.7595\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16371.2666 - val_loss: 73.0849\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33093.4336 - val_loss: 73.7620\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1023.1633 - val_loss: 69.7726\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49942.0664 - val_loss: 70.4912\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44033.2773 - val_loss: 73.4535\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2509.7793 - val_loss: 73.5490\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10660.7588 - val_loss: 76.3847\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28182.1914 - val_loss: 74.9479\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7426.1187 - val_loss: 75.5554\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34733.6680 - val_loss: 76.6933\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15153.2930 - val_loss: 72.0437\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 50189.6367 - val_loss: 72.0655\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 56372.0977 - val_loss: 74.5998\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16767.1895 - val_loss: 78.7222\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54571.6055 - val_loss: 80.0475\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48680.0469 - val_loss: 78.2774\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13522.0547 - val_loss: 74.7541\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 80905.1875 - val_loss: 73.5352\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 63335.7305 - val_loss: 76.9300\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10873.0176 - val_loss: 80.7702\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 52395.5781 - val_loss: 82.4775\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 53114.1992 - val_loss: 81.5955\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21202.6445 - val_loss: 79.4725\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30623.9570 - val_loss: 79.6990\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20074.4844 - val_loss: 80.9461\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20617.0977 - val_loss: 82.0081\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 768.6415 - val_loss: 80.3494\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19447.2715 - val_loss: 80.1516\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26697.8965 - val_loss: 81.2744\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3621.6455 - val_loss: 81.5475\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9298.0889 - val_loss: 81.8974\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4612.9233 - val_loss: 81.4567\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8529.5059 - val_loss: 82.3431\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11978.6084 - val_loss: 82.0128\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6627.3193 - val_loss: 82.2690\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8694.5488 - val_loss: 82.0213\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13187.2412 - val_loss: 81.8751\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 953.6768 - val_loss: 84.2402\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38465.3242 - val_loss: 84.6609\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45277.8555 - val_loss: 84.3866\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25863.2207 - val_loss: 82.8692\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19671.1426 - val_loss: 82.1845\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16591.0586 - val_loss: 83.2838\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13838.3877 - val_loss: 83.8241\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3999.4807 - val_loss: 83.0126\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9782.6143 - val_loss: 83.1058\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9946.6504 - val_loss: 84.3259\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24976.7441 - val_loss: 84.7048\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f1e304c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 14 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 163127.8906 - val_loss: 78.5908\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41766.9688 - val_loss: 91.4670\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 176973.7031 - val_loss: 98.1660\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 144696.6406 - val_loss: 96.4824\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 109480.6875 - val_loss: 92.5277\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25748.4316 - val_loss: 91.2241\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22494.5215 - val_loss: 92.5721\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11971.0654 - val_loss: 92.6035\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3337.5034 - val_loss: 92.8469\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25325.6836 - val_loss: 93.5167\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22437.0215 - val_loss: 92.0129\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15636.8271 - val_loss: 92.5430\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 259.8364 - val_loss: 91.9351\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36994.0430 - val_loss: 91.5528\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15361.4326 - val_loss: 93.6788\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22848.1172 - val_loss: 94.0572\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32722.7637 - val_loss: 93.4282\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5591.0449 - val_loss: 93.0366\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8373.1885 - val_loss: 93.0451\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2879.5032 - val_loss: 93.4395\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21256.1621 - val_loss: 93.5275\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3380.2085 - val_loss: 92.7299\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8910.9287 - val_loss: 92.2658\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23002.6504 - val_loss: 93.0846\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1538.8148 - val_loss: 95.0373\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54210.9727 - val_loss: 95.1669\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 47756.0195 - val_loss: 94.0463\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1275.0394 - val_loss: 93.5911\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20488.3906 - val_loss: 94.0006\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9202.8828 - val_loss: 92.8309\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35202.6953 - val_loss: 92.3108\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27223.9688 - val_loss: 93.4582\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2800.3181 - val_loss: 93.5695\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3259.1028 - val_loss: 94.4063\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25865.3086 - val_loss: 94.3514\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12996.9717 - val_loss: 93.0161\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36118.5078 - val_loss: 92.5876\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29376.7168 - val_loss: 93.9067\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15652.0840 - val_loss: 94.3667\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6577.4160 - val_loss: 93.3719\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22300.4941 - val_loss: 93.3397\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16241.1494 - val_loss: 93.9848\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3123.6658 - val_loss: 94.0644\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4101.9907 - val_loss: 94.4224\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19911.1895 - val_loss: 94.7209\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14153.1953 - val_loss: 93.3598\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27395.4453 - val_loss: 93.4333\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20394.5781 - val_loss: 94.4960\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4828.7749 - val_loss: 94.3025\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3773.2573 - val_loss: 94.6406\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f51aa3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 15 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 131656.5000 - val_loss: 81.0404\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 317116.0312 - val_loss: 88.7454\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 166903.0156 - val_loss: 83.2900\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20743.1094 - val_loss: 78.2198\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 142688.2656 - val_loss: 79.1034\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 91561.6875 - val_loss: 83.1507\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54022.6641 - val_loss: 83.9367\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16970.0098 - val_loss: 82.5940\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 65517.5742 - val_loss: 80.9674\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 81201.4141 - val_loss: 82.8079\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6314.1470 - val_loss: 83.0197\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21824.5332 - val_loss: 83.7578\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8189.2671 - val_loss: 83.8487\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7797.2417 - val_loss: 83.6458\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14926.1895 - val_loss: 85.6079\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55164.7852 - val_loss: 84.8059\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21393.6777 - val_loss: 83.8849\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21243.6953 - val_loss: 85.7760\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47220.4492 - val_loss: 86.0371\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11255.6299 - val_loss: 83.1676\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 91876.5156 - val_loss: 82.9127\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 85563.9219 - val_loss: 84.6099\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26174.2598 - val_loss: 86.7718\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39502.9883 - val_loss: 85.7915\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13444.6377 - val_loss: 86.2506\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31655.6719 - val_loss: 86.8920\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32206.5195 - val_loss: 85.4466\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48055.2617 - val_loss: 86.7398\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13808.5049 - val_loss: 87.1593\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13289.8682 - val_loss: 87.6315\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22856.5156 - val_loss: 87.4211\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11621.7803 - val_loss: 86.9202\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27769.2930 - val_loss: 88.1443\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17707.4199 - val_loss: 88.2067\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4194.4395 - val_loss: 88.4190\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9706.9775 - val_loss: 87.8709\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19636.9277 - val_loss: 88.2194\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8992.0928 - val_loss: 88.1735\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 847.2345 - val_loss: 88.7838\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23803.7832 - val_loss: 88.4619\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2333.1240 - val_loss: 88.1210\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35440.7539 - val_loss: 88.2858\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11203.8291 - val_loss: 89.3264\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18357.5352 - val_loss: 88.8135\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27523.1621 - val_loss: 90.1995\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29239.1621 - val_loss: 89.3093\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31483.0957 - val_loss: 88.9512\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21991.4434 - val_loss: 89.9544\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6114.1880 - val_loss: 88.4595\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71223.7656 - val_loss: 88.1223\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f641e430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 16 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 90.6197 - val_loss: 75.7808\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53.6848 - val_loss: 42.5828\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49.0163 - val_loss: 40.5554\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38.4520 - val_loss: 43.4724\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33.1499 - val_loss: 38.4154\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27.4808 - val_loss: 25.0751\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.0561 - val_loss: 20.9368\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21.6161 - val_loss: 21.3773\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18.7822 - val_loss: 10.9183\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17.7679 - val_loss: 12.4261\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16.2790 - val_loss: 5.2604\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.0504 - val_loss: 8.6419\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4286 - val_loss: 5.4606\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.1946 - val_loss: 5.7717\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.7958 - val_loss: 2.1513\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.1006 - val_loss: 4.7479\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.9057 - val_loss: 2.2712\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.1420 - val_loss: 2.6090\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.1964 - val_loss: 3.0103\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.9375 - val_loss: 3.8568\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5401 - val_loss: 2.4856\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.8894 - val_loss: 2.6290\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.6164 - val_loss: 2.1452\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2346 - val_loss: 2.4409\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.0380 - val_loss: 2.7058\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8429 - val_loss: 2.4093\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6060 - val_loss: 1.9701\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6954 - val_loss: 2.6154\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2242 - val_loss: 2.3511\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0272 - val_loss: 4.9483\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.2373 - val_loss: 2.5139\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5831 - val_loss: 7.0217\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0294 - val_loss: 3.5751\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7141 - val_loss: 4.4218\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4034 - val_loss: 2.0333\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8580 - val_loss: 3.2556\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9620 - val_loss: 2.1298\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.5476 - val_loss: 4.6926\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0560 - val_loss: 2.0378\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0942 - val_loss: 4.9257\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8975 - val_loss: 2.0209\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3067 - val_loss: 4.2952\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1807 - val_loss: 2.6041\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4893 - val_loss: 2.3966\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4752 - val_loss: 2.5365\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1070 - val_loss: 4.0355\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0601 - val_loss: 1.9466\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.9109 - val_loss: 4.5157\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.9413 - val_loss: 2.2114\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3325 - val_loss: 3.4154\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f641e4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 17 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 68.5332 - val_loss: 50.9179\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.3294 - val_loss: 11.4554\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.5382 - val_loss: 29.0248\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21.1687 - val_loss: 35.7190\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19.9525 - val_loss: 25.2437\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16.9839 - val_loss: 17.3437\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.1056 - val_loss: 18.5914\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.3005 - val_loss: 17.3014\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.8360 - val_loss: 12.9502\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.4855 - val_loss: 12.2743\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.3607 - val_loss: 6.4067\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6227 - val_loss: 6.3556\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.5166 - val_loss: 1.8382\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2782 - val_loss: 3.0541\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8820 - val_loss: 2.8322\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2852 - val_loss: 1.7129\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9328 - val_loss: 3.0586\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5198 - val_loss: 1.9757\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4114 - val_loss: 3.2394\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1866 - val_loss: 2.3273\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0192 - val_loss: 2.4374\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8749 - val_loss: 2.2146\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.3269 - val_loss: 2.7351\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.2520 - val_loss: 2.6990\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0976 - val_loss: 2.5161\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9351 - val_loss: 2.5750\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9476 - val_loss: 2.6081\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0000 - val_loss: 2.6079\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8037 - val_loss: 2.5576\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5974 - val_loss: 2.6687\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.3368 - val_loss: 2.6194\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.2856 - val_loss: 2.5567\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3424 - val_loss: 2.7126\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.6437 - val_loss: 3.2058\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7407 - val_loss: 2.7040\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.4414 - val_loss: 2.4207\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.2979 - val_loss: 3.4177\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.6925 - val_loss: 2.4119\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.0602 - val_loss: 2.9193\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1690 - val_loss: 2.8480\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.2460 - val_loss: 2.5877\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4622 - val_loss: 3.7932\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5910 - val_loss: 2.9864\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3102 - val_loss: 1.9125\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.6015 - val_loss: 2.2128\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.5277 - val_loss: 2.3825\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.7612 - val_loss: 2.2426\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.6987 - val_loss: 2.1328\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.2925 - val_loss: 2.0457\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3.2050 - val_loss: 2.1396\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff414c94a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 18 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 135955.0781 - val_loss: 87.3064\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 76791.1875 - val_loss: 91.2909\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26497.9316 - val_loss: 87.6479\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 62214.9688 - val_loss: 85.4854\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47155.5938 - val_loss: 87.4956\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1750.4104 - val_loss: 88.4788\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5320.2476 - val_loss: 90.4294\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30728.1250 - val_loss: 89.5273\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3083.7180 - val_loss: 87.7056\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39973.6719 - val_loss: 87.6561\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31273.4219 - val_loss: 89.1863\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5171.9600 - val_loss: 89.2645\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8359.5791 - val_loss: 89.8188\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29676.4180 - val_loss: 90.5514\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21766.7188 - val_loss: 87.8336\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 74294.6172 - val_loss: 86.7881\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50749.7266 - val_loss: 88.4111\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5358.9126 - val_loss: 90.3930\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3207.0947 - val_loss: 88.9242\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39162.6758 - val_loss: 89.1153\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30977.7871 - val_loss: 90.5705\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3434.0786 - val_loss: 90.3866\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7161.9907 - val_loss: 90.7519\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13140.9277 - val_loss: 90.8665\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1632.9180 - val_loss: 90.9222\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18500.8066 - val_loss: 91.3217\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13066.3389 - val_loss: 90.7804\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20283.1914 - val_loss: 90.2664\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15487.8223 - val_loss: 91.9702\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27826.5156 - val_loss: 92.0426\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27420.1934 - val_loss: 91.4899\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6275.8481 - val_loss: 90.1024\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34800.9961 - val_loss: 89.9399\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33854.1211 - val_loss: 90.2949\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12556.1230 - val_loss: 91.9754\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40571.0000 - val_loss: 92.8791\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41270.5781 - val_loss: 92.3664\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13520.5264 - val_loss: 91.6068\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23275.8203 - val_loss: 91.0137\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17740.9043 - val_loss: 92.0435\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13031.4766 - val_loss: 92.1830\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8926.2510 - val_loss: 91.9325\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19778.4531 - val_loss: 91.3310\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17242.7227 - val_loss: 92.3904\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16345.1299 - val_loss: 92.4769\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12638.5605 - val_loss: 91.8001\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21088.4707 - val_loss: 91.6088\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13076.1758 - val_loss: 92.6718\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29075.0039 - val_loss: 93.1191\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26783.3672 - val_loss: 92.5715\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f86089d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 19 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 26510.8223 - val_loss: 70.9590\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 203013.6875 - val_loss: 74.7248\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 132838.3594 - val_loss: 81.5180\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 414.0841 - val_loss: 81.6577\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16772.8379 - val_loss: 84.5151\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 52514.3086 - val_loss: 84.7505\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26686.9336 - val_loss: 80.8542\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42106.9922 - val_loss: 81.0620\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38958.0391 - val_loss: 82.0536\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22508.6250 - val_loss: 87.7190\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 112407.4062 - val_loss: 89.4387\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 112622.5625 - val_loss: 87.3982\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 55111.0547 - val_loss: 84.8864\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13371.2900 - val_loss: 80.6560\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 119525.6953 - val_loss: 78.9285\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 89421.8672 - val_loss: 81.0946\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34348.3594 - val_loss: 84.7886\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48990.1680 - val_loss: 87.1575\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43163.0234 - val_loss: 86.1432\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9150.6113 - val_loss: 83.7323\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 63836.0859 - val_loss: 83.2701\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54899.4883 - val_loss: 84.3817\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28958.4121 - val_loss: 86.8702\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36032.9062 - val_loss: 87.5949\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34042.2617 - val_loss: 86.7837\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1311.3274 - val_loss: 86.4530\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13483.2432 - val_loss: 86.5259\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1260.0332 - val_loss: 86.3868\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3470.1448 - val_loss: 86.1128\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20926.5059 - val_loss: 85.5694\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19463.6543 - val_loss: 86.8765\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22153.7168 - val_loss: 87.1174\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15219.9590 - val_loss: 85.5377\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35345.6953 - val_loss: 85.4049\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27879.4746 - val_loss: 86.7246\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18146.4609 - val_loss: 87.3336\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3584.8938 - val_loss: 86.9561\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2082.4993 - val_loss: 86.7552\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4984.6030 - val_loss: 87.5473\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21502.0605 - val_loss: 87.4970\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9762.0420 - val_loss: 86.2219\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20037.1582 - val_loss: 86.4021\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16972.9062 - val_loss: 87.5961\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24806.1719 - val_loss: 87.9704\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19035.8301 - val_loss: 86.1530\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46067.0312 - val_loss: 85.5953\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39460.9883 - val_loss: 86.2143\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2974.3948 - val_loss: 87.9765\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 50704.1797 - val_loss: 89.6993\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 50450.7539 - val_loss: 88.8861\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f105a430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 20 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 1250.6459 - val_loss: 126.4502\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 291920.2500 - val_loss: 122.8488\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 209763.2344 - val_loss: 116.5422\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 74290.6016 - val_loss: 110.2347\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 88808.2422 - val_loss: 107.1629\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 54345.4648 - val_loss: 110.1611\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28773.5391 - val_loss: 112.2887\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17534.1719 - val_loss: 109.2942\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43375.8203 - val_loss: 108.9783\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36718.3320 - val_loss: 110.4891\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 755.3131 - val_loss: 113.7272\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 55186.7500 - val_loss: 113.9072\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 61034.3359 - val_loss: 113.0858\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44040.0586 - val_loss: 109.6332\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31809.0781 - val_loss: 109.1675\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29523.8594 - val_loss: 110.3926\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1710.5183 - val_loss: 110.2062\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13018.3623 - val_loss: 110.6290\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17194.5488 - val_loss: 111.0045\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2343.2832 - val_loss: 109.0724\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37051.6094 - val_loss: 108.8017\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31683.2930 - val_loss: 110.0720\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16051.6221 - val_loss: 110.8432\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12099.8633 - val_loss: 110.0845\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5191.5024 - val_loss: 112.9760\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 82310.1328 - val_loss: 114.1154\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 76800.9531 - val_loss: 111.3490\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17482.3184 - val_loss: 108.5152\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54740.6367 - val_loss: 107.2790\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 53172.5508 - val_loss: 108.6515\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21482.8496 - val_loss: 110.7496\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24923.4199 - val_loss: 110.6390\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24182.4434 - val_loss: 109.2806\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14295.0674 - val_loss: 109.0467\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1674.5780 - val_loss: 110.3737\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35009.5156 - val_loss: 110.7324\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31512.5059 - val_loss: 109.2733\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10646.9375 - val_loss: 108.9554\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2697.3650 - val_loss: 108.8496\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12807.0898 - val_loss: 108.9181\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3363.9922 - val_loss: 108.8075\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5397.1938 - val_loss: 109.2690\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9922.7158 - val_loss: 108.9975\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4305.1602 - val_loss: 109.1751\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6273.0225 - val_loss: 108.4863\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13609.9561 - val_loss: 108.8482\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4658.6992 - val_loss: 108.7069\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14594.9209 - val_loss: 108.5256\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 183.6289 - val_loss: 108.4945\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11373.9248 - val_loss: 108.8099\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e8cce8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 21 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 98.6643 - val_loss: 85.4504\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 56.8166 - val_loss: 51.0842\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44.7651 - val_loss: 34.8623\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36.7180 - val_loss: 36.6299\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 30.2451 - val_loss: 34.1135\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25.1240 - val_loss: 15.1488\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24.5494 - val_loss: 11.3435\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20.2498 - val_loss: 18.1395\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18.0671 - val_loss: 4.2332\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16.1120 - val_loss: 8.2547\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.8190 - val_loss: 3.0739\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.7178 - val_loss: 2.9857\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.5035 - val_loss: 4.2294\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.3147 - val_loss: 3.1881\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.0487 - val_loss: 5.2101\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.3972 - val_loss: 3.0082\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.4756 - val_loss: 4.4296\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.4789 - val_loss: 2.6498\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9136 - val_loss: 3.1442\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7229 - val_loss: 2.6519\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.5857 - val_loss: 2.9873\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.1090 - val_loss: 2.9088\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8022 - val_loss: 2.7865\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6115 - val_loss: 3.0960\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8682 - val_loss: 4.1069\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.8762 - val_loss: 3.0100\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6423 - val_loss: 4.6913\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.4360 - val_loss: 2.7814\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8379 - val_loss: 3.9497\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.5053 - val_loss: 2.8635\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7252 - val_loss: 2.9925\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.1732 - val_loss: 2.4093\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.7894 - val_loss: 3.2386\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0085 - val_loss: 3.3859\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6818 - val_loss: 2.8735\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.3855 - val_loss: 4.2207\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.9210 - val_loss: 2.8197\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3627 - val_loss: 3.5956\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.8632 - val_loss: 2.4608\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5581 - val_loss: 2.8290\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1251 - val_loss: 5.1093\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.6902 - val_loss: 3.4268\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.2516 - val_loss: 3.1637\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0271 - val_loss: 2.5487\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.3250 - val_loss: 2.9087\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.8847 - val_loss: 3.1958\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.9386 - val_loss: 3.1788\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0122 - val_loss: 2.8217\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2328 - val_loss: 3.1147\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0097 - val_loss: 3.9934\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f1618670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 22 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 31440.0332 - val_loss: 120.6831\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 225946.9531 - val_loss: 117.3979\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 155411.3281 - val_loss: 111.9560\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 55863.7812 - val_loss: 105.2192\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 104243.9844 - val_loss: 101.8137\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 84958.7891 - val_loss: 105.8001\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3945.3672 - val_loss: 110.3978\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 108724.8516 - val_loss: 112.2082\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 100425.6797 - val_loss: 110.6461\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49332.4258 - val_loss: 107.2652\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 230.1364 - val_loss: 101.7825\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 129670.5000 - val_loss: 99.5190\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 120243.0156 - val_loss: 100.8195\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 90684.5703 - val_loss: 105.5637\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6576.8013 - val_loss: 109.8317\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 72526.0000 - val_loss: 110.8560\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 81940.2188 - val_loss: 109.8464\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49785.0156 - val_loss: 107.3779\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13612.9629 - val_loss: 106.1069\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3801.2886 - val_loss: 106.9015\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8892.5039 - val_loss: 107.3769\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25153.1660 - val_loss: 107.1446\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1193.8082 - val_loss: 106.4620\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2594.9199 - val_loss: 105.2848\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39598.7891 - val_loss: 104.8408\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24722.1328 - val_loss: 107.4052\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32233.7871 - val_loss: 107.8750\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 34556.6133 - val_loss: 107.2561\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15268.0244 - val_loss: 104.9912\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27496.3691 - val_loss: 104.7954\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32358.0293 - val_loss: 105.2973\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19424.8066 - val_loss: 107.6213\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46066.2266 - val_loss: 108.1003\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40288.9844 - val_loss: 107.4952\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13926.5000 - val_loss: 104.9807\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42822.7227 - val_loss: 103.9047\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48169.3984 - val_loss: 104.5066\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27773.9863 - val_loss: 106.2830\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21212.9941 - val_loss: 106.7197\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18438.8594 - val_loss: 105.3754\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22703.2012 - val_loss: 105.1224\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11221.9814 - val_loss: 106.3684\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29129.4512 - val_loss: 106.9536\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24124.1641 - val_loss: 105.6935\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12011.2139 - val_loss: 105.5171\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2878.1235 - val_loss: 106.5478\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23408.6406 - val_loss: 106.5800\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17284.4707 - val_loss: 105.6655\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1715.2433 - val_loss: 105.8635\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5175.4775 - val_loss: 105.4595\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e6343dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 23 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 87.4752 - val_loss: 66.5407\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38.6695 - val_loss: 19.1595\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.4869 - val_loss: 24.7892\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26.5074 - val_loss: 35.1459\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.8563 - val_loss: 26.7365\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.7777 - val_loss: 18.5696\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.6574 - val_loss: 11.8027\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.1478 - val_loss: 13.5290\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.7096 - val_loss: 5.7445\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.5585 - val_loss: 9.7204\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4970 - val_loss: 5.2473\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.6424 - val_loss: 9.2998\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.8105 - val_loss: 5.4999\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1337 - val_loss: 7.1331\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6405 - val_loss: 6.3210\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2635 - val_loss: 5.7801\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9702 - val_loss: 6.2138\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7850 - val_loss: 3.8928\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9839 - val_loss: 7.1312\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8599 - val_loss: 3.3533\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.5075 - val_loss: 5.3214\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7081 - val_loss: 4.0273\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6108 - val_loss: 5.8406\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7339 - val_loss: 2.9807\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.6002 - val_loss: 4.7967\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0921 - val_loss: 3.8751\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2349 - val_loss: 2.8038\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4351 - val_loss: 4.5574\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8543 - val_loss: 3.3926\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5642 - val_loss: 4.4561\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7857 - val_loss: 3.2545\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1524 - val_loss: 4.0335\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1588 - val_loss: 2.9350\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1372 - val_loss: 4.0086\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8563 - val_loss: 3.0052\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6377 - val_loss: 2.6749\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.6839 - val_loss: 2.0973\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4439 - val_loss: 4.7627\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2804 - val_loss: 2.2093\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.9391 - val_loss: 3.8207\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4143 - val_loss: 2.0315\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.8504 - val_loss: 3.4491\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9279 - val_loss: 2.5484\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.5850 - val_loss: 2.5754\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7218 - val_loss: 2.8043\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.6066 - val_loss: 2.5921\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7474 - val_loss: 2.4035\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.4044 - val_loss: 2.8070\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.1911 - val_loss: 3.2598\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5335 - val_loss: 4.1560\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4111ca040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 24 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 5350052.0000 - val_loss: 100.3621\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4323456.0000 - val_loss: 99.0235\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4463709.0000 - val_loss: 98.3777\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1531187.7500 - val_loss: 97.1471\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 864985.5000 - val_loss: 96.0739\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 974826.5000 - val_loss: 95.1140\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 484112.9375 - val_loss: 93.9448\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 148744.6875 - val_loss: 92.8314\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 458919.1562 - val_loss: 91.9049\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 410598.9375 - val_loss: 90.7971\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 381090.4062 - val_loss: 89.6737\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 384606.1562 - val_loss: 88.6705\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 142063.6250 - val_loss: 87.6825\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 531570.1250 - val_loss: 86.5715\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 234988.2031 - val_loss: 85.4954\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 125156.4766 - val_loss: 84.4621\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 421074.4688 - val_loss: 83.3426\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 395852.5938 - val_loss: 82.2702\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 491696.3750 - val_loss: 81.3099\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 374936.4688 - val_loss: 80.0880\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 747249.6875 - val_loss: 79.0890\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1019372.8125 - val_loss: 78.4103\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1016972.8125 - val_loss: 77.7153\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 517686.5938 - val_loss: 77.1852\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 153968.9219 - val_loss: 76.4095\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 295330.4062 - val_loss: 75.6237\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 689798.1875 - val_loss: 74.8224\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 520652.5312 - val_loss: 74.2975\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 196227.8750 - val_loss: 73.5730\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 213570.9844 - val_loss: 72.8388\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 176348.9688 - val_loss: 72.1325\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 166189.0156 - val_loss: 71.3183\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 213699.4844 - val_loss: 70.5320\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 180915.8125 - val_loss: 69.8156\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 206682.7969 - val_loss: 69.0411\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 188139.4844 - val_loss: 68.3578\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 191687.6562 - val_loss: 67.5107\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 206188.0469 - val_loss: 66.7185\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 165567.8281 - val_loss: 66.0453\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 198814.8281 - val_loss: 65.3955\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 142561.7969 - val_loss: 64.6531\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 467153.7812 - val_loss: 63.9017\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 709609.1875 - val_loss: 63.3757\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 998838.1250 - val_loss: 62.9677\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 539115.8125 - val_loss: 62.7402\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 257697.5781 - val_loss: 62.5399\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 137959.8750 - val_loss: 62.1068\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 386496.4688 - val_loss: 61.6834\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 94319.5625 - val_loss: 61.1569\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 252936.8906 - val_loss: 60.7000\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f4e620d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 25 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 56383.3281 - val_loss: 83.5461\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 84243.0469 - val_loss: 86.6122\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39381.8242 - val_loss: 85.2723\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35115.1055 - val_loss: 83.3502\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34603.8594 - val_loss: 85.8583\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11796.7832 - val_loss: 85.5864\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8848.9336 - val_loss: 86.5016\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12362.4561 - val_loss: 86.0919\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5578.2925 - val_loss: 87.1231\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28139.5684 - val_loss: 87.0775\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9833.8320 - val_loss: 85.4084\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 54610.0938 - val_loss: 84.9725\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43439.2344 - val_loss: 86.6568\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6358.1328 - val_loss: 87.5430\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3161.0134 - val_loss: 88.2004\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26128.5215 - val_loss: 88.4772\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17304.3867 - val_loss: 86.8662\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52267.4570 - val_loss: 86.3521\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35950.9414 - val_loss: 88.1790\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4420.6890 - val_loss: 90.7442\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 92343.3438 - val_loss: 91.9579\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 74766.8594 - val_loss: 91.3125\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42238.7734 - val_loss: 90.0704\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1999.8115 - val_loss: 88.1906\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54482.8633 - val_loss: 88.1052\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 57401.0117 - val_loss: 89.5091\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33039.5469 - val_loss: 91.4098\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7604.7871 - val_loss: 91.2491\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 482.3163 - val_loss: 92.0323\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30046.0918 - val_loss: 92.1376\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12177.2871 - val_loss: 91.1894\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4188.2637 - val_loss: 91.0709\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8434.9043 - val_loss: 91.3680\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1636.9939 - val_loss: 91.2036\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5079.4546 - val_loss: 91.5897\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11423.7959 - val_loss: 91.4692\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3768.3906 - val_loss: 90.5948\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27578.6328 - val_loss: 90.6985\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18729.1074 - val_loss: 91.1970\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1625.1929 - val_loss: 91.4245\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2657.2410 - val_loss: 91.8848\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21402.9551 - val_loss: 92.0600\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12219.2471 - val_loss: 91.0216\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18056.6211 - val_loss: 90.9852\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22451.4219 - val_loss: 91.4051\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7362.6685 - val_loss: 92.4052\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23873.6680 - val_loss: 92.6086\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22610.5586 - val_loss: 92.2562\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2662.0417 - val_loss: 92.0510\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13290.8379 - val_loss: 92.3533\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f0926160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 26 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 54599.4258 - val_loss: 102.1008\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 99127.7266 - val_loss: 101.6390\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 60901.9219 - val_loss: 94.4740\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 59147.8008 - val_loss: 93.6187\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32607.0527 - val_loss: 96.9573\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12537.7549 - val_loss: 96.7497\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6642.9868 - val_loss: 94.7219\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26352.5371 - val_loss: 95.4342\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10856.8408 - val_loss: 97.1003\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22108.4531 - val_loss: 97.3083\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13396.6475 - val_loss: 94.8778\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41776.7266 - val_loss: 94.7413\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24148.7227 - val_loss: 97.1640\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10085.6357 - val_loss: 97.0000\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5941.7720 - val_loss: 94.9371\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35873.1562 - val_loss: 95.3161\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20626.7168 - val_loss: 97.7993\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39929.0078 - val_loss: 98.6145\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32541.5859 - val_loss: 95.8618\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30498.1914 - val_loss: 95.5961\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15566.3535 - val_loss: 97.0170\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32666.5332 - val_loss: 98.2724\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26680.6992 - val_loss: 95.3777\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42279.4102 - val_loss: 94.9147\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35102.7422 - val_loss: 96.7832\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4455.8140 - val_loss: 96.6962\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5463.2568 - val_loss: 98.0028\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19822.2832 - val_loss: 97.1736\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2893.5664 - val_loss: 97.6969\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22837.2285 - val_loss: 97.8269\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10472.3086 - val_loss: 95.9316\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38553.8125 - val_loss: 95.5939\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32583.6621 - val_loss: 97.1036\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13802.8896 - val_loss: 97.7560\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5816.2598 - val_loss: 97.3507\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8492.8965 - val_loss: 97.4128\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1330.5214 - val_loss: 94.7906\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51546.2852 - val_loss: 94.6057\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 56343.7578 - val_loss: 95.3499\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31563.5762 - val_loss: 97.0001\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2432.5110 - val_loss: 97.4185\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2594.9536 - val_loss: 96.4193\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22100.6270 - val_loss: 96.9361\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12002.4658 - val_loss: 98.3070\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29441.8789 - val_loss: 98.6257\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20231.3574 - val_loss: 97.5654\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14669.8203 - val_loss: 97.0772\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8742.2852 - val_loss: 98.0250\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9557.4521 - val_loss: 97.9175\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5972.7310 - val_loss: 97.1956\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f2629dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 27 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 15926.5312 - val_loss: 113.8146\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 268348.1562 - val_loss: 112.9916\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 194767.6406 - val_loss: 107.9479\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 85527.0547 - val_loss: 102.2767\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10593.2393 - val_loss: 101.5730\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23701.2031 - val_loss: 102.7588\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29429.4746 - val_loss: 103.2321\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8644.1982 - val_loss: 100.8942\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71804.6094 - val_loss: 99.4763\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 63834.1836 - val_loss: 102.8590\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7258.0698 - val_loss: 102.8905\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6308.8369 - val_loss: 101.6613\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28203.7246 - val_loss: 101.8798\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12535.2988 - val_loss: 103.5415\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34526.6484 - val_loss: 103.9286\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26570.3809 - val_loss: 101.7232\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44609.2734 - val_loss: 100.9973\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29411.0391 - val_loss: 103.8499\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51061.9453 - val_loss: 105.0128\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43907.5938 - val_loss: 104.0167\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3881.3923 - val_loss: 101.8148\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54608.6523 - val_loss: 100.4026\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53860.6719 - val_loss: 101.7230\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24647.8594 - val_loss: 104.1897\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30586.0137 - val_loss: 104.1549\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29500.4336 - val_loss: 103.4590\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1698.8247 - val_loss: 101.3062\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34813.9258 - val_loss: 101.0346\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40466.1562 - val_loss: 102.2350\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1050.1133 - val_loss: 103.5109\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26958.2441 - val_loss: 103.8423\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26740.6113 - val_loss: 102.7087\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 941.1248 - val_loss: 100.4498\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50436.8047 - val_loss: 100.5558\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48337.8672 - val_loss: 101.9086\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5660.4360 - val_loss: 103.2167\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13614.3877 - val_loss: 103.4038\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18042.3301 - val_loss: 102.3095\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8257.9971 - val_loss: 102.8422\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8895.7070 - val_loss: 102.3832\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16652.4121 - val_loss: 102.2534\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5463.8667 - val_loss: 103.7478\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34835.2344 - val_loss: 103.8361\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29594.3262 - val_loss: 102.9520\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4358.3853 - val_loss: 101.1096\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42775.2891 - val_loss: 100.7862\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42690.5820 - val_loss: 101.6785\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12110.1445 - val_loss: 103.0470\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33708.0781 - val_loss: 103.7051\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31320.2344 - val_loss: 102.4879\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3eda3af70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 28 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 181036.0938 - val_loss: 71.9586\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36333.0469 - val_loss: 78.6447\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17293.0781 - val_loss: 78.7618\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 73318.1562 - val_loss: 83.1664\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43093.5664 - val_loss: 78.4871\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48219.2930 - val_loss: 77.2548\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38917.2383 - val_loss: 79.1254\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21079.5078 - val_loss: 87.0044\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 135417.5000 - val_loss: 90.2427\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 130996.0391 - val_loss: 89.2451\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 73560.8359 - val_loss: 86.4242\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53308.3359 - val_loss: 79.9161\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 105682.1328 - val_loss: 77.4821\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 106679.9766 - val_loss: 79.8408\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 62328.7969 - val_loss: 82.8803\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8353.4502 - val_loss: 86.4841\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55977.1523 - val_loss: 88.0495\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 59064.6445 - val_loss: 87.2568\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18097.9375 - val_loss: 85.6307\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3408.4004 - val_loss: 80.9446\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 124100.0234 - val_loss: 79.2894\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 119399.6172 - val_loss: 80.4716\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 86319.1641 - val_loss: 84.2452\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43565.5703 - val_loss: 88.2527\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55439.6445 - val_loss: 89.7586\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 54490.7969 - val_loss: 88.5122\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18548.6504 - val_loss: 86.4348\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13427.5088 - val_loss: 86.4280\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15620.4307 - val_loss: 88.0795\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14454.6875 - val_loss: 87.5835\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3437.2385 - val_loss: 87.7607\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19051.4727 - val_loss: 88.4120\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15462.5596 - val_loss: 87.4519\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14574.6270 - val_loss: 87.3634\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4000.1816 - val_loss: 88.6727\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18339.4785 - val_loss: 88.6097\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14896.3252 - val_loss: 87.7351\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8843.6436 - val_loss: 87.8885\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2192.2703 - val_loss: 87.5963\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12994.8311 - val_loss: 87.8341\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1555.1821 - val_loss: 87.7724\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29745.7012 - val_loss: 86.8856\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12224.3623 - val_loss: 88.1102\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32691.4219 - val_loss: 89.6975\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24732.4629 - val_loss: 89.0848\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 572.8859 - val_loss: 88.3503\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2351.2961 - val_loss: 89.4599\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29376.1113 - val_loss: 89.6029\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12345.5967 - val_loss: 88.7331\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2487.2908 - val_loss: 85.9879\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f0926310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 29 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 52188.5195 - val_loss: 102.1557\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 239340.9688 - val_loss: 105.0413\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 154378.1250 - val_loss: 100.7078\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 125419.5391 - val_loss: 91.5901\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25166.5820 - val_loss: 90.5210\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49273.6094 - val_loss: 92.4438\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11430.3203 - val_loss: 96.0171\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51480.3438 - val_loss: 96.4612\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43802.1641 - val_loss: 95.6295\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30851.2988 - val_loss: 90.8945\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52473.3633 - val_loss: 90.4183\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66036.2734 - val_loss: 91.6392\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39241.9297 - val_loss: 94.8354\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31101.3711 - val_loss: 96.1118\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21767.5684 - val_loss: 95.1862\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18658.4004 - val_loss: 93.6355\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17192.3066 - val_loss: 94.6153\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15941.9707 - val_loss: 95.3596\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10227.2217 - val_loss: 93.0719\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31180.8027 - val_loss: 93.5477\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22843.1113 - val_loss: 95.3122\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26044.2051 - val_loss: 96.0959\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4371.6108 - val_loss: 94.1060\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49951.4453 - val_loss: 92.5882\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46068.4883 - val_loss: 95.1259\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14546.1797 - val_loss: 95.8908\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7814.0142 - val_loss: 94.2698\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37673.1836 - val_loss: 93.7854\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28080.5664 - val_loss: 95.3191\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12364.0166 - val_loss: 96.0607\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8263.7168 - val_loss: 94.3306\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43218.2305 - val_loss: 93.7757\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23820.4453 - val_loss: 95.5604\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23733.6797 - val_loss: 96.9124\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12852.4014 - val_loss: 95.7967\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3100.1980 - val_loss: 95.7457\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5055.7910 - val_loss: 96.9836\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25759.1348 - val_loss: 96.8972\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8272.8828 - val_loss: 96.0255\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18196.6113 - val_loss: 95.1016\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21520.5254 - val_loss: 96.0265\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6798.6187 - val_loss: 96.2137\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9380.7754 - val_loss: 96.0699\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11826.1172 - val_loss: 96.6504\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3988.2439 - val_loss: 95.8180\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20345.2461 - val_loss: 95.4871\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13565.3564 - val_loss: 96.0775\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9340.8789 - val_loss: 96.8443\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10124.8535 - val_loss: 95.7816\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16024.1592 - val_loss: 96.1155\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f8b5d9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 30 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 133176.9688 - val_loss: 104.2155\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46306.9609 - val_loss: 103.8752\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9633.9609 - val_loss: 95.8822\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 107772.3594 - val_loss: 96.1515\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 85792.2422 - val_loss: 101.4220\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18908.7324 - val_loss: 102.6486\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7568.5542 - val_loss: 97.7411\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 72264.7734 - val_loss: 97.7290\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 60222.6914 - val_loss: 101.3921\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17930.5781 - val_loss: 102.1686\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7277.6348 - val_loss: 101.9248\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39601.8203 - val_loss: 103.7607\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14861.1973 - val_loss: 100.7935\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24787.9609 - val_loss: 99.8454\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27728.0586 - val_loss: 101.3901\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4452.8979 - val_loss: 101.0435\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13732.5381 - val_loss: 101.5775\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7604.8657 - val_loss: 101.1462\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7802.5923 - val_loss: 102.5422\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29677.6094 - val_loss: 102.6248\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9248.4141 - val_loss: 99.7511\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35945.4453 - val_loss: 99.2490\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31912.8906 - val_loss: 100.0827\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8704.3389 - val_loss: 104.7209\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 54816.3320 - val_loss: 105.5383\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 71288.1562 - val_loss: 104.5988\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47366.4883 - val_loss: 101.6632\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23495.9727 - val_loss: 100.2605\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2657.5710 - val_loss: 101.9439\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41787.3945 - val_loss: 103.9064\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45501.3906 - val_loss: 103.2568\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27220.5566 - val_loss: 100.5321\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21662.9824 - val_loss: 100.0498\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21315.9434 - val_loss: 101.3583\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2788.2727 - val_loss: 100.8398\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11582.1650 - val_loss: 101.0277\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3485.8022 - val_loss: 104.1833\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 82476.4375 - val_loss: 105.5624\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 74986.0078 - val_loss: 103.6505\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30414.3848 - val_loss: 101.4558\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21029.2012 - val_loss: 100.3759\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19365.2461 - val_loss: 101.4537\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12066.7676 - val_loss: 101.8764\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3854.9277 - val_loss: 100.1289\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29969.4570 - val_loss: 100.0117\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23418.6719 - val_loss: 100.7274\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1369.5654 - val_loss: 102.5966\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25754.7324 - val_loss: 102.9212\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33336.6562 - val_loss: 102.3433\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16116.9766 - val_loss: 100.6532\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415381820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 31 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 92.3821 - val_loss: 80.8588\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58.1111 - val_loss: 48.3559\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54.7856 - val_loss: 44.2718\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44.6114 - val_loss: 46.8890\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.2010 - val_loss: 38.7345\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32.5321 - val_loss: 33.2866\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.4657 - val_loss: 26.7985\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.8210 - val_loss: 20.9620\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.3779 - val_loss: 14.2258\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.8518 - val_loss: 10.3231\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.7727 - val_loss: 5.2475\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18.1463 - val_loss: 4.4746\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.0042 - val_loss: 4.8934\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.8400 - val_loss: 4.4110\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.7202 - val_loss: 3.7678\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.7033 - val_loss: 5.8510\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.6943 - val_loss: 3.2009\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.3458 - val_loss: 4.0802\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.6130 - val_loss: 3.8409\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.8649 - val_loss: 6.0727\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.1912 - val_loss: 2.8127\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.7573 - val_loss: 4.9124\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.8951 - val_loss: 2.5614\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.0052 - val_loss: 6.3614\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7177 - val_loss: 3.2469\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5009 - val_loss: 5.4739\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.4115 - val_loss: 2.4291\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.3632 - val_loss: 3.5876\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.1929 - val_loss: 7.2509\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5291 - val_loss: 2.5075\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3066 - val_loss: 5.4441\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7413 - val_loss: 2.7589\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5491 - val_loss: 6.6554\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.8112 - val_loss: 2.1240\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3566 - val_loss: 3.9261\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8863 - val_loss: 3.5900\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4829 - val_loss: 4.0039\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9249 - val_loss: 4.2370\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4800 - val_loss: 3.5820\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.2897 - val_loss: 3.4669\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9924 - val_loss: 4.3263\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9350 - val_loss: 2.9481\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7299 - val_loss: 3.4458\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6743 - val_loss: 2.4527\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6451 - val_loss: 4.3532\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8400 - val_loss: 2.1769\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5277 - val_loss: 5.3087\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0710 - val_loss: 1.9764\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1100 - val_loss: 4.1037\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0199 - val_loss: 1.9976\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e4c09d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 32 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 70.5322 - val_loss: 55.8174\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.8911 - val_loss: 29.8439\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.2466 - val_loss: 30.1579\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.2136 - val_loss: 27.0238\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.2324 - val_loss: 6.2748\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.1979 - val_loss: 11.2819\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19.8616 - val_loss: 7.6408\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.5075 - val_loss: 7.3200\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.2860 - val_loss: 7.7690\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.7862 - val_loss: 5.2516\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.8221 - val_loss: 4.2926\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.0307 - val_loss: 5.3824\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.4774 - val_loss: 3.9651\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.3707 - val_loss: 3.8588\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.8867 - val_loss: 3.9387\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.5106 - val_loss: 3.6337\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.2071 - val_loss: 4.0915\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.0705 - val_loss: 3.1917\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.7182 - val_loss: 3.1193\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1232 - val_loss: 2.9454\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.8582 - val_loss: 5.2152\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1422 - val_loss: 2.3512\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.4688 - val_loss: 2.6283\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1186 - val_loss: 3.9489\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0932 - val_loss: 2.9851\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6718 - val_loss: 3.8597\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.5175 - val_loss: 3.8549\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8364 - val_loss: 3.3468\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3785 - val_loss: 2.6440\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2560 - val_loss: 2.0423\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4419 - val_loss: 2.3174\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5352 - val_loss: 3.0756\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4079 - val_loss: 2.1992\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.6943 - val_loss: 3.5752\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9643 - val_loss: 2.1732\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9755 - val_loss: 1.9962\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8919 - val_loss: 1.8139\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.4687 - val_loss: 2.9638\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3981 - val_loss: 1.6684\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7029 - val_loss: 3.0124\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7853 - val_loss: 2.2882\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6709 - val_loss: 4.0888\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3170 - val_loss: 2.6458\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2799 - val_loss: 2.0991\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8710 - val_loss: 1.7313\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6629 - val_loss: 2.6074\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8155 - val_loss: 2.5615\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6682 - val_loss: 2.0775\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6579 - val_loss: 2.0426\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9265 - val_loss: 2.5995\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fb5afa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 33 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 67.1121 - val_loss: 49.6435\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.9333 - val_loss: 17.2210\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.2685 - val_loss: 24.1717\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.8820 - val_loss: 27.6474\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.0104 - val_loss: 15.8727\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.6814 - val_loss: 11.7158\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.8187 - val_loss: 13.3288\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.4525 - val_loss: 5.6403\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7703 - val_loss: 2.4416\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1971 - val_loss: 2.6574\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6003 - val_loss: 3.2175\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4007 - val_loss: 2.4669\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4781 - val_loss: 2.4903\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1291 - val_loss: 4.2844\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.7688 - val_loss: 3.0664\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9252 - val_loss: 2.5637\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6504 - val_loss: 2.9376\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7755 - val_loss: 3.2149\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8235 - val_loss: 2.7980\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2394 - val_loss: 2.4145\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9742 - val_loss: 2.2921\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7144 - val_loss: 2.6091\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5280 - val_loss: 2.4603\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6220 - val_loss: 2.2030\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2011 - val_loss: 2.1143\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0012 - val_loss: 2.4329\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0354 - val_loss: 2.1455\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.8912 - val_loss: 2.0632\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7888 - val_loss: 2.2337\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7483 - val_loss: 2.2413\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6393 - val_loss: 2.0356\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6125 - val_loss: 1.9994\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4771 - val_loss: 1.5685\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.6007 - val_loss: 2.4942\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.4010 - val_loss: 1.9655\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2623 - val_loss: 1.6098\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.4401 - val_loss: 2.0824\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1791 - val_loss: 1.9466\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2383 - val_loss: 1.7103\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.4561 - val_loss: 2.1687\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2128 - val_loss: 1.7438\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.8444 - val_loss: 1.6007\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0194 - val_loss: 2.5954\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.9609 - val_loss: 1.5694\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.9902 - val_loss: 1.6200\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.3893 - val_loss: 2.8924\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1322 - val_loss: 2.0125\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.6200 - val_loss: 2.1323\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4970 - val_loss: 2.2258\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5800 - val_loss: 1.7573\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff414ee5550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 34 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 73674.1094 - val_loss: 123.2118\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 375275.4062 - val_loss: 122.2649\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 221200.6250 - val_loss: 116.0569\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34340.6562 - val_loss: 112.9044\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29914.7539 - val_loss: 112.9797\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26011.4434 - val_loss: 110.5861\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18556.9570 - val_loss: 109.7421\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26905.8281 - val_loss: 109.5683\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11563.2891 - val_loss: 108.9285\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26583.3398 - val_loss: 107.9485\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28138.7734 - val_loss: 105.9201\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49879.5234 - val_loss: 105.9666\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48391.3711 - val_loss: 107.2028\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 83701.6406 - val_loss: 105.4978\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24787.4551 - val_loss: 104.0727\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23690.7754 - val_loss: 105.3193\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7274.2773 - val_loss: 104.9184\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33337.3281 - val_loss: 105.4721\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23335.2559 - val_loss: 105.3960\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5837.8477 - val_loss: 105.8854\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28695.8887 - val_loss: 105.5259\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15083.0391 - val_loss: 105.6749\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24661.0781 - val_loss: 105.8305\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3446.4644 - val_loss: 105.8346\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17708.1641 - val_loss: 104.8047\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22103.6230 - val_loss: 105.2857\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15542.8174 - val_loss: 104.3522\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28116.3789 - val_loss: 104.8837\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34983.8906 - val_loss: 106.6910\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 54872.2812 - val_loss: 106.1069\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28595.7109 - val_loss: 104.3389\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 59617.8008 - val_loss: 104.9695\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7332.3110 - val_loss: 104.9481\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17524.8496 - val_loss: 103.8813\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30196.2871 - val_loss: 103.0767\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9531.8359 - val_loss: 103.0367\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12648.8066 - val_loss: 101.4797\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31746.0430 - val_loss: 101.3034\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17031.2969 - val_loss: 101.6489\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16306.7578 - val_loss: 100.1137\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49598.6992 - val_loss: 99.3710\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28893.7109 - val_loss: 100.8559\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49797.8633 - val_loss: 101.2294\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33265.3672 - val_loss: 100.2698\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57924.8633 - val_loss: 100.1906\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 38986.8867 - val_loss: 101.1404\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18773.5996 - val_loss: 102.0575\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7242.2690 - val_loss: 101.4185\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4999.3423 - val_loss: 101.6195\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12806.8359 - val_loss: 101.1263\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e4c09f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 35 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 84.7125 - val_loss: 65.1536\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.9035 - val_loss: 17.5763\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.5628 - val_loss: 13.6918\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.5629 - val_loss: 30.7340\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20.9053 - val_loss: 30.5881\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.5079 - val_loss: 17.2492\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15.7368 - val_loss: 14.5375\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.2708 - val_loss: 16.9397\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.5822 - val_loss: 12.0862\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.8867 - val_loss: 8.5532\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4398 - val_loss: 8.3108\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3274 - val_loss: 6.1214\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9490 - val_loss: 6.4155\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3390 - val_loss: 5.5493\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1922 - val_loss: 7.0094\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0165 - val_loss: 5.7435\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.9353 - val_loss: 6.8750\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.8636 - val_loss: 6.0741\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.5545 - val_loss: 6.4123\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6856 - val_loss: 3.5729\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7101 - val_loss: 6.5253\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4680 - val_loss: 3.1780\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6884 - val_loss: 4.7181\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3860 - val_loss: 4.1733\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9918 - val_loss: 4.3371\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7083 - val_loss: 4.2265\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6252 - val_loss: 5.4900\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6677 - val_loss: 3.2292\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5908 - val_loss: 4.5849\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.2752 - val_loss: 3.8106\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1784 - val_loss: 2.7891\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1929 - val_loss: 3.8592\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9302 - val_loss: 3.9765\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9791 - val_loss: 2.9226\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7316 - val_loss: 3.4310\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6323 - val_loss: 2.9882\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.5421 - val_loss: 3.2417\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4441 - val_loss: 2.9085\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3648 - val_loss: 3.3750\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3426 - val_loss: 2.4187\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6522 - val_loss: 4.3246\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8162 - val_loss: 2.7336\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8289 - val_loss: 3.2952\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4217 - val_loss: 1.9002\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4042 - val_loss: 1.8375\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2463 - val_loss: 1.8984\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.1525 - val_loss: 1.8894\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.9359 - val_loss: 1.7765\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.9050 - val_loss: 2.3273\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7201 - val_loss: 1.8046\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f51aa1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 36 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 10511.8760 - val_loss: 107.8094\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 154720.3594 - val_loss: 103.2500\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 93009.5234 - val_loss: 106.5666\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66693.9766 - val_loss: 114.1340\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71094.7734 - val_loss: 114.8175\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 89280.3828 - val_loss: 113.0855\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45205.6953 - val_loss: 110.3928\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5448.8589 - val_loss: 109.6403\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2932.1831 - val_loss: 110.7895\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36112.9883 - val_loss: 110.3355\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16692.2109 - val_loss: 109.3237\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18017.8965 - val_loss: 108.1609\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20553.8594 - val_loss: 109.0483\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6169.2188 - val_loss: 108.4155\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8330.0986 - val_loss: 109.1310\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28334.8320 - val_loss: 109.3135\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13408.6582 - val_loss: 106.9368\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44161.4258 - val_loss: 106.3389\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46542.8125 - val_loss: 106.5509\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36745.0703 - val_loss: 108.9061\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52859.1484 - val_loss: 109.6693\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50271.8477 - val_loss: 109.0299\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25019.3164 - val_loss: 106.7303\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36262.6914 - val_loss: 105.5004\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37958.4258 - val_loss: 105.7722\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21895.4141 - val_loss: 107.2306\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13480.3301 - val_loss: 107.2514\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16660.7480 - val_loss: 106.4535\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12144.3672 - val_loss: 106.2591\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1093.6143 - val_loss: 106.2079\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12477.6982 - val_loss: 106.2816\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 825.7177 - val_loss: 106.0187\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9783.7637 - val_loss: 106.4632\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5644.2646 - val_loss: 106.1056\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12307.0859 - val_loss: 106.1769\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3742.2766 - val_loss: 107.4428\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45640.9141 - val_loss: 107.8703\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33121.9258 - val_loss: 106.4985\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2404.7871 - val_loss: 104.6497\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61676.1562 - val_loss: 103.6849\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 51044.5039 - val_loss: 104.1796\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42529.9453 - val_loss: 105.9586\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16118.6367 - val_loss: 106.3086\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23995.7324 - val_loss: 106.0130\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16156.6807 - val_loss: 104.6248\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26558.1816 - val_loss: 104.3535\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22698.1895 - val_loss: 105.0988\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 830.3701 - val_loss: 106.2333\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38423.9844 - val_loss: 106.6472\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33607.2891 - val_loss: 106.0964\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40fad7160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 37 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 91.9403 - val_loss: 66.2253\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.9528 - val_loss: 14.9595\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.7184 - val_loss: 4.0020\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.8688 - val_loss: 21.7645\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.8323 - val_loss: 25.0143\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.3306 - val_loss: 15.2026\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.7512 - val_loss: 9.2699\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.9673 - val_loss: 12.9585\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.6549 - val_loss: 13.9679\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5810 - val_loss: 10.7352\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4745 - val_loss: 9.8762\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5321 - val_loss: 7.2306\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4089 - val_loss: 3.5296\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6534 - val_loss: 2.8710\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5378 - val_loss: 3.7219\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3164 - val_loss: 2.6062\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4893 - val_loss: 2.5704\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.0698 - val_loss: 2.6828\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8921 - val_loss: 2.3868\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8792 - val_loss: 2.7386\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7783 - val_loss: 2.4894\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.7282 - val_loss: 2.5555\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5468 - val_loss: 2.3489\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4800 - val_loss: 2.1738\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4311 - val_loss: 2.2032\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.3825 - val_loss: 2.1587\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.3050 - val_loss: 2.5830\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2974 - val_loss: 2.4187\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1428 - val_loss: 2.1643\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0585 - val_loss: 2.1205\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.9489 - val_loss: 2.2521\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0774 - val_loss: 2.6288\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0789 - val_loss: 2.5180\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2320 - val_loss: 2.4068\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0794 - val_loss: 2.5042\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0208 - val_loss: 2.0384\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5110 - val_loss: 2.8490\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.3246 - val_loss: 2.8319\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.8725 - val_loss: 1.8811\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2364 - val_loss: 2.4362\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4.4940 - val_loss: 4.4430\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9063 - val_loss: 2.9203\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1198 - val_loss: 2.8294\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.6610 - val_loss: 1.7953\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.3037 - val_loss: 1.8271\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2900 - val_loss: 1.8848\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.1894 - val_loss: 1.8950\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3287 - val_loss: 1.7620\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2475 - val_loss: 1.8734\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2018 - val_loss: 1.7725\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f26294c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 38 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 98.1183 - val_loss: 81.1111\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 53.1284 - val_loss: 40.5059\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.9518 - val_loss: 23.6605\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.2726 - val_loss: 36.8824\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.8025 - val_loss: 39.0141\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26.9235 - val_loss: 24.8061\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.7119 - val_loss: 15.2137\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19.7414 - val_loss: 23.3275\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.5735 - val_loss: 12.8965\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.8079 - val_loss: 7.4154\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.1598 - val_loss: 12.8553\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.9617 - val_loss: 3.0298\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.7696 - val_loss: 4.2881\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.7084 - val_loss: 5.1047\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.2343 - val_loss: 5.1687\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.5780 - val_loss: 5.6925\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.7222 - val_loss: 3.6166\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7538 - val_loss: 6.8834\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.9509 - val_loss: 3.4511\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.3908 - val_loss: 5.0910\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8774 - val_loss: 4.6970\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1927 - val_loss: 5.7135\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1950 - val_loss: 3.3404\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9487 - val_loss: 5.7802\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0574 - val_loss: 4.3646\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7234 - val_loss: 4.7959\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7658 - val_loss: 3.7452\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9368 - val_loss: 4.8502\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5855 - val_loss: 4.5627\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4472 - val_loss: 4.2016\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5670 - val_loss: 5.0985\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1730 - val_loss: 4.2117\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.8833 - val_loss: 6.0549\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0450 - val_loss: 3.8843\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8066 - val_loss: 4.2946\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5047 - val_loss: 4.4400\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.3815 - val_loss: 4.3333\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.2878 - val_loss: 3.4038\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5665 - val_loss: 5.4740\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.6746 - val_loss: 2.9365\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6852 - val_loss: 6.5263\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9574 - val_loss: 2.8834\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.6057 - val_loss: 7.0880\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2280 - val_loss: 3.4912\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6857 - val_loss: 3.8878\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.7607 - val_loss: 3.7796\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7402 - val_loss: 2.9827\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.2726 - val_loss: 4.9001\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8638 - val_loss: 3.4061\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7587 - val_loss: 3.7984\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415518940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 39 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 163694.1719 - val_loss: 89.8920\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 221687.6875 - val_loss: 94.2756\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36690.2305 - val_loss: 100.9838\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 133782.3906 - val_loss: 100.9685\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30057.1309 - val_loss: 98.5687\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14202.7939 - val_loss: 99.7497\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64782.1523 - val_loss: 99.0591\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29336.5234 - val_loss: 98.1673\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11848.3623 - val_loss: 99.8598\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18328.5215 - val_loss: 100.5894\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16238.3145 - val_loss: 105.1060\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 142625.2031 - val_loss: 106.7115\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 92148.4844 - val_loss: 104.1723\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10291.4014 - val_loss: 103.2726\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25625.4180 - val_loss: 103.5493\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16400.1816 - val_loss: 102.0522\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42317.9141 - val_loss: 100.9234\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17993.9531 - val_loss: 102.1451\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64125.1328 - val_loss: 102.4453\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50803.5547 - val_loss: 100.6557\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34040.3477 - val_loss: 100.2931\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17430.4805 - val_loss: 100.7135\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10823.8877 - val_loss: 98.3608\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 67145.6250 - val_loss: 97.7431\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44559.8164 - val_loss: 99.6206\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38574.0586 - val_loss: 99.3882\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18030.3652 - val_loss: 98.6052\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38084.0195 - val_loss: 97.5869\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27725.0000 - val_loss: 99.7100\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 78902.1016 - val_loss: 100.4306\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 54569.3477 - val_loss: 98.8163\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24461.1797 - val_loss: 98.7792\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9587.5332 - val_loss: 99.0730\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6391.2778 - val_loss: 97.1869\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58375.2031 - val_loss: 97.0412\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42601.0742 - val_loss: 98.3597\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52590.4688 - val_loss: 98.8564\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33326.0234 - val_loss: 98.1155\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 38579.5234 - val_loss: 95.7576\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 74113.0391 - val_loss: 95.9046\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50067.1875 - val_loss: 97.4161\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 58988.5117 - val_loss: 97.8783\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58078.7969 - val_loss: 96.6221\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28733.9512 - val_loss: 96.8556\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16935.6738 - val_loss: 98.0698\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8370.8223 - val_loss: 97.8262\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7006.6201 - val_loss: 98.4958\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11319.5752 - val_loss: 98.0863\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33090.1133 - val_loss: 98.0234\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16926.9258 - val_loss: 99.8375\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff400334790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 40 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 97.0229 - val_loss: 85.3424\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 79.6455 - val_loss: 74.1916\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66.2855 - val_loss: 57.3439\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52.4212 - val_loss: 39.2113\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.8412 - val_loss: 37.1162\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.9207 - val_loss: 26.4522\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.8290 - val_loss: 17.7993\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36.1423 - val_loss: 28.0730\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35.1195 - val_loss: 23.7784\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.0107 - val_loss: 14.0873\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.4649 - val_loss: 13.7034\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26.5743 - val_loss: 10.0149\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25.1624 - val_loss: 8.7045\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22.7246 - val_loss: 11.3990\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.1451 - val_loss: 5.9505\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.2190 - val_loss: 3.5137\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.3414 - val_loss: 5.6423\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.9059 - val_loss: 8.1246\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.4335 - val_loss: 3.8974\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2144 - val_loss: 4.0832\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.7754 - val_loss: 4.2602\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.5072 - val_loss: 7.3811\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.3770 - val_loss: 2.6890\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.4731 - val_loss: 5.1381\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4441 - val_loss: 6.7383\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0409 - val_loss: 2.5803\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2489 - val_loss: 5.9219\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.4443 - val_loss: 4.3595\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.3514 - val_loss: 3.5082\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.1856 - val_loss: 10.6043\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.1975 - val_loss: 2.6425\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.9008 - val_loss: 2.3571\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.9496 - val_loss: 9.4079\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2443 - val_loss: 2.5132\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6455 - val_loss: 3.1236\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4826 - val_loss: 4.5010\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2937 - val_loss: 4.3553\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9026 - val_loss: 3.9401\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8042 - val_loss: 3.3509\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7891 - val_loss: 4.1821\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1463 - val_loss: 2.9575\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0825 - val_loss: 5.8726\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0729 - val_loss: 2.8468\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.7677 - val_loss: 2.6603\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.5862 - val_loss: 4.4217\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2116 - val_loss: 2.6372\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.3054 - val_loss: 4.1863\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1089 - val_loss: 2.9300\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.5877 - val_loss: 3.3761\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9930 - val_loss: 3.2708\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3eff75c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 41 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 184339.3594 - val_loss: 85.8184\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 123303.8047 - val_loss: 99.1677\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 205312.0000 - val_loss: 103.1634\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 185267.3906 - val_loss: 101.0606\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 99790.6172 - val_loss: 98.2196\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2348.3562 - val_loss: 95.0274\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66717.1484 - val_loss: 92.7752\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 86296.6875 - val_loss: 93.7753\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42135.0898 - val_loss: 95.1353\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1937.3446 - val_loss: 96.4655\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9950.1670 - val_loss: 95.8661\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18228.8281 - val_loss: 96.2001\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2343.2859 - val_loss: 97.7333\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 51374.5781 - val_loss: 98.0089\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36554.8008 - val_loss: 97.1371\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7427.0195 - val_loss: 94.8704\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 80008.3594 - val_loss: 93.9891\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 77676.7266 - val_loss: 95.6161\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21731.6875 - val_loss: 97.1402\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21684.6562 - val_loss: 97.9073\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20837.1504 - val_loss: 97.4135\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8054.0845 - val_loss: 97.2845\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5045.4893 - val_loss: 97.0692\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7890.5664 - val_loss: 97.4966\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6524.9561 - val_loss: 96.9745\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25901.8965 - val_loss: 96.8265\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10195.3037 - val_loss: 98.1786\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42261.0469 - val_loss: 98.8537\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32992.2305 - val_loss: 98.1115\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 650.0109 - val_loss: 96.3067\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 57426.9219 - val_loss: 95.6658\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58197.7188 - val_loss: 96.7148\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26401.1191 - val_loss: 98.4673\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30768.2871 - val_loss: 98.9648\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25933.4766 - val_loss: 98.1984\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7616.1030 - val_loss: 98.0982\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3278.5212 - val_loss: 97.7064\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12646.7900 - val_loss: 98.1776\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2065.9343 - val_loss: 97.5816\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24655.5781 - val_loss: 97.7645\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9816.0576 - val_loss: 99.1073\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25047.6348 - val_loss: 99.0518\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21022.8691 - val_loss: 98.6923\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19378.2207 - val_loss: 97.8049\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15652.7207 - val_loss: 99.3145\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26826.7773 - val_loss: 99.2373\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21264.3047 - val_loss: 98.8829\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11548.5449 - val_loss: 98.1692\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8639.2744 - val_loss: 98.5734\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9204.8975 - val_loss: 98.9812\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff414d78b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 42 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 96672.5625 - val_loss: 111.8020\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 140475.1562 - val_loss: 114.7098\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 89634.8359 - val_loss: 108.4184\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6157.0420 - val_loss: 100.7767\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 138428.2812 - val_loss: 97.4148\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 128504.6016 - val_loss: 99.6173\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52075.4648 - val_loss: 102.2714\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28417.4336 - val_loss: 104.3119\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8776.9824 - val_loss: 102.3631\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44090.9180 - val_loss: 101.1878\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35830.6680 - val_loss: 102.1915\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6441.3955 - val_loss: 103.8191\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5009.8228 - val_loss: 102.6353\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34729.3398 - val_loss: 102.1650\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22069.8711 - val_loss: 104.0122\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6244.9214 - val_loss: 103.9523\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3812.0608 - val_loss: 103.1169\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18360.8809 - val_loss: 103.1412\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10193.6934 - val_loss: 104.8627\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41634.6758 - val_loss: 105.6106\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18810.9746 - val_loss: 103.5584\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30221.1484 - val_loss: 102.2315\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27407.5820 - val_loss: 102.8352\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7483.2837 - val_loss: 104.0438\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6167.2261 - val_loss: 102.3869\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34103.1172 - val_loss: 102.4024\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17937.3223 - val_loss: 103.6061\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18410.8184 - val_loss: 104.4170\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14993.9258 - val_loss: 102.6355\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28519.8066 - val_loss: 102.5251\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15060.8486 - val_loss: 103.5890\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7477.3823 - val_loss: 103.7831\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3723.9783 - val_loss: 103.0273\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9755.8350 - val_loss: 103.2118\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5190.0137 - val_loss: 104.4662\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28395.9902 - val_loss: 104.5075\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16683.4023 - val_loss: 103.1598\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26427.5156 - val_loss: 102.3341\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13636.6592 - val_loss: 104.0300\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20110.5469 - val_loss: 104.3636\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20222.0645 - val_loss: 103.5055\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3384.1860 - val_loss: 101.3360\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40227.1094 - val_loss: 101.2802\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40575.5156 - val_loss: 102.4285\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16247.1758 - val_loss: 104.2528\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27544.3887 - val_loss: 104.3372\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22698.7012 - val_loss: 103.6699\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6007.0493 - val_loss: 101.7468\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28807.4902 - val_loss: 101.5252\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33735.4883 - val_loss: 102.0911\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fb709670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 43 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 75.1308 - val_loss: 57.4022\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.9831 - val_loss: 34.0618\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38.6888 - val_loss: 37.8524\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32.9715 - val_loss: 39.5368\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 28.9616 - val_loss: 29.0017\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24.6726 - val_loss: 20.6245\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.6595 - val_loss: 20.2894\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.6163 - val_loss: 10.4609\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.4159 - val_loss: 5.6910\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.2032 - val_loss: 7.9934\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.0284 - val_loss: 4.4194\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.3147 - val_loss: 9.3016\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.8338 - val_loss: 3.9333\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2150 - val_loss: 4.1496\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.6891 - val_loss: 4.4198\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3366 - val_loss: 3.2665\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7787 - val_loss: 3.5083\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9149 - val_loss: 2.3277\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7539 - val_loss: 4.7176\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.5851 - val_loss: 2.1881\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.8042 - val_loss: 3.4492\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7249 - val_loss: 2.1422\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9450 - val_loss: 3.6613\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5096 - val_loss: 1.8891\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3799 - val_loss: 1.9939\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1698 - val_loss: 2.7617\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.2643 - val_loss: 1.9649\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2813 - val_loss: 3.9053\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1881 - val_loss: 1.9472\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7946 - val_loss: 1.8490\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4151 - val_loss: 1.9594\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5175 - val_loss: 3.5841\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3262 - val_loss: 1.8784\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9207 - val_loss: 1.7923\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9888 - val_loss: 1.9352\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6988 - val_loss: 2.4511\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4824 - val_loss: 1.5784\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4215 - val_loss: 2.3706\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2506 - val_loss: 1.5753\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5054 - val_loss: 3.0868\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1172 - val_loss: 1.9212\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4763 - val_loss: 1.5247\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2394 - val_loss: 1.4828\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.9385 - val_loss: 2.1623\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2355 - val_loss: 2.4022\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8076 - val_loss: 3.0810\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2708 - val_loss: 2.2293\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8463 - val_loss: 1.5009\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9486 - val_loss: 2.6246\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1830 - val_loss: 2.0120\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fb515dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 44 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 83.8206 - val_loss: 64.2180\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58.4232 - val_loss: 36.3701\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52.4161 - val_loss: 36.0769\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.3239 - val_loss: 39.0586\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.5268 - val_loss: 27.4327\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 29.5107 - val_loss: 22.9123\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.4440 - val_loss: 19.7886\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.4262 - val_loss: 10.2595\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.1809 - val_loss: 7.2576\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.7459 - val_loss: 6.3556\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.1162 - val_loss: 3.8009\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.2571 - val_loss: 5.3021\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.7176 - val_loss: 4.5663\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.7403 - val_loss: 7.8204\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.9608 - val_loss: 3.7854\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.5438 - val_loss: 7.3067\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.9054 - val_loss: 5.8127\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7347 - val_loss: 5.3190\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2095 - val_loss: 7.0923\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1683 - val_loss: 3.8074\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3930 - val_loss: 7.6570\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5862 - val_loss: 4.2818\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.3764 - val_loss: 7.4956\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9861 - val_loss: 4.5269\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6373 - val_loss: 7.6650\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3309 - val_loss: 3.4339\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5126 - val_loss: 7.4098\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9163 - val_loss: 3.7455\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5747 - val_loss: 6.2546\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0877 - val_loss: 4.8491\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7924 - val_loss: 3.6573\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5304 - val_loss: 5.8706\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2723 - val_loss: 4.2498\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3640 - val_loss: 4.0169\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3850 - val_loss: 6.1082\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4424 - val_loss: 3.3839\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4962 - val_loss: 5.4233\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8806 - val_loss: 4.1275\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1531 - val_loss: 5.2800\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0941 - val_loss: 4.5994\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6910 - val_loss: 3.8755\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0145 - val_loss: 4.2973\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0512 - val_loss: 6.0643\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6510 - val_loss: 3.2302\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5672 - val_loss: 6.2217\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5784 - val_loss: 3.2859\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8261 - val_loss: 4.9075\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5355 - val_loss: 4.8350\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9953 - val_loss: 3.7824\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2810 - val_loss: 4.3052\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f51aa820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 45 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 46864.2930 - val_loss: 110.8147\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 149513.8750 - val_loss: 114.6573\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 107463.5625 - val_loss: 107.4942\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5815.9590 - val_loss: 100.5885\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 99524.7422 - val_loss: 98.8870\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 94710.9688 - val_loss: 100.7219\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37216.2070 - val_loss: 103.1908\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28284.2871 - val_loss: 103.3972\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22633.9180 - val_loss: 102.1472\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4437.5195 - val_loss: 102.5372\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6733.7427 - val_loss: 102.0316\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15147.8389 - val_loss: 102.2527\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1980.6476 - val_loss: 102.1505\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39610.5703 - val_loss: 101.0525\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25069.4004 - val_loss: 103.0326\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7225.7334 - val_loss: 103.2524\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10297.6221 - val_loss: 102.4657\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29029.8789 - val_loss: 101.9833\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11039.4297 - val_loss: 103.9948\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46515.9883 - val_loss: 105.0217\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44477.8438 - val_loss: 103.6262\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5241.1797 - val_loss: 103.2223\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11697.4814 - val_loss: 103.4275\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5245.6211 - val_loss: 101.8963\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43228.0312 - val_loss: 101.5710\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34634.9883 - val_loss: 103.0802\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12005.3828 - val_loss: 103.5904\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5770.9360 - val_loss: 102.2285\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36561.6758 - val_loss: 101.7895\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24466.7754 - val_loss: 102.5583\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6106.2788 - val_loss: 105.1456\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 66405.0781 - val_loss: 106.2887\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 67374.7266 - val_loss: 105.5406\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39908.3633 - val_loss: 104.2165\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4238.1865 - val_loss: 102.3952\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45185.7227 - val_loss: 101.1148\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43399.2539 - val_loss: 102.3842\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1516.6017 - val_loss: 103.4271\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23936.0039 - val_loss: 104.3511\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30828.3457 - val_loss: 103.9295\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14448.5869 - val_loss: 102.7461\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5329.4165 - val_loss: 102.6505\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7513.9458 - val_loss: 103.0106\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14516.2207 - val_loss: 103.4104\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3853.7993 - val_loss: 102.1393\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31995.5195 - val_loss: 101.4944\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28537.8809 - val_loss: 101.8685\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1423.9548 - val_loss: 103.2333\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33066.3242 - val_loss: 104.4831\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41925.5273 - val_loss: 104.4610\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fd37cf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 46 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 8772.3594 - val_loss: 109.7424\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 224003.3125 - val_loss: 106.1858\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 135745.7188 - val_loss: 102.8818\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 63078.2188 - val_loss: 97.5219\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40567.6406 - val_loss: 95.6319\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41520.3867 - val_loss: 97.5633\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3822.6052 - val_loss: 100.9030\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 91122.7812 - val_loss: 102.0152\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 76031.0703 - val_loss: 100.9180\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20443.8320 - val_loss: 98.8779\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42328.4492 - val_loss: 96.8823\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48036.2969 - val_loss: 98.0300\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6486.2007 - val_loss: 99.3650\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30400.9277 - val_loss: 100.5902\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37260.6055 - val_loss: 99.9850\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13854.0605 - val_loss: 98.1836\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34852.4102 - val_loss: 97.9430\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32102.5098 - val_loss: 98.7624\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 755.0989 - val_loss: 100.3809\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 60734.1250 - val_loss: 101.3552\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46110.7109 - val_loss: 100.2746\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 857.2261 - val_loss: 98.7445\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56047.6523 - val_loss: 97.1605\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54280.6992 - val_loss: 98.1780\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13308.0908 - val_loss: 99.2326\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 17519.9434 - val_loss: 100.1641\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26429.3359 - val_loss: 99.9667\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2388.4771 - val_loss: 99.0925\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40841.6016 - val_loss: 98.0021\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34846.5664 - val_loss: 98.5858\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6728.9780 - val_loss: 99.7311\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38714.1719 - val_loss: 100.5734\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36209.4570 - val_loss: 99.4752\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10941.6895 - val_loss: 99.0893\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6736.5601 - val_loss: 100.3518\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44865.9258 - val_loss: 100.7540\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40914.5195 - val_loss: 100.0061\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8322.7549 - val_loss: 99.1419\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24706.1719 - val_loss: 98.5817\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23713.8887 - val_loss: 99.1667\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2118.1313 - val_loss: 100.1720\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35874.4805 - val_loss: 100.4246\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32808.7305 - val_loss: 99.9042\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18247.2598 - val_loss: 98.7334\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27288.0371 - val_loss: 98.4794\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23530.5898 - val_loss: 98.7586\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16833.1367 - val_loss: 100.1822\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44536.3945 - val_loss: 100.7172\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43446.3320 - val_loss: 100.2852\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23388.4648 - val_loss: 99.4644\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fe130160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 47 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2274\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f2629a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 48 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 129110.6172 - val_loss: 88.2708\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 70069.1641 - val_loss: 92.2595\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38281.0117 - val_loss: 86.2932\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44163.9922 - val_loss: 86.7691\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32289.2559 - val_loss: 88.6394\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6024.6860 - val_loss: 88.8347\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3383.1328 - val_loss: 91.3734\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43635.0000 - val_loss: 90.5325\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10766.6094 - val_loss: 88.3288\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38009.7812 - val_loss: 87.4232\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32500.0469 - val_loss: 90.4378\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41811.8750 - val_loss: 91.4977\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17336.4160 - val_loss: 88.3986\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26598.6934 - val_loss: 88.1996\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35125.1523 - val_loss: 90.0381\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 223.0268 - val_loss: 89.5887\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22630.6230 - val_loss: 89.9759\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2130.6621 - val_loss: 89.9781\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18769.1738 - val_loss: 90.2263\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8740.0801 - val_loss: 90.5725\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14762.6328 - val_loss: 90.3430\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2610.2124 - val_loss: 90.5964\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4619.7617 - val_loss: 91.3186\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22902.0801 - val_loss: 91.5571\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13839.5342 - val_loss: 89.2548\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43035.9258 - val_loss: 89.1873\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25502.8906 - val_loss: 90.4083\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25563.3691 - val_loss: 92.4058\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19163.4316 - val_loss: 90.5112\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29612.6973 - val_loss: 90.2420\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19196.9824 - val_loss: 91.3674\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21455.8789 - val_loss: 92.4015\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11413.2490 - val_loss: 90.4272\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41664.6211 - val_loss: 90.1129\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34256.2930 - val_loss: 91.0243\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14175.0117 - val_loss: 94.8303\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55505.8086 - val_loss: 95.4335\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55761.5508 - val_loss: 94.1848\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22219.0684 - val_loss: 92.8608\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1394.8508 - val_loss: 92.5056\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 229.6948 - val_loss: 93.3067\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37815.6992 - val_loss: 93.8355\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19444.9434 - val_loss: 92.2426\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30425.4609 - val_loss: 91.6553\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27960.8164 - val_loss: 92.9516\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 222.3129 - val_loss: 94.9669\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35426.4570 - val_loss: 95.0387\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36671.3086 - val_loss: 94.5253\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8843.2051 - val_loss: 93.2780\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27014.4531 - val_loss: 92.0182\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fb709a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 49 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 84.6960 - val_loss: 70.1938\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47.0208 - val_loss: 39.1538\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43.3020 - val_loss: 33.1176\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.1385 - val_loss: 33.2727\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26.2886 - val_loss: 24.2413\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.9879 - val_loss: 14.7997\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.8066 - val_loss: 10.8412\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.4173 - val_loss: 5.7144\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.0764 - val_loss: 5.2114\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.8384 - val_loss: 7.0096\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.4301 - val_loss: 2.4977\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.0106 - val_loss: 3.1652\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.9284 - val_loss: 3.0404\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.2254 - val_loss: 5.1615\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.2001 - val_loss: 2.9952\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.6167 - val_loss: 3.4393\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.1668 - val_loss: 3.1987\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5927 - val_loss: 3.0860\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2144 - val_loss: 4.0579\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8191 - val_loss: 3.0093\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9731 - val_loss: 3.9316\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8205 - val_loss: 3.1091\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2822 - val_loss: 3.3745\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8774 - val_loss: 3.1997\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2604 - val_loss: 3.5545\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9391 - val_loss: 3.1658\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.6221 - val_loss: 2.7403\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3374 - val_loss: 6.3727\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7437 - val_loss: 3.1674\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0828 - val_loss: 5.4867\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6361 - val_loss: 3.4657\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0638 - val_loss: 4.9427\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4965 - val_loss: 3.4524\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6411 - val_loss: 5.0701\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2530 - val_loss: 3.2456\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2872 - val_loss: 3.1239\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4123 - val_loss: 3.2493\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3113 - val_loss: 2.9954\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1851 - val_loss: 2.7212\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.4271 - val_loss: 4.1109\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2590 - val_loss: 2.8485\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9882 - val_loss: 2.8149\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7871 - val_loss: 2.8089\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9660 - val_loss: 4.3382\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9934 - val_loss: 2.9413\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9552 - val_loss: 2.9668\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0673 - val_loss: 3.2133\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5470 - val_loss: 2.7764\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6160 - val_loss: 4.4653\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6287 - val_loss: 2.8541\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4042b0790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 50 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 84.2234 - val_loss: 65.4209\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.2888 - val_loss: 22.5491\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.1133 - val_loss: 22.7889\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26.3115 - val_loss: 34.7859\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.0836 - val_loss: 24.4862\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.0450 - val_loss: 9.4531\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.1598 - val_loss: 14.1278\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.9885 - val_loss: 4.0630\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.3957 - val_loss: 6.1543\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6068 - val_loss: 3.9178\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9422 - val_loss: 5.6853\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7452 - val_loss: 5.6428\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2610 - val_loss: 6.0847\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9924 - val_loss: 4.5499\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.0135 - val_loss: 6.6633\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6247 - val_loss: 3.8312\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8129 - val_loss: 7.4290\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1633 - val_loss: 3.9387\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0623 - val_loss: 5.3690\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4162 - val_loss: 3.8876\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5189 - val_loss: 6.1788\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6988 - val_loss: 3.5317\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7192 - val_loss: 5.4635\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8328 - val_loss: 3.6763\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9311 - val_loss: 5.0034\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1172 - val_loss: 5.0230\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1075 - val_loss: 3.3761\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8698 - val_loss: 3.7555\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4337 - val_loss: 4.0059\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3448 - val_loss: 3.7228\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5447 - val_loss: 3.2834\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5136 - val_loss: 5.0734\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5986 - val_loss: 3.2796\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9070 - val_loss: 3.2727\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3256 - val_loss: 4.1624\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2481 - val_loss: 3.3033\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.1304 - val_loss: 3.4181\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1827 - val_loss: 3.1874\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2178 - val_loss: 3.6674\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.1345 - val_loss: 3.6005\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0881 - val_loss: 3.3688\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2379 - val_loss: 3.3534\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7848 - val_loss: 3.2198\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8270 - val_loss: 3.2548\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9661 - val_loss: 2.9166\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2529 - val_loss: 2.9474\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9430 - val_loss: 3.5222\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8604 - val_loss: 2.8677\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9108 - val_loss: 3.2709\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1439 - val_loss: 3.2469\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fa09dca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 51 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 745925.1875 - val_loss: 76.6415\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 399081.0000 - val_loss: 95.9610\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 170452.4062 - val_loss: 100.5094\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 126466.8125 - val_loss: 97.1022\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47640.3945 - val_loss: 94.6641\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5681.7642 - val_loss: 94.6271\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28304.6836 - val_loss: 94.5099\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33273.7148 - val_loss: 97.1858\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 111085.6016 - val_loss: 98.9005\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29442.9512 - val_loss: 93.9266\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 164576.5625 - val_loss: 90.1545\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 151688.2969 - val_loss: 95.4735\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64052.0508 - val_loss: 97.4707\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6916.8428 - val_loss: 96.2361\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71736.4375 - val_loss: 97.7918\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54424.6953 - val_loss: 92.4039\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 150912.7500 - val_loss: 90.6658\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 131824.7969 - val_loss: 93.3255\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 50260.7695 - val_loss: 98.2979\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 68757.3672 - val_loss: 98.8135\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 83711.2266 - val_loss: 96.7985\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3975.5708 - val_loss: 93.3720\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 108424.1328 - val_loss: 92.2414\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 101772.3906 - val_loss: 95.1844\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20100.7168 - val_loss: 96.0799\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45114.0742 - val_loss: 94.8322\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18756.2480 - val_loss: 98.7642\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 96973.1719 - val_loss: 99.3895\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 94473.5000 - val_loss: 97.7459\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24579.8262 - val_loss: 94.3711\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 84157.9219 - val_loss: 93.1670\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 80692.6484 - val_loss: 95.2627\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11452.5518 - val_loss: 98.7939\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 123193.6328 - val_loss: 100.1844\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 105786.9297 - val_loss: 99.0591\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 83121.2578 - val_loss: 94.0357\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 100672.8125 - val_loss: 92.5292\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 106644.9141 - val_loss: 93.7730\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49862.6875 - val_loss: 96.5389\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10820.9551 - val_loss: 96.8510\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21347.2656 - val_loss: 95.7438\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39774.6055 - val_loss: 95.3355\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15441.8418 - val_loss: 97.4280\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34806.3203 - val_loss: 97.3917\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33037.6523 - val_loss: 95.7637\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40035.2539 - val_loss: 95.3851\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26507.0332 - val_loss: 98.1021\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 92641.8281 - val_loss: 99.0963\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 81960.5312 - val_loss: 95.9459\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48647.2070 - val_loss: 94.9496\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f492e550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 52 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 31596.6250 - val_loss: 86.5606\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 252693.6250 - val_loss: 90.0168\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 156008.8750 - val_loss: 94.0031\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 83579.9766 - val_loss: 102.1032\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 84696.2578 - val_loss: 104.3874\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 77112.5234 - val_loss: 100.7136\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1722.7896 - val_loss: 101.1579\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16495.4434 - val_loss: 99.1786\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26049.0605 - val_loss: 100.1900\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8832.8975 - val_loss: 99.5051\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33503.0820 - val_loss: 99.0087\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6827.6987 - val_loss: 100.0782\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 695.7687 - val_loss: 101.8061\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42137.0781 - val_loss: 101.1860\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21784.1992 - val_loss: 97.5810\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45496.9297 - val_loss: 97.8057\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37894.8359 - val_loss: 99.0008\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8701.2324 - val_loss: 99.8835\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2422.2820 - val_loss: 101.0633\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37559.0508 - val_loss: 101.0762\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13524.0303 - val_loss: 98.4064\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64311.1445 - val_loss: 96.7910\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 57675.1172 - val_loss: 100.1036\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38302.4062 - val_loss: 101.3716\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14759.5430 - val_loss: 99.1592\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48985.7188 - val_loss: 97.4365\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39613.6797 - val_loss: 99.8146\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19829.9961 - val_loss: 100.3226\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12991.5391 - val_loss: 98.5826\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20555.4961 - val_loss: 98.9735\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8184.6992 - val_loss: 99.7419\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14242.4922 - val_loss: 100.4654\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19376.1191 - val_loss: 99.2470\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22915.7109 - val_loss: 98.7846\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8609.9189 - val_loss: 101.4732\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 71535.1562 - val_loss: 102.7898\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 55164.0000 - val_loss: 101.2029\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4652.5908 - val_loss: 98.9800\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48594.4883 - val_loss: 96.8888\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55717.3828 - val_loss: 97.6237\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27915.6973 - val_loss: 98.9058\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9836.0918 - val_loss: 101.7080\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66223.2969 - val_loss: 102.4599\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 65864.2344 - val_loss: 101.3446\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37686.1953 - val_loss: 99.4381\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5686.7261 - val_loss: 99.1502\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4448.5195 - val_loss: 100.1841\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22602.9219 - val_loss: 99.9776\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8231.7451 - val_loss: 99.2794\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1433.8051 - val_loss: 98.8560\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ff58e1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 53 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 77.6914 - val_loss: 57.4951\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.9205 - val_loss: 10.6053\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26.5309 - val_loss: 4.8094\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.8582 - val_loss: 23.7496\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.7109 - val_loss: 26.0409\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.6329 - val_loss: 15.5479\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.3521 - val_loss: 7.4554\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.1464 - val_loss: 13.0838\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.2166 - val_loss: 13.1946\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.3685 - val_loss: 7.5671\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.1660 - val_loss: 10.7253\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5559 - val_loss: 5.7422\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8144 - val_loss: 3.5972\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2088 - val_loss: 3.2407\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1586 - val_loss: 3.0444\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9331 - val_loss: 3.2971\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8715 - val_loss: 4.3347\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8289 - val_loss: 3.0645\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6420 - val_loss: 4.0190\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7892 - val_loss: 2.8022\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.3026 - val_loss: 2.7896\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5991 - val_loss: 2.8219\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7066 - val_loss: 2.8596\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6522 - val_loss: 2.8657\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0590 - val_loss: 3.2858\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1654 - val_loss: 2.9401\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8927 - val_loss: 2.6839\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5822 - val_loss: 4.5260\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9667 - val_loss: 2.9992\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6737 - val_loss: 3.1900\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.0511 - val_loss: 3.1536\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5676 - val_loss: 3.6301\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2216 - val_loss: 3.4286\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8276 - val_loss: 2.8941\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7924 - val_loss: 3.6396\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8289 - val_loss: 2.7965\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9164 - val_loss: 2.7458\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6578 - val_loss: 3.1456\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6107 - val_loss: 2.7423\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2435 - val_loss: 2.6890\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2791 - val_loss: 2.8498\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.9990 - val_loss: 2.6425\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.9894 - val_loss: 3.2541\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9600 - val_loss: 2.5947\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0306 - val_loss: 2.6488\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.7980 - val_loss: 2.7426\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0654 - val_loss: 2.4453\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.8433 - val_loss: 2.5282\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.8117 - val_loss: 2.4329\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7604 - val_loss: 2.4100\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4055e9e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 54 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 92516.7266 - val_loss: 108.9161\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18680.9531 - val_loss: 106.4736\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23674.2012 - val_loss: 107.4332\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9681.5781 - val_loss: 106.7964\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12455.2920 - val_loss: 106.4530\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3279.5789 - val_loss: 105.7822\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12507.6318 - val_loss: 107.6342\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71489.1484 - val_loss: 108.3166\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31268.4570 - val_loss: 104.8865\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61603.0742 - val_loss: 105.3741\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12417.6035 - val_loss: 107.2847\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28470.6582 - val_loss: 106.3548\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16300.2334 - val_loss: 106.8011\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26611.4180 - val_loss: 106.6916\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2711.1824 - val_loss: 102.1182\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 166683.2969 - val_loss: 101.3831\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 170205.7500 - val_loss: 102.9010\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 73340.6719 - val_loss: 106.1186\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 131565.8906 - val_loss: 107.2359\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 67330.6484 - val_loss: 104.3721\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46200.6445 - val_loss: 104.3218\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25318.5117 - val_loss: 106.6960\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 65805.3438 - val_loss: 106.9494\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36831.4453 - val_loss: 105.2957\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43520.5312 - val_loss: 104.0151\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31186.4805 - val_loss: 104.3834\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28025.1191 - val_loss: 105.8127\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 61389.8945 - val_loss: 105.2493\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37525.7500 - val_loss: 103.8364\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47656.2734 - val_loss: 103.6300\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26041.3008 - val_loss: 104.1006\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34533.2422 - val_loss: 104.8772\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24921.9082 - val_loss: 104.0165\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4411.5859 - val_loss: 104.0543\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5822.2334 - val_loss: 103.9104\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8384.4697 - val_loss: 104.3232\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10610.0146 - val_loss: 103.7821\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11537.7715 - val_loss: 103.9602\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1689.1949 - val_loss: 103.3138\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30469.4043 - val_loss: 103.6591\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8711.3467 - val_loss: 104.0231\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11762.2734 - val_loss: 103.2948\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25951.2949 - val_loss: 103.4008\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4793.6650 - val_loss: 103.6535\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10657.6377 - val_loss: 103.0190\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25286.1055 - val_loss: 103.1824\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4344.9395 - val_loss: 103.4315\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11126.8516 - val_loss: 102.8561\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26002.7715 - val_loss: 102.8324\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4280.4487 - val_loss: 103.6110\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f2182940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 55 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 46564.1641 - val_loss: 92.3039\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 140877.4375 - val_loss: 96.1103\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 113784.9375 - val_loss: 90.2713\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2751.5093 - val_loss: 90.4019\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8392.2002 - val_loss: 88.5826\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32483.4238 - val_loss: 89.4277\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7821.3320 - val_loss: 92.0830\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37075.8398 - val_loss: 92.3958\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30340.3086 - val_loss: 89.9135\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35458.3438 - val_loss: 89.1926\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19762.5156 - val_loss: 92.7651\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52027.0234 - val_loss: 93.9250\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 47437.8984 - val_loss: 93.1122\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16937.9824 - val_loss: 90.5058\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39427.3945 - val_loss: 89.6897\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37424.2344 - val_loss: 90.7581\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4457.1704 - val_loss: 93.2367\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47119.9258 - val_loss: 94.7618\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41491.4922 - val_loss: 93.9475\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12613.2295 - val_loss: 90.6339\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 64722.3086 - val_loss: 88.8496\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55785.1914 - val_loss: 91.3852\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12201.1133 - val_loss: 94.3071\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32764.3848 - val_loss: 94.3207\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31806.8184 - val_loss: 92.6071\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5228.9346 - val_loss: 93.0236\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14309.4814 - val_loss: 93.0704\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 225.4272 - val_loss: 90.3773\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61283.8164 - val_loss: 89.7664\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 56073.9922 - val_loss: 91.0834\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30298.7402 - val_loss: 93.2470\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16905.4434 - val_loss: 93.8426\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15446.3418 - val_loss: 92.7288\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17666.3613 - val_loss: 92.5623\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10130.2559 - val_loss: 93.9108\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23865.1621 - val_loss: 94.1996\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19145.3594 - val_loss: 93.1834\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12455.0732 - val_loss: 92.8998\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3279.6143 - val_loss: 93.7533\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26822.5352 - val_loss: 94.4771\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23471.3145 - val_loss: 92.9429\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13967.8369 - val_loss: 92.8782\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9806.0439 - val_loss: 93.3180\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3255.7139 - val_loss: 93.7484\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6588.3423 - val_loss: 93.4007\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5818.2266 - val_loss: 93.4922\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 592.1917 - val_loss: 92.8935\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17882.6094 - val_loss: 93.0314\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6651.0752 - val_loss: 94.0818\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15578.0244 - val_loss: 94.2315\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fb709550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 56 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 37832.4531 - val_loss: 57.8400\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 117768.7344 - val_loss: 61.9784\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 67395.6016 - val_loss: 68.0880\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39712.1445 - val_loss: 70.4858\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18964.4824 - val_loss: 67.8532\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 64355.3477 - val_loss: 66.4072\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48435.2500 - val_loss: 71.2146\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 29790.8379 - val_loss: 72.9398\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22443.2988 - val_loss: 72.4870\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31195.3789 - val_loss: 70.8367\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15297.3994 - val_loss: 73.2315\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6806.7515 - val_loss: 73.7382\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10334.5869 - val_loss: 72.3974\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17124.4668 - val_loss: 73.3663\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2461.2258 - val_loss: 75.6026\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38334.1641 - val_loss: 75.7401\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25642.5352 - val_loss: 74.6848\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12901.2266 - val_loss: 74.0050\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1956.0029 - val_loss: 75.5661\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31310.2656 - val_loss: 76.3638\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26593.7754 - val_loss: 74.5293\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16312.1641 - val_loss: 75.0536\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1046.9199 - val_loss: 75.0928\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29941.0098 - val_loss: 74.2110\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26396.7793 - val_loss: 76.6056\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16045.4492 - val_loss: 76.6442\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6956.0396 - val_loss: 74.7660\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35532.8555 - val_loss: 75.2079\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23397.7969 - val_loss: 76.9091\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11729.2529 - val_loss: 77.4766\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3273.6406 - val_loss: 76.2676\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35452.0781 - val_loss: 75.8321\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26103.3320 - val_loss: 77.6003\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19177.9219 - val_loss: 78.7372\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2421.9810 - val_loss: 77.3405\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24273.1367 - val_loss: 77.0577\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26170.3926 - val_loss: 78.4209\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6523.8008 - val_loss: 78.8422\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7695.7402 - val_loss: 79.0149\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 700.3051 - val_loss: 78.5158\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14158.9873 - val_loss: 79.1496\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 687.5937 - val_loss: 81.3221\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50856.9844 - val_loss: 81.8724\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45375.7461 - val_loss: 80.9044\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8064.6553 - val_loss: 79.6025\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30442.0391 - val_loss: 78.8267\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29454.2070 - val_loss: 80.4437\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3487.2363 - val_loss: 80.6207\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7999.4312 - val_loss: 81.1187\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13358.3760 - val_loss: 81.4610\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fd37c310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 57 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 83.5213 - val_loss: 59.6254\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.9635 - val_loss: 16.1367\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 32.0048 - val_loss: 25.8911\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24.0310 - val_loss: 32.2795\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21.4217 - val_loss: 22.1133\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.8309 - val_loss: 13.3279\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.0716 - val_loss: 14.9847\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.0137 - val_loss: 9.8550\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9589 - val_loss: 8.5981\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.6918 - val_loss: 3.6643\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.3421 - val_loss: 4.5963\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8544 - val_loss: 3.8748\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3293 - val_loss: 5.1306\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9493 - val_loss: 6.1208\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0503 - val_loss: 5.2598\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8102 - val_loss: 5.1954\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.2726 - val_loss: 4.8766\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0098 - val_loss: 4.5537\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1175 - val_loss: 5.3924\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7201 - val_loss: 4.5231\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3011 - val_loss: 4.5797\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0894 - val_loss: 5.2005\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9092 - val_loss: 3.8342\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8758 - val_loss: 3.8196\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.8221 - val_loss: 3.7557\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.8009 - val_loss: 4.9265\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6721 - val_loss: 3.9509\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7028 - val_loss: 3.8382\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6774 - val_loss: 4.9351\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.5073 - val_loss: 4.1397\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.4094 - val_loss: 3.9000\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6768 - val_loss: 4.5804\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7703 - val_loss: 6.4221\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2324 - val_loss: 4.2292\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.0869 - val_loss: 3.5469\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5328 - val_loss: 4.4617\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.2950 - val_loss: 3.7542\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.3345 - val_loss: 4.3115\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2185 - val_loss: 3.4575\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5444 - val_loss: 3.6702\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.2892 - val_loss: 3.4390\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.3475 - val_loss: 4.2586\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.3447 - val_loss: 4.2351\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.2394 - val_loss: 3.6316\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.4920 - val_loss: 3.4436\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3596 - val_loss: 3.3670\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.7378 - val_loss: 5.2647\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.4553 - val_loss: 3.8656\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.2599 - val_loss: 3.3134\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2625 - val_loss: 3.9087\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fd37c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 58 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 2710124.7500 - val_loss: 96.4905\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4653060.0000 - val_loss: 95.1928\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5011019.5000 - val_loss: 94.7680\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1622384.2500 - val_loss: 94.2649\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 630081.1875 - val_loss: 93.4888\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 895093.3750 - val_loss: 92.7464\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 768709.8750 - val_loss: 92.0804\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 723392.1875 - val_loss: 91.3594\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 609377.1250 - val_loss: 90.7276\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 732708.6250 - val_loss: 90.0920\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 723812.5000 - val_loss: 89.3367\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 417964.2500 - val_loss: 88.7023\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 796938.8125 - val_loss: 88.0392\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 287277.4062 - val_loss: 87.4047\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 197250.8125 - val_loss: 86.8161\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 216179.2031 - val_loss: 86.2007\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 228308.3125 - val_loss: 85.5883\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 182027.4531 - val_loss: 84.9523\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 196417.5469 - val_loss: 84.4036\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 215953.7656 - val_loss: 83.7516\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 299514.9062 - val_loss: 83.1085\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 702767.1875 - val_loss: 82.5333\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 478939.2500 - val_loss: 81.9162\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 396600.0938 - val_loss: 81.3558\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 682284.6875 - val_loss: 80.8176\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 321093.3125 - val_loss: 80.3082\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 212036.9688 - val_loss: 79.8350\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 524482.8125 - val_loss: 79.3353\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 588781.5000 - val_loss: 78.9538\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 254467.5781 - val_loss: 78.5361\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 267147.8438 - val_loss: 78.0734\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 602080.9375 - val_loss: 77.7291\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 455211.6875 - val_loss: 77.3698\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 147830.8125 - val_loss: 77.0483\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 133884.7656 - val_loss: 76.6123\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 365982.9375 - val_loss: 76.1847\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 605754.6250 - val_loss: 75.8203\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 264394.6250 - val_loss: 75.4970\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 120143.0156 - val_loss: 75.1135\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 362457.1562 - val_loss: 74.7405\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 563598.6250 - val_loss: 74.4192\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 291196.0000 - val_loss: 74.1358\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 167522.8906 - val_loss: 73.8155\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 138548.0469 - val_loss: 73.4813\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 148546.1250 - val_loss: 73.1627\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 167683.1719 - val_loss: 72.8219\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 139158.7188 - val_loss: 72.4590\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 172534.8750 - val_loss: 72.1379\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 216979.5312 - val_loss: 71.8003\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 521656.2188 - val_loss: 71.5353\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415518430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 59 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 94.9445 - val_loss: 70.8635\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38.8296 - val_loss: 17.9858\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.1076 - val_loss: 21.1947\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28.4102 - val_loss: 37.4341\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.0868 - val_loss: 35.4854\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24.1823 - val_loss: 20.3415\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.0609 - val_loss: 12.6691\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18.3789 - val_loss: 19.6727\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.4942 - val_loss: 19.6810\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.0063 - val_loss: 7.2794\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.4227 - val_loss: 9.7046\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.7793 - val_loss: 6.0517\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.8243 - val_loss: 7.3300\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.3685 - val_loss: 6.5392\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.9408 - val_loss: 7.3636\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.7361 - val_loss: 6.7617\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.7039 - val_loss: 5.8567\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3967 - val_loss: 6.0051\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.7909 - val_loss: 6.9399\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6135 - val_loss: 5.8106\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3840 - val_loss: 5.6125\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5841 - val_loss: 7.7527\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4376 - val_loss: 4.0379\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0162 - val_loss: 6.6623\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.8635 - val_loss: 4.1310\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0170 - val_loss: 7.7409\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6119 - val_loss: 3.7364\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.4720 - val_loss: 6.2577\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2298 - val_loss: 4.5923\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0708 - val_loss: 4.6623\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0704 - val_loss: 7.0351\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4612 - val_loss: 2.8990\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6229 - val_loss: 6.9131\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1855 - val_loss: 3.0592\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.9462 - val_loss: 4.4519\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6523 - val_loss: 3.7732\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.2865 - val_loss: 4.8478\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0702 - val_loss: 3.4708\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1392 - val_loss: 4.7384\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8773 - val_loss: 3.5932\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7610 - val_loss: 4.2684\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.7386 - val_loss: 3.4449\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1101 - val_loss: 6.2603\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.4643 - val_loss: 2.1359\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1357 - val_loss: 5.9306\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0480 - val_loss: 2.2063\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2886 - val_loss: 5.3713\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.5217 - val_loss: 2.2826\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1967 - val_loss: 4.5553\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.0726 - val_loss: 2.7343\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff414d78b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 60 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 96.8599 - val_loss: 83.1623\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 52.4455 - val_loss: 46.8444\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40.1174 - val_loss: 26.1837\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 35.5793 - val_loss: 37.4511\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29.8913 - val_loss: 41.7728\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26.6892 - val_loss: 29.5036\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21.7110 - val_loss: 13.7233\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18.0071 - val_loss: 21.2727\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17.6178 - val_loss: 15.3875\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.5898 - val_loss: 6.3995\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.1121 - val_loss: 11.1781\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.3203 - val_loss: 3.2530\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.3964 - val_loss: 11.2895\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.5944 - val_loss: 3.5625\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.1715 - val_loss: 8.9029\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5772 - val_loss: 4.7386\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.0705 - val_loss: 7.2638\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.5528 - val_loss: 5.4358\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1077 - val_loss: 4.5314\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.8050 - val_loss: 4.2607\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.7583 - val_loss: 6.0096\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.2928 - val_loss: 4.1691\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.0976 - val_loss: 4.0476\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7925 - val_loss: 4.4899\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5436 - val_loss: 3.4389\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6957 - val_loss: 3.4048\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.1810 - val_loss: 3.5272\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9538 - val_loss: 5.2866\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0972 - val_loss: 3.0595\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5742 - val_loss: 5.2766\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9320 - val_loss: 3.0774\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.2611 - val_loss: 6.7790\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4380 - val_loss: 3.0320\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.7668 - val_loss: 4.5243\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0931 - val_loss: 4.2439\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0514 - val_loss: 4.8894\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.4572 - val_loss: 2.8952\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9340 - val_loss: 3.1225\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4865 - val_loss: 2.6694\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1093 - val_loss: 2.5248\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8722 - val_loss: 2.3209\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8570 - val_loss: 2.4769\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6916 - val_loss: 2.4848\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7678 - val_loss: 2.6545\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.8588 - val_loss: 2.6449\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2624 - val_loss: 2.5537\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8258 - val_loss: 2.7842\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.5529 - val_loss: 2.5103\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3974 - val_loss: 2.7180\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.5478 - val_loss: 3.1500\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff407e83550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 61 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 76283.9297 - val_loss: 102.7614\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 160029.5469 - val_loss: 104.9410\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 104981.5469 - val_loss: 97.4408\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 61568.3438 - val_loss: 94.1967\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16687.2383 - val_loss: 98.9745\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44545.8242 - val_loss: 100.6243\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48868.5156 - val_loss: 97.8137\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14716.5244 - val_loss: 98.1976\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3460.7085 - val_loss: 96.5018\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25943.7520 - val_loss: 98.4277\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5190.0879 - val_loss: 96.6899\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32448.7031 - val_loss: 97.5587\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10268.5752 - val_loss: 101.8539\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 88874.4453 - val_loss: 103.0812\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 70950.2422 - val_loss: 101.0142\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7350.8184 - val_loss: 97.6092\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 48556.8711 - val_loss: 94.8391\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 60648.8086 - val_loss: 96.4125\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19806.9883 - val_loss: 98.0099\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8682.8857 - val_loss: 99.3161\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22692.1094 - val_loss: 98.8458\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4346.0366 - val_loss: 98.8037\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6293.7070 - val_loss: 97.5176\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31032.1094 - val_loss: 97.3757\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13206.9883 - val_loss: 100.7928\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 71360.3125 - val_loss: 102.2137\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 67403.3125 - val_loss: 100.7901\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35525.6367 - val_loss: 97.8723\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37931.5078 - val_loss: 96.7179\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31856.9941 - val_loss: 97.7495\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3447.8464 - val_loss: 98.5077\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3878.9573 - val_loss: 99.3849\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25552.3301 - val_loss: 99.4612\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12319.2705 - val_loss: 97.5021\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25676.1973 - val_loss: 97.5580\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24088.9180 - val_loss: 98.5343\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11202.3857 - val_loss: 98.9159\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2145.8721 - val_loss: 97.1637\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43156.8906 - val_loss: 96.8417\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33152.9102 - val_loss: 97.7815\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 794.7944 - val_loss: 98.4469\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9771.7891 - val_loss: 98.5449\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18331.1016 - val_loss: 99.3424\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10606.4502 - val_loss: 98.6647\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16639.4785 - val_loss: 97.8147\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18669.3027 - val_loss: 98.3652\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1007.1309 - val_loss: 100.4699\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 58945.6523 - val_loss: 101.3117\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52533.0938 - val_loss: 100.6941\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19855.9844 - val_loss: 98.5255\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ecf7df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 62 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 77.8886 - val_loss: 59.2821\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.4392 - val_loss: 14.5438\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25.9709 - val_loss: 8.0277\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21.8534 - val_loss: 23.1426\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.6628 - val_loss: 25.4689\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.2054 - val_loss: 15.3698\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.7735 - val_loss: 12.7598\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.0009 - val_loss: 17.2588\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.9349 - val_loss: 10.4577\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.9583 - val_loss: 12.9425\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.7144 - val_loss: 6.9800\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.3606 - val_loss: 6.9280\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.6105 - val_loss: 4.4273\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.1114 - val_loss: 4.6544\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6370 - val_loss: 4.5438\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9102 - val_loss: 3.4099\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5230 - val_loss: 4.1148\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3783 - val_loss: 3.3186\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1860 - val_loss: 4.1343\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9212 - val_loss: 3.2282\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7303 - val_loss: 3.5796\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4017 - val_loss: 3.5144\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4155 - val_loss: 3.3351\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4901 - val_loss: 3.2097\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9128 - val_loss: 3.4733\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.9577 - val_loss: 3.6597\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9819 - val_loss: 3.1975\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9394 - val_loss: 2.9302\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4972 - val_loss: 2.7697\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2407 - val_loss: 2.7772\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4837 - val_loss: 3.4794\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.5400 - val_loss: 2.4718\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2500 - val_loss: 2.8567\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2764 - val_loss: 3.8891\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.2829 - val_loss: 2.6378\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.7648 - val_loss: 2.5014\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6634 - val_loss: 2.6269\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.8110 - val_loss: 2.8073\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.0208 - val_loss: 4.1591\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2302 - val_loss: 2.5077\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.4206 - val_loss: 2.3603\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.6620 - val_loss: 2.3804\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.3483 - val_loss: 2.4363\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.3147 - val_loss: 2.3009\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.4259 - val_loss: 2.4043\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.5048 - val_loss: 3.3775\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.3794 - val_loss: 2.2579\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1572 - val_loss: 2.6352\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.1474 - val_loss: 2.3400\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.1410 - val_loss: 2.8129\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fb5afe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 63 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 4876359.5000 - val_loss: 106.9348\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2661467.2500 - val_loss: 105.4917\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1735421.2500 - val_loss: 104.0520\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 476089.5938 - val_loss: 102.9121\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 417697.2188 - val_loss: 101.8028\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 820022.3125 - val_loss: 100.7408\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1198198.7500 - val_loss: 99.7137\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1638205.7500 - val_loss: 98.8474\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 615895.5625 - val_loss: 98.0354\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 799268.6250 - val_loss: 97.1562\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 448301.1562 - val_loss: 96.1532\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 155123.0312 - val_loss: 95.2407\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 494472.0625 - val_loss: 94.3542\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 313179.0312 - val_loss: 93.4581\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 356160.5938 - val_loss: 92.5882\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 247982.0781 - val_loss: 91.8157\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 460668.8438 - val_loss: 91.0017\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 122383.2656 - val_loss: 90.3641\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 115979.7891 - val_loss: 89.6124\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 174647.6094 - val_loss: 88.8736\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 491113.1562 - val_loss: 88.1157\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 137338.3750 - val_loss: 87.4589\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 262702.5312 - val_loss: 86.6824\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 398316.4062 - val_loss: 85.9886\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 114676.2109 - val_loss: 85.2461\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 295582.0625 - val_loss: 84.5941\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 412019.5938 - val_loss: 83.8616\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 153419.2969 - val_loss: 83.0162\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 473449.2500 - val_loss: 82.3372\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 149094.1875 - val_loss: 81.7155\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 536428.4375 - val_loss: 81.0474\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 652432.1250 - val_loss: 80.4957\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 261913.5469 - val_loss: 79.9623\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 203618.2969 - val_loss: 79.4105\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 253607.3750 - val_loss: 78.7866\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 628380.3125 - val_loss: 78.2176\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 461653.7500 - val_loss: 77.7302\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 112186.8516 - val_loss: 77.2174\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 260324.1094 - val_loss: 76.8271\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 565106.1875 - val_loss: 76.2944\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 739753.1875 - val_loss: 75.9351\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 799255.0625 - val_loss: 75.7414\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 334555.9688 - val_loss: 75.4362\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 310970.3750 - val_loss: 75.1043\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 230880.8750 - val_loss: 74.6980\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 271077.0938 - val_loss: 74.3704\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 306990.8750 - val_loss: 73.9763\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 305594.5312 - val_loss: 73.5971\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79849.2734 - val_loss: 73.1879\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 257252.2656 - val_loss: 72.7238\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e6343160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 64 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 23077.8516 - val_loss: 91.7814\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 297762.8750 - val_loss: 88.2851\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 206170.4531 - val_loss: 93.3308\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 99297.4609 - val_loss: 98.7551\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 27165.7910 - val_loss: 100.8659\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36177.7461 - val_loss: 99.3316\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1670.7054 - val_loss: 100.1246\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21007.0430 - val_loss: 98.9788\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16855.0547 - val_loss: 99.2855\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19397.3184 - val_loss: 99.4923\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9270.9111 - val_loss: 96.6494\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 1s 100ms/step - loss: 78802.4141 - val_loss: 96.0933\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 78508.0469 - val_loss: 97.2563\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38930.5273 - val_loss: 99.1530\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 21485.0000 - val_loss: 98.9502\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18865.7598 - val_loss: 97.9911\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6131.7017 - val_loss: 98.2233\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6557.1147 - val_loss: 97.7908\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20890.6367 - val_loss: 97.6653\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1730.9135 - val_loss: 98.3834\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53473.7930 - val_loss: 99.6038\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40266.5898 - val_loss: 98.5283\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11307.7012 - val_loss: 97.6235\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10452.2793 - val_loss: 97.8383\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16133.2432 - val_loss: 97.3629\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8066.6670 - val_loss: 98.4927\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39250.7891 - val_loss: 98.6239\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28608.4961 - val_loss: 97.6622\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15209.4180 - val_loss: 97.1998\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7642.0610 - val_loss: 98.2610\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42900.2031 - val_loss: 98.5791\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37083.3438 - val_loss: 97.2589\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14937.0742 - val_loss: 97.0880\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2419.1169 - val_loss: 97.7162\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14303.7734 - val_loss: 97.6565\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12873.6035 - val_loss: 97.2002\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1268.8763 - val_loss: 97.3364\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5567.2949 - val_loss: 96.8254\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29139.2070 - val_loss: 96.5009\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2692.3623 - val_loss: 97.4687\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 42801.2852 - val_loss: 98.4930\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47982.5625 - val_loss: 98.0429\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23490.1035 - val_loss: 96.9370\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30067.0918 - val_loss: 96.2654\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13442.3340 - val_loss: 96.9194\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2453.3608 - val_loss: 98.8311\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 89856.9766 - val_loss: 99.5817\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 90431.5859 - val_loss: 98.8111\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 58588.6641 - val_loss: 97.8943\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13103.0566 - val_loss: 96.9070\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415e1cca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 65 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 90.2774 - val_loss: 69.4652\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.4820 - val_loss: 18.1657\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35.0528 - val_loss: 20.9058\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24.9016 - val_loss: 34.6539\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26.0262 - val_loss: 28.8575\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20.5114 - val_loss: 13.8297\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19.8195 - val_loss: 15.5310\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.0921 - val_loss: 17.1853\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.8865 - val_loss: 12.6614\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.3518 - val_loss: 9.0251\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.3714 - val_loss: 9.6609\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.3042 - val_loss: 4.1604\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.0308 - val_loss: 9.1325\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.1216 - val_loss: 3.7105\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.8848 - val_loss: 6.4757\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0427 - val_loss: 5.1388\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8101 - val_loss: 7.0262\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.4308 - val_loss: 5.2409\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.1488 - val_loss: 5.4248\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.8740 - val_loss: 3.4200\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5062 - val_loss: 5.1710\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.3563 - val_loss: 4.0216\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.2255 - val_loss: 4.4130\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0229 - val_loss: 4.3523\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7659 - val_loss: 3.2484\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8854 - val_loss: 3.2682\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5396 - val_loss: 3.1593\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3681 - val_loss: 5.9215\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4965 - val_loss: 2.8820\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8990 - val_loss: 5.1293\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9097 - val_loss: 2.8252\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8882 - val_loss: 4.1001\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9690 - val_loss: 2.8835\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4173 - val_loss: 2.6814\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3374 - val_loss: 3.9190\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0987 - val_loss: 3.0340\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9074 - val_loss: 4.7404\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0193 - val_loss: 2.2642\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3484 - val_loss: 5.6205\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5273 - val_loss: 2.4639\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3888 - val_loss: 3.9164\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5689 - val_loss: 2.8965\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.3877 - val_loss: 3.3258\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.1306 - val_loss: 2.6390\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6432 - val_loss: 3.7607\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2929 - val_loss: 3.2902\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9543 - val_loss: 3.5126\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0362 - val_loss: 2.6391\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9509 - val_loss: 4.1654\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.8088 - val_loss: 2.6604\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415518dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 66 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 83.8889 - val_loss: 65.0929\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35.4326 - val_loss: 19.6442\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34.8727 - val_loss: 23.7026\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25.9129 - val_loss: 36.1732\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24.2515 - val_loss: 32.9293\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.4257 - val_loss: 20.8272\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18.3501 - val_loss: 15.8349\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.7444 - val_loss: 19.5690\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.9565 - val_loss: 7.5289\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.9448 - val_loss: 10.7673\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.5846 - val_loss: 4.8424\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.6422 - val_loss: 10.5533\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1755 - val_loss: 7.2245\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.8388 - val_loss: 8.0602\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.6419 - val_loss: 5.0961\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.0290 - val_loss: 9.8246\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.8161 - val_loss: 3.9597\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.7524 - val_loss: 7.3105\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9039 - val_loss: 4.4854\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.2000 - val_loss: 7.0728\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.0301 - val_loss: 4.9219\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6190 - val_loss: 5.1606\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.5050 - val_loss: 6.6267\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2911 - val_loss: 4.0048\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6931 - val_loss: 7.4786\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9227 - val_loss: 3.0963\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6285 - val_loss: 6.6151\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4341 - val_loss: 3.4310\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6962 - val_loss: 5.0745\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.1067 - val_loss: 3.8909\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.5274 - val_loss: 3.8500\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3219 - val_loss: 2.7746\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.4027 - val_loss: 4.9855\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.3396 - val_loss: 3.1977\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0511 - val_loss: 3.8039\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0657 - val_loss: 3.8058\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8387 - val_loss: 4.1143\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.4862 - val_loss: 2.2960\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7791 - val_loss: 3.9571\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2103 - val_loss: 2.6651\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.2331 - val_loss: 2.1692\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0129 - val_loss: 2.4677\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.7283 - val_loss: 2.8964\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.8332 - val_loss: 2.0383\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7312 - val_loss: 3.0222\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7015 - val_loss: 2.5820\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6723 - val_loss: 2.7912\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.3904 - val_loss: 2.3514\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.3181 - val_loss: 2.0116\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.1289 - val_loss: 2.0281\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f0ff8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 67 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 101.1103 - val_loss: 78.7461\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53.5781 - val_loss: 34.5422\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 27.8039 - val_loss: 8.1441\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26.6083 - val_loss: 15.6625\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19.9749 - val_loss: 28.0584\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19.8963 - val_loss: 25.5347\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.1834 - val_loss: 16.0443\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.2468 - val_loss: 10.7139\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.2198 - val_loss: 14.5088\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.6060 - val_loss: 15.1505\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.6081 - val_loss: 11.8167\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.7291 - val_loss: 11.7552\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.7462 - val_loss: 9.4017\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6158 - val_loss: 7.6672\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3244 - val_loss: 5.8920\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.5094 - val_loss: 5.6109\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3395 - val_loss: 5.3680\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1244 - val_loss: 5.5924\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8592 - val_loss: 6.1128\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.9685 - val_loss: 5.0239\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4456 - val_loss: 6.5121\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3342 - val_loss: 5.5695\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.3370 - val_loss: 5.3171\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0888 - val_loss: 5.7086\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.0414 - val_loss: 5.3970\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.0476 - val_loss: 5.3289\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7937 - val_loss: 5.5007\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.9345 - val_loss: 6.3243\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.9202 - val_loss: 5.3192\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.5384 - val_loss: 5.7915\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.5874 - val_loss: 5.5558\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5302 - val_loss: 5.5144\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5896 - val_loss: 5.2543\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6283 - val_loss: 5.2166\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3834 - val_loss: 5.1016\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5601 - val_loss: 5.9797\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.5821 - val_loss: 5.0325\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.5160 - val_loss: 4.9724\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6866 - val_loss: 5.7788\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.5213 - val_loss: 4.9969\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3024 - val_loss: 5.2159\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.2007 - val_loss: 5.3376\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.2940 - val_loss: 4.9209\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.0302 - val_loss: 5.3023\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.8271 - val_loss: 4.9576\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.9265 - val_loss: 5.5380\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.0239 - val_loss: 4.9496\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.7756 - val_loss: 4.8889\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7464 - val_loss: 5.0350\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.7189 - val_loss: 4.8113\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff406ea3940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 68 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 103.4565 - val_loss: 84.1204\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 57.0581 - val_loss: 34.1237\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 32.6344 - val_loss: 5.7858\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25.2133 - val_loss: 28.0096\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22.4521 - val_loss: 32.8914\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20.8923 - val_loss: 21.8098\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.2639 - val_loss: 11.1347\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16.4102 - val_loss: 11.9877\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.4694 - val_loss: 17.3641\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.3192 - val_loss: 11.6147\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.5405 - val_loss: 10.4843\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.0150 - val_loss: 6.2272\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3585 - val_loss: 3.7109\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.8445 - val_loss: 4.7847\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6241 - val_loss: 3.7174\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.2993 - val_loss: 4.1605\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2620 - val_loss: 4.5707\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5109 - val_loss: 3.6419\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8204 - val_loss: 4.4483\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.5542 - val_loss: 4.2587\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.6375 - val_loss: 3.7490\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.9793 - val_loss: 4.0354\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5107 - val_loss: 3.8789\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.3067 - val_loss: 3.8484\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.3947 - val_loss: 4.2041\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0230 - val_loss: 3.8345\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.8874 - val_loss: 3.8949\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7901 - val_loss: 4.1477\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7548 - val_loss: 3.7829\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7319 - val_loss: 3.8340\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6282 - val_loss: 3.7916\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5362 - val_loss: 4.3998\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8653 - val_loss: 3.8531\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6493 - val_loss: 3.6961\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.4783 - val_loss: 3.7318\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.3229 - val_loss: 3.6915\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3996 - val_loss: 3.6294\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.4058 - val_loss: 4.0368\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.2363 - val_loss: 3.6419\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.1488 - val_loss: 4.1929\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.2663 - val_loss: 3.6478\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.0681 - val_loss: 3.6941\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5554 - val_loss: 4.9980\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.8634 - val_loss: 3.6495\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.6056 - val_loss: 3.5606\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7878 - val_loss: 4.0482\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.3411 - val_loss: 4.0452\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.1715 - val_loss: 3.6361\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.2231 - val_loss: 3.5981\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.9644 - val_loss: 3.8005\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f492edc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 69 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 79.7509 - val_loss: 56.4394\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31.2069 - val_loss: 6.8286\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 23.6561 - val_loss: 14.2571\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17.4508 - val_loss: 23.2649\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.5816 - val_loss: 20.2827\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.1930 - val_loss: 12.6427\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.8031 - val_loss: 11.3628\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.9011 - val_loss: 12.8787\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.7373 - val_loss: 7.4791\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.2658 - val_loss: 7.1331\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0880 - val_loss: 4.5972\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.8304 - val_loss: 5.2486\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.1471 - val_loss: 4.5934\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9244 - val_loss: 4.2957\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3537 - val_loss: 4.2034\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.1863 - val_loss: 4.3870\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9877 - val_loss: 4.5701\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.9812 - val_loss: 4.7819\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.7018 - val_loss: 4.8060\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5981 - val_loss: 4.3818\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9806 - val_loss: 4.2757\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9314 - val_loss: 4.3504\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.8929 - val_loss: 5.0352\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7191 - val_loss: 4.3592\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.3690 - val_loss: 4.3160\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.2891 - val_loss: 4.5925\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5246 - val_loss: 4.7728\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.8250 - val_loss: 5.7451\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2242 - val_loss: 4.1957\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.0813 - val_loss: 4.1425\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.1418 - val_loss: 4.2784\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.1511 - val_loss: 4.3974\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5203 - val_loss: 4.3288\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.8288 - val_loss: 4.1862\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8813 - val_loss: 4.1610\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.0813 - val_loss: 4.4990\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0557 - val_loss: 4.1721\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8738 - val_loss: 4.1721\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.1334 - val_loss: 4.4122\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.3224 - val_loss: 4.1715\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2122 - val_loss: 4.1205\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2737 - val_loss: 4.3380\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.8424 - val_loss: 3.9431\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.7488 - val_loss: 3.9406\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.5106 - val_loss: 3.8968\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3.4858 - val_loss: 3.8561\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.5269 - val_loss: 3.9205\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.5803 - val_loss: 3.7565\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3539 - val_loss: 3.7851\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.5844 - val_loss: 3.8052\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ecf7d700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 70 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 438721.1562 - val_loss: 102.1142\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 359030.2500 - val_loss: 91.7340\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 292607.2500 - val_loss: 90.4362\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 157411.7656 - val_loss: 97.2752\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 298147.5625 - val_loss: 100.3038\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 205912.3125 - val_loss: 95.5007\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22486.3730 - val_loss: 95.1126\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 102404.8125 - val_loss: 97.1971\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 118825.0391 - val_loss: 95.0156\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 62670.7773 - val_loss: 100.6914\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 316894.7188 - val_loss: 100.8173\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 107989.7734 - val_loss: 96.0529\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 233525.8750 - val_loss: 92.7436\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 211295.5312 - val_loss: 95.7764\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 82824.4609 - val_loss: 98.0029\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 43833.0039 - val_loss: 97.3611\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 75684.9688 - val_loss: 99.3197\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 93831.8047 - val_loss: 94.9220\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 274412.7500 - val_loss: 94.6132\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 106227.8516 - val_loss: 98.6603\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 123278.5625 - val_loss: 100.3660\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 122495.0625 - val_loss: 96.4539\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 184916.4375 - val_loss: 96.6859\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 114708.8672 - val_loss: 99.9956\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 76726.9141 - val_loss: 97.6987\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 157062.5938 - val_loss: 97.1763\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47232.2617 - val_loss: 98.9993\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 21892.4746 - val_loss: 94.9355\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 233474.9219 - val_loss: 95.2641\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 144364.1875 - val_loss: 99.7135\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 123467.4062 - val_loss: 100.3484\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 103167.9609 - val_loss: 97.1116\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 181285.8281 - val_loss: 95.6940\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 90373.1484 - val_loss: 99.4900\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 196480.7031 - val_loss: 101.4025\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 168774.9062 - val_loss: 96.9627\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 118773.2344 - val_loss: 96.5177\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 83446.6016 - val_loss: 99.9680\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 175433.0625 - val_loss: 100.4090\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 78372.9922 - val_loss: 97.6621\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 180373.7344 - val_loss: 95.9577\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 98997.1797 - val_loss: 99.4192\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 116174.9375 - val_loss: 100.1424\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 60033.5664 - val_loss: 97.8490\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 81824.7344 - val_loss: 97.4240\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 39605.2383 - val_loss: 100.0988\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 194521.5312 - val_loss: 101.0292\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 138238.1719 - val_loss: 96.5543\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 145978.6562 - val_loss: 96.0817\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 133900.0625 - val_loss: 97.9829\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fd37c310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 71 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 36452.7773 - val_loss: 83.4491\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 185211.4375 - val_loss: 74.7176\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 124559.8047 - val_loss: 87.0061\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17910.3887 - val_loss: 93.4827\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1495.4263 - val_loss: 88.1386\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40051.9688 - val_loss: 88.2711\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 39146.2852 - val_loss: 90.3769\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3310.6599 - val_loss: 92.0186\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7528.1836 - val_loss: 94.1476\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 28446.7266 - val_loss: 94.2081\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16252.5889 - val_loss: 88.1233\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 43546.6523 - val_loss: 88.5621\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38465.6250 - val_loss: 91.4170\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4903.5215 - val_loss: 97.6124\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 83473.6016 - val_loss: 100.6566\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 77506.8516 - val_loss: 94.9748\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 511.5998 - val_loss: 93.4042\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7333.8608 - val_loss: 91.4876\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14309.4619 - val_loss: 93.2745\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7783.4829 - val_loss: 92.0343\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18322.6055 - val_loss: 92.3715\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2475.0161 - val_loss: 92.1747\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8558.4395 - val_loss: 93.5777\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10728.4443 - val_loss: 92.8916\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16107.8994 - val_loss: 92.2430\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5099.4448 - val_loss: 96.3153\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 56400.5781 - val_loss: 98.2170\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32497.2266 - val_loss: 95.1612\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7291.1133 - val_loss: 87.9085\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 85810.7500 - val_loss: 84.6658\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 89500.8672 - val_loss: 85.5003\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 80100.1094 - val_loss: 91.9612\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6501.7266 - val_loss: 94.3365\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4418.5977 - val_loss: 92.0466\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19249.2754 - val_loss: 92.8546\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11535.6797 - val_loss: 95.7012\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31962.7695 - val_loss: 96.6358\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18046.2754 - val_loss: 93.3707\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20853.8691 - val_loss: 92.2068\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20127.3027 - val_loss: 94.1807\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 145.8242 - val_loss: 97.9060\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44142.4805 - val_loss: 98.2522\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41762.1016 - val_loss: 95.9586\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7759.9678 - val_loss: 93.6387\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7544.2905 - val_loss: 93.2718\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11643.4326 - val_loss: 95.1675\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11061.2754 - val_loss: 94.5352\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5286.9727 - val_loss: 94.5030\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15258.7959 - val_loss: 95.6314\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10200.3174 - val_loss: 93.8258\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40c99c160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 72 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1531179.5000 - val_loss: 86.8908\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 200448.5000 - val_loss: 93.4097\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 203544.1250 - val_loss: 94.5872\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 202218.6406 - val_loss: 92.7245\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61907.1133 - val_loss: 90.3134\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 278444.2812 - val_loss: 90.9446\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 66014.1328 - val_loss: 93.5529\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 193745.1250 - val_loss: 95.3412\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 200904.1250 - val_loss: 93.0251\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 175618.2969 - val_loss: 90.4759\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 279496.5938 - val_loss: 91.5771\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 53672.0039 - val_loss: 93.8794\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 65929.8906 - val_loss: 94.1412\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 71810.4844 - val_loss: 94.4676\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 103762.5625 - val_loss: 94.8516\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 123951.0938 - val_loss: 93.5017\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 102492.8750 - val_loss: 94.7940\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 59523.9336 - val_loss: 95.2687\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 59213.4883 - val_loss: 95.8940\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 80928.8906 - val_loss: 97.3990\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 92685.5156 - val_loss: 97.4051\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 77282.9062 - val_loss: 96.7452\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 102018.7578 - val_loss: 97.7567\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 148152.2969 - val_loss: 100.4238\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 245446.6875 - val_loss: 99.6855\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17542.9395 - val_loss: 97.6115\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 160597.1875 - val_loss: 96.2791\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 218291.5625 - val_loss: 97.6133\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 69707.5625 - val_loss: 99.1704\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 81192.0781 - val_loss: 97.8463\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 95809.7500 - val_loss: 97.4030\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49639.1484 - val_loss: 98.3140\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39897.4727 - val_loss: 98.6169\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30438.5918 - val_loss: 99.3906\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45501.3789 - val_loss: 98.6379\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 98684.9375 - val_loss: 98.7524\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57837.4023 - val_loss: 100.0676\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 69526.0156 - val_loss: 98.7084\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 166328.0625 - val_loss: 98.8866\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 77658.6484 - val_loss: 100.3767\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35721.9141 - val_loss: 100.1862\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 74861.0312 - val_loss: 99.9799\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42699.8789 - val_loss: 100.8959\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25012.0762 - val_loss: 100.4429\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23794.8906 - val_loss: 100.8428\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42686.5742 - val_loss: 100.3911\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57575.3750 - val_loss: 100.5794\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 125787.3828 - val_loss: 98.6990\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 259409.6094 - val_loss: 99.0214\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 99017.5625 - val_loss: 100.9910\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40dd82040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 73 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 75614.5547 - val_loss: 114.0082\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 85770.7734 - val_loss: 113.5445\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45949.4062 - val_loss: 108.7725\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 44016.3438 - val_loss: 108.4241\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23588.7285 - val_loss: 110.5049\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 56763.7617 - val_loss: 111.7678\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47137.8906 - val_loss: 107.7524\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30986.6191 - val_loss: 107.5054\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30714.5879 - val_loss: 108.0033\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6336.9771 - val_loss: 108.8999\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4403.2041 - val_loss: 107.4906\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29617.0684 - val_loss: 107.5176\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17231.8359 - val_loss: 109.2497\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45104.2383 - val_loss: 109.9631\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30945.8809 - val_loss: 107.1529\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36671.4336 - val_loss: 106.2665\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31321.6152 - val_loss: 106.7269\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8197.4072 - val_loss: 107.7485\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6053.3989 - val_loss: 106.4083\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37873.1367 - val_loss: 106.0149\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24732.2930 - val_loss: 107.3554\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16648.4824 - val_loss: 107.6883\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8949.4131 - val_loss: 106.8185\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6873.7900 - val_loss: 106.8862\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3295.5789 - val_loss: 107.7661\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27979.6934 - val_loss: 107.8403\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20369.3359 - val_loss: 106.1482\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32066.3516 - val_loss: 105.7015\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18998.0840 - val_loss: 106.6259\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11608.2119 - val_loss: 106.9938\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8448.7959 - val_loss: 105.6133\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27569.6270 - val_loss: 105.7407\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18151.1309 - val_loss: 107.0999\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30086.4902 - val_loss: 107.3579\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19642.7188 - val_loss: 106.1442\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15196.4141 - val_loss: 105.7552\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10136.2402 - val_loss: 106.7612\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28099.2559 - val_loss: 107.0106\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14669.4131 - val_loss: 106.2298\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18904.1934 - val_loss: 105.1820\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19439.4961 - val_loss: 105.8980\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14232.3721 - val_loss: 106.1520\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4602.9893 - val_loss: 105.7529\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 190.2611 - val_loss: 106.9521\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40047.3242 - val_loss: 107.0047\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31080.7930 - val_loss: 106.0735\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2505.5115 - val_loss: 104.6190\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37209.5547 - val_loss: 104.0240\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37354.7422 - val_loss: 104.7856\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15072.3369 - val_loss: 106.0455\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e8e31430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 74 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 69.0401 - val_loss: 46.5945\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36.0936 - val_loss: 13.0295\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.7664 - val_loss: 24.5482\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25.3973 - val_loss: 31.9018\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.5994 - val_loss: 24.4314\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.1884 - val_loss: 14.2310\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.9706 - val_loss: 16.2824\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.0622 - val_loss: 13.3372\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.7375 - val_loss: 7.9598\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0755 - val_loss: 5.0104\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6856 - val_loss: 4.1774\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1052 - val_loss: 3.8046\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5761 - val_loss: 6.8087\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.3315 - val_loss: 4.0915\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0209 - val_loss: 4.1539\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4668 - val_loss: 3.7394\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9946 - val_loss: 4.6253\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5520 - val_loss: 3.8651\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2312 - val_loss: 4.1166\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3485 - val_loss: 4.1835\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2067 - val_loss: 3.4182\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0466 - val_loss: 3.4829\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7551 - val_loss: 4.4740\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9613 - val_loss: 4.3930\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.1638 - val_loss: 2.8725\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.6940 - val_loss: 3.5230\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5890 - val_loss: 3.1422\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5346 - val_loss: 4.9016\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8882 - val_loss: 2.7776\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8449 - val_loss: 3.4664\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3666 - val_loss: 3.7170\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2309 - val_loss: 3.1072\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.3594 - val_loss: 3.1300\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0401 - val_loss: 3.2668\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3113 - val_loss: 2.6976\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1736 - val_loss: 2.8717\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6204 - val_loss: 4.8293\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9264 - val_loss: 2.7619\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0832 - val_loss: 2.6923\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0962 - val_loss: 3.1824\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9241 - val_loss: 2.5428\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.8718 - val_loss: 3.5308\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4120 - val_loss: 2.5329\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9937 - val_loss: 2.4137\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.9195 - val_loss: 3.7413\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6064 - val_loss: 2.5950\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.8768 - val_loss: 2.4763\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.8398 - val_loss: 3.0336\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1503 - val_loss: 2.3946\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1587 - val_loss: 2.7805\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f871ad30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 75 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 110.1108 - val_loss: 97.0229\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 68.6454 - val_loss: 69.2472\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.3681 - val_loss: 39.3168\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38.9715 - val_loss: 37.3076\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 30.3599 - val_loss: 42.3504\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.0045 - val_loss: 37.4342\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.9183 - val_loss: 23.0070\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.6301 - val_loss: 24.2166\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.4992 - val_loss: 16.7131\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.7298 - val_loss: 14.0133\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.5065 - val_loss: 9.0484\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.6192 - val_loss: 8.2343\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.7511 - val_loss: 8.4676\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.1965 - val_loss: 6.8950\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.1082 - val_loss: 10.3119\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.4585 - val_loss: 3.8145\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.9315 - val_loss: 10.2294\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4601 - val_loss: 4.4615\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.0246 - val_loss: 5.8031\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.3789 - val_loss: 4.2805\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.0074 - val_loss: 5.1929\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.5356 - val_loss: 4.8374\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1616 - val_loss: 4.1169\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8424 - val_loss: 4.4470\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.5980 - val_loss: 4.5644\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1445 - val_loss: 4.3969\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9177 - val_loss: 3.8406\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6266 - val_loss: 4.9315\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2273 - val_loss: 4.2948\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8826 - val_loss: 4.6956\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6613 - val_loss: 4.3494\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1987 - val_loss: 4.5132\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0160 - val_loss: 4.9297\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0827 - val_loss: 4.4592\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6461 - val_loss: 4.1673\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1262 - val_loss: 4.2320\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1815 - val_loss: 5.0734\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9379 - val_loss: 4.0787\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1762 - val_loss: 4.0708\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8180 - val_loss: 4.5574\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5751 - val_loss: 4.6566\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.1525 - val_loss: 4.8482\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2202 - val_loss: 6.3405\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7139 - val_loss: 5.2194\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4662 - val_loss: 5.8064\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3368 - val_loss: 5.9855\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8958 - val_loss: 5.5571\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9432 - val_loss: 5.7083\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2742 - val_loss: 5.4157\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5955 - val_loss: 5.0780\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4055e9550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 76 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 233837.3750 - val_loss: 81.5747\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 181187.1719 - val_loss: 95.4236\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51961.9766 - val_loss: 97.7183\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 59208.2578 - val_loss: 96.0327\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15707.2646 - val_loss: 91.5986\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 67860.4219 - val_loss: 91.2099\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58140.1445 - val_loss: 92.6924\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8898.2686 - val_loss: 95.8372\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22997.8652 - val_loss: 96.6287\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36207.9648 - val_loss: 95.1214\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10568.2666 - val_loss: 94.8509\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7196.4819 - val_loss: 95.0638\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1882.7659 - val_loss: 93.0107\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50127.0312 - val_loss: 93.0869\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35254.9609 - val_loss: 95.3880\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4792.5098 - val_loss: 95.2276\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 153.4439 - val_loss: 93.3570\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52815.0508 - val_loss: 93.0874\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33468.7383 - val_loss: 94.7320\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12779.4004 - val_loss: 95.8493\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9350.2451 - val_loss: 93.9260\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50136.9805 - val_loss: 93.3298\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25422.4766 - val_loss: 95.4079\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17860.9355 - val_loss: 96.4417\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19424.7695 - val_loss: 96.0329\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 447.3214 - val_loss: 93.0638\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 62963.1172 - val_loss: 92.3640\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 68100.3281 - val_loss: 93.6657\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38378.1914 - val_loss: 95.5720\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3843.6562 - val_loss: 95.7943\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 846.8802 - val_loss: 94.4192\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33602.5781 - val_loss: 94.7039\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17264.5566 - val_loss: 95.4938\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17422.6230 - val_loss: 96.6554\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17288.4824 - val_loss: 95.8521\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16990.0723 - val_loss: 95.3604\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11538.1641 - val_loss: 97.5127\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 52544.8906 - val_loss: 98.2283\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49472.5625 - val_loss: 96.8424\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10170.5107 - val_loss: 95.2887\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29180.1504 - val_loss: 94.7513\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28089.2500 - val_loss: 95.9339\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2774.1924 - val_loss: 97.7123\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 51113.5781 - val_loss: 98.2604\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47621.2617 - val_loss: 96.9496\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18077.5195 - val_loss: 95.1637\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32890.0273 - val_loss: 94.8020\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28116.0391 - val_loss: 95.2655\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13633.4453 - val_loss: 97.3676\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 51511.4844 - val_loss: 98.4427\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40c3ee0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 77 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 75.6366 - val_loss: 56.5995\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 67.7759 - val_loss: 37.5884\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48.0881 - val_loss: 45.3428\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38.5708 - val_loss: 40.8704\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.4017 - val_loss: 23.2512\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.3474 - val_loss: 16.2957\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.6340 - val_loss: 22.9530\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24.7516 - val_loss: 17.9229\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.2847 - val_loss: 10.1433\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.8252 - val_loss: 9.0700\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.4067 - val_loss: 4.5674\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.3599 - val_loss: 3.9126\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.1929 - val_loss: 4.1935\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.1727 - val_loss: 3.7716\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.2487 - val_loss: 4.3455\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.1674 - val_loss: 3.6937\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.1755 - val_loss: 3.7619\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.3556 - val_loss: 3.7297\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.7534 - val_loss: 3.8794\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.0204 - val_loss: 3.6805\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.9967 - val_loss: 3.7429\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3859 - val_loss: 3.8116\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.2156 - val_loss: 3.6891\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.8860 - val_loss: 3.2129\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.1644 - val_loss: 3.9256\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.5588 - val_loss: 3.7172\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4459 - val_loss: 4.4679\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2108 - val_loss: 3.0691\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1608 - val_loss: 4.8775\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9465 - val_loss: 3.4653\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5488 - val_loss: 2.5534\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4690 - val_loss: 4.1441\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7363 - val_loss: 2.7755\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.4921 - val_loss: 3.4077\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1441 - val_loss: 3.1547\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2134 - val_loss: 3.5582\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.5347 - val_loss: 3.7536\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3003 - val_loss: 3.1339\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0559 - val_loss: 4.1657\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1009 - val_loss: 3.5624\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1587 - val_loss: 3.8400\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0563 - val_loss: 3.3507\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.6622 - val_loss: 3.8039\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9315 - val_loss: 4.3227\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9941 - val_loss: 3.4327\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4340 - val_loss: 4.3707\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.0695 - val_loss: 3.5458\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8764 - val_loss: 4.3006\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1534 - val_loss: 3.1542\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2247 - val_loss: 4.4078\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fc59b670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 78 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 47.6097 - val_loss: 27.1801\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.4620 - val_loss: 9.7769\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.5169 - val_loss: 22.6992\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.8905 - val_loss: 24.7748\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.2623 - val_loss: 11.6840\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.1187 - val_loss: 8.6026\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.3961 - val_loss: 14.3098\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.6118 - val_loss: 10.8922\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.7890 - val_loss: 3.9573\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7988 - val_loss: 3.0705\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.2494 - val_loss: 2.7626\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9343 - val_loss: 3.4062\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7445 - val_loss: 2.5906\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9402 - val_loss: 2.5334\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.9428 - val_loss: 2.4032\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4270 - val_loss: 3.9678\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4523 - val_loss: 2.6431\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0432 - val_loss: 2.8149\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9286 - val_loss: 2.6001\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7551 - val_loss: 2.9244\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.3997 - val_loss: 4.3364\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1824 - val_loss: 2.5923\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9600 - val_loss: 4.0578\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7668 - val_loss: 2.9711\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6476 - val_loss: 3.7014\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7735 - val_loss: 2.9043\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9063 - val_loss: 2.8858\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2671 - val_loss: 2.5914\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8457 - val_loss: 2.6632\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7734 - val_loss: 3.5361\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9717 - val_loss: 3.3670\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7574 - val_loss: 3.1734\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5742 - val_loss: 2.7375\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5919 - val_loss: 3.5603\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4263 - val_loss: 3.1730\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.0944 - val_loss: 3.0294\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3453 - val_loss: 2.9021\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.3110 - val_loss: 3.2028\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1337 - val_loss: 3.2017\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5089 - val_loss: 2.9250\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2529 - val_loss: 2.7808\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.2661 - val_loss: 3.4471\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0762 - val_loss: 2.7272\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1274 - val_loss: 2.7886\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.1258 - val_loss: 3.2977\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.8423 - val_loss: 3.6360\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5291 - val_loss: 3.4865\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.9681 - val_loss: 2.7776\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0204 - val_loss: 2.6143\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9427 - val_loss: 2.4216\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f653b670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 79 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 2635165.0000 - val_loss: 104.2869\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4741336.5000 - val_loss: 101.0215\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3273854.7500 - val_loss: 100.1489\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2489863.2500 - val_loss: 98.8634\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1571717.2500 - val_loss: 97.3650\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1387220.5000 - val_loss: 95.8651\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1263804.7500 - val_loss: 94.9531\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1244789.5000 - val_loss: 94.3506\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1077458.5000 - val_loss: 93.5341\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 457613.2500 - val_loss: 92.7773\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 629535.3750 - val_loss: 92.0459\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 286148.5938 - val_loss: 91.1290\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 430894.8438 - val_loss: 90.2520\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 716896.5000 - val_loss: 89.6078\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 871236.6250 - val_loss: 88.7959\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 666794.3750 - val_loss: 88.0857\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 759775.8125 - val_loss: 87.4290\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 773641.1875 - val_loss: 86.8458\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 569129.8125 - val_loss: 86.2722\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 200517.8750 - val_loss: 85.6880\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 368238.1562 - val_loss: 85.1562\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 608751.0000 - val_loss: 84.4945\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 178815.8438 - val_loss: 83.8833\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 165494.9219 - val_loss: 83.3735\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 110144.0156 - val_loss: 82.7907\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 345261.4375 - val_loss: 82.0522\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 88113.7734 - val_loss: 81.4158\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 261926.0312 - val_loss: 80.7107\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 260618.8438 - val_loss: 80.1355\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 293049.6875 - val_loss: 79.5464\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 299272.0938 - val_loss: 78.9721\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 84420.8516 - val_loss: 78.4310\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 339123.9375 - val_loss: 77.8917\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 545568.0625 - val_loss: 77.3072\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 707806.1875 - val_loss: 76.8558\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 496638.2500 - val_loss: 76.5532\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 301313.9062 - val_loss: 76.1238\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 554768.3750 - val_loss: 75.7959\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 177219.4844 - val_loss: 75.4032\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 291325.1562 - val_loss: 75.0021\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 68187.9922 - val_loss: 74.5238\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 235328.1562 - val_loss: 73.9725\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 239969.1094 - val_loss: 73.5235\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 254068.9531 - val_loss: 73.0860\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 198347.3438 - val_loss: 72.5897\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 205192.0938 - val_loss: 72.1569\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 164017.7500 - val_loss: 71.6762\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 236443.4688 - val_loss: 71.2907\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 87578.3125 - val_loss: 70.8622\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 284275.4375 - val_loss: 70.4753\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fe088280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 80 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 110.1549 - val_loss: 86.5478\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 50.6607 - val_loss: 30.0123\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.8385 - val_loss: 24.0092\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.1758 - val_loss: 38.5138\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27.8157 - val_loss: 40.4899\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.4287 - val_loss: 29.1961\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.4844 - val_loss: 20.2706\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.7009 - val_loss: 20.4929\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.0992 - val_loss: 20.6267\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.8679 - val_loss: 14.4230\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.8914 - val_loss: 11.2184\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.0170 - val_loss: 7.4778\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.5331 - val_loss: 5.6204\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.8517 - val_loss: 5.6420\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.0990 - val_loss: 4.4207\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1301 - val_loss: 5.6015\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3818 - val_loss: 3.1829\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0713 - val_loss: 4.1048\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7041 - val_loss: 3.3576\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4995 - val_loss: 2.7525\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2164 - val_loss: 3.0202\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1141 - val_loss: 4.5760\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4214 - val_loss: 4.3822\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1976 - val_loss: 3.1212\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3087 - val_loss: 3.2783\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3085 - val_loss: 2.8920\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9808 - val_loss: 3.0460\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9131 - val_loss: 4.3445\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0432 - val_loss: 4.3802\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1391 - val_loss: 3.7074\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2325 - val_loss: 3.6124\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1109 - val_loss: 2.9729\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3504 - val_loss: 2.7214\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0456 - val_loss: 2.5682\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9881 - val_loss: 2.5256\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9202 - val_loss: 2.7586\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.9003 - val_loss: 2.5262\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8111 - val_loss: 2.8494\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0811 - val_loss: 3.5536\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0146 - val_loss: 3.4220\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2129 - val_loss: 3.2512\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7419 - val_loss: 2.1847\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6440 - val_loss: 2.5502\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5107 - val_loss: 2.6499\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2671 - val_loss: 2.3850\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1818 - val_loss: 2.1952\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0085 - val_loss: 3.0660\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4748 - val_loss: 2.5504\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0826 - val_loss: 2.2193\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9292 - val_loss: 2.2928\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40edac040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 81 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 2929798.5000 - val_loss: 94.7012\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4892476.0000 - val_loss: 93.6548\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4906121.0000 - val_loss: 93.1607\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1591218.1250 - val_loss: 92.6961\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 746364.7500 - val_loss: 92.0804\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 882154.1875 - val_loss: 91.3212\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 733039.5000 - val_loss: 90.6047\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 915942.5000 - val_loss: 89.8484\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 299108.8750 - val_loss: 89.1159\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 258840.8906 - val_loss: 88.3348\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 244703.8750 - val_loss: 87.5111\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 211803.9844 - val_loss: 86.7393\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 246032.9688 - val_loss: 86.1452\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 167047.9219 - val_loss: 85.4262\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 594445.5625 - val_loss: 84.8366\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 717220.1875 - val_loss: 84.1643\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 455763.7500 - val_loss: 83.4235\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 791446.5000 - val_loss: 82.9518\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 655404.5000 - val_loss: 82.4622\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 484574.7812 - val_loss: 81.8697\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 710032.4375 - val_loss: 81.3499\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 583041.3750 - val_loss: 80.8337\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 585673.3750 - val_loss: 80.3632\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 675334.5625 - val_loss: 80.0367\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 378514.7188 - val_loss: 79.5360\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 652748.6250 - val_loss: 79.1104\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 184694.3125 - val_loss: 78.7099\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 192279.7344 - val_loss: 78.2487\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 163422.6562 - val_loss: 77.8091\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 203349.7344 - val_loss: 77.3383\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 205736.9375 - val_loss: 76.8437\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 154618.8125 - val_loss: 76.3312\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 622305.8125 - val_loss: 75.9563\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 548899.5000 - val_loss: 75.5763\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 571752.8750 - val_loss: 75.2109\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 396622.9062 - val_loss: 74.9493\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 580803.1875 - val_loss: 74.6883\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 503035.0625 - val_loss: 74.4543\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 449432.7500 - val_loss: 74.1973\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 136480.3594 - val_loss: 73.8583\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 150455.5469 - val_loss: 73.5082\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 170369.9219 - val_loss: 73.1281\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 164019.7344 - val_loss: 72.8080\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 155979.3438 - val_loss: 72.4164\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 143733.9531 - val_loss: 72.0639\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 171377.6094 - val_loss: 71.7620\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 168409.3438 - val_loss: 71.4475\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 149100.5000 - val_loss: 71.1603\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 158140.0781 - val_loss: 70.8372\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 154573.7812 - val_loss: 70.4806\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff407c9ed30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 82 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 949.8048 - val_loss: 88.8660\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 204190.0000 - val_loss: 90.7203\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 143383.1406 - val_loss: 94.1961\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33987.3359 - val_loss: 97.7814\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27193.7598 - val_loss: 98.9313\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33929.7070 - val_loss: 97.7478\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17475.3379 - val_loss: 97.3180\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7947.9170 - val_loss: 97.5637\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36261.7305 - val_loss: 96.4074\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13106.6211 - val_loss: 98.3956\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23832.3633 - val_loss: 99.0225\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25705.6543 - val_loss: 97.4095\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14619.3057 - val_loss: 97.8532\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 118.0451 - val_loss: 96.7375\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24175.7637 - val_loss: 97.7130\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5427.8687 - val_loss: 97.5328\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21125.3184 - val_loss: 97.2959\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4477.9438 - val_loss: 99.1190\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 50758.2305 - val_loss: 99.9914\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42248.2578 - val_loss: 98.5482\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15129.2139 - val_loss: 95.6524\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71635.5547 - val_loss: 94.6861\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 65622.2656 - val_loss: 95.9436\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41365.3242 - val_loss: 98.5551\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42408.8789 - val_loss: 99.6395\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38005.5508 - val_loss: 97.6719\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27641.5781 - val_loss: 96.9205\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11151.1641 - val_loss: 98.2255\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28039.8164 - val_loss: 99.0831\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25180.6074 - val_loss: 98.2451\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1758.3746 - val_loss: 96.4580\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41836.4062 - val_loss: 96.1811\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41786.4180 - val_loss: 96.9328\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13168.5469 - val_loss: 98.2468\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24705.4863 - val_loss: 99.0976\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21777.0703 - val_loss: 98.6836\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13664.6943 - val_loss: 96.4333\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 53704.3359 - val_loss: 95.8154\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54212.8398 - val_loss: 96.1591\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26917.4004 - val_loss: 97.9956\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21415.6289 - val_loss: 99.1106\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20442.4531 - val_loss: 97.8443\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9092.9854 - val_loss: 98.0333\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3128.1023 - val_loss: 97.7456\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14772.7793 - val_loss: 97.6997\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3634.6267 - val_loss: 98.7212\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21771.2461 - val_loss: 98.9129\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19301.9922 - val_loss: 98.5099\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4705.1025 - val_loss: 97.1735\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 26112.6504 - val_loss: 97.1019\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fe088550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 83 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 85.7837 - val_loss: 59.3265\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.2515 - val_loss: 4.5944\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.2132 - val_loss: 4.2812\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.0848 - val_loss: 18.4783\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.5690 - val_loss: 15.8293\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5544 - val_loss: 5.5210\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2208 - val_loss: 7.2492\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1292 - val_loss: 10.6175\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0372 - val_loss: 7.3645\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3737 - val_loss: 6.2204\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0481 - val_loss: 7.5543\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5678 - val_loss: 5.1516\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2264 - val_loss: 6.6649\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7236 - val_loss: 4.8718\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.3497 - val_loss: 4.4957\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1068 - val_loss: 5.3848\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0063 - val_loss: 4.0154\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7362 - val_loss: 3.3688\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.8240 - val_loss: 3.7421\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5755 - val_loss: 3.4035\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.9863 - val_loss: 3.6020\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.6985 - val_loss: 3.9789\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5081 - val_loss: 3.5272\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.3831 - val_loss: 4.6257\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.5854 - val_loss: 3.4442\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5232 - val_loss: 7.0923\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.3365 - val_loss: 4.0607\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.3634 - val_loss: 6.4026\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0020 - val_loss: 3.5463\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7356 - val_loss: 3.4856\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2674 - val_loss: 3.4446\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2077 - val_loss: 3.3321\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.0729 - val_loss: 3.3390\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.0691 - val_loss: 3.4065\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.0564 - val_loss: 3.2785\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.0376 - val_loss: 3.3981\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0152 - val_loss: 3.8058\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9581 - val_loss: 3.2795\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.9641 - val_loss: 3.3072\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.0020 - val_loss: 3.2587\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9602 - val_loss: 3.3133\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.8463 - val_loss: 3.4304\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.8431 - val_loss: 3.4895\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8651 - val_loss: 3.2353\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.8691 - val_loss: 3.5799\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.0451 - val_loss: 3.5454\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.7675 - val_loss: 3.2567\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.7335 - val_loss: 3.2676\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.8096 - val_loss: 3.5445\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5309 - val_loss: 3.2781\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40c9040d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 84 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 74.3432 - val_loss: 59.1530\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.6252 - val_loss: 28.0105\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36.5642 - val_loss: 28.0182\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 31.9340 - val_loss: 34.2997\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.7549 - val_loss: 25.1061\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.9801 - val_loss: 15.1301\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21.3102 - val_loss: 16.5927\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.1521 - val_loss: 10.6015\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.6733 - val_loss: 9.0594\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 15.4209 - val_loss: 8.6895\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.2280 - val_loss: 8.8308\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.5561 - val_loss: 9.5990\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.2541 - val_loss: 9.6179\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.3790 - val_loss: 9.6562\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.2276 - val_loss: 9.4145\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.5488 - val_loss: 9.4363\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.3885 - val_loss: 9.3214\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.3066 - val_loss: 9.2856\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.5521 - val_loss: 9.1942\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.1971 - val_loss: 9.8422\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.4625 - val_loss: 9.4062\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.4272 - val_loss: 9.0286\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.0576 - val_loss: 8.9582\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.6826 - val_loss: 9.8041\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.5423 - val_loss: 9.0662\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.6056 - val_loss: 9.7524\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.3932 - val_loss: 8.8536\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.5286 - val_loss: 9.0266\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.2759 - val_loss: 9.3605\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.1455 - val_loss: 8.7376\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.2389 - val_loss: 8.8317\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.9629 - val_loss: 8.7139\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.9743 - val_loss: 8.9658\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.1514 - val_loss: 8.8370\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.2124 - val_loss: 9.1882\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.8742 - val_loss: 8.7361\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.7060 - val_loss: 8.5361\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4520 - val_loss: 8.3918\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3846 - val_loss: 8.6721\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4376 - val_loss: 8.4931\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.6808 - val_loss: 8.6631\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.3293 - val_loss: 8.2852\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.3744 - val_loss: 8.7765\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.6607 - val_loss: 8.1939\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.6558 - val_loss: 8.0320\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.1004 - val_loss: 8.3235\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.1708 - val_loss: 8.0719\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0015 - val_loss: 8.5634\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.8980 - val_loss: 7.9080\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.9104 - val_loss: 8.6210\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff411129dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 85 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 84.8697 - val_loss: 66.2117\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41.4509 - val_loss: 20.4250\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.6878 - val_loss: 9.7135\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.0285 - val_loss: 23.3694\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.6063 - val_loss: 26.7957\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.9683 - val_loss: 18.9115\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.5877 - val_loss: 10.1747\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.1488 - val_loss: 15.9570\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.1479 - val_loss: 15.6850\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4161 - val_loss: 9.6762\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.6615 - val_loss: 11.1333\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3032 - val_loss: 10.2368\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4928 - val_loss: 6.0455\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9166 - val_loss: 8.4460\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3202 - val_loss: 6.6659\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2487 - val_loss: 7.3038\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9056 - val_loss: 6.2084\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4031 - val_loss: 7.0127\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0037 - val_loss: 5.8784\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7537 - val_loss: 6.2436\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8179 - val_loss: 6.1477\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6483 - val_loss: 6.2911\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2692 - val_loss: 8.5580\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9292 - val_loss: 7.4645\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0567 - val_loss: 8.1149\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1277 - val_loss: 6.5525\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7679 - val_loss: 7.1470\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2759 - val_loss: 6.1631\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9385 - val_loss: 6.9027\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4397 - val_loss: 6.2309\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.4238 - val_loss: 6.3264\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0849 - val_loss: 6.5131\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7083 - val_loss: 6.3817\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.7280 - val_loss: 6.6208\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2813 - val_loss: 6.4477\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0583 - val_loss: 6.2314\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0566 - val_loss: 6.2281\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7739 - val_loss: 6.2383\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.9389 - val_loss: 6.3323\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1863 - val_loss: 6.2527\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0747 - val_loss: 6.2916\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.9791 - val_loss: 6.4313\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.3055 - val_loss: 6.5063\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6356 - val_loss: 6.4136\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1153 - val_loss: 6.2908\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.0570 - val_loss: 6.0984\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9753 - val_loss: 6.0851\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7297 - val_loss: 6.1260\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7300 - val_loss: 6.0472\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.8458 - val_loss: 6.0285\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40e0cba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 86 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 81.4171 - val_loss: 61.1080\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36.1188 - val_loss: 18.1275\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.4398 - val_loss: 25.5253\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23.2442 - val_loss: 31.9255\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.3258 - val_loss: 24.0833\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20.1361 - val_loss: 16.4436\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.1152 - val_loss: 18.3449\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.6382 - val_loss: 16.5164\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.4320 - val_loss: 10.9384\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.0361 - val_loss: 7.4606\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.6011 - val_loss: 8.0006\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2028 - val_loss: 7.6478\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2892 - val_loss: 7.6259\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8207 - val_loss: 7.2875\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5152 - val_loss: 7.0635\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2255 - val_loss: 6.9185\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0703 - val_loss: 7.0936\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6731 - val_loss: 7.1827\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6197 - val_loss: 7.2842\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5818 - val_loss: 7.3372\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0791 - val_loss: 7.4350\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6121 - val_loss: 6.9326\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1523 - val_loss: 6.8752\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2026 - val_loss: 8.8285\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7116 - val_loss: 7.2200\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1924 - val_loss: 7.2187\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5338 - val_loss: 7.1658\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9684 - val_loss: 6.5016\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4907 - val_loss: 6.4650\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5870 - val_loss: 6.2949\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7964 - val_loss: 6.4537\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.6050 - val_loss: 6.2819\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5163 - val_loss: 6.2426\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3860 - val_loss: 7.0647\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4662 - val_loss: 6.3212\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.2790 - val_loss: 6.4371\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.3153 - val_loss: 6.0506\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2957 - val_loss: 6.4402\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3033 - val_loss: 6.2267\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3040 - val_loss: 5.9061\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3871 - val_loss: 6.2726\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0320 - val_loss: 5.8490\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2636 - val_loss: 6.1536\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3684 - val_loss: 6.7791\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2689 - val_loss: 5.8875\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9298 - val_loss: 6.2207\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1176 - val_loss: 5.6437\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.0789 - val_loss: 5.6587\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2257 - val_loss: 6.4448\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3064 - val_loss: 5.2397\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4117124c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 87 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 14854.0957 - val_loss: 87.9653\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22957.8457 - val_loss: 89.8292\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44794.0078 - val_loss: 89.2687\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27542.1973 - val_loss: 80.5331\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 77839.2812 - val_loss: 80.4382\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 84965.6719 - val_loss: 83.4892\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32945.2812 - val_loss: 87.1066\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6106.5874 - val_loss: 93.1937\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 78183.9844 - val_loss: 94.3306\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 85209.0781 - val_loss: 93.3427\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57097.7422 - val_loss: 90.8417\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4228.2515 - val_loss: 87.8008\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 66196.8125 - val_loss: 87.6325\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 63361.8750 - val_loss: 88.4492\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43372.2656 - val_loss: 92.2414\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10860.4141 - val_loss: 92.9107\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23147.5684 - val_loss: 92.1375\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5627.6245 - val_loss: 91.9335\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4713.7271 - val_loss: 91.3130\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18566.1055 - val_loss: 91.2500\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6542.8555 - val_loss: 92.2185\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1226.0267 - val_loss: 92.6517\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9172.1074 - val_loss: 92.1458\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 825.5308 - val_loss: 93.2385\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 29573.1211 - val_loss: 93.6281\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3904.5901 - val_loss: 91.7088\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37471.4609 - val_loss: 89.7424\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40323.5117 - val_loss: 91.1028\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9881.7676 - val_loss: 92.3669\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30331.9414 - val_loss: 94.1174\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26320.1426 - val_loss: 92.6917\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 835.0554 - val_loss: 90.3347\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 53849.0312 - val_loss: 89.8867\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 51072.1758 - val_loss: 91.2666\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25872.0625 - val_loss: 93.3917\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21449.0156 - val_loss: 94.2516\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15704.3867 - val_loss: 93.6811\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5039.2803 - val_loss: 92.9493\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6201.5273 - val_loss: 93.7053\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7363.3691 - val_loss: 93.4108\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1325.2769 - val_loss: 92.0988\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23136.1094 - val_loss: 92.5049\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15730.3555 - val_loss: 93.7107\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4645.3525 - val_loss: 93.4961\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1647.2399 - val_loss: 94.1035\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13798.3486 - val_loss: 93.9257\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5240.5093 - val_loss: 92.7254\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27389.5762 - val_loss: 92.3754\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20339.8301 - val_loss: 93.5409\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5614.5815 - val_loss: 93.8883\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4055e9040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 88 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 69269.7188 - val_loss: 106.3058\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 189257.7969 - val_loss: 109.5125\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 138010.7969 - val_loss: 103.5583\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19948.9453 - val_loss: 97.6890\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 128618.9844 - val_loss: 95.2339\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 121938.5625 - val_loss: 97.4732\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 49945.3906 - val_loss: 100.1261\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48621.0938 - val_loss: 101.1251\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 39805.9688 - val_loss: 99.4460\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13612.4033 - val_loss: 99.4995\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3951.3792 - val_loss: 101.1708\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 68103.2422 - val_loss: 101.7425\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38373.2695 - val_loss: 100.1783\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10331.1650 - val_loss: 97.4058\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 106508.7109 - val_loss: 96.4364\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 105330.4375 - val_loss: 97.9883\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 67155.2109 - val_loss: 100.0959\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15755.8057 - val_loss: 100.9355\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 653.2757 - val_loss: 99.5027\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 54260.4453 - val_loss: 98.7943\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 50048.9102 - val_loss: 99.8637\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9788.2793 - val_loss: 101.3328\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52128.8281 - val_loss: 102.2032\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35141.4258 - val_loss: 101.3486\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12836.4609 - val_loss: 99.0624\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 63212.3477 - val_loss: 98.1954\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 67508.7500 - val_loss: 98.9386\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44565.0430 - val_loss: 100.2381\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4715.8560 - val_loss: 101.8351\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64363.3281 - val_loss: 102.3937\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 60485.7305 - val_loss: 101.5998\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18789.0996 - val_loss: 100.7672\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11507.1328 - val_loss: 100.0329\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16872.0977 - val_loss: 100.6842\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11173.7939 - val_loss: 100.8083\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5029.4785 - val_loss: 99.3102\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54020.8086 - val_loss: 98.9505\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51885.4805 - val_loss: 99.5229\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23279.0820 - val_loss: 100.4783\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6304.3540 - val_loss: 102.2387\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 61807.4336 - val_loss: 102.7171\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 62125.5781 - val_loss: 102.0567\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42653.3438 - val_loss: 100.8933\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1118.8135 - val_loss: 99.6710\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 50459.3164 - val_loss: 99.1778\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48303.7148 - val_loss: 99.8815\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23530.7832 - val_loss: 101.0615\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8471.2100 - val_loss: 101.0350\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8802.9717 - val_loss: 100.5243\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19630.9004 - val_loss: 100.2244\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fb709700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 89 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 55.1854 - val_loss: 38.2379\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27.1896 - val_loss: 12.0219\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 26.0548 - val_loss: 26.2981\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22.2771 - val_loss: 27.5843\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19.7559 - val_loss: 17.0294\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.7268 - val_loss: 10.9205\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.2117 - val_loss: 16.8694\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.6182 - val_loss: 11.6401\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.9327 - val_loss: 6.3848\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.7535 - val_loss: 8.7456\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.0006 - val_loss: 5.7144\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0559 - val_loss: 7.2190\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.2585 - val_loss: 5.1295\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.4955 - val_loss: 7.4074\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.0481 - val_loss: 5.3147\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2455 - val_loss: 7.4109\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5648 - val_loss: 5.1802\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3439 - val_loss: 6.4438\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.9717 - val_loss: 5.2962\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1195 - val_loss: 6.7808\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8005 - val_loss: 4.9789\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9830 - val_loss: 5.8341\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6289 - val_loss: 5.0486\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1037 - val_loss: 5.2463\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9259 - val_loss: 5.4223\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9098 - val_loss: 4.7181\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.8932 - val_loss: 5.0741\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.8666 - val_loss: 5.5312\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6043 - val_loss: 4.7483\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2440 - val_loss: 5.9622\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3762 - val_loss: 4.4056\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4774 - val_loss: 5.8895\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3817 - val_loss: 4.4741\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4311 - val_loss: 6.1773\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4355 - val_loss: 4.5406\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9108 - val_loss: 4.6027\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7374 - val_loss: 5.2475\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.7787 - val_loss: 4.1503\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1148 - val_loss: 5.5943\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0882 - val_loss: 4.6405\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0736 - val_loss: 5.1628\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1870 - val_loss: 4.4846\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1037 - val_loss: 4.2676\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.1849 - val_loss: 4.2637\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8514 - val_loss: 4.4725\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9215 - val_loss: 4.2898\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8664 - val_loss: 4.2038\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7375 - val_loss: 4.3611\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7073 - val_loss: 4.0589\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4655 - val_loss: 4.0671\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4149565e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 90 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 183ms/step - loss: 48115.2969 - val_loss: 113.6021\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 118691.7891 - val_loss: 109.7883\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 53615.2188 - val_loss: 105.3806\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13757.0938 - val_loss: 95.8317\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 155401.1250 - val_loss: 92.5511\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 139222.2969 - val_loss: 95.6114\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 87894.7188 - val_loss: 100.5956\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 230.1226 - val_loss: 105.4113\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 63613.3086 - val_loss: 106.7868\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 72211.4375 - val_loss: 105.1080\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35351.7383 - val_loss: 102.2660\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16785.6621 - val_loss: 101.2994\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13295.9092 - val_loss: 103.5377\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29344.7734 - val_loss: 103.1401\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16148.5557 - val_loss: 100.9491\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17139.9980 - val_loss: 101.2446\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9022.6504 - val_loss: 102.2833\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24972.5781 - val_loss: 103.0260\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19723.3613 - val_loss: 100.6045\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39881.3281 - val_loss: 99.7362\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33734.8789 - val_loss: 102.7009\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17999.9785 - val_loss: 102.7061\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19037.4414 - val_loss: 101.0326\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12887.3750 - val_loss: 101.4009\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4365.9048 - val_loss: 101.1285\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17418.3086 - val_loss: 100.8322\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 163.7539 - val_loss: 100.9974\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28798.1094 - val_loss: 99.9902\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12373.8730 - val_loss: 101.6679\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33177.9531 - val_loss: 102.9666\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18365.7559 - val_loss: 101.6600\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17912.0723 - val_loss: 100.0681\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20285.1250 - val_loss: 100.5590\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4590.1157 - val_loss: 102.7654\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49106.6055 - val_loss: 103.6212\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46720.5547 - val_loss: 101.9491\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14020.4707 - val_loss: 99.8690\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39782.1328 - val_loss: 98.8468\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27252.3145 - val_loss: 100.0819\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9951.4424 - val_loss: 101.0528\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6812.0264 - val_loss: 99.2124\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26881.5566 - val_loss: 99.3077\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23622.7344 - val_loss: 99.8960\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8625.5645 - val_loss: 101.8059\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29328.2734 - val_loss: 102.1482\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30251.3125 - val_loss: 101.6409\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16422.1816 - val_loss: 99.8070\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29860.4766 - val_loss: 99.0562\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25207.1602 - val_loss: 99.5488\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11574.3672 - val_loss: 101.7372\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f51aa550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 91 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 96.7129 - val_loss: 79.0853\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 68.4667 - val_loss: 65.6520\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53.8682 - val_loss: 52.0229\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42.4852 - val_loss: 40.5131\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34.7872 - val_loss: 35.7212\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.8603 - val_loss: 23.9990\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.0596 - val_loss: 13.8327\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.1890 - val_loss: 6.1193\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.9828 - val_loss: 6.1131\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.0123 - val_loss: 7.0932\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.1166 - val_loss: 8.6917\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.6441 - val_loss: 5.9813\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.7254 - val_loss: 6.5326\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.3611 - val_loss: 6.3314\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.9662 - val_loss: 5.9990\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0902 - val_loss: 5.9161\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.7459 - val_loss: 7.0748\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.0433 - val_loss: 5.6339\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.4997 - val_loss: 6.2576\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.8066 - val_loss: 5.9517\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.6077 - val_loss: 5.6014\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2136 - val_loss: 5.6511\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.6490 - val_loss: 5.9333\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.2029 - val_loss: 5.2560\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.4117 - val_loss: 5.5694\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4974 - val_loss: 5.4040\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2634 - val_loss: 5.7633\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.9162 - val_loss: 4.9483\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.3549 - val_loss: 5.4324\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9744 - val_loss: 5.2550\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.6237 - val_loss: 4.9179\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.0111 - val_loss: 6.2352\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.8853 - val_loss: 4.7518\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8192 - val_loss: 4.9615\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4935 - val_loss: 4.7633\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5509 - val_loss: 4.9066\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9297 - val_loss: 4.9380\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.1492 - val_loss: 5.3813\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7607 - val_loss: 4.6607\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5852 - val_loss: 4.9268\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.5534 - val_loss: 4.5476\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.2072 - val_loss: 5.0243\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.3945 - val_loss: 4.5655\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9342 - val_loss: 4.3844\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3665 - val_loss: 4.6439\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5234 - val_loss: 4.4260\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3644 - val_loss: 4.3416\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3410 - val_loss: 4.2423\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6515 - val_loss: 4.8775\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0996 - val_loss: 4.4507\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fe088790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 92 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 83.5428 - val_loss: 58.9442\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.5043 - val_loss: 3.9097\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.9808 - val_loss: 4.1272\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.7096 - val_loss: 25.7136\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.0365 - val_loss: 23.7010\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18.7365 - val_loss: 11.5124\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.8596 - val_loss: 9.1400\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.7842 - val_loss: 11.9418\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.7842 - val_loss: 8.1613\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.8332 - val_loss: 4.5454\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.7362 - val_loss: 4.8256\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0672 - val_loss: 4.2202\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.3884 - val_loss: 4.4746\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.0965 - val_loss: 4.6845\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4484 - val_loss: 4.7235\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2586 - val_loss: 4.9240\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4361 - val_loss: 4.6316\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3342 - val_loss: 4.5974\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8082 - val_loss: 5.2537\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1126 - val_loss: 5.2725\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5055 - val_loss: 4.6150\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7649 - val_loss: 4.4751\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6724 - val_loss: 4.5610\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4696 - val_loss: 4.4269\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2541 - val_loss: 4.4173\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0594 - val_loss: 4.3806\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1721 - val_loss: 4.8317\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2790 - val_loss: 4.8366\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8090 - val_loss: 4.4871\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8372 - val_loss: 4.5169\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5663 - val_loss: 4.6595\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4162 - val_loss: 5.3385\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2769 - val_loss: 4.2636\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2463 - val_loss: 4.4542\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8168 - val_loss: 3.7477\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6592 - val_loss: 3.7713\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6227 - val_loss: 3.7192\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5941 - val_loss: 3.5601\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5338 - val_loss: 3.5291\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.2349 - val_loss: 3.4626\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9729 - val_loss: 4.1457\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0613 - val_loss: 3.5218\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8913 - val_loss: 3.6474\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.1734 - val_loss: 4.9660\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1384 - val_loss: 3.4576\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7217 - val_loss: 4.1385\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4152 - val_loss: 3.2449\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.5322 - val_loss: 4.0754\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.6713 - val_loss: 3.6659\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3963 - val_loss: 3.4655\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40a20d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 93 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 75.3671 - val_loss: 59.8615\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51.4355 - val_loss: 36.1255\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45.2539 - val_loss: 44.1520\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.1314 - val_loss: 46.0137\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 33.1782 - val_loss: 30.8285\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 28.6867 - val_loss: 15.5707\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.8099 - val_loss: 20.1740\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 23.2174 - val_loss: 12.4494\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19.7058 - val_loss: 7.2620\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.5701 - val_loss: 12.7633\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.4317 - val_loss: 7.8625\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.3100 - val_loss: 8.7246\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.4989 - val_loss: 6.3157\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.8275 - val_loss: 5.8600\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.3882 - val_loss: 4.8760\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.0463 - val_loss: 3.2790\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.6280 - val_loss: 6.5585\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.0131 - val_loss: 3.3008\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.0712 - val_loss: 5.8706\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.8265 - val_loss: 2.9407\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.3249 - val_loss: 3.4050\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.6005 - val_loss: 6.1442\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.2323 - val_loss: 2.8762\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.8479 - val_loss: 3.3103\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.1546 - val_loss: 3.6589\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.8657 - val_loss: 3.8315\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7936 - val_loss: 3.5124\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.7584 - val_loss: 2.3616\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.8369 - val_loss: 2.8781\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.6397 - val_loss: 3.5225\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6023 - val_loss: 2.8894\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3754 - val_loss: 2.4753\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2021 - val_loss: 3.6028\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6991 - val_loss: 2.3936\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8908 - val_loss: 3.3052\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6236 - val_loss: 2.4006\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3266 - val_loss: 2.7615\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4484 - val_loss: 2.6422\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5553 - val_loss: 2.3385\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4418 - val_loss: 3.4563\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3254 - val_loss: 3.3421\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0487 - val_loss: 2.3313\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0937 - val_loss: 2.6795\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4633 - val_loss: 2.4815\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7515 - val_loss: 3.7376\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8255 - val_loss: 2.6540\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.2308 - val_loss: 2.3738\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2049 - val_loss: 2.6063\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8476 - val_loss: 2.8931\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7822 - val_loss: 2.8697\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e51d79d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 94 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 83.8682 - val_loss: 60.8412\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.1578 - val_loss: 7.0498\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 36.2378 - val_loss: 8.7173\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.9794 - val_loss: 26.4209\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24.1248 - val_loss: 24.9965\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.5120 - val_loss: 13.1445\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.0549 - val_loss: 6.0553\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.9425 - val_loss: 6.9630\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4610 - val_loss: 9.4641\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.0213 - val_loss: 6.2969\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.8599 - val_loss: 6.4768\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.7863 - val_loss: 6.7734\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.4401 - val_loss: 7.1831\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4704 - val_loss: 6.2629\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7967 - val_loss: 5.8819\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3786 - val_loss: 8.4216\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5486 - val_loss: 6.0787\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3485 - val_loss: 5.3025\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0087 - val_loss: 5.4379\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7704 - val_loss: 5.8106\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1628 - val_loss: 5.1104\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1411 - val_loss: 5.1271\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9659 - val_loss: 5.0630\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8307 - val_loss: 5.0938\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8365 - val_loss: 5.1916\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6764 - val_loss: 4.9220\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7781 - val_loss: 4.8257\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8023 - val_loss: 4.6533\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6568 - val_loss: 5.4351\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7127 - val_loss: 4.6833\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7921 - val_loss: 7.3026\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1712 - val_loss: 5.2825\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7172 - val_loss: 5.7718\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7435 - val_loss: 4.2837\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2044 - val_loss: 5.2588\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2913 - val_loss: 4.6418\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4912 - val_loss: 4.2544\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1386 - val_loss: 5.1664\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2809 - val_loss: 4.0920\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1481 - val_loss: 4.6953\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3284 - val_loss: 3.9627\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8183 - val_loss: 3.8986\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0182 - val_loss: 4.4129\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0703 - val_loss: 3.9185\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8350 - val_loss: 3.8544\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6504 - val_loss: 4.3779\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8245 - val_loss: 3.7649\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5548 - val_loss: 4.0596\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9711 - val_loss: 3.6821\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2320 - val_loss: 4.5183\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff414e03ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 95 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 94.3481 - val_loss: 73.8067\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53.7227 - val_loss: 35.0107\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.1922 - val_loss: 26.4812\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36.5053 - val_loss: 35.5560\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32.7562 - val_loss: 35.1224\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27.5448 - val_loss: 20.8060\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22.9309 - val_loss: 20.9636\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.3731 - val_loss: 16.9686\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.5098 - val_loss: 6.2264\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.0094 - val_loss: 8.7766\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.4638 - val_loss: 5.6495\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4134 - val_loss: 8.0732\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.2801 - val_loss: 6.4757\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.4512 - val_loss: 5.9609\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.9399 - val_loss: 5.7414\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.9684 - val_loss: 6.2999\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.4987 - val_loss: 5.0902\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.6852 - val_loss: 5.1978\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.7839 - val_loss: 6.1154\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.3672 - val_loss: 5.8843\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.7055 - val_loss: 4.8021\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.9767 - val_loss: 6.1824\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.9308 - val_loss: 5.0101\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.7324 - val_loss: 5.4916\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.2311 - val_loss: 4.9571\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.9625 - val_loss: 5.3730\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.1314 - val_loss: 5.5916\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.2523 - val_loss: 4.6337\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.5599 - val_loss: 4.8795\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.8145 - val_loss: 5.9243\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4836 - val_loss: 4.3835\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.0410 - val_loss: 5.2657\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.3806 - val_loss: 4.4140\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1755 - val_loss: 4.8051\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6991 - val_loss: 4.9503\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.6475 - val_loss: 4.5453\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5655 - val_loss: 5.4642\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6356 - val_loss: 4.2980\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.5704 - val_loss: 5.1304\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3305 - val_loss: 5.1399\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5125 - val_loss: 4.1633\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3336 - val_loss: 4.4453\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1947 - val_loss: 4.7291\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0049 - val_loss: 4.1673\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8682 - val_loss: 5.1600\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4578 - val_loss: 4.2600\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9032 - val_loss: 4.0606\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7530 - val_loss: 6.6626\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6075 - val_loss: 3.9043\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3915 - val_loss: 5.3260\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415a0d700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 96 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 60.3899 - val_loss: 33.0315\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.2380 - val_loss: 4.4680\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21.9736 - val_loss: 14.8945\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.7127 - val_loss: 25.2578\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.1388 - val_loss: 14.2249\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.3982 - val_loss: 11.1257\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.2763 - val_loss: 16.9731\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.0724 - val_loss: 14.9222\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.4503 - val_loss: 9.4469\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8054 - val_loss: 12.2611\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.5037 - val_loss: 6.9751\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.2532 - val_loss: 9.6004\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6732 - val_loss: 2.6856\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4108 - val_loss: 7.7229\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7425 - val_loss: 2.7119\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1835 - val_loss: 6.3070\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.8464 - val_loss: 5.9149\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4463 - val_loss: 3.9055\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2840 - val_loss: 6.2588\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1493 - val_loss: 2.4702\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.1650 - val_loss: 6.8563\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.2953 - val_loss: 2.1754\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.0319 - val_loss: 6.7055\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3458 - val_loss: 2.2956\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.9707 - val_loss: 4.0478\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6274 - val_loss: 2.1801\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.9867 - val_loss: 2.2734\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8187 - val_loss: 3.4017\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.7280 - val_loss: 2.2129\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.6135 - val_loss: 3.6677\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.3888 - val_loss: 2.1558\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.2692 - val_loss: 2.4118\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1387 - val_loss: 2.2269\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.1714 - val_loss: 2.1013\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.3352 - val_loss: 2.2813\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1908 - val_loss: 2.1654\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.9175 - val_loss: 2.5194\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1634 - val_loss: 2.8686\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.9409 - val_loss: 2.2669\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.9207 - val_loss: 2.3016\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.9527 - val_loss: 1.9806\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8263 - val_loss: 2.0237\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8806 - val_loss: 2.5246\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.3245 - val_loss: 2.0730\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.0284 - val_loss: 1.9678\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9304 - val_loss: 2.0988\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.7695 - val_loss: 2.0784\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7569 - val_loss: 2.0320\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.7061 - val_loss: 2.2183\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7348 - val_loss: 2.0231\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40b1d15e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 97 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 67.2410 - val_loss: 41.3820\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.9308 - val_loss: 10.8691\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.7152 - val_loss: 7.8256\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 14.9903 - val_loss: 18.5035\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.2145 - val_loss: 12.6041\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.7572 - val_loss: 6.0165\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.6748 - val_loss: 2.5179\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5793 - val_loss: 9.9906\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4109 - val_loss: 4.6515\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.4698 - val_loss: 4.3222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1331 - val_loss: 2.7655\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.2878 - val_loss: 2.7309\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.7549 - val_loss: 2.6799\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9335 - val_loss: 3.3817\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9294 - val_loss: 3.5459\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.5430 - val_loss: 3.3021\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.5558 - val_loss: 2.5177\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.1622 - val_loss: 2.9115\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.0938 - val_loss: 2.4029\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.8848 - val_loss: 2.4863\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.8546 - val_loss: 3.7873\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.8944 - val_loss: 2.6110\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7355 - val_loss: 2.7593\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.7649 - val_loss: 3.0950\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4.1442 - val_loss: 3.1325\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2298 - val_loss: 6.0002\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5607 - val_loss: 2.6911\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.4119 - val_loss: 2.5177\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.0962 - val_loss: 4.2654\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.3241 - val_loss: 3.6550\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.8918 - val_loss: 5.5768\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.5934 - val_loss: 2.9216\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.0167 - val_loss: 3.4477\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.3608 - val_loss: 2.5506\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.3566 - val_loss: 4.0482\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1918 - val_loss: 3.0124\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.1841 - val_loss: 3.1914\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.3191 - val_loss: 2.9555\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.3048 - val_loss: 2.9541\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1390 - val_loss: 3.6865\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1834 - val_loss: 4.2162\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 3.6479 - val_loss: 2.5704\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.8899 - val_loss: 4.2172\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.9700 - val_loss: 3.3450\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1534 - val_loss: 2.8229\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1436 - val_loss: 3.1257\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.1081 - val_loss: 4.3953\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.8089 - val_loss: 3.4108\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.8163 - val_loss: 3.7191\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.7701 - val_loss: 3.9218\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40250c040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 98 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 90.0224 - val_loss: 65.1241\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44.8239 - val_loss: 23.5598\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.1326 - val_loss: 16.9930\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30.6133 - val_loss: 23.4026\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.3056 - val_loss: 27.8743\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.4417 - val_loss: 17.4092\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.5304 - val_loss: 13.6432\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.2684 - val_loss: 19.4223\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.4254 - val_loss: 11.1479\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.2144 - val_loss: 10.5429\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.5769 - val_loss: 12.2740\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.3456 - val_loss: 10.4699\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.5968 - val_loss: 10.8088\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.9985 - val_loss: 12.6579\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.4741 - val_loss: 9.7843\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.9031 - val_loss: 10.7728\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.4499 - val_loss: 10.3012\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.4616 - val_loss: 9.7811\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.1850 - val_loss: 9.7350\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1579 - val_loss: 9.5122\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.4399 - val_loss: 9.8437\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.1081 - val_loss: 9.2847\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.1582 - val_loss: 10.3977\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.6034 - val_loss: 9.2965\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.2034 - val_loss: 9.2144\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.9371 - val_loss: 9.0261\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.8867 - val_loss: 8.9157\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.1382 - val_loss: 8.9755\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.2230 - val_loss: 9.9828\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.1891 - val_loss: 9.0097\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8272 - val_loss: 8.7019\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3183 - val_loss: 8.6228\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.1072 - val_loss: 8.9380\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.9672 - val_loss: 8.5488\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7668 - val_loss: 8.4731\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.8706 - val_loss: 8.6697\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.1921 - val_loss: 8.3989\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7545 - val_loss: 8.5196\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4690 - val_loss: 8.1744\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7866 - val_loss: 9.0300\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.3884 - val_loss: 8.0689\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3756 - val_loss: 8.4325\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8512 - val_loss: 7.9924\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9712 - val_loss: 7.9499\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.9878 - val_loss: 7.9527\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.3209 - val_loss: 7.9045\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.9263 - val_loss: 8.3286\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.5581 - val_loss: 7.7253\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0665 - val_loss: 7.6504\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0588 - val_loss: 7.7561\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415518550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 99 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 72095.5000 - val_loss: 102.1964\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 113447.2266 - val_loss: 99.6164\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53621.2500 - val_loss: 95.2517\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60173.2695 - val_loss: 92.5638\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 22372.9453 - val_loss: 96.3162\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55007.5625 - val_loss: 98.6803\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48313.1758 - val_loss: 97.7058\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33443.3555 - val_loss: 92.5648\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 105619.2656 - val_loss: 90.3079\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 84442.6875 - val_loss: 91.9692\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34150.0547 - val_loss: 95.6499\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 37348.8984 - val_loss: 97.9301\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43977.1328 - val_loss: 97.5768\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24965.6191 - val_loss: 95.2312\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18292.1992 - val_loss: 95.1901\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20305.5371 - val_loss: 96.6634\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13019.3838 - val_loss: 96.3303\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5483.5239 - val_loss: 96.5583\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13795.3779 - val_loss: 96.5248\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1131.4647 - val_loss: 96.9547\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22933.5078 - val_loss: 97.0374\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10584.4717 - val_loss: 95.1589\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32525.3379 - val_loss: 95.0141\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 27728.0566 - val_loss: 96.0763\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3827.8137 - val_loss: 96.2702\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9722.2715 - val_loss: 96.3585\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12413.9199 - val_loss: 96.8880\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9492.3301 - val_loss: 95.4175\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 34518.5547 - val_loss: 95.1684\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19634.0527 - val_loss: 96.3605\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2588.7981 - val_loss: 99.0642\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 70678.7188 - val_loss: 99.8018\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 69939.4531 - val_loss: 98.5376\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37560.7461 - val_loss: 96.7983\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14563.3457 - val_loss: 96.1384\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9192.2471 - val_loss: 97.1487\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10429.0859 - val_loss: 96.9901\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6638.7070 - val_loss: 95.7684\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 28058.9570 - val_loss: 95.7989\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12808.7285 - val_loss: 96.5646\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3471.5439 - val_loss: 99.2201\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 63721.9219 - val_loss: 99.8697\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 72318.7344 - val_loss: 99.7318\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47577.6094 - val_loss: 98.1356\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5752.1968 - val_loss: 96.2263\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25162.9180 - val_loss: 95.4209\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36485.4180 - val_loss: 95.9173\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17226.2676 - val_loss: 96.7933\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15449.8271 - val_loss: 97.5099\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4480.5195 - val_loss: 96.6038\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff414dd7ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 100 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 102.1818 - val_loss: 82.5336\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 62.8999 - val_loss: 42.9365\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.9679 - val_loss: 7.0541\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.6710 - val_loss: 16.2559\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.5367 - val_loss: 24.8073\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.0032 - val_loss: 14.8938\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.0549 - val_loss: 8.2146\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5195 - val_loss: 12.6801\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2833 - val_loss: 15.0892\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.2661 - val_loss: 12.1350\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.5004 - val_loss: 6.5066\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0601 - val_loss: 10.5913\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3799 - val_loss: 8.5120\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9234 - val_loss: 6.4253\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0836 - val_loss: 8.4068\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5031 - val_loss: 4.9712\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.1140 - val_loss: 6.8522\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7752 - val_loss: 4.2211\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6469 - val_loss: 4.2062\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.1827 - val_loss: 4.7999\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1957 - val_loss: 4.5897\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.6852 - val_loss: 4.3649\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.6496 - val_loss: 4.4063\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.6795 - val_loss: 4.2937\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.4775 - val_loss: 4.2455\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4725 - val_loss: 4.2492\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3.5450 - val_loss: 4.1741\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4214 - val_loss: 4.3157\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.5378 - val_loss: 4.1565\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.2574 - val_loss: 4.0599\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.3271 - val_loss: 4.1487\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3739 - val_loss: 4.0943\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2288 - val_loss: 4.7158\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.8095 - val_loss: 4.2634\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4809 - val_loss: 3.9949\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.1220 - val_loss: 4.2596\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.2533 - val_loss: 4.0155\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2105 - val_loss: 3.9278\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.3523 - val_loss: 4.0697\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.3214 - val_loss: 4.6747\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.6356 - val_loss: 3.8292\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.2151 - val_loss: 3.9509\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.0296 - val_loss: 4.2152\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.9915 - val_loss: 3.7354\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.0233 - val_loss: 3.7708\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.9859 - val_loss: 3.9962\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4376 - val_loss: 4.4111\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7062 - val_loss: 5.1397\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4902 - val_loss: 3.7313\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.2692 - val_loss: 3.7396\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff414dd7700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 101 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 82.3652 - val_loss: 63.9967\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37.7713 - val_loss: 22.5939\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.8116 - val_loss: 27.8111\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27.9615 - val_loss: 36.4421\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26.0441 - val_loss: 31.8040\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22.3858 - val_loss: 18.8963\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.3412 - val_loss: 17.1085\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.1345 - val_loss: 17.4500\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.6416 - val_loss: 10.3560\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.8346 - val_loss: 5.3409\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.2465 - val_loss: 7.7745\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.6650 - val_loss: 6.5968\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.4488 - val_loss: 5.2332\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.8836 - val_loss: 6.7311\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.4922 - val_loss: 5.4300\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8693 - val_loss: 5.4724\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7358 - val_loss: 4.4200\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.4201 - val_loss: 2.5642\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6276 - val_loss: 4.4826\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2118 - val_loss: 1.1837\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3732 - val_loss: 5.9234\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7752 - val_loss: 1.6803\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.4581 - val_loss: 3.9781\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0975 - val_loss: 2.3706\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9009 - val_loss: 2.6248\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9016 - val_loss: 4.3603\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7754 - val_loss: 1.8174\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.2058 - val_loss: 2.8287\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7330 - val_loss: 1.9005\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6835 - val_loss: 1.8345\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2260 - val_loss: 2.3670\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.2974 - val_loss: 1.7622\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.4339 - val_loss: 1.7319\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7548 - val_loss: 3.2680\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8773 - val_loss: 1.8631\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6741 - val_loss: 1.7347\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.0539 - val_loss: 1.4652\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6945 - val_loss: 1.5956\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8582 - val_loss: 2.7661\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3480 - val_loss: 2.2850\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8645 - val_loss: 2.7862\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.7787 - val_loss: 1.7263\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7609 - val_loss: 1.7447\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.7539 - val_loss: 1.7545\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.2476 - val_loss: 2.4242\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.2739 - val_loss: 1.5677\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2294 - val_loss: 2.1562\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.1520 - val_loss: 1.5042\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0169 - val_loss: 1.6072\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.9666 - val_loss: 1.3915\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415518ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 102 finished\n"
     ]
    }
   ],
   "source": [
    "zipcodes = nv_zipcodes\n",
    "dict_mape = {}\n",
    "dict_pred = {}\n",
    "\n",
    "for zipcode in range(len(zipcodes)):\n",
    "\n",
    "    # init a RMM model\n",
    "    rnn_model = Sequential()\n",
    "    # add 4 layers of RNN and a last layer\n",
    "\n",
    "    # we define shape on first layer, (60,1) because we use 60 inputs per prediction\n",
    "    rnn_model.add(LSTM(units= 60, return_sequences = False, input_shape=((60,1))))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # 3 other layers\n",
    "    #rnn_model.add(LSTM(units= 30, return_sequences = True))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # return_sequence is False because we want only 1 output after this layer\n",
    "    #rnn_model.add(LSTM(units= 60, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # last layer \n",
    "\n",
    "    rnn_model.add(Dense(units=1))\n",
    "\n",
    "    # compile - because this is a regression model we want to minimize MSE\n",
    "\n",
    "    rnn_model.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "\n",
    "    # We get only the specific column(Zipcode from our train and test datas)\n",
    "    train_data = train.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    test_data = test.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # We are using normalizaion rather than standascaler. \n",
    "    # In a upward trending timeseries it is better to not start from negative\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Because we are using 60 previous values to model and predict the next value, \n",
    "    # We set X_train from arrays of 60 for each y_train value\n",
    "    # Same idea for test data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(train_data_scaled)):\n",
    "        X_train.append(train_data_scaled[i-60:i])\n",
    "        y_train.append(train_data_scaled[i])\n",
    "\n",
    "    data_total = pd.concat((train.iloc[:,zipcode:zipcode+1], test.iloc[:,zipcode:zipcode+1]),axis=0)\n",
    "    inputs = data_total[len(train)-60:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(60,len(inputs)):\n",
    "        X_test.append(inputs[i-60:i])\n",
    "        y_test.append(inputs[i])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(test_data)\n",
    "\n",
    "    # We need numpy arrays for our model\n",
    "    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # We fit our data to our zipcode specific data\n",
    "    rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, scaler.transform(y_test)))\n",
    "\n",
    "    # Make predictions on the data\n",
    "\n",
    "    y_hat_raw = rnn_model.predict(X_test)\n",
    "    y_hat = scaler.inverse_transform(y_hat_raw)\n",
    "\n",
    "    # Use the score on unseen test data to calculate the MAPE\n",
    "\n",
    "    dict_mape[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_test)/y_test))      \n",
    "\n",
    "    # We get the last 60 values from our test data which is basically last 60 values in the data set\n",
    "    last_60 = df_time_series.iloc[-60:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # Before we use our data we scale it\n",
    "    last_60 = scaler.transform(last_60)\n",
    "    \n",
    "    # Our input should be in (x,60,1) format\n",
    "    x_new_pred = last_60[-60:].reshape(1,60,1)\n",
    "\n",
    "    # make a prediction, add to the last_60 for the next prediction and \n",
    "    y_pred = rnn_model.predict(x_new_pred)\n",
    "\n",
    "    # We add our predition to our list of predictions for zipcode specific predictions list\n",
    "    dict_pred[zipcodes[zipcode]]=scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(f'Iteration number {zipcode} finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_keys = list(dict_mape.keys())\n",
    "rnn_mape = list(dict_mape.values())\n",
    "rnn_pred = []\n",
    "rnn_dict = {}\n",
    "for zipcode in dict_pred.keys():\n",
    "    rnn_pred.append(dict_pred[zipcode].astype(int)[0][0])\n",
    "for zc in rnn_keys:\n",
    "    a = []\n",
    "    a.append(dict_mape[zc])\n",
    "    a.append(dict_pred[zc].astype(float)[0][0])\n",
    "    a.append('RNN')\n",
    "    rnn_dict[zc] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95804: [0.5249661853680645, 72680.1015625, 'RNN'],\n",
       " 95817: [0.4872030385214798, 81155.828125, 'RNN'],\n",
       " 95813: [0.008052491635078938, 343416.90625, 'RNN'],\n",
       " 95785: [0.014499261495305815, 408869.96875, 'RNN'],\n",
       " 95819: [0.020140183496271478, 299286.53125, 'RNN'],\n",
       " 95770: [0.46004740014319195, 98583.3671875, 'RNN'],\n",
       " 95806: [0.5511401233777548, 62497.55078125, 'RNN'],\n",
       " 95790: [0.02367226537890664, 307056.4375, 'RNN'],\n",
       " 95799: [0.41608277029750435, 110232.8046875, 'RNN'],\n",
       " 95844: [0.013734452486544268, 298359.625, 'RNN'],\n",
       " 95843: [0.39383061728555874, 133019.71875, 'RNN'],\n",
       " 95815: [0.49980302429945644, 82623.078125, 'RNN'],\n",
       " 95825: [0.3942505029359258, 138097.171875, 'RNN'],\n",
       " 95818: [0.4399410165041235, 94415.8046875, 'RNN'],\n",
       " 95811: [0.4545158547574294, 78562.640625, 'RNN'],\n",
       " 95931: [0.4469864096516115, 115641.796875, 'RNN'],\n",
       " 95753: [0.367702129081654, 151804.90625, 'RNN'],\n",
       " 95827: [0.014149623323571657, 334876.96875, 'RNN'],\n",
       " 95937: [0.01106950871377929, 443817.4375, 'RNN'],\n",
       " 95914: [0.3962134958245149, 186625.390625, 'RNN'],\n",
       " 95754: [0.38858440349825074, 122805.0390625, 'RNN'],\n",
       " 95824: [0.4486604391826165, 117255.9765625, 'RNN'],\n",
       " 95945: [0.018090461313527963, 386534.28125, 'RNN'],\n",
       " 95800: [0.5656622848442678, 60476.26953125, 'RNN'],\n",
       " 95751: [0.019762942180094688, 335353.0, 'RNN'],\n",
       " 95769: [0.21667706419518556, 86911.03125, 'RNN'],\n",
       " 95909: [0.4736750189217418, 101884.4375, 'RNN'],\n",
       " 95771: [0.4483536146492791, 96108.7734375, 'RNN'],\n",
       " 95935: [0.49463097058456856, 105299.2109375, 'RNN'],\n",
       " 95798: [0.4292759466549264, 100036.8046875, 'RNN'],\n",
       " 95835: [0.381836419726009, 144332.734375, 'RNN'],\n",
       " 95845: [0.404282683209148, 146092.984375, 'RNN'],\n",
       " 95865: [0.006950994861642115, 294969.0625, 'RNN'],\n",
       " 95809: [0.0103706304773791, 303950.53125, 'RNN'],\n",
       " 95944: [0.007698578540429971, 412032.59375, 'RNN'],\n",
       " 399671: [0.40402479265833646, 127076.765625, 'RNN'],\n",
       " 95831: [0.007776241631509558, 426532.34375, 'RNN'],\n",
       " 95803: [0.5675767198529673, 59429.484375, 'RNN'],\n",
       " 95939: [0.009068167814745441, 656712.25, 'RNN'],\n",
       " 399665: [0.01682286102009584, 303646.9375, 'RNN'],\n",
       " 95826: [0.40527579748533116, 127564.046875, 'RNN'],\n",
       " 95830: [0.01155801068183575, 318444.09375, 'RNN'],\n",
       " 95932: [0.47243489344488304, 123397.6171875, 'RNN'],\n",
       " 95792: [0.4190261918120196, 112753.9296875, 'RNN'],\n",
       " 95837: [0.008590925900175631, 315318.90625, 'RNN'],\n",
       " 95750: [0.01583413992347332, 265949.625, 'RNN'],\n",
       " 95838: [0.5093627009142933, 75168.0859375, 'RNN'],\n",
       " 95912: [0.46436777043507865, 126588.5390625, 'RNN'],\n",
       " 95940: [0.2805022474664093, 115599.75, 'RNN'],\n",
       " 95841: [0.4119015224054596, 112776.1328125, 'RNN'],\n",
       " 95793: [0.01081627666331684, 299161.46875, 'RNN'],\n",
       " 95952: [0.012382276621760361, 263685.28125, 'RNN'],\n",
       " 95963: [0.09982480165100077, 210254.015625, 'RNN'],\n",
       " 95816: [0.4341434613046418, 114738.1875, 'RNN'],\n",
       " 95779: [0.010360700351435591, 356813.90625, 'RNN'],\n",
       " 95852: [0.5032267669392712, 75490.859375, 'RNN'],\n",
       " 95783: [0.30532257510450905, 114232.0, 'RNN'],\n",
       " 95814: [0.3261871025380606, 154928.890625, 'RNN'],\n",
       " 95957: [0.017065609874507906, 262641.46875, 'RNN'],\n",
       " 95888: [0.18244216115737263, 145080.1875, 'RNN'],\n",
       " 95861: [0.010756883153635951, 288260.0625, 'RNN'],\n",
       " 95840: [0.013820067004406725, 351100.34375, 'RNN'],\n",
       " 95842: [0.3997020177692815, 155280.640625, 'RNN'],\n",
       " 95766: [0.009368452837126064, 240933.203125, 'RNN'],\n",
       " 95883: [0.15954867712904547, 175055.625, 'RNN'],\n",
       " 95911: [0.47797922855479613, 109065.421875, 'RNN'],\n",
       " 95744: [0.010473932170971098, 318112.03125, 'RNN'],\n",
       " 95834: [0.009394672482179175, 436116.71875, 'RNN'],\n",
       " 95928: [0.021138152233605073, 321487.03125, 'RNN'],\n",
       " 95901: [0.018004448203545187, 395866.75, 'RNN'],\n",
       " 95890: [0.017911963964382834, 370710.75, 'RNN'],\n",
       " 95966: [0.0808115364295576, 215836.546875, 'RNN'],\n",
       " 95768: [0.1733520922342198, 131972.71875, 'RNN'],\n",
       " 95805: [0.34266690764383356, 153063.921875, 'RNN'],\n",
       " 399673: [0.476622498447178, 117211.03125, 'RNN'],\n",
       " 95954: [0.010580071578349318, 401904.875, 'RNN'],\n",
       " 399672: [0.023979937058078583, 408207.84375, 'RNN'],\n",
       " 95787: [0.3512317701965836, 75996.546875, 'RNN'],\n",
       " 95839: [0.017919257828032824, 276303.84375, 'RNN'],\n",
       " 399674: [0.009868474953755129, 540381.5625, 'RNN'],\n",
       " 95922: [0.11958216448976217, 115630.546875, 'RNN'],\n",
       " 95866: [0.009660255868905196, 304155.875, 'RNN'],\n",
       " 95907: [0.17004602987803982, 108999.390625, 'RNN'],\n",
       " 95788: [0.3868782573250403, 106090.9765625, 'RNN'],\n",
       " 95926: [0.018466005514636286, 940217.8125, 'RNN'],\n",
       " 95930: [0.04262366952726488, 330331.15625, 'RNN'],\n",
       " 95956: [0.02499140964878115, 314692.71875, 'RNN'],\n",
       " 95938: [0.0253975958046679, 414122.34375, 'RNN'],\n",
       " 95795: [0.3713807055743366, 142028.828125, 'RNN'],\n",
       " 95923: [0.32989818430053386, 406266.625, 'RNN'],\n",
       " 95955: [0.018945583709221687, 416612.0, 'RNN'],\n",
       " 95924: [0.25452267571340503, 247805.40625, 'RNN'],\n",
       " 95775: [0.013901971524148082, 211011.375, 'RNN'],\n",
       " 95919: [0.0187014152464257, 281860.09375, 'RNN'],\n",
       " 95794: [0.010119659933326806, 324525.40625, 'RNN'],\n",
       " 399666: [0.014901668557356765, 324443.5, 'RNN'],\n",
       " 95760: [0.018313854166105106, 300813.1875, 'RNN'],\n",
       " 95916: [0.010283915515249062, 454169.15625, 'RNN'],\n",
       " 95891: [0.019385074320294134, 659704.125, 'RNN'],\n",
       " 95820: [0.026546641662656644, 333096.4375, 'RNN'],\n",
       " 95917: [0.40237694269085855, 105471.84375, 'RNN'],\n",
       " 95893: [0.025635352695454836, 2101477.25, 'RNN'],\n",
       " 95851: [0.005617965905931265, 360632.53125, 'RNN']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20516228703411893"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 11875.9033 - val_loss: 69.0568\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 575708.7500 - val_loss: 61.0181\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 456049.1562 - val_loss: 77.9666\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 91782.3594 - val_loss: 87.6209\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 101103.6250 - val_loss: 94.8351\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 87383.8516 - val_loss: 93.6977\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18860.0586 - val_loss: 91.2972\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 122725.7734 - val_loss: 90.4104\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 92015.9766 - val_loss: 92.1689\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27409.3750 - val_loss: 94.9449\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58708.3750 - val_loss: 95.8137\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67696.7812 - val_loss: 94.6813\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2072.3923 - val_loss: 93.6693\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62078.5781 - val_loss: 92.4866\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 66424.5938 - val_loss: 92.9639\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 52574.6133 - val_loss: 95.8494\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 40743.3008 - val_loss: 96.2555\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57689.8008 - val_loss: 96.0740\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13925.4297 - val_loss: 94.0977\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 71836.1797 - val_loss: 92.7057\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 56192.7109 - val_loss: 93.6802\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27672.6211 - val_loss: 96.5110\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 93852.1719 - val_loss: 98.0043\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83419.5859 - val_loss: 97.0346\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 41800.0547 - val_loss: 95.1833\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55237.0664 - val_loss: 94.3291\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36053.5938 - val_loss: 95.6466\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5821.1465 - val_loss: 96.2009\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3625.6208 - val_loss: 94.9854\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33061.6914 - val_loss: 95.4035\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21046.6406 - val_loss: 96.7803\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 35625.4023 - val_loss: 97.0786\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21915.9434 - val_loss: 95.9213\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15309.4805 - val_loss: 95.8079\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10826.1367 - val_loss: 96.8418\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25131.3984 - val_loss: 96.7363\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9749.7998 - val_loss: 96.0104\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8450.7783 - val_loss: 96.0844\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6889.0059 - val_loss: 97.1899\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36515.5781 - val_loss: 97.1593\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17046.2148 - val_loss: 96.3064\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25251.2441 - val_loss: 95.7405\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21469.2207 - val_loss: 97.0352\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23688.2988 - val_loss: 96.9371\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10104.8623 - val_loss: 96.0340\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22655.3672 - val_loss: 96.0355\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15628.1221 - val_loss: 97.0761\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15123.8203 - val_loss: 96.8379\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4428.3394 - val_loss: 96.0201\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31946.8691 - val_loss: 95.8847\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff41491b9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 0 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 309446.6250 - val_loss: 125.7575\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 843952.8125 - val_loss: 120.5679\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 330845.6875 - val_loss: 105.8469\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 487479.0625 - val_loss: 101.8364\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 387529.0938 - val_loss: 107.6897\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50418.6367 - val_loss: 107.5138\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33631.5234 - val_loss: 105.2253\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 156991.8438 - val_loss: 104.8049\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64626.4141 - val_loss: 106.9548\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 78772.1016 - val_loss: 105.5906\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48273.9688 - val_loss: 104.3472\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57455.9805 - val_loss: 105.7982\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 152645.2031 - val_loss: 106.9204\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65478.1367 - val_loss: 104.2133\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 132542.5156 - val_loss: 103.4300\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 107915.0938 - val_loss: 105.2033\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55318.3672 - val_loss: 105.7421\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38043.8008 - val_loss: 103.4452\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 148478.6094 - val_loss: 103.1451\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 99039.0703 - val_loss: 104.3699\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16758.1719 - val_loss: 105.0505\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14704.1377 - val_loss: 104.1759\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 104479.9062 - val_loss: 103.3647\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84596.1250 - val_loss: 104.7114\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51768.1055 - val_loss: 105.0226\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 36380.8867 - val_loss: 103.8292\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55085.6719 - val_loss: 105.2375\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63130.7578 - val_loss: 105.4178\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 29586.0723 - val_loss: 104.3466\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38486.7344 - val_loss: 105.1283\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32820.0586 - val_loss: 104.3039\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22162.8926 - val_loss: 104.3174\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13947.0957 - val_loss: 103.4936\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69670.4766 - val_loss: 103.4186\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19552.5078 - val_loss: 104.3677\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42776.3320 - val_loss: 103.1945\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24738.5977 - val_loss: 103.4500\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4722.7427 - val_loss: 102.8344\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23033.6309 - val_loss: 103.6843\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51739.2422 - val_loss: 103.2423\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51494.4844 - val_loss: 102.3513\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53019.4570 - val_loss: 103.6433\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70057.7891 - val_loss: 103.0566\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67308.3047 - val_loss: 101.5161\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47294.6523 - val_loss: 102.6304\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 52476.3398 - val_loss: 102.4769\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20214.0098 - val_loss: 101.4274\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 77998.4375 - val_loss: 100.9890\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37408.4141 - val_loss: 102.3944\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 122255.7656 - val_loss: 103.5184\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40c904a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 1 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 64.3210 - val_loss: 44.0059\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.5235 - val_loss: 47.6096\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 41.6903 - val_loss: 43.4013\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.2729 - val_loss: 24.4373\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.2224 - val_loss: 21.7981\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26.2704 - val_loss: 12.9673\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23.0919 - val_loss: 9.6258\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21.2642 - val_loss: 5.0714\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20.6508 - val_loss: 8.9359\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.3687 - val_loss: 5.0597\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.1156 - val_loss: 10.3401\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.0633 - val_loss: 5.6516\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.6806 - val_loss: 10.6140\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.3474 - val_loss: 6.3035\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.8319 - val_loss: 9.5223\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.8908 - val_loss: 5.0297\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.5028 - val_loss: 7.1409\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.6123 - val_loss: 5.4959\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.4302 - val_loss: 7.0235\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.4133 - val_loss: 4.7990\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.4121 - val_loss: 5.8347\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.0602 - val_loss: 4.9098\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.1269 - val_loss: 5.6963\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.8087 - val_loss: 4.8796\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.1757 - val_loss: 5.7485\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.9598 - val_loss: 4.7525\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.5301 - val_loss: 5.6738\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.5028 - val_loss: 4.8351\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.9655 - val_loss: 4.5118\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.8084 - val_loss: 4.8031\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.0775 - val_loss: 5.5793\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.9339 - val_loss: 3.5982\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.3487 - val_loss: 3.6334\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.8186 - val_loss: 2.5945\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.0843 - val_loss: 6.0806\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.6878 - val_loss: 3.5164\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.6140 - val_loss: 5.8716\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2945 - val_loss: 5.2031\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3713 - val_loss: 3.4459\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.9601 - val_loss: 3.7392\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.1455 - val_loss: 6.2513\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.4695 - val_loss: 3.0587\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.7432 - val_loss: 5.0767\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.4758 - val_loss: 4.9586\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.6350 - val_loss: 3.1258\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.4444 - val_loss: 4.0315\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.3193 - val_loss: 2.7215\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.8581 - val_loss: 3.2750\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.0824 - val_loss: 3.5859\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.2798 - val_loss: 5.6307\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40c99cb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 2 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 88.3805 - val_loss: 58.4686\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.4543 - val_loss: 7.3806\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28.1905 - val_loss: 26.8240\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23.3957 - val_loss: 34.5480\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21.1040 - val_loss: 20.1608\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20.2921 - val_loss: 13.1993\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.8876 - val_loss: 20.6906\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.2490 - val_loss: 14.3797\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.0576 - val_loss: 6.6028\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.8398 - val_loss: 8.4359\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.1353 - val_loss: 3.2852\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7384 - val_loss: 3.9064\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1129 - val_loss: 6.8500\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.1082 - val_loss: 2.4831\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.7757 - val_loss: 7.8351\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.1751 - val_loss: 2.9415\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.8953 - val_loss: 2.4635\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.6436 - val_loss: 5.9884\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.7909 - val_loss: 3.0676\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.6268 - val_loss: 4.8909\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.4472 - val_loss: 3.8211\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.9911 - val_loss: 2.5763\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.7441 - val_loss: 4.6102\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.5672 - val_loss: 4.6264\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.0066 - val_loss: 3.2979\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.1148 - val_loss: 2.5961\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.0412 - val_loss: 3.5381\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.1192 - val_loss: 3.3269\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.5499 - val_loss: 4.2803\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.8408 - val_loss: 3.5715\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3571 - val_loss: 2.8022\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.0770 - val_loss: 2.5855\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.0624 - val_loss: 2.7092\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.9969 - val_loss: 3.8392\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.8424 - val_loss: 2.6508\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0485 - val_loss: 2.6254\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0279 - val_loss: 4.4580\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0851 - val_loss: 3.3793\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3670 - val_loss: 2.6732\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.7014 - val_loss: 3.3017\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3968 - val_loss: 2.3638\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3133 - val_loss: 2.5706\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.2965 - val_loss: 3.1785\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.3059 - val_loss: 3.2110\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.0304 - val_loss: 4.7029\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.2220 - val_loss: 2.6337\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3142 - val_loss: 2.5548\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.0063 - val_loss: 5.7832\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1624 - val_loss: 2.6736\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4.5083 - val_loss: 2.4359\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff422189550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 3 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 281ms/step - loss: 77.3252 - val_loss: 57.7040\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59.2161 - val_loss: 41.3480\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44.2361 - val_loss: 47.2164\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.2119 - val_loss: 21.4263\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28.7928 - val_loss: 20.8752\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21.2841 - val_loss: 7.3947\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20.0837 - val_loss: 11.5637\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.1857 - val_loss: 6.7580\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.5396 - val_loss: 13.0547\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.6086 - val_loss: 9.5063\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.4918 - val_loss: 7.7237\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.6807 - val_loss: 5.7727\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.2648 - val_loss: 11.2500\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.9200 - val_loss: 7.2792\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.5902 - val_loss: 6.5619\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.1180 - val_loss: 7.5063\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.5635 - val_loss: 8.3853\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.1428 - val_loss: 6.1330\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.0831 - val_loss: 7.9743\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.5103 - val_loss: 5.1247\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.8992 - val_loss: 8.5867\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.0012 - val_loss: 4.3038\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.5687 - val_loss: 6.7611\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.4726 - val_loss: 6.6766\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.4734 - val_loss: 6.7728\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.2217 - val_loss: 4.9057\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.7072 - val_loss: 6.8260\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.9462 - val_loss: 4.6706\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.8535 - val_loss: 5.8391\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.0084 - val_loss: 8.7268\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.4633 - val_loss: 3.2081\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.5405 - val_loss: 7.6598\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.3506 - val_loss: 4.3490\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.0522 - val_loss: 4.6304\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.9195 - val_loss: 9.9212\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3758 - val_loss: 3.1073\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9436 - val_loss: 5.3565\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1736 - val_loss: 4.7551\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5315 - val_loss: 5.1167\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.7911 - val_loss: 3.5152\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6896 - val_loss: 4.2091\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4084 - val_loss: 6.7179\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6916 - val_loss: 4.3556\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0705 - val_loss: 3.3259\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.1869 - val_loss: 4.9476\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6403 - val_loss: 2.8433\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.2309 - val_loss: 7.1492\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9302 - val_loss: 3.0619\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5792 - val_loss: 4.3535\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.8835 - val_loss: 4.0645\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415b63820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 4 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 22054.0723 - val_loss: 54.7441\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 465038.4688 - val_loss: 47.7803\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 272850.2812 - val_loss: 65.6688\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 36618.7383 - val_loss: 78.3701\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48339.6562 - val_loss: 85.2473\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 107447.0391 - val_loss: 86.1854\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 71201.3906 - val_loss: 84.4040\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32135.7207 - val_loss: 84.0791\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13259.6230 - val_loss: 86.5022\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 56824.5391 - val_loss: 87.3736\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47814.0469 - val_loss: 85.4692\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23132.0781 - val_loss: 85.9547\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6906.7837 - val_loss: 88.3611\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 80588.9766 - val_loss: 89.0073\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60831.7578 - val_loss: 87.3816\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20998.6543 - val_loss: 86.4632\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12525.4512 - val_loss: 87.2017\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22861.3496 - val_loss: 86.7542\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7513.2754 - val_loss: 88.5606\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57605.2500 - val_loss: 89.4848\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45139.8633 - val_loss: 88.1656\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9729.0391 - val_loss: 85.2708\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 112967.0781 - val_loss: 84.2351\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 94298.1250 - val_loss: 86.9192\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42479.2852 - val_loss: 90.3999\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46105.9062 - val_loss: 91.7571\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48851.9102 - val_loss: 91.6820\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1918.1770 - val_loss: 89.9576\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 60030.1758 - val_loss: 88.3368\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 70670.7266 - val_loss: 89.1704\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48604.5977 - val_loss: 91.3043\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8733.8994 - val_loss: 91.9630\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2507.1965 - val_loss: 91.1474\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38461.2188 - val_loss: 90.8560\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23341.7969 - val_loss: 91.7701\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9129.2891 - val_loss: 92.7785\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13349.2539 - val_loss: 92.2543\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23083.9316 - val_loss: 91.9528\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4583.6416 - val_loss: 92.6070\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11693.0967 - val_loss: 92.6283\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2808.8838 - val_loss: 92.5157\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24304.1797 - val_loss: 92.2340\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11471.8730 - val_loss: 94.1646\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 54938.6875 - val_loss: 95.0308\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51574.5312 - val_loss: 94.2149\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9634.1035 - val_loss: 93.1160\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11090.6943 - val_loss: 92.9890\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19176.2559 - val_loss: 93.8066\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12350.6523 - val_loss: 93.9988\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1646.6506 - val_loss: 94.2508\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40e0cbc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 5 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 185ms/step - loss: 179910.9688 - val_loss: 99.4670\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 70245.3281 - val_loss: 101.9572\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 21935.6816 - val_loss: 95.5659\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 76551.6094 - val_loss: 96.1346\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 59235.4023 - val_loss: 99.7304\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12186.9541 - val_loss: 98.5190\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14257.4180 - val_loss: 99.0269\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 23054.8945 - val_loss: 99.0199\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 448.9286 - val_loss: 96.5339\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 61319.6445 - val_loss: 95.8365\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 49945.7617 - val_loss: 98.0548\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4327.3267 - val_loss: 101.6469\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 104530.0234 - val_loss: 102.7269\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 92157.3516 - val_loss: 100.8878\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40005.2578 - val_loss: 98.1017\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30926.3184 - val_loss: 97.1512\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27349.5000 - val_loss: 98.5212\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13026.9072 - val_loss: 98.1112\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5479.3833 - val_loss: 98.3106\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12523.3066 - val_loss: 97.9425\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7808.3789 - val_loss: 97.9688\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23853.5273 - val_loss: 98.8335\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18385.7871 - val_loss: 97.3671\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24578.9277 - val_loss: 97.2160\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11113.7734 - val_loss: 98.2220\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20031.9668 - val_loss: 98.6722\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15718.1172 - val_loss: 97.2723\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 28423.2598 - val_loss: 97.2513\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19627.7188 - val_loss: 98.8061\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34151.7656 - val_loss: 99.1943\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25912.9609 - val_loss: 97.8953\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16588.4160 - val_loss: 97.7069\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11095.8721 - val_loss: 99.0730\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22266.2559 - val_loss: 98.7894\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10822.3066 - val_loss: 98.2832\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14582.0938 - val_loss: 97.6227\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15458.7832 - val_loss: 98.5870\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21955.7148 - val_loss: 98.8314\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1384.8699 - val_loss: 97.5222\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33295.3984 - val_loss: 96.9062\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34542.3086 - val_loss: 97.7324\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10798.0811 - val_loss: 99.1654\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37685.5508 - val_loss: 99.7205\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30324.7559 - val_loss: 99.2619\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1344.0420 - val_loss: 97.7370\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44746.2812 - val_loss: 96.7886\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47008.1953 - val_loss: 96.9858\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22043.3359 - val_loss: 98.3617\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21425.1367 - val_loss: 99.1472\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18474.1816 - val_loss: 98.4862\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff42046aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 6 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 85.9869 - val_loss: 57.2859\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67.4021 - val_loss: 41.6701\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 51.9584 - val_loss: 50.9334\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 46.3664 - val_loss: 49.0788\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.5864 - val_loss: 30.6838\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34.6950 - val_loss: 23.1230\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30.8314 - val_loss: 26.6388\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25.2710 - val_loss: 14.3053\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21.9654 - val_loss: 7.0914\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22.2974 - val_loss: 5.3176\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.6897 - val_loss: 4.1393\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.4656 - val_loss: 3.9058\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.0327 - val_loss: 8.1020\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.4119 - val_loss: 3.8268\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.1445 - val_loss: 7.4367\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.5353 - val_loss: 4.6476\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.2754 - val_loss: 6.2953\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17.6530 - val_loss: 4.7111\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.9842 - val_loss: 7.0231\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.6703 - val_loss: 2.9444\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.1897 - val_loss: 8.3084\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.7360 - val_loss: 3.3854\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.0773 - val_loss: 4.1303\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.6028 - val_loss: 6.0266\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.2957 - val_loss: 1.9012\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.5309 - val_loss: 6.7198\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0066 - val_loss: 3.4538\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.9788 - val_loss: 3.6533\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1811 - val_loss: 3.3959\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.4023 - val_loss: 5.9898\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2414 - val_loss: 2.4433\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.7378 - val_loss: 6.0387\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0838 - val_loss: 2.8039\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5554 - val_loss: 5.0970\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9379 - val_loss: 2.8888\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8365 - val_loss: 4.0245\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2159 - val_loss: 5.8815\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6750 - val_loss: 1.7275\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.2723 - val_loss: 5.0453\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3070 - val_loss: 1.7327\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.9410 - val_loss: 3.8336\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0633 - val_loss: 1.6567\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.1566 - val_loss: 4.8308\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3084 - val_loss: 1.8207\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.0324 - val_loss: 3.5193\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5156 - val_loss: 2.2200\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.2076 - val_loss: 2.1301\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.6714 - val_loss: 2.1642\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.6099 - val_loss: 2.4405\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.7041 - val_loss: 2.4621\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3dbfba160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 7 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 27434.3418 - val_loss: 82.5532\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 469386.5312 - val_loss: 78.3002\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 326715.8438 - val_loss: 87.3487\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 90573.6641 - val_loss: 94.4191\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21895.2129 - val_loss: 98.9772\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56880.8555 - val_loss: 98.7687\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3839.6509 - val_loss: 97.9106\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30548.0488 - val_loss: 98.3706\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14475.2715 - val_loss: 96.0023\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68914.9531 - val_loss: 95.3048\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46191.9453 - val_loss: 97.0581\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4164.8232 - val_loss: 100.8306\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 115671.8672 - val_loss: 102.4147\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 109653.7812 - val_loss: 100.9299\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56923.0469 - val_loss: 98.2949\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5480.2036 - val_loss: 97.6748\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9635.1377 - val_loss: 99.0032\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23694.9824 - val_loss: 98.3976\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3675.2217 - val_loss: 96.9618\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52102.2148 - val_loss: 96.3267\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44865.4219 - val_loss: 98.4460\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15542.1367 - val_loss: 98.3719\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1925.2930 - val_loss: 97.0534\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 50327.2070 - val_loss: 96.4779\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35083.9062 - val_loss: 97.6967\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13038.7109 - val_loss: 100.7204\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 83937.6719 - val_loss: 101.5210\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 81806.6641 - val_loss: 100.2880\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37420.8320 - val_loss: 98.4467\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18317.5625 - val_loss: 97.8261\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15748.0986 - val_loss: 98.8076\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8087.4468 - val_loss: 98.5237\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3369.8652 - val_loss: 98.9570\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27152.4219 - val_loss: 99.3163\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 13764.7246 - val_loss: 97.9966\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 42413.4023 - val_loss: 97.2074\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22567.8516 - val_loss: 98.6278\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9382.4561 - val_loss: 99.0970\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12024.1162 - val_loss: 98.3770\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8564.3037 - val_loss: 98.7547\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1106.4946 - val_loss: 97.7820\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38255.6328 - val_loss: 97.5991\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11202.3057 - val_loss: 99.2605\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32802.4844 - val_loss: 100.1008\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36031.4062 - val_loss: 99.6727\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11442.0146 - val_loss: 98.0678\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 45255.5938 - val_loss: 97.2819\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40198.3320 - val_loss: 97.8045\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 29996.2793 - val_loss: 100.2994\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61469.1836 - val_loss: 101.2557\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40b1d18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 8 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 70.2138 - val_loss: 60.5665\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.7526 - val_loss: 56.9996\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44.6419 - val_loss: 44.2654\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38.6196 - val_loss: 27.3254\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 32.2473 - val_loss: 19.5110\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 26.3061 - val_loss: 10.8294\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24.0420 - val_loss: 7.0078\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22.4495 - val_loss: 8.3504\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 20.8588 - val_loss: 9.2666\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22.1453 - val_loss: 12.0812\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23.0769 - val_loss: 10.7465\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21.4899 - val_loss: 8.1050\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19.5572 - val_loss: 7.4876\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19.0825 - val_loss: 8.9501\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.7534 - val_loss: 11.4778\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.8684 - val_loss: 8.3856\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17.8552 - val_loss: 9.0186\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.1456 - val_loss: 7.5706\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.1741 - val_loss: 9.7945\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.0654 - val_loss: 7.8354\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.5259 - val_loss: 8.3388\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.7667 - val_loss: 7.7512\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.8014 - val_loss: 9.5436\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.7903 - val_loss: 8.5605\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.9871 - val_loss: 8.0615\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.2316 - val_loss: 7.1285\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.3930 - val_loss: 9.8553\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.4018 - val_loss: 8.0967\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.9079 - val_loss: 6.5766\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.1104 - val_loss: 9.6138\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.2410 - val_loss: 7.6856\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.7650 - val_loss: 7.2767\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17.5352 - val_loss: 9.2932\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.2738 - val_loss: 7.2160\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18.1836 - val_loss: 6.8664\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.5180 - val_loss: 12.2937\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.5986 - val_loss: 6.6648\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.8459 - val_loss: 10.4700\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.1981 - val_loss: 6.9925\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.9769 - val_loss: 5.2640\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.2550 - val_loss: 6.7636\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.1002 - val_loss: 6.9036\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.9266 - val_loss: 6.7995\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.0658 - val_loss: 5.2556\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.2696 - val_loss: 5.6738\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.4698 - val_loss: 6.9825\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.6167 - val_loss: 5.1164\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.0105 - val_loss: 4.5448\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.3338 - val_loss: 6.0202\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.3286 - val_loss: 5.6889\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4212a1820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 9 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 138864.5625 - val_loss: 94.2905\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7272.4653 - val_loss: 92.3851\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 38518.0234 - val_loss: 92.8518\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17591.7168 - val_loss: 100.7824\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 160050.6250 - val_loss: 103.6080\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 144644.2969 - val_loss: 101.3917\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69320.0078 - val_loss: 98.2100\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13225.9297 - val_loss: 96.2390\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5447.0962 - val_loss: 97.2294\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33954.7227 - val_loss: 97.6190\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21292.5820 - val_loss: 96.6752\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15064.9756 - val_loss: 96.3074\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4706.8086 - val_loss: 97.1520\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21923.8691 - val_loss: 97.2739\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16937.7656 - val_loss: 95.9252\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31431.0488 - val_loss: 95.9805\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15247.1348 - val_loss: 97.2621\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13018.4473 - val_loss: 97.2199\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10987.6914 - val_loss: 96.0038\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22417.3066 - val_loss: 96.5278\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5091.3687 - val_loss: 97.3984\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32079.6348 - val_loss: 98.0208\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25552.2676 - val_loss: 96.7932\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23033.8848 - val_loss: 96.4513\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12446.1992 - val_loss: 97.6764\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19732.2793 - val_loss: 97.8477\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14823.5293 - val_loss: 96.8436\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21972.9473 - val_loss: 96.8348\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11839.2617 - val_loss: 98.1454\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 18777.1523 - val_loss: 98.0317\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14158.2188 - val_loss: 96.9232\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31599.7344 - val_loss: 96.6249\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15065.0742 - val_loss: 98.2372\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29795.8418 - val_loss: 98.8833\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29357.5625 - val_loss: 98.1442\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4197.5562 - val_loss: 98.0044\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6870.8276 - val_loss: 97.8184\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7302.3535 - val_loss: 98.1812\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8947.5547 - val_loss: 97.9427\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11128.7764 - val_loss: 97.9238\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 879.6202 - val_loss: 99.1736\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35096.3945 - val_loss: 99.3241\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32048.8652 - val_loss: 98.4202\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1724.5605 - val_loss: 97.1663\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46297.3750 - val_loss: 96.7202\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42321.2539 - val_loss: 97.7059\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10902.5449 - val_loss: 98.9623\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20096.3887 - val_loss: 99.3099\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21424.1934 - val_loss: 98.6234\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5211.1812 - val_loss: 98.7301\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3de092ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 10 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 139794.7969 - val_loss: 78.0915\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 896220.5000 - val_loss: 78.8172\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 548071.6875 - val_loss: 91.4380\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 153441.4531 - val_loss: 102.9657\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 340638.9062 - val_loss: 105.8927\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 337509.5938 - val_loss: 103.9173\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 158594.2969 - val_loss: 98.8337\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71886.8438 - val_loss: 97.6404\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 87342.1250 - val_loss: 100.1268\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34219.2812 - val_loss: 99.6971\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6037.9077 - val_loss: 96.7012\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 223537.6562 - val_loss: 95.9664\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 178274.5469 - val_loss: 99.8245\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55041.8789 - val_loss: 100.5753\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36800.4180 - val_loss: 98.9131\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 64434.3438 - val_loss: 98.6104\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34383.3672 - val_loss: 100.7047\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 73253.0391 - val_loss: 100.4730\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43164.0352 - val_loss: 98.6705\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52441.7461 - val_loss: 98.7892\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20420.8457 - val_loss: 100.2680\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 94045.9297 - val_loss: 100.8425\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46146.8359 - val_loss: 99.1211\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39445.9688 - val_loss: 98.5052\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44138.5586 - val_loss: 99.9953\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 59648.6172 - val_loss: 100.0851\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35784.5195 - val_loss: 98.7566\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8462.8340 - val_loss: 99.8437\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50431.3750 - val_loss: 99.4619\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20705.8594 - val_loss: 98.8887\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18619.4590 - val_loss: 99.4503\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8539.1484 - val_loss: 98.6057\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13525.0879 - val_loss: 99.0400\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 81820.9766 - val_loss: 99.5495\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27830.3379 - val_loss: 97.5368\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 108753.1172 - val_loss: 96.5026\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 109398.4922 - val_loss: 98.8140\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 40511.6328 - val_loss: 99.0989\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13110.9912 - val_loss: 97.8983\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 97414.6094 - val_loss: 97.0945\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 64984.5508 - val_loss: 98.5172\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5559.2944 - val_loss: 101.4663\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 171026.0156 - val_loss: 101.8980\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 165909.0469 - val_loss: 100.8971\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 81653.6250 - val_loss: 98.8174\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11466.4102 - val_loss: 98.5936\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14478.1660 - val_loss: 99.6784\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 62021.7227 - val_loss: 99.6797\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20886.2012 - val_loss: 98.7847\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7593.7803 - val_loss: 99.1608\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40c99c3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 11 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 289149.9062 - val_loss: 78.2196\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 380655.0312 - val_loss: 91.9499\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 102030.0781 - val_loss: 94.9951\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 56312.6250 - val_loss: 90.9715\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 85958.5000 - val_loss: 95.2433\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 99723.0078 - val_loss: 96.1708\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8986.9961 - val_loss: 94.1697\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 147251.2344 - val_loss: 91.8859\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 141170.1250 - val_loss: 94.0449\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29761.9766 - val_loss: 96.2476\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35286.0781 - val_loss: 94.4180\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38785.5078 - val_loss: 95.4566\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23654.3750 - val_loss: 95.3099\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37271.0586 - val_loss: 95.1421\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8323.7656 - val_loss: 95.8428\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34821.1406 - val_loss: 94.8219\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32084.7363 - val_loss: 94.6303\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14886.6230 - val_loss: 94.7602\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47568.7383 - val_loss: 94.7066\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13821.6377 - val_loss: 96.2545\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50732.6562 - val_loss: 95.9443\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33708.4180 - val_loss: 94.1875\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 68729.7266 - val_loss: 94.8168\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14843.5166 - val_loss: 96.7958\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40574.8477 - val_loss: 96.5802\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4474.6597 - val_loss: 96.3319\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40090.9766 - val_loss: 96.5823\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11651.1299 - val_loss: 98.0353\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30509.7891 - val_loss: 97.6887\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37491.1133 - val_loss: 97.1489\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20865.2793 - val_loss: 98.6388\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39695.0312 - val_loss: 98.2098\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5146.2095 - val_loss: 98.4385\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17874.1895 - val_loss: 98.0751\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8591.4033 - val_loss: 98.3671\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31748.2754 - val_loss: 98.2842\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9733.0947 - val_loss: 97.0540\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52984.2109 - val_loss: 97.1579\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24336.2305 - val_loss: 98.7467\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63290.5078 - val_loss: 98.8155\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28330.4844 - val_loss: 96.8366\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 96796.5781 - val_loss: 96.5499\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 75191.8828 - val_loss: 97.8240\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31787.4629 - val_loss: 99.4100\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63135.9727 - val_loss: 98.9950\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35369.9883 - val_loss: 97.0841\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 29575.7871 - val_loss: 97.6337\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7680.8608 - val_loss: 97.2897\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10585.4717 - val_loss: 97.7257\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26603.8828 - val_loss: 97.6726\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff414c941f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 12 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 569397.5625 - val_loss: 80.8198\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 122183.1484 - val_loss: 98.6092\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 353584.4375 - val_loss: 101.2955\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 320088.5625 - val_loss: 97.1091\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 100473.3516 - val_loss: 92.4376\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38897.6797 - val_loss: 96.4458\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 105592.7266 - val_loss: 95.7181\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27882.8281 - val_loss: 94.4805\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21076.0215 - val_loss: 95.4016\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23293.7383 - val_loss: 93.9359\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49943.4492 - val_loss: 94.0817\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20094.5000 - val_loss: 95.0976\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9022.8789 - val_loss: 94.7145\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12587.2275 - val_loss: 94.1056\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16280.4902 - val_loss: 94.7123\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36449.9297 - val_loss: 92.1925\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 77974.8281 - val_loss: 93.0601\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24188.3477 - val_loss: 94.3229\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12329.9893 - val_loss: 93.1325\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48870.3164 - val_loss: 93.3787\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23703.5391 - val_loss: 96.3690\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 131515.5312 - val_loss: 96.9245\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 101278.5312 - val_loss: 94.6848\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24815.5684 - val_loss: 94.4619\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2200.4128 - val_loss: 95.2036\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17340.8184 - val_loss: 95.1290\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12639.7471 - val_loss: 96.5642\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42091.5742 - val_loss: 96.2220\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18267.7637 - val_loss: 94.6962\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 81914.0938 - val_loss: 95.7171\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20050.8418 - val_loss: 97.5546\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 88802.4062 - val_loss: 98.5642\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 84040.8438 - val_loss: 96.3213\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 53206.6367 - val_loss: 96.2768\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25715.4727 - val_loss: 97.4951\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21192.8535 - val_loss: 96.9118\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46382.7812 - val_loss: 96.6121\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17790.9414 - val_loss: 97.5552\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 68241.3906 - val_loss: 98.8141\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 56561.1445 - val_loss: 97.8254\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25337.7832 - val_loss: 96.2011\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 83015.4375 - val_loss: 96.6893\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29685.1543 - val_loss: 98.7797\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 63629.9023 - val_loss: 99.0167\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 58639.7227 - val_loss: 97.2518\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47998.4492 - val_loss: 97.3094\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26966.7129 - val_loss: 98.6677\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19661.6816 - val_loss: 97.0522\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43338.7109 - val_loss: 96.8371\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27492.9219 - val_loss: 98.3840\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff41e4e0310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 13 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 129338.0938 - val_loss: 97.3541\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 67054.6250 - val_loss: 98.9670\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17036.6914 - val_loss: 96.2149\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47347.3438 - val_loss: 96.1505\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27940.1777 - val_loss: 97.8291\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26298.0156 - val_loss: 99.8321\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28008.2070 - val_loss: 99.2325\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1423.0133 - val_loss: 98.4798\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5689.8296 - val_loss: 99.4092\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14355.8721 - val_loss: 98.9850\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2382.2180 - val_loss: 97.3559\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 52379.3047 - val_loss: 96.6971\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30785.7988 - val_loss: 98.1335\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32481.2539 - val_loss: 100.3167\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28597.8125 - val_loss: 98.1517\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21452.1465 - val_loss: 98.7062\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12117.5205 - val_loss: 100.2346\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 37781.6484 - val_loss: 101.1241\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12621.1592 - val_loss: 99.0393\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 43236.4180 - val_loss: 97.6224\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27679.2266 - val_loss: 99.0427\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11668.5586 - val_loss: 99.6986\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3032.2578 - val_loss: 99.1248\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32594.2168 - val_loss: 98.2580\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29659.8496 - val_loss: 99.1091\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5019.3472 - val_loss: 99.8777\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16898.5332 - val_loss: 99.3944\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6468.5771 - val_loss: 101.1675\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44070.4297 - val_loss: 101.6064\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 40328.7305 - val_loss: 100.7851\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22345.1074 - val_loss: 99.0158\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32211.5820 - val_loss: 98.7255\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27751.8496 - val_loss: 99.7989\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3977.0984 - val_loss: 101.8079\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 43156.9766 - val_loss: 101.5827\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37104.9688 - val_loss: 100.4315\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6266.9268 - val_loss: 100.2609\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5844.2432 - val_loss: 100.4364\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 745.6092 - val_loss: 99.9035\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16343.2383 - val_loss: 99.8917\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11707.2559 - val_loss: 100.9574\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14465.1992 - val_loss: 100.5599\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3234.9819 - val_loss: 100.0247\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17646.9258 - val_loss: 99.3901\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19054.6309 - val_loss: 99.8764\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4029.7000 - val_loss: 100.0755\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7633.2510 - val_loss: 100.0203\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10925.8320 - val_loss: 100.4202\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8127.0361 - val_loss: 99.4862\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26867.4883 - val_loss: 99.2952\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4215453a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 14 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 12281.1953 - val_loss: 131.6496\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 534078.8125 - val_loss: 132.8793\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 301963.3125 - val_loss: 123.6430\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 116038.2500 - val_loss: 112.9322\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60968.7500 - val_loss: 107.8041\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 77651.7266 - val_loss: 108.6220\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 887.2258 - val_loss: 107.6874\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26872.0449 - val_loss: 108.3220\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13964.1377 - val_loss: 107.1424\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49525.1445 - val_loss: 106.6879\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20990.5840 - val_loss: 109.4651\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 69515.3828 - val_loss: 109.5460\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 78777.9453 - val_loss: 107.9328\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20741.3203 - val_loss: 105.7637\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 56794.0273 - val_loss: 105.5183\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51135.1953 - val_loss: 107.0457\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17650.2754 - val_loss: 106.9494\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8665.6416 - val_loss: 107.0604\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32551.3945 - val_loss: 107.4242\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4645.8398 - val_loss: 106.7956\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7370.0903 - val_loss: 105.9901\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25967.6172 - val_loss: 106.4564\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11193.3359 - val_loss: 106.4947\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11797.8203 - val_loss: 106.2509\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6274.1543 - val_loss: 107.4888\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34253.3359 - val_loss: 107.0085\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15802.7764 - val_loss: 106.0722\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34635.0898 - val_loss: 105.3883\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27674.1309 - val_loss: 107.0308\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 36184.4883 - val_loss: 106.8198\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22344.4336 - val_loss: 105.3388\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20160.1426 - val_loss: 105.5481\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6407.4995 - val_loss: 106.0876\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42847.3867 - val_loss: 107.0688\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40330.0625 - val_loss: 106.0541\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8212.8730 - val_loss: 105.5897\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11994.3047 - val_loss: 105.5757\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24255.4648 - val_loss: 104.8682\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19194.9902 - val_loss: 106.2669\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46403.3086 - val_loss: 106.5051\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34482.8398 - val_loss: 104.9608\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 35482.5547 - val_loss: 104.2239\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12357.4912 - val_loss: 105.4178\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23267.8379 - val_loss: 105.7433\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26940.7949 - val_loss: 105.0107\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6375.1836 - val_loss: 104.9106\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6446.0698 - val_loss: 104.3100\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14218.6436 - val_loss: 104.8308\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9039.9678 - val_loss: 104.4314\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20069.4102 - val_loss: 104.3125\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff41330db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 15 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 356020.2500 - val_loss: 86.0905\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 397247.7188 - val_loss: 98.6152\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 87031.9375 - val_loss: 105.7260\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 196756.1250 - val_loss: 104.1302\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59630.4883 - val_loss: 101.4130\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30158.7598 - val_loss: 102.6779\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 77123.0156 - val_loss: 103.8388\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 46079.0742 - val_loss: 101.1882\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 61043.3164 - val_loss: 101.3106\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30882.8594 - val_loss: 102.7193\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22380.1211 - val_loss: 100.4720\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 133432.1250 - val_loss: 100.4823\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48903.3789 - val_loss: 102.5776\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 80814.1641 - val_loss: 103.7858\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 80417.0625 - val_loss: 103.1536\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19260.7422 - val_loss: 101.8394\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12603.6338 - val_loss: 103.3166\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 61633.4062 - val_loss: 103.0609\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31289.6445 - val_loss: 101.9353\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 55487.8555 - val_loss: 101.2142\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36234.1562 - val_loss: 102.7925\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 107354.1250 - val_loss: 103.7340\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 81318.3516 - val_loss: 101.4570\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 88396.6484 - val_loss: 100.5871\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 67513.1875 - val_loss: 101.8943\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2276.5918 - val_loss: 104.2514\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 158724.0781 - val_loss: 104.8409\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 151497.5312 - val_loss: 103.6701\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 97423.7734 - val_loss: 101.5089\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30364.2207 - val_loss: 101.0258\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 35218.6133 - val_loss: 101.5724\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5905.2568 - val_loss: 101.8055\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6518.8687 - val_loss: 101.3904\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10912.8096 - val_loss: 101.4839\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2928.1023 - val_loss: 101.9056\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29150.1738 - val_loss: 101.2370\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11508.2031 - val_loss: 101.6610\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22419.5957 - val_loss: 101.1094\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17321.7305 - val_loss: 101.3105\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12577.7197 - val_loss: 101.3331\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12507.4590 - val_loss: 101.2711\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8092.1108 - val_loss: 100.8710\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32330.2344 - val_loss: 101.0244\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12882.2314 - val_loss: 101.2160\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35130.1641 - val_loss: 100.8223\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25769.4375 - val_loss: 101.9956\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 58948.3828 - val_loss: 102.0138\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47474.2695 - val_loss: 100.9026\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 35103.0078 - val_loss: 100.7361\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30824.8027 - val_loss: 102.0471\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d4c84700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 16 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 325ms/step - loss: 53.8850 - val_loss: 36.8404\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 38.7681 - val_loss: 43.0947\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31.9696 - val_loss: 25.4933\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26.7543 - val_loss: 23.4649\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 22.7803 - val_loss: 15.5878\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.3187 - val_loss: 2.7923\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20.5069 - val_loss: 8.5787\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.3824 - val_loss: 6.0491\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.8056 - val_loss: 9.1496\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.2786 - val_loss: 3.3730\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.3650 - val_loss: 5.1529\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.5831 - val_loss: 3.0475\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.3933 - val_loss: 4.1309\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.8489 - val_loss: 3.5407\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.4124 - val_loss: 2.7410\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.1281 - val_loss: 2.5137\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.4657 - val_loss: 2.8817\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.4680 - val_loss: 3.4132\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.6823 - val_loss: 2.7257\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.9114 - val_loss: 5.2225\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.4149 - val_loss: 2.9280\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.9501 - val_loss: 1.9037\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.7004 - val_loss: 2.6567\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.4002 - val_loss: 4.7422\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.3949 - val_loss: 3.0343\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8301 - val_loss: 2.3595\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5612 - val_loss: 3.8233\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.3009 - val_loss: 2.3391\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.6368 - val_loss: 2.6535\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.0964 - val_loss: 5.1035\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.7107 - val_loss: 2.0120\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3298 - val_loss: 2.8931\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.7119 - val_loss: 2.5056\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.5810 - val_loss: 2.0660\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5920 - val_loss: 2.1834\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4572 - val_loss: 8.5432\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.6718 - val_loss: 2.5467\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.6347 - val_loss: 2.5088\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9876 - val_loss: 2.9381\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.5226 - val_loss: 3.4438\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.4563 - val_loss: 4.1828\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.3897 - val_loss: 2.4171\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.4548 - val_loss: 4.2419\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.8199 - val_loss: 5.7590\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.0216 - val_loss: 2.4723\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.9699 - val_loss: 2.1577\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.5869 - val_loss: 3.2433\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.4933 - val_loss: 3.8370\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.0459 - val_loss: 2.2978\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2023 - val_loss: 2.6030\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e8e31c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 17 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 61.8103 - val_loss: 32.4450\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31.3227 - val_loss: 17.2159\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24.7219 - val_loss: 35.0363\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21.5556 - val_loss: 27.2859\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.8435 - val_loss: 19.5139\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.1953 - val_loss: 19.5981\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.6472 - val_loss: 15.4473\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.2854 - val_loss: 9.6003\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.0840 - val_loss: 4.9503\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7793 - val_loss: 4.8190\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.4441 - val_loss: 3.2652\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5149 - val_loss: 2.5730\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.8810 - val_loss: 5.0141\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.0571 - val_loss: 3.1058\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3458 - val_loss: 4.2498\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8258 - val_loss: 4.6507\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.5057 - val_loss: 4.2304\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.7781 - val_loss: 4.7039\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.1990 - val_loss: 6.1314\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.7557 - val_loss: 4.5071\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.5313 - val_loss: 3.9069\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.9839 - val_loss: 4.5330\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.0512 - val_loss: 4.4308\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.8647 - val_loss: 5.1180\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4327 - val_loss: 4.1532\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.6899 - val_loss: 4.7358\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7065 - val_loss: 3.3850\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.2357 - val_loss: 3.2934\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0780 - val_loss: 5.4411\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.1813 - val_loss: 4.9287\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.6704 - val_loss: 4.6561\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.9019 - val_loss: 3.6444\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.4411 - val_loss: 3.2591\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9581 - val_loss: 3.8907\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.8181 - val_loss: 3.7656\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.6655 - val_loss: 3.6335\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5942 - val_loss: 3.7362\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.3807 - val_loss: 3.3961\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5188 - val_loss: 3.5355\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5717 - val_loss: 3.7984\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.3626 - val_loss: 2.9876\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5378 - val_loss: 3.1460\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.3027 - val_loss: 3.4178\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.1478 - val_loss: 2.8785\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.0362 - val_loss: 3.1462\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.2573 - val_loss: 2.8708\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.2207 - val_loss: 3.1433\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.9293 - val_loss: 3.3156\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.8943 - val_loss: 3.0141\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.7104 - val_loss: 3.1830\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff420c999d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 18 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 199303.0625 - val_loss: 89.5123\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3544.2078 - val_loss: 103.3720\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 309650.3750 - val_loss: 105.0179\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 243569.2031 - val_loss: 100.9643\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 121103.6562 - val_loss: 96.0178\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42003.8555 - val_loss: 93.6593\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 31751.9629 - val_loss: 95.7816\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 68709.9688 - val_loss: 95.8450\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 45053.9531 - val_loss: 94.5056\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21432.0938 - val_loss: 94.1927\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12067.4219 - val_loss: 95.7474\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 62281.7617 - val_loss: 95.8758\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 49168.1055 - val_loss: 94.4643\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10462.3701 - val_loss: 94.7892\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1486.3121 - val_loss: 94.0180\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37624.1992 - val_loss: 94.3790\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9743.7949 - val_loss: 95.3146\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26063.0371 - val_loss: 95.5311\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20929.0234 - val_loss: 94.9599\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23938.6055 - val_loss: 94.5552\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12965.2598 - val_loss: 95.8857\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32361.4668 - val_loss: 95.7544\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24238.9082 - val_loss: 94.9595\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19905.5820 - val_loss: 94.8640\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4859.5146 - val_loss: 95.9077\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 57779.9219 - val_loss: 96.5504\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38120.8945 - val_loss: 95.2230\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12371.7549 - val_loss: 94.9863\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13017.7383 - val_loss: 95.8749\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34314.7695 - val_loss: 96.1062\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25305.2051 - val_loss: 94.7567\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47214.9258 - val_loss: 94.4368\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32815.8828 - val_loss: 95.2619\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11348.2451 - val_loss: 95.8339\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 732.6832 - val_loss: 95.3709\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32990.4414 - val_loss: 94.8008\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 35317.5625 - val_loss: 95.4090\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13744.2471 - val_loss: 96.9619\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 43054.2305 - val_loss: 97.0290\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 43184.5938 - val_loss: 96.3831\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10961.0283 - val_loss: 95.1786\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47096.6680 - val_loss: 94.9202\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 41890.2070 - val_loss: 95.6328\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2789.7686 - val_loss: 96.6999\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37953.3438 - val_loss: 97.2431\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39106.9883 - val_loss: 96.8180\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10014.5205 - val_loss: 95.8239\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29087.6875 - val_loss: 95.6421\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 29862.3457 - val_loss: 96.4256\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6253.9595 - val_loss: 96.4048\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d746a820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 19 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 34729.8438 - val_loss: 88.8166\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 162571.2969 - val_loss: 97.5890\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 137032.5938 - val_loss: 94.7363\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38505.8633 - val_loss: 89.7316\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 108331.9766 - val_loss: 87.1125\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 97082.1484 - val_loss: 92.3316\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15521.1123 - val_loss: 93.4490\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7795.6768 - val_loss: 91.0668\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44894.1562 - val_loss: 92.0849\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27426.9316 - val_loss: 94.0396\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3899.6804 - val_loss: 94.0309\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3588.9741 - val_loss: 95.1858\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42574.5039 - val_loss: 95.9649\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20097.6387 - val_loss: 93.8478\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41144.5703 - val_loss: 93.2384\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38702.3516 - val_loss: 94.0287\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10362.6689 - val_loss: 95.6744\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5264.2441 - val_loss: 95.7759\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9346.8682 - val_loss: 95.4368\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13041.3467 - val_loss: 95.6731\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7843.9556 - val_loss: 95.6847\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3232.8821 - val_loss: 96.5939\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22987.1270 - val_loss: 96.2849\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3115.3855 - val_loss: 96.2821\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6496.6387 - val_loss: 95.6949\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15635.3770 - val_loss: 95.9726\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10158.9932 - val_loss: 96.2705\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4384.4658 - val_loss: 96.6226\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19690.6758 - val_loss: 96.6980\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10015.5420 - val_loss: 94.8245\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 51998.2109 - val_loss: 94.6604\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40271.2891 - val_loss: 95.4821\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10224.8105 - val_loss: 98.0726\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60508.8555 - val_loss: 99.4777\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 62186.3008 - val_loss: 98.8984\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31900.3262 - val_loss: 97.7893\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2242.4011 - val_loss: 97.6538\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2043.1328 - val_loss: 98.6780\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24236.4336 - val_loss: 98.3918\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12102.8154 - val_loss: 97.4819\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 23430.7559 - val_loss: 97.4287\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14429.9873 - val_loss: 98.3355\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11235.5625 - val_loss: 98.4140\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5310.0610 - val_loss: 97.7181\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29755.4082 - val_loss: 97.3086\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20567.6328 - val_loss: 98.7459\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13259.4141 - val_loss: 98.9130\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15809.0811 - val_loss: 98.4899\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13333.2695 - val_loss: 98.2380\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 465.3791 - val_loss: 98.3715\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e3c17310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 20 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 302133.6250 - val_loss: 91.1941\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 37440.5391 - val_loss: 98.0636\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7482.1060 - val_loss: 87.9717\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 149635.3125 - val_loss: 88.9303\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 114019.5938 - val_loss: 92.2466\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4759.6230 - val_loss: 94.3821\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 41944.3750 - val_loss: 93.6172\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21721.7949 - val_loss: 97.2433\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 93483.5938 - val_loss: 98.9167\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 81908.7578 - val_loss: 94.5875\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25189.0469 - val_loss: 94.2583\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20479.6309 - val_loss: 96.4920\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46793.9766 - val_loss: 97.0511\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25127.1035 - val_loss: 94.5648\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16618.3340 - val_loss: 94.5618\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15204.2188 - val_loss: 95.8995\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42278.2188 - val_loss: 96.7509\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5305.9717 - val_loss: 94.7193\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 71446.7109 - val_loss: 92.3113\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 68550.7812 - val_loss: 94.7312\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6656.3872 - val_loss: 95.5680\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14292.7686 - val_loss: 95.4310\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5056.8354 - val_loss: 97.4829\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 53376.3398 - val_loss: 97.6511\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39002.3398 - val_loss: 96.2589\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3249.3296 - val_loss: 93.7876\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47988.2773 - val_loss: 93.6020\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 54775.9492 - val_loss: 94.4549\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18621.5527 - val_loss: 96.1060\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33741.2891 - val_loss: 97.1811\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30140.5391 - val_loss: 95.7917\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13305.4023 - val_loss: 96.1876\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2367.9993 - val_loss: 97.9834\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 53775.1406 - val_loss: 98.3919\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35950.3008 - val_loss: 97.4411\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4524.5229 - val_loss: 94.9512\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 65359.9688 - val_loss: 93.7568\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 66101.7109 - val_loss: 94.9970\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27420.9629 - val_loss: 96.7449\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 33649.0938 - val_loss: 97.5124\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15507.8984 - val_loss: 96.4516\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28983.6152 - val_loss: 95.7905\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11313.6484 - val_loss: 96.7913\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 709.3712 - val_loss: 99.2147\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 80113.2266 - val_loss: 100.0621\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 85550.4766 - val_loss: 99.8752\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 75377.5859 - val_loss: 98.5405\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15422.8799 - val_loss: 97.5227\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29041.9316 - val_loss: 96.4018\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28176.5625 - val_loss: 97.4071\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3fd6b2af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 21 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 68.9129 - val_loss: 46.8597\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 43.2562 - val_loss: 40.5214\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35.5703 - val_loss: 42.2567\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31.0926 - val_loss: 25.3244\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 25.4829 - val_loss: 27.0977\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23.8125 - val_loss: 9.5176\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20.0644 - val_loss: 8.9211\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.5299 - val_loss: 6.3718\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.2812 - val_loss: 3.8997\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.8399 - val_loss: 7.8691\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 17.5644 - val_loss: 3.0545\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.1415 - val_loss: 4.4032\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.3053 - val_loss: 9.0142\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.3091 - val_loss: 6.0722\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.7303 - val_loss: 6.6622\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.0877 - val_loss: 5.1299\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.8400 - val_loss: 5.9695\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.6950 - val_loss: 4.5656\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.1443 - val_loss: 4.6259\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.3242 - val_loss: 3.8439\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.0485 - val_loss: 3.7059\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.8762 - val_loss: 4.3718\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.6891 - val_loss: 4.1990\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.2724 - val_loss: 5.7766\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.8913 - val_loss: 3.4545\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.1065 - val_loss: 4.0759\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.0390 - val_loss: 4.1983\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.3258 - val_loss: 5.0333\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5745 - val_loss: 3.0668\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.4110 - val_loss: 5.0759\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.5284 - val_loss: 3.0151\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.5098 - val_loss: 4.7621\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.1325 - val_loss: 2.9241\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3584 - val_loss: 2.7310\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.1394 - val_loss: 2.9467\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.4985 - val_loss: 3.0987\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.4827 - val_loss: 2.9275\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.5700 - val_loss: 3.0352\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.0330 - val_loss: 2.8810\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.7322 - val_loss: 3.3459\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.4527 - val_loss: 2.9453\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.1998 - val_loss: 2.7978\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.6890 - val_loss: 3.9645\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.5064 - val_loss: 3.8075\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1684 - val_loss: 3.2551\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.8897 - val_loss: 5.5044\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.3723 - val_loss: 3.8914\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5012 - val_loss: 6.4665\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.3639 - val_loss: 4.9081\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.0520 - val_loss: 3.7918\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d64cbf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 22 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 130630.6328 - val_loss: 112.3270\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 189453.1562 - val_loss: 115.9274\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 120612.9844 - val_loss: 107.9225\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30807.7754 - val_loss: 104.1664\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9204.9502 - val_loss: 107.4193\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 60692.4336 - val_loss: 107.3552\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48211.9961 - val_loss: 103.6483\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36086.8906 - val_loss: 103.4836\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19223.5898 - val_loss: 107.1208\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 60668.8477 - val_loss: 106.8992\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40574.1133 - val_loss: 105.1330\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14583.8535 - val_loss: 100.3499\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 89940.8281 - val_loss: 99.8120\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 87108.8594 - val_loss: 101.9876\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46079.5820 - val_loss: 106.0932\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32704.2598 - val_loss: 105.6402\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24443.7617 - val_loss: 103.6074\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14790.3672 - val_loss: 104.1518\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5390.5117 - val_loss: 103.9077\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34032.1016 - val_loss: 102.7773\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26159.7949 - val_loss: 104.1936\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17713.1113 - val_loss: 104.4402\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5874.1211 - val_loss: 102.9346\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30433.1250 - val_loss: 102.8305\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22724.9648 - val_loss: 104.3186\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10791.8965 - val_loss: 103.8955\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2977.4395 - val_loss: 104.1325\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7571.8584 - val_loss: 104.2793\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13112.1641 - val_loss: 103.8810\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23997.5996 - val_loss: 102.8243\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20580.6660 - val_loss: 104.1947\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16724.2363 - val_loss: 104.0166\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7141.5254 - val_loss: 102.2728\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 53179.3086 - val_loss: 101.6835\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46305.8906 - val_loss: 104.0079\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 32312.7930 - val_loss: 104.7381\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25069.1875 - val_loss: 103.8636\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9533.7422 - val_loss: 103.2397\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3194.5852 - val_loss: 104.5280\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33294.7461 - val_loss: 104.4523\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22024.1992 - val_loss: 103.8293\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11818.7363 - val_loss: 101.1661\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 71528.9766 - val_loss: 100.3255\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 74253.0156 - val_loss: 100.6813\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 52112.2812 - val_loss: 102.0995\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15621.0908 - val_loss: 104.0823\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45873.1719 - val_loss: 104.7062\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48591.2734 - val_loss: 104.2532\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28603.9336 - val_loss: 102.8286\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11269.2461 - val_loss: 102.2792\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3dac518b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 23 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 55.5971 - val_loss: 22.9394\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.8742 - val_loss: 27.9730\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 1s 196ms/step - loss: 26.2443 - val_loss: 36.4267\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23.5424 - val_loss: 16.4677\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 21.2988 - val_loss: 13.4385\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.4133 - val_loss: 16.7143\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.3225 - val_loss: 7.8219\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7505 - val_loss: 4.3902\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.8596 - val_loss: 7.8843\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.2962 - val_loss: 4.2139\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.0321 - val_loss: 3.9199\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4971 - val_loss: 9.8077\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.5805 - val_loss: 4.0289\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.6286 - val_loss: 3.4198\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7448 - val_loss: 6.4786\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.4010 - val_loss: 4.3122\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0432 - val_loss: 4.9059\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6338 - val_loss: 4.4618\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5501 - val_loss: 4.0564\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.7171 - val_loss: 3.6377\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.3781 - val_loss: 3.6856\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.5589 - val_loss: 4.9463\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.2930 - val_loss: 3.8058\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.3074 - val_loss: 4.2213\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.9161 - val_loss: 4.7677\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.0971 - val_loss: 3.9812\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.6162 - val_loss: 3.5489\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.6648 - val_loss: 4.0431\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.7020 - val_loss: 4.2802\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.3519 - val_loss: 3.4262\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.0809 - val_loss: 4.0848\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.2272 - val_loss: 3.6297\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.1202 - val_loss: 3.7586\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.8271 - val_loss: 4.4453\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.8041 - val_loss: 3.5333\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.4294 - val_loss: 3.6370\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.0787 - val_loss: 3.1955\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.6253 - val_loss: 2.9946\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.6367 - val_loss: 4.4795\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.5965 - val_loss: 3.1618\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.2608 - val_loss: 3.0237\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.8590 - val_loss: 2.9157\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.7984 - val_loss: 2.8009\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.3700 - val_loss: 2.8633\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.1885 - val_loss: 4.3360\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.2099 - val_loss: 2.8977\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.0461 - val_loss: 2.9609\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.9577 - val_loss: 3.9164\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.7254 - val_loss: 2.7081\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.9919 - val_loss: 4.3355\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3dabf4dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 24 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 2552627.5000 - val_loss: 99.4151\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9692551.0000 - val_loss: 98.7766\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6499212.5000 - val_loss: 98.1134\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3029010.0000 - val_loss: 97.5047\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 988605.5625 - val_loss: 97.4225\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1274537.7500 - val_loss: 97.1977\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1170714.8750 - val_loss: 97.4569\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 913373.8750 - val_loss: 97.3510\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1301862.7500 - val_loss: 97.4171\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1645385.1250 - val_loss: 97.3347\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 637881.6875 - val_loss: 97.3361\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 766192.3125 - val_loss: 97.3401\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 881908.8750 - val_loss: 97.2367\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 269318.9062 - val_loss: 97.1590\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 250920.5312 - val_loss: 97.0867\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 654717.0625 - val_loss: 96.9512\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1009128.3125 - val_loss: 96.8549\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 276660.7188 - val_loss: 96.7584\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 263901.0938 - val_loss: 96.6729\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 241336.6094 - val_loss: 96.5812\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 247090.4219 - val_loss: 96.4827\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 285599.0000 - val_loss: 96.3778\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 654779.5625 - val_loss: 96.3192\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 890270.4375 - val_loss: 96.2576\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 296151.0625 - val_loss: 96.1926\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 363056.2500 - val_loss: 96.0978\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 777149.1250 - val_loss: 96.0941\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 657626.3125 - val_loss: 96.0504\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 799390.4375 - val_loss: 96.0435\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 273037.5000 - val_loss: 96.0233\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 241647.1094 - val_loss: 95.9832\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 206030.1562 - val_loss: 95.9395\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 203610.2031 - val_loss: 95.8800\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 599632.8125 - val_loss: 95.8809\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 668271.0625 - val_loss: 95.8815\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 467648.9375 - val_loss: 95.8549\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 725950.1875 - val_loss: 95.9243\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 681940.5000 - val_loss: 95.9307\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 380621.5625 - val_loss: 95.9872\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 220216.4844 - val_loss: 95.9987\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 492956.9375 - val_loss: 95.9843\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 824207.7500 - val_loss: 96.0694\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1208365.0000 - val_loss: 96.1179\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 467733.5938 - val_loss: 96.2085\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 282150.8438 - val_loss: 96.2568\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 376630.6875 - val_loss: 96.2843\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 147736.4531 - val_loss: 96.2935\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 395633.7188 - val_loss: 96.3128\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 306245.8438 - val_loss: 96.3279\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 174073.5625 - val_loss: 96.3249\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3daaeb0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 25 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 73838.9375 - val_loss: 83.3262\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 117674.6875 - val_loss: 87.6636\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 57701.7891 - val_loss: 93.3990\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 90562.6406 - val_loss: 95.6648\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 75284.2891 - val_loss: 92.7344\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 24766.7617 - val_loss: 93.0966\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25124.3496 - val_loss: 94.8334\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33644.7500 - val_loss: 94.9398\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13890.6748 - val_loss: 93.5100\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 49001.6992 - val_loss: 93.3239\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37793.2812 - val_loss: 94.3682\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12644.9023 - val_loss: 94.8911\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3545.5801 - val_loss: 93.8421\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41614.5898 - val_loss: 94.0036\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31108.2559 - val_loss: 94.9755\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14152.3584 - val_loss: 95.4439\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 598.0123 - val_loss: 94.7487\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46487.4805 - val_loss: 94.1686\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35927.2656 - val_loss: 95.6917\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14172.0820 - val_loss: 96.0238\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10989.5137 - val_loss: 95.7087\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15454.9736 - val_loss: 95.6692\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3275.1821 - val_loss: 96.2015\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 40318.9258 - val_loss: 97.0864\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31353.0195 - val_loss: 96.3930\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6417.3164 - val_loss: 95.0186\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62530.5078 - val_loss: 94.8078\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59057.3008 - val_loss: 95.2812\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33873.0781 - val_loss: 97.1273\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40205.8398 - val_loss: 98.2588\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 26270.2129 - val_loss: 97.3955\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7699.6284 - val_loss: 97.5440\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4881.1953 - val_loss: 97.6081\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13249.3623 - val_loss: 97.7471\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4374.0972 - val_loss: 99.2553\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 60654.5195 - val_loss: 99.6550\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33122.0742 - val_loss: 97.8113\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 246.5612 - val_loss: 97.5337\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6727.2539 - val_loss: 97.7326\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7969.8452 - val_loss: 97.7448\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 488.5030 - val_loss: 97.3288\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29494.4805 - val_loss: 97.1716\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 25673.5996 - val_loss: 97.9080\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7072.8188 - val_loss: 97.9091\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1117.6852 - val_loss: 97.3313\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31900.3457 - val_loss: 97.3582\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21922.7148 - val_loss: 97.7973\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10268.8564 - val_loss: 98.8422\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36502.9258 - val_loss: 99.0549\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 37597.3281 - val_loss: 98.9515\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4212dd790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 26 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 136895.5781 - val_loss: 95.3182\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 143255.0625 - val_loss: 88.2007\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 68638.7578 - val_loss: 98.5088\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 76989.6016 - val_loss: 102.3427\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 70872.1484 - val_loss: 100.4831\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5145.8652 - val_loss: 100.5683\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11426.0996 - val_loss: 99.2881\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28916.2207 - val_loss: 100.2335\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17960.5625 - val_loss: 100.4782\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5731.9858 - val_loss: 96.8460\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 98258.5547 - val_loss: 96.3399\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 94635.6172 - val_loss: 97.2321\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39137.1719 - val_loss: 99.3049\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16432.5840 - val_loss: 101.0179\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32764.5684 - val_loss: 100.7820\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20846.2090 - val_loss: 97.7528\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 82319.8359 - val_loss: 97.0362\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 75552.3516 - val_loss: 99.0869\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19353.3164 - val_loss: 102.1761\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 60104.3945 - val_loss: 102.8810\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44593.2305 - val_loss: 100.6815\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15330.9688 - val_loss: 100.2883\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2038.7506 - val_loss: 101.0648\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23299.5684 - val_loss: 101.1490\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18517.8086 - val_loss: 100.2901\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3097.2271 - val_loss: 100.4828\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5886.5117 - val_loss: 100.1157\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6645.5532 - val_loss: 100.3743\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1203.9033 - val_loss: 99.5056\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 30206.9336 - val_loss: 99.6708\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10334.5840 - val_loss: 100.5850\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27994.3652 - val_loss: 101.2022\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 22481.2812 - val_loss: 100.3811\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19464.8594 - val_loss: 99.8878\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1121.4843 - val_loss: 101.0335\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 26764.8066 - val_loss: 101.4108\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29469.7461 - val_loss: 100.6801\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6353.0425 - val_loss: 100.4033\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5269.8066 - val_loss: 100.4029\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 493.5967 - val_loss: 101.1763\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24862.5117 - val_loss: 100.8570\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6106.7222 - val_loss: 100.0944\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27321.5000 - val_loss: 99.5801\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21735.6562 - val_loss: 100.3709\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1747.8357 - val_loss: 102.0319\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 64425.8633 - val_loss: 102.5883\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 60610.2578 - val_loss: 101.6858\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35847.8828 - val_loss: 100.1908\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28526.1406 - val_loss: 99.5910\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15852.9717 - val_loss: 100.4293\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3cb1bdb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 27 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 10163.6865 - val_loss: 117.8539\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 394473.1875 - val_loss: 119.9663\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 293826.1875 - val_loss: 112.1696\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 63787.5781 - val_loss: 107.0754\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 81649.8906 - val_loss: 102.5161\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 69506.0234 - val_loss: 104.6909\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4818.9629 - val_loss: 104.5954\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5458.7495 - val_loss: 105.6998\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 47341.0078 - val_loss: 105.6332\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21245.9121 - val_loss: 103.8460\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 22124.1719 - val_loss: 103.6812\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23846.6504 - val_loss: 104.6632\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12126.7637 - val_loss: 104.1411\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2701.7839 - val_loss: 105.1031\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 35168.9258 - val_loss: 104.5710\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4515.4058 - val_loss: 103.4395\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 48641.8398 - val_loss: 102.6776\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41576.1367 - val_loss: 104.0086\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1140.1154 - val_loss: 106.2208\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 88455.7812 - val_loss: 106.6232\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 83939.0547 - val_loss: 105.1298\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 24035.6719 - val_loss: 103.7147\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12257.7236 - val_loss: 103.2679\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16218.2666 - val_loss: 103.7381\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12497.5273 - val_loss: 103.8818\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 637.2697 - val_loss: 104.3192\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 22308.8262 - val_loss: 104.0192\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2973.4800 - val_loss: 102.9363\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 33632.9336 - val_loss: 102.8383\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 26675.1152 - val_loss: 103.6636\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10766.9453 - val_loss: 103.7962\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1323.6748 - val_loss: 104.2075\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25408.3945 - val_loss: 104.0985\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10393.3457 - val_loss: 102.7915\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46925.1992 - val_loss: 102.3200\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 39026.7227 - val_loss: 103.4133\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18342.3086 - val_loss: 103.8842\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12236.1396 - val_loss: 102.1952\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 49118.4141 - val_loss: 101.9931\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 45170.5000 - val_loss: 102.4476\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24013.9648 - val_loss: 103.9560\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20549.1621 - val_loss: 104.0340\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 26958.8379 - val_loss: 103.6574\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9019.9756 - val_loss: 102.2286\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 52411.9570 - val_loss: 101.6239\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48511.5508 - val_loss: 102.3526\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11383.1885 - val_loss: 103.4173\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26695.8477 - val_loss: 103.6387\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 27790.2129 - val_loss: 103.1328\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2748.8376 - val_loss: 102.9462\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3cb1bdd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 28 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 197552.3750 - val_loss: 93.7595\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 135846.9688 - val_loss: 93.3499\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 55675.0664 - val_loss: 86.4605\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 75793.9375 - val_loss: 86.8065\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 50817.3750 - val_loss: 91.4118\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 19198.2871 - val_loss: 90.8685\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5715.1016 - val_loss: 87.1379\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 61484.8242 - val_loss: 88.4928\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33332.8516 - val_loss: 90.7823\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31008.1914 - val_loss: 92.4610\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23100.5449 - val_loss: 89.0093\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51737.2031 - val_loss: 89.4533\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36984.7383 - val_loss: 92.8872\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31901.9629 - val_loss: 92.8247\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15713.0078 - val_loss: 90.3959\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47929.1797 - val_loss: 90.2357\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36683.0195 - val_loss: 93.3267\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27686.3613 - val_loss: 93.3355\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16282.5859 - val_loss: 90.9386\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59336.0078 - val_loss: 90.2332\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42534.4805 - val_loss: 93.6789\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25253.8848 - val_loss: 94.4723\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26309.5508 - val_loss: 93.8716\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9500.2529 - val_loss: 90.9803\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 80809.9531 - val_loss: 90.1239\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 76457.0000 - val_loss: 92.3093\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 33989.9336 - val_loss: 95.0585\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22746.1855 - val_loss: 95.2467\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23462.4844 - val_loss: 94.2265\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2644.7253 - val_loss: 94.7978\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12737.5469 - val_loss: 94.5327\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13300.1738 - val_loss: 94.3034\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 433.3885 - val_loss: 95.7330\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45316.2461 - val_loss: 96.4566\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36175.4531 - val_loss: 95.7002\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12926.3477 - val_loss: 93.6239\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 57816.1250 - val_loss: 92.8067\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 52007.6367 - val_loss: 93.4306\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25240.6582 - val_loss: 95.7156\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11605.1328 - val_loss: 96.2246\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 24922.2832 - val_loss: 95.4579\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2045.4294 - val_loss: 95.7554\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19570.4766 - val_loss: 95.8482\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7275.6836 - val_loss: 94.1692\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 48934.6992 - val_loss: 93.7355\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 37219.5938 - val_loss: 95.1938\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2504.4648 - val_loss: 96.9357\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32810.9883 - val_loss: 97.4091\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33361.7734 - val_loss: 96.4563\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 989.5332 - val_loss: 94.6075\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff41d709e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 29 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 9084.4053 - val_loss: 130.7537\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 535081.5625 - val_loss: 133.5620\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 363926.7500 - val_loss: 119.6453\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 178116.1406 - val_loss: 106.7267\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51851.7812 - val_loss: 102.6378\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 46526.1562 - val_loss: 104.6375\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6684.8408 - val_loss: 103.5359\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10161.6279 - val_loss: 105.9476\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47573.2383 - val_loss: 104.3313\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13919.1279 - val_loss: 100.6521\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 90245.0234 - val_loss: 100.2975\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 63028.4531 - val_loss: 102.1850\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16064.8223 - val_loss: 106.5744\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 132507.1875 - val_loss: 108.7204\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 111314.2344 - val_loss: 106.1003\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 27279.6406 - val_loss: 102.9873\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 57184.2812 - val_loss: 101.0949\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 57903.2109 - val_loss: 102.4606\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 405.3088 - val_loss: 103.3021\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24786.0000 - val_loss: 103.0797\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8391.2451 - val_loss: 104.8454\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36137.1641 - val_loss: 104.9062\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24913.7988 - val_loss: 103.7696\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14439.2734 - val_loss: 103.3055\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6708.4312 - val_loss: 105.4203\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 50638.4141 - val_loss: 105.1492\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33414.7031 - val_loss: 103.5372\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29010.1094 - val_loss: 102.5420\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14737.3340 - val_loss: 105.0461\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39332.6406 - val_loss: 105.1021\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 41740.5312 - val_loss: 103.5080\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 932.4451 - val_loss: 103.8933\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20421.7871 - val_loss: 103.3326\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1844.2461 - val_loss: 100.9168\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 85493.0938 - val_loss: 99.9797\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 78427.1875 - val_loss: 102.4460\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8248.2266 - val_loss: 103.1959\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1142.3087 - val_loss: 103.5120\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23644.2090 - val_loss: 103.5198\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13478.8594 - val_loss: 101.6958\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31884.6914 - val_loss: 101.9547\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20732.3867 - val_loss: 102.5321\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1470.0865 - val_loss: 103.0814\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6468.3159 - val_loss: 102.1015\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23799.6094 - val_loss: 102.3910\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10992.0156 - val_loss: 104.0393\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38022.6641 - val_loss: 103.9164\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27914.4316 - val_loss: 102.5639\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20964.6230 - val_loss: 102.1363\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9296.5342 - val_loss: 103.3591\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3db59bdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 30 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 389125.0625 - val_loss: 101.8688\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 191765.2188 - val_loss: 112.4506\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 109198.9062 - val_loss: 97.7967\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 141638.6094 - val_loss: 95.2769\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 135885.3750 - val_loss: 100.4566\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7094.5059 - val_loss: 101.1718\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23796.4844 - val_loss: 102.7704\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 44456.5742 - val_loss: 103.0699\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24077.4590 - val_loss: 95.1701\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 162251.9062 - val_loss: 93.3418\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 150308.8281 - val_loss: 94.9202\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 86464.7812 - val_loss: 101.5776\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59760.8164 - val_loss: 104.9679\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 64125.6758 - val_loss: 103.9070\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1435.0466 - val_loss: 100.8769\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 66430.4766 - val_loss: 98.1831\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 82925.0391 - val_loss: 99.2382\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26110.2617 - val_loss: 101.4570\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5067.3706 - val_loss: 107.4758\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 119140.2891 - val_loss: 108.2674\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 146865.0469 - val_loss: 107.4157\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 103121.4141 - val_loss: 104.1365\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12668.8516 - val_loss: 99.5496\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 45774.9531 - val_loss: 96.7302\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 87285.3594 - val_loss: 96.8967\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30035.1777 - val_loss: 101.0024\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22750.7988 - val_loss: 102.4151\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34794.7578 - val_loss: 101.6906\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9466.2754 - val_loss: 101.1758\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19559.0078 - val_loss: 101.7535\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9433.9570 - val_loss: 99.9025\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 59451.4688 - val_loss: 99.0651\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51634.0781 - val_loss: 101.7050\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 30148.5918 - val_loss: 102.1732\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22972.0977 - val_loss: 101.2355\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15456.1230 - val_loss: 100.5663\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3235.6675 - val_loss: 101.6484\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38420.2500 - val_loss: 102.3858\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30248.6152 - val_loss: 101.0811\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9991.2588 - val_loss: 100.7710\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1608.1071 - val_loss: 102.2556\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44042.5312 - val_loss: 102.4160\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35953.5312 - val_loss: 100.6377\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26557.2949 - val_loss: 100.0342\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 893.1262 - val_loss: 100.6151\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25982.8574 - val_loss: 100.0334\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 911.9575 - val_loss: 100.6026\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16588.7344 - val_loss: 100.4765\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8496.4795 - val_loss: 102.1361\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42569.9180 - val_loss: 102.2519\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ca332e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 31 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 71.4267 - val_loss: 46.8055\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47.7045 - val_loss: 40.7772\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37.9910 - val_loss: 38.4247\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31.5357 - val_loss: 24.6816\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26.6529 - val_loss: 20.2418\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20.9754 - val_loss: 9.2098\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.8890 - val_loss: 9.3666\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.4514 - val_loss: 3.9614\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.1195 - val_loss: 5.8747\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.3556 - val_loss: 5.5762\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.1730 - val_loss: 3.7558\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.9268 - val_loss: 3.6142\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.1325 - val_loss: 4.2409\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.2324 - val_loss: 4.8549\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.3925 - val_loss: 4.6519\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.3649 - val_loss: 3.4280\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.8787 - val_loss: 4.0999\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.0296 - val_loss: 3.0304\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.3297 - val_loss: 3.4510\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.0578 - val_loss: 3.2442\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.7445 - val_loss: 4.4587\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.5926 - val_loss: 4.0127\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.7658 - val_loss: 3.0416\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.3432 - val_loss: 5.3707\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.1660 - val_loss: 3.0491\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.4425 - val_loss: 6.0871\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.7740 - val_loss: 3.6088\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.0976 - val_loss: 5.3209\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.8626 - val_loss: 3.4709\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.5388 - val_loss: 6.8550\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.0909 - val_loss: 2.8124\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.3941 - val_loss: 3.3508\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.8169 - val_loss: 4.3536\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.6602 - val_loss: 2.9104\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.5559 - val_loss: 4.1996\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.5929 - val_loss: 3.8316\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3884 - val_loss: 1.7058\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.0942 - val_loss: 12.5524\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5721 - val_loss: 2.6058\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.0196 - val_loss: 3.9267\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.0078 - val_loss: 2.1325\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.6395 - val_loss: 4.3225\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.8630 - val_loss: 1.8617\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.7556 - val_loss: 4.8292\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.7637 - val_loss: 2.0335\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5709 - val_loss: 6.0852\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.3116 - val_loss: 2.2185\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9237 - val_loss: 5.4942\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.6040 - val_loss: 4.1982\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.5149 - val_loss: 6.3260\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ca332ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 32 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 58.4178 - val_loss: 36.6097\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 48.2605 - val_loss: 35.5196\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36.2936 - val_loss: 46.6882\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 34.2935 - val_loss: 29.2464\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28.7221 - val_loss: 20.7214\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23.2851 - val_loss: 21.8878\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.0304 - val_loss: 12.3863\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19.1178 - val_loss: 4.6488\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.7885 - val_loss: 14.3806\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.8501 - val_loss: 3.6171\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.7988 - val_loss: 11.9391\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.9623 - val_loss: 5.7318\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.2592 - val_loss: 8.3741\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.5846 - val_loss: 5.2439\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.2838 - val_loss: 8.2674\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.1553 - val_loss: 3.8908\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.7237 - val_loss: 4.8794\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.9392 - val_loss: 6.0466\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.8541 - val_loss: 4.6635\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.0087 - val_loss: 5.1779\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.3928 - val_loss: 4.4193\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.6724 - val_loss: 6.2688\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.5988 - val_loss: 3.7238\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.3750 - val_loss: 4.7127\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.0889 - val_loss: 5.9683\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.0734 - val_loss: 5.4487\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.3877 - val_loss: 7.2920\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.6838 - val_loss: 3.8835\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.2106 - val_loss: 4.3743\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.1122 - val_loss: 4.8012\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.9676 - val_loss: 3.8615\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.7659 - val_loss: 6.4583\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.5626 - val_loss: 4.2088\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.5652 - val_loss: 3.6074\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.3563 - val_loss: 4.8459\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.3279 - val_loss: 5.1848\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.2455 - val_loss: 2.7638\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7947 - val_loss: 6.0286\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.8429 - val_loss: 2.7610\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.9826 - val_loss: 3.0771\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.7623 - val_loss: 5.5085\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.7292 - val_loss: 3.0350\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.2232 - val_loss: 2.9064\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.7507 - val_loss: 5.2541\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.8236 - val_loss: 4.1915\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.1208 - val_loss: 2.4536\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.3253 - val_loss: 2.5283\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.3627 - val_loss: 6.1826\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.7867 - val_loss: 3.2307\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3529 - val_loss: 3.3650\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff41d709430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 33 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 47.6858 - val_loss: 20.5220\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35.0386 - val_loss: 21.8986\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24.6451 - val_loss: 34.4991\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24.2881 - val_loss: 21.1917\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19.5713 - val_loss: 12.3489\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.0743 - val_loss: 12.3075\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.7168 - val_loss: 3.3102\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.0246 - val_loss: 3.6951\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.9771 - val_loss: 6.2776\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.3162 - val_loss: 5.7939\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.7097 - val_loss: 6.8981\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.5233 - val_loss: 6.5903\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.4196 - val_loss: 5.7471\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.6741 - val_loss: 6.1857\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.5573 - val_loss: 4.3435\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.2956 - val_loss: 4.6864\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.6179 - val_loss: 5.0523\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.1876 - val_loss: 4.3649\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.9179 - val_loss: 5.8585\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.2442 - val_loss: 4.8130\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.7290 - val_loss: 6.0344\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.2590 - val_loss: 5.7219\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.7283 - val_loss: 4.8218\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6237 - val_loss: 3.5443\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.6105 - val_loss: 3.3800\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.7541 - val_loss: 3.9845\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.5059 - val_loss: 4.9994\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.0899 - val_loss: 3.7664\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2857 - val_loss: 3.5763\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.3334 - val_loss: 3.4402\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0954 - val_loss: 3.7381\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.1219 - val_loss: 3.3394\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.6512 - val_loss: 4.2751\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.7979 - val_loss: 3.5077\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.5343 - val_loss: 3.1632\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.7367 - val_loss: 3.2186\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3700 - val_loss: 3.2110\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.0109 - val_loss: 2.9518\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.9944 - val_loss: 3.2076\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.0201 - val_loss: 3.6659\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.4585 - val_loss: 2.7230\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.5725 - val_loss: 2.5603\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.5816 - val_loss: 2.3974\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3751 - val_loss: 2.6570\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.3671 - val_loss: 2.7141\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.1849 - val_loss: 2.4245\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.5043 - val_loss: 2.5356\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.3177 - val_loss: 2.8175\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3014 - val_loss: 2.1793\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.9571 - val_loss: 2.4229\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40b1d1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 34 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 124813.8125 - val_loss: 93.3185\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 102255.4297 - val_loss: 97.6761\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 248932.2656 - val_loss: 100.8528\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 149388.7969 - val_loss: 94.4780\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 140493.3125 - val_loss: 93.9339\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 99402.9688 - val_loss: 99.2959\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 125192.0156 - val_loss: 99.5848\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44194.4414 - val_loss: 97.7557\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38337.5781 - val_loss: 98.9210\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18762.1348 - val_loss: 98.8537\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33474.3906 - val_loss: 98.2385\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33310.3828 - val_loss: 100.5860\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 65754.4844 - val_loss: 101.4550\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 41561.7578 - val_loss: 99.4100\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17192.2402 - val_loss: 99.5499\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29243.3027 - val_loss: 98.3759\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20901.4590 - val_loss: 98.8816\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4478.0996 - val_loss: 99.5144\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10248.7607 - val_loss: 100.6256\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5735.0537 - val_loss: 100.6153\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9891.5059 - val_loss: 100.1988\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12136.0078 - val_loss: 100.3710\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 58363.3633 - val_loss: 100.4960\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20180.3594 - val_loss: 99.3318\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 17968.5801 - val_loss: 100.8529\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51519.6875 - val_loss: 100.4430\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10942.3379 - val_loss: 98.8226\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 89448.7344 - val_loss: 98.9726\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 64801.3672 - val_loss: 100.0667\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46361.5742 - val_loss: 100.4577\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34394.6250 - val_loss: 99.5431\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31037.7363 - val_loss: 100.7781\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 37370.2461 - val_loss: 101.2640\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15839.1006 - val_loss: 100.3596\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7598.9595 - val_loss: 100.6000\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 61740.0000 - val_loss: 100.7597\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 37298.6992 - val_loss: 98.6220\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 80167.6172 - val_loss: 97.7836\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 76598.2188 - val_loss: 99.4544\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40732.0312 - val_loss: 99.6978\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 23963.4629 - val_loss: 98.6227\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 82866.6562 - val_loss: 98.2110\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 68478.9766 - val_loss: 99.5657\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14953.1270 - val_loss: 99.4265\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4070.4812 - val_loss: 98.8269\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10822.5801 - val_loss: 98.6461\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24461.8965 - val_loss: 97.6119\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16238.3555 - val_loss: 98.3840\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15165.0918 - val_loss: 98.6678\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15347.6680 - val_loss: 97.7923\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3c8a0e3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 35 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 57.4321 - val_loss: 25.6595\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28.1364 - val_loss: 14.3515\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 22.5069 - val_loss: 35.9225\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22.2368 - val_loss: 24.6171\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18.4686 - val_loss: 13.8771\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.0919 - val_loss: 20.1921\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.6069 - val_loss: 13.4278\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.6218 - val_loss: 10.2489\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.8420 - val_loss: 5.5405\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.3672 - val_loss: 8.1557\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8746 - val_loss: 6.4330\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.4881 - val_loss: 4.5546\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.1887 - val_loss: 5.3700\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.9253 - val_loss: 3.7989\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.8611 - val_loss: 6.4821\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.4969 - val_loss: 2.5045\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5143 - val_loss: 4.2913\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7725 - val_loss: 3.4037\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4127 - val_loss: 2.2201\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.1105 - val_loss: 8.8628\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4453 - val_loss: 2.7199\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.3035 - val_loss: 2.6529\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4364 - val_loss: 5.4392\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3583 - val_loss: 3.7383\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0859 - val_loss: 5.5675\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.9073 - val_loss: 2.0535\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4407 - val_loss: 3.2717\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4823 - val_loss: 3.5911\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.3364 - val_loss: 2.5264\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.3714 - val_loss: 2.2326\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.2746 - val_loss: 4.4479\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.1251 - val_loss: 3.2279\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.3446 - val_loss: 3.8583\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6536 - val_loss: 2.3039\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7162 - val_loss: 3.0231\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.4749 - val_loss: 2.0877\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.4224 - val_loss: 2.0602\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.2826 - val_loss: 1.8896\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2673 - val_loss: 3.3663\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6095 - val_loss: 2.6917\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.3730 - val_loss: 2.7433\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.4552 - val_loss: 3.2549\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.4568 - val_loss: 1.8663\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.0531 - val_loss: 3.3074\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3827 - val_loss: 2.4937\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.0102 - val_loss: 1.7331\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.7378 - val_loss: 3.8862\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.8011 - val_loss: 4.8278\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.4444 - val_loss: 1.5312\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.1065 - val_loss: 2.6243\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3c69e59d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 36 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 25247.8594 - val_loss: 70.3737\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 443366.5312 - val_loss: 71.6385\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 255818.6250 - val_loss: 80.7186\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 167625.7656 - val_loss: 92.7706\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 163651.3125 - val_loss: 97.7970\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 146234.8750 - val_loss: 93.1988\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14363.8936 - val_loss: 92.5413\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6351.7656 - val_loss: 94.8051\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 69025.5469 - val_loss: 94.8323\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47970.2305 - val_loss: 93.4068\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34120.8633 - val_loss: 93.0947\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13120.9365 - val_loss: 94.4513\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 49291.5977 - val_loss: 95.3834\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40346.2383 - val_loss: 93.9948\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8537.4434 - val_loss: 94.4270\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6339.7593 - val_loss: 94.2180\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20909.8125 - val_loss: 93.8893\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21499.3066 - val_loss: 95.3804\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36518.3633 - val_loss: 95.3403\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16028.6006 - val_loss: 93.6721\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 45256.4727 - val_loss: 93.7286\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34739.4492 - val_loss: 94.9709\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21763.5195 - val_loss: 95.5530\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 991.0709 - val_loss: 94.6965\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 43454.0430 - val_loss: 93.7682\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48947.8164 - val_loss: 94.6610\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4290.1250 - val_loss: 96.2927\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 48144.3633 - val_loss: 97.1169\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 46844.4180 - val_loss: 96.3253\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5174.9429 - val_loss: 94.5991\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 68174.4844 - val_loss: 93.8054\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 64093.5586 - val_loss: 95.2066\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4277.3086 - val_loss: 96.6305\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63652.6055 - val_loss: 98.3085\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 55013.5586 - val_loss: 97.5960\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12470.9033 - val_loss: 96.0827\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 26970.3066 - val_loss: 95.5704\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 37547.4375 - val_loss: 95.9687\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 12464.3457 - val_loss: 97.5022\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 55055.0938 - val_loss: 98.4395\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 35369.4570 - val_loss: 97.6594\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10268.2217 - val_loss: 95.3900\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 74806.9688 - val_loss: 94.6690\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 81778.2344 - val_loss: 95.3986\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 46437.2539 - val_loss: 96.5785\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20812.8809 - val_loss: 99.3284\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 69095.2891 - val_loss: 100.3116\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 73349.4922 - val_loss: 99.9930\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 48490.7930 - val_loss: 98.7625\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9284.5059 - val_loss: 98.1456\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d4c848b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 37 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 73.2044 - val_loss: 40.7292\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28.6897 - val_loss: 6.4736\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25.3595 - val_loss: 32.2962\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23.7535 - val_loss: 34.9684\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 19.6738 - val_loss: 19.4694\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.8931 - val_loss: 13.4064\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.9818 - val_loss: 20.1098\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.1831 - val_loss: 23.0447\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.5589 - val_loss: 8.0820\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.2298 - val_loss: 15.1289\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.8839 - val_loss: 3.0498\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4030 - val_loss: 4.9917\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.8678 - val_loss: 4.9733\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7802 - val_loss: 3.4045\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0165 - val_loss: 2.6912\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3922 - val_loss: 4.3439\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.2764 - val_loss: 6.0891\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3044 - val_loss: 4.1741\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.4209 - val_loss: 7.4828\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.6328 - val_loss: 2.6530\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.7482 - val_loss: 2.7252\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.6489 - val_loss: 3.8918\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3387 - val_loss: 3.5108\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.2189 - val_loss: 2.6260\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.4971 - val_loss: 2.9396\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7875 - val_loss: 3.2292\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.0956 - val_loss: 2.8100\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.8589 - val_loss: 3.8777\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.7849 - val_loss: 4.1125\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.4237 - val_loss: 2.9858\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.8758 - val_loss: 3.1280\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5956 - val_loss: 3.1000\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.8849 - val_loss: 4.5146\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.0883 - val_loss: 2.9735\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.7778 - val_loss: 3.1027\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.3840 - val_loss: 3.3584\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.3533 - val_loss: 4.2614\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.0802 - val_loss: 2.8445\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.4522 - val_loss: 4.4704\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.0920 - val_loss: 3.3400\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.4819 - val_loss: 3.1891\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.4452 - val_loss: 3.1971\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.0635 - val_loss: 3.9060\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.1203 - val_loss: 3.3742\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.8081 - val_loss: 3.4627\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.7637 - val_loss: 3.3859\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.9603 - val_loss: 2.9181\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.4876 - val_loss: 3.9416\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.1819 - val_loss: 3.7765\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.2606 - val_loss: 6.7677\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4155ccf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 38 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 72.8588 - val_loss: 43.2210\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 52.3241 - val_loss: 32.4710\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41.2060 - val_loss: 49.7535\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35.7096 - val_loss: 39.4274\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 29.5822 - val_loss: 30.1854\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26.9633 - val_loss: 28.4945\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23.2196 - val_loss: 21.8317\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19.0212 - val_loss: 11.7306\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.0577 - val_loss: 5.4230\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.6351 - val_loss: 6.7526\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.7074 - val_loss: 10.5901\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.1503 - val_loss: 2.4940\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.1321 - val_loss: 9.9489\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.7931 - val_loss: 5.3402\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.6401 - val_loss: 3.0565\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.7273 - val_loss: 9.1128\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.8473 - val_loss: 4.0482\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.4041 - val_loss: 6.6791\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.2584 - val_loss: 3.4258\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.7873 - val_loss: 6.1457\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.8010 - val_loss: 4.0392\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.2946 - val_loss: 3.3179\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.2725 - val_loss: 4.7392\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.3590 - val_loss: 2.6661\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.2806 - val_loss: 5.4817\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.0749 - val_loss: 5.2504\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.0624 - val_loss: 2.7657\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.6351 - val_loss: 6.0022\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.6024 - val_loss: 2.9186\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.1607 - val_loss: 6.8269\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.6709 - val_loss: 3.3488\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.9520 - val_loss: 6.4012\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.8962 - val_loss: 2.8462\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.3737 - val_loss: 4.8279\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.7542 - val_loss: 8.4839\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.2071 - val_loss: 5.2022\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8998 - val_loss: 8.4269\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.7612 - val_loss: 2.9205\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.9660 - val_loss: 3.3823\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5085 - val_loss: 6.4663\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.3207 - val_loss: 3.8186\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.8947 - val_loss: 2.9530\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.8706 - val_loss: 6.4217\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.7734 - val_loss: 4.4368\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6164 - val_loss: 3.8572\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2863 - val_loss: 6.4600\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.3616 - val_loss: 3.1194\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.5547 - val_loss: 7.1867\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.9420 - val_loss: 4.2750\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.9256 - val_loss: 5.1530\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3caf30310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 39 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 265653.4062 - val_loss: 111.3532\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 207790.2344 - val_loss: 101.9529\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 92996.1328 - val_loss: 99.9420\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 94813.8047 - val_loss: 104.3073\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 87221.5312 - val_loss: 103.8739\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63308.5508 - val_loss: 99.5989\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 131271.9375 - val_loss: 99.4332\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 61274.9414 - val_loss: 103.3161\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 53498.4297 - val_loss: 103.0276\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28898.8125 - val_loss: 99.5364\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 107199.1562 - val_loss: 99.2281\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 50157.8867 - val_loss: 102.4646\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 101154.7266 - val_loss: 103.6790\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 81707.4766 - val_loss: 101.2446\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 68527.7031 - val_loss: 99.9919\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32056.5762 - val_loss: 101.1307\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5905.1689 - val_loss: 100.9639\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18029.2871 - val_loss: 101.1492\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15931.0049 - val_loss: 98.9900\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10417.3086 - val_loss: 98.6139\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23915.4023 - val_loss: 98.4864\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20967.8066 - val_loss: 101.1391\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18281.1055 - val_loss: 101.4666\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32566.5195 - val_loss: 102.3155\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12974.7012 - val_loss: 104.9175\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 98326.6562 - val_loss: 104.3539\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 61471.4062 - val_loss: 102.1471\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17437.8945 - val_loss: 99.6360\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 81535.3047 - val_loss: 99.8012\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13601.4453 - val_loss: 100.9976\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 75118.6406 - val_loss: 101.2680\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 70268.8203 - val_loss: 100.0857\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11873.7412 - val_loss: 100.6576\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5867.1157 - val_loss: 99.6510\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 80392.2734 - val_loss: 99.5976\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32652.3262 - val_loss: 101.3842\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11007.2480 - val_loss: 101.1090\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15183.8896 - val_loss: 100.9903\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18106.6191 - val_loss: 99.8023\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10738.1992 - val_loss: 100.7934\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6581.3950 - val_loss: 100.5925\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10192.9346 - val_loss: 101.7588\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 68585.6484 - val_loss: 101.8879\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 42438.3672 - val_loss: 100.0136\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52679.8828 - val_loss: 99.7755\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49107.2305 - val_loss: 101.1195\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35784.5000 - val_loss: 101.3121\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15474.0889 - val_loss: 99.5712\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 66443.1797 - val_loss: 99.2055\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 56203.2812 - val_loss: 100.4164\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d03eb670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 40 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 97.5534 - val_loss: 79.5426\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 80.0021 - val_loss: 67.8547\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 61.7973 - val_loss: 48.4933\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 52.7072 - val_loss: 43.9517\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 49.3200 - val_loss: 38.7282\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42.7340 - val_loss: 30.6041\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39.8783 - val_loss: 25.8215\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 38.9179 - val_loss: 19.7094\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39.1615 - val_loss: 19.4811\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34.9602 - val_loss: 14.8635\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32.6038 - val_loss: 17.6592\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32.2859 - val_loss: 11.5360\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32.5461 - val_loss: 10.9953\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29.1283 - val_loss: 3.8152\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.6728 - val_loss: 16.5505\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21.9163 - val_loss: 4.4389\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23.3288 - val_loss: 11.1155\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21.4101 - val_loss: 7.0650\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.0784 - val_loss: 11.4681\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.8887 - val_loss: 7.9414\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.1084 - val_loss: 9.0279\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.1659 - val_loss: 9.6158\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.7566 - val_loss: 8.9227\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.2374 - val_loss: 7.0078\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.8100 - val_loss: 7.2392\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.8270 - val_loss: 8.4034\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.0831 - val_loss: 6.0787\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.9615 - val_loss: 6.4899\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4539 - val_loss: 6.9785\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.0396 - val_loss: 9.0592\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.3744 - val_loss: 6.5213\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.2863 - val_loss: 6.7526\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4963 - val_loss: 4.6524\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.6171 - val_loss: 5.6507\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.2227 - val_loss: 8.1427\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.5237 - val_loss: 4.6574\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8932 - val_loss: 4.2838\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.1479 - val_loss: 5.4336\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.4148 - val_loss: 3.6713\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.0762 - val_loss: 7.4968\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.4666 - val_loss: 2.8225\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.4304 - val_loss: 9.5956\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9684 - val_loss: 2.8330\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.4215 - val_loss: 11.2776\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.3279 - val_loss: 2.8553\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.5913 - val_loss: 6.7302\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.8262 - val_loss: 2.5818\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.3788 - val_loss: 8.0883\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.2683 - val_loss: 2.9348\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.5396 - val_loss: 9.0903\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e3c17e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 41 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 71669.1016 - val_loss: 77.4026\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 303993.7500 - val_loss: 77.4043\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 138210.5938 - val_loss: 84.5922\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 83461.6250 - val_loss: 99.1544\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 372817.4688 - val_loss: 105.6417\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 284237.1250 - val_loss: 101.8701\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 142158.7344 - val_loss: 97.6931\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 48796.5703 - val_loss: 92.5937\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 158286.7500 - val_loss: 90.5495\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 148523.0156 - val_loss: 92.3805\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 59104.3945 - val_loss: 95.0705\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11029.7686 - val_loss: 100.0240\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 140994.9375 - val_loss: 99.9135\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 144078.1875 - val_loss: 98.7128\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 76519.5547 - val_loss: 96.0230\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16085.3535 - val_loss: 94.5477\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10243.0859 - val_loss: 95.3161\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35948.8438 - val_loss: 96.3930\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 37022.4688 - val_loss: 95.9110\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1728.2103 - val_loss: 95.8048\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8911.2969 - val_loss: 94.9222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 29703.8848 - val_loss: 95.4921\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1618.4261 - val_loss: 95.2237\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33217.3750 - val_loss: 95.2356\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19878.5957 - val_loss: 97.1466\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 47501.5039 - val_loss: 97.1302\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41608.8242 - val_loss: 96.3861\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3213.0801 - val_loss: 94.6409\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 89793.2500 - val_loss: 94.0039\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 85645.9766 - val_loss: 95.4722\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22466.3262 - val_loss: 97.0419\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31736.5293 - val_loss: 97.4576\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32738.2969 - val_loss: 96.6904\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17897.8535 - val_loss: 96.5562\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6322.5659 - val_loss: 96.7054\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21294.2559 - val_loss: 96.4561\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12174.4922 - val_loss: 97.3187\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25311.4258 - val_loss: 97.3460\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15377.2881 - val_loss: 96.3847\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41697.3516 - val_loss: 96.1319\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27007.5371 - val_loss: 97.1887\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22999.1875 - val_loss: 97.5141\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12744.9170 - val_loss: 96.9386\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15684.6328 - val_loss: 96.9050\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10000.8047 - val_loss: 97.9997\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 38209.1719 - val_loss: 97.8684\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 22871.2422 - val_loss: 96.8661\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30180.8379 - val_loss: 96.7629\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17610.6816 - val_loss: 97.6485\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19590.6816 - val_loss: 97.7224\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ce6df430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 42 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 171346.7344 - val_loss: 73.3763\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41984.1016 - val_loss: 83.9264\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38971.7500 - val_loss: 81.2387\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 94004.9141 - val_loss: 79.6423\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 44395.9375 - val_loss: 86.7863\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 74631.8672 - val_loss: 89.6431\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 67680.4141 - val_loss: 88.9691\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47102.9258 - val_loss: 82.2151\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 139928.5625 - val_loss: 80.7058\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 120040.4609 - val_loss: 84.9730\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 73525.3203 - val_loss: 91.0210\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 50304.4609 - val_loss: 92.8001\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24064.0156 - val_loss: 90.5648\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9702.7285 - val_loss: 90.8272\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7224.0010 - val_loss: 93.1404\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 51789.0117 - val_loss: 93.5002\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36908.8320 - val_loss: 91.5364\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24558.6426 - val_loss: 91.4360\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6686.0967 - val_loss: 92.8711\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33347.9414 - val_loss: 93.5631\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26837.9922 - val_loss: 92.1814\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8680.5283 - val_loss: 92.7228\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3571.0740 - val_loss: 92.0273\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37452.7148 - val_loss: 91.6291\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21773.3164 - val_loss: 94.3382\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40257.9727 - val_loss: 94.9938\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 41424.4883 - val_loss: 94.0440\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3605.8562 - val_loss: 92.3400\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39050.9727 - val_loss: 92.1599\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 38729.2852 - val_loss: 93.5730\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7023.4351 - val_loss: 94.2052\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 107.1417 - val_loss: 91.8802\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 72501.1797 - val_loss: 91.5508\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 69096.9844 - val_loss: 93.4073\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24727.1719 - val_loss: 95.3542\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33787.4023 - val_loss: 96.5575\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 25799.9883 - val_loss: 95.1535\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9825.3516 - val_loss: 95.3428\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8904.2520 - val_loss: 96.2257\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23439.1621 - val_loss: 96.6318\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 17505.2441 - val_loss: 95.1896\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20320.9141 - val_loss: 95.5070\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13155.3525 - val_loss: 96.2228\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16308.2314 - val_loss: 96.7546\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8136.2666 - val_loss: 95.7697\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30016.7461 - val_loss: 95.3576\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25713.9883 - val_loss: 96.8724\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 17728.9238 - val_loss: 97.0723\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6137.0508 - val_loss: 96.3487\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20443.8320 - val_loss: 96.0842\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d1fef9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 43 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 70.9863 - val_loss: 47.1003\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 45.4513 - val_loss: 33.1910\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39.7083 - val_loss: 42.2582\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33.1549 - val_loss: 36.9387\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28.5269 - val_loss: 24.0304\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23.5058 - val_loss: 10.6572\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.5812 - val_loss: 9.9766\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.3411 - val_loss: 12.6385\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.8912 - val_loss: 6.0221\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.9684 - val_loss: 10.1256\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.3641 - val_loss: 5.6422\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.4809 - val_loss: 7.8763\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.5861 - val_loss: 5.8070\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.5653 - val_loss: 6.4997\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.5724 - val_loss: 5.8410\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.2173 - val_loss: 5.5147\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.8904 - val_loss: 6.5663\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.6129 - val_loss: 5.2909\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.8983 - val_loss: 6.7101\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.1803 - val_loss: 5.5399\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.7440 - val_loss: 4.9453\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7881 - val_loss: 3.9572\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4052 - val_loss: 4.5812\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.1055 - val_loss: 3.7935\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.1320 - val_loss: 3.5519\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5499 - val_loss: 4.5980\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.1149 - val_loss: 3.6303\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.8085 - val_loss: 2.9966\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7667 - val_loss: 4.8548\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.6659 - val_loss: 3.5182\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.6855 - val_loss: 2.6510\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.9400 - val_loss: 4.3570\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4108 - val_loss: 2.3817\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.8067 - val_loss: 2.1768\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.5627 - val_loss: 2.3690\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.2017 - val_loss: 2.8153\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.8101 - val_loss: 2.1623\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.0327 - val_loss: 1.9217\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.6869 - val_loss: 2.2548\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.3321 - val_loss: 2.0841\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.9286 - val_loss: 2.0270\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.8686 - val_loss: 1.9618\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.8758 - val_loss: 2.0483\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.8129 - val_loss: 2.3264\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.6915 - val_loss: 2.0895\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.8842 - val_loss: 2.1039\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.6655 - val_loss: 3.8431\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.7160 - val_loss: 3.0593\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.5874 - val_loss: 2.2311\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.0014 - val_loss: 2.6722\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d1fef670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 44 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 81.5181 - val_loss: 54.3305\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 57.7668 - val_loss: 60.0502\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45.7891 - val_loss: 41.9367\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 44.0744 - val_loss: 41.6776\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36.0690 - val_loss: 31.1340\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32.6047 - val_loss: 24.0254\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27.6416 - val_loss: 8.8828\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21.6407 - val_loss: 7.5942\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.0114 - val_loss: 7.3309\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.5808 - val_loss: 8.8222\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20.6543 - val_loss: 9.6570\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29.7155 - val_loss: 7.1029\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26.0544 - val_loss: 12.3520\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 21.7765 - val_loss: 7.4030\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.3405 - val_loss: 10.4191\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.5706 - val_loss: 5.9630\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.2513 - val_loss: 7.8460\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.9063 - val_loss: 5.7767\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.2064 - val_loss: 6.4488\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.6126 - val_loss: 6.0489\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.3128 - val_loss: 5.5194\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.4862 - val_loss: 12.1954\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.5868 - val_loss: 6.4577\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18.1700 - val_loss: 7.4602\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.5053 - val_loss: 7.6525\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.2117 - val_loss: 4.8975\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.6796 - val_loss: 8.9113\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.1128 - val_loss: 6.3005\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.9675 - val_loss: 8.8810\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.2890 - val_loss: 5.6925\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.1737 - val_loss: 6.1164\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.8791 - val_loss: 7.6215\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.3030 - val_loss: 5.4174\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.8024 - val_loss: 6.6972\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.0499 - val_loss: 3.6291\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.0747 - val_loss: 6.4503\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.7889 - val_loss: 3.8194\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3231 - val_loss: 5.2185\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4967 - val_loss: 3.8582\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.2442 - val_loss: 6.6880\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.5850 - val_loss: 4.2451\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.2731 - val_loss: 3.9481\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.2320 - val_loss: 4.5310\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.0417 - val_loss: 5.4572\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5278 - val_loss: 3.3940\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.2586 - val_loss: 5.7463\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9758 - val_loss: 3.3008\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9053 - val_loss: 6.1328\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.6520 - val_loss: 3.3694\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.7156 - val_loss: 3.7413\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff411712a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 45 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 128904.7500 - val_loss: 112.1659\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 234762.8750 - val_loss: 116.3128\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 131336.0469 - val_loss: 109.3278\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14658.1562 - val_loss: 101.0615\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 115720.9844 - val_loss: 98.2646\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 122256.5234 - val_loss: 99.2994\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41730.3945 - val_loss: 101.1388\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55931.7227 - val_loss: 102.6205\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33902.5469 - val_loss: 100.3744\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13654.3223 - val_loss: 100.3529\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16563.9004 - val_loss: 101.9981\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32291.0098 - val_loss: 101.6235\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2993.1711 - val_loss: 100.6321\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12918.6592 - val_loss: 100.0660\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28854.9531 - val_loss: 101.3135\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18689.1406 - val_loss: 101.5476\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 779.4147 - val_loss: 101.4130\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6677.8071 - val_loss: 100.5695\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23914.5645 - val_loss: 100.8363\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1914.0504 - val_loss: 101.7278\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 56961.4805 - val_loss: 103.2686\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42016.7188 - val_loss: 101.9790\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6799.3633 - val_loss: 101.1182\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 124.6822 - val_loss: 100.4528\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25511.1934 - val_loss: 100.7522\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7707.4751 - val_loss: 102.0483\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 47286.0273 - val_loss: 102.8258\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35259.4062 - val_loss: 100.8022\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33523.3789 - val_loss: 100.0178\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 26041.8398 - val_loss: 100.8283\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2155.5034 - val_loss: 102.9884\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 70645.2266 - val_loss: 103.8460\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 65248.8359 - val_loss: 103.2602\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22975.4922 - val_loss: 101.3488\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7883.2065 - val_loss: 98.0597\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 114008.8438 - val_loss: 96.5186\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 107623.4375 - val_loss: 97.2421\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 81234.0234 - val_loss: 98.7945\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37007.8555 - val_loss: 100.5575\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11598.0762 - val_loss: 101.2745\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17298.7871 - val_loss: 101.1198\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5469.1611 - val_loss: 100.5905\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 777.0666 - val_loss: 100.9451\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19216.6777 - val_loss: 101.4019\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20023.1855 - val_loss: 100.7628\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3029.8123 - val_loss: 100.7801\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5466.2515 - val_loss: 100.3959\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8684.9570 - val_loss: 100.7028\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8491.2998 - val_loss: 100.7545\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13704.8311 - val_loss: 100.2416\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d03eb430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 46 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 256442.0312 - val_loss: 86.5419\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38551.9766 - val_loss: 103.4117\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 341356.5625 - val_loss: 109.4332\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 312638.8125 - val_loss: 102.6383\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 98382.1094 - val_loss: 97.6910\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 72765.4375 - val_loss: 94.9545\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 41755.5859 - val_loss: 97.5048\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17353.5469 - val_loss: 97.7491\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 24099.3066 - val_loss: 97.2221\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1958.3267 - val_loss: 94.8160\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 97195.6562 - val_loss: 94.5933\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 92444.2734 - val_loss: 96.0066\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28209.9668 - val_loss: 97.5369\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37028.1406 - val_loss: 98.0543\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31970.6719 - val_loss: 97.6303\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23598.0195 - val_loss: 96.6700\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14018.8438 - val_loss: 98.1376\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 55663.8672 - val_loss: 98.7108\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 47623.8359 - val_loss: 97.7174\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11091.7891 - val_loss: 97.4313\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1750.3180 - val_loss: 97.1458\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16092.3936 - val_loss: 97.6301\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3609.0239 - val_loss: 97.0936\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19407.7246 - val_loss: 97.6114\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4376.7720 - val_loss: 97.2635\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13924.9658 - val_loss: 97.7206\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4935.2485 - val_loss: 97.1575\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 33725.3945 - val_loss: 96.9920\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2894.1099 - val_loss: 98.3775\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24918.6621 - val_loss: 98.7380\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37259.5352 - val_loss: 97.9990\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4620.8403 - val_loss: 97.8777\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25333.6465 - val_loss: 98.3478\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20117.9551 - val_loss: 97.1852\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 34931.7070 - val_loss: 97.1443\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21344.7031 - val_loss: 98.0751\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31537.4043 - val_loss: 98.6463\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20262.5430 - val_loss: 97.3399\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39214.9609 - val_loss: 97.0386\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35873.8125 - val_loss: 98.0648\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13221.7471 - val_loss: 98.2651\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5230.2891 - val_loss: 98.2026\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22048.5215 - val_loss: 98.6390\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15923.3994 - val_loss: 97.7538\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 35422.7969 - val_loss: 97.3762\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24164.5449 - val_loss: 98.7102\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 17000.6543 - val_loss: 98.8247\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19642.2773 - val_loss: 98.1168\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15016.9014 - val_loss: 98.2161\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 737.7365 - val_loss: 98.0280\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3c4eed160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 47 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - val_loss: 96.2273\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3bd0770d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 48 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 301977.8438 - val_loss: 85.9285\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13491.4551 - val_loss: 101.2984\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 179782.6875 - val_loss: 106.7263\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 170839.1406 - val_loss: 103.0799\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55225.8359 - val_loss: 98.9959\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34397.7930 - val_loss: 97.2444\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 29360.1875 - val_loss: 98.6732\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 483.8452 - val_loss: 103.2626\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 116007.0391 - val_loss: 103.7885\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 108859.2812 - val_loss: 102.2557\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 62698.2617 - val_loss: 99.0229\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20097.5020 - val_loss: 98.5912\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17161.1191 - val_loss: 99.2792\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33201.6992 - val_loss: 100.6671\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 28649.9863 - val_loss: 99.3957\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16572.4316 - val_loss: 99.1949\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1829.3199 - val_loss: 99.1254\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9424.6162 - val_loss: 99.0770\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11143.6582 - val_loss: 100.6135\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36658.0742 - val_loss: 100.5070\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10465.8154 - val_loss: 99.4329\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39836.9258 - val_loss: 98.0004\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41104.9961 - val_loss: 98.6803\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5093.7900 - val_loss: 100.5315\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42679.8867 - val_loss: 101.4473\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 43393.2656 - val_loss: 100.1675\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 167.6297 - val_loss: 98.5527\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32970.9922 - val_loss: 98.4935\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 35489.0195 - val_loss: 99.5416\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5302.1489 - val_loss: 99.7841\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12260.5068 - val_loss: 99.8326\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9964.2295 - val_loss: 99.9596\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12122.4873 - val_loss: 99.7726\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20281.2285 - val_loss: 100.5014\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14683.9756 - val_loss: 98.5774\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 50718.4062 - val_loss: 98.2347\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46299.8125 - val_loss: 99.5816\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11473.1699 - val_loss: 101.4452\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 62138.6992 - val_loss: 102.1910\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 42244.9102 - val_loss: 101.2412\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1940.4613 - val_loss: 99.2638\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 55694.7383 - val_loss: 98.0561\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 60008.1250 - val_loss: 98.6569\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 32868.6953 - val_loss: 99.5604\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9788.9297 - val_loss: 101.2965\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 59671.8750 - val_loss: 102.1628\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 56539.5469 - val_loss: 100.9287\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5373.8608 - val_loss: 99.9948\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14734.5967 - val_loss: 99.3360\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 27758.6348 - val_loss: 99.6464\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3dbfbadc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 49 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 62.8246 - val_loss: 33.9823\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 52.8694 - val_loss: 40.2576\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40.5240 - val_loss: 54.7918\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 40.3926 - val_loss: 36.8568\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30.9216 - val_loss: 21.5492\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28.1171 - val_loss: 22.6329\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22.5144 - val_loss: 11.4316\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.5370 - val_loss: 8.4423\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.2916 - val_loss: 4.3855\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19.6715 - val_loss: 9.9529\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.0780 - val_loss: 4.1987\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.5936 - val_loss: 4.1280\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.4802 - val_loss: 3.4647\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.4448 - val_loss: 3.9829\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.3853 - val_loss: 5.1403\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.1602 - val_loss: 4.9847\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.8789 - val_loss: 4.2574\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.8951 - val_loss: 3.4597\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.1849 - val_loss: 4.3845\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.3709 - val_loss: 4.0004\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.8418 - val_loss: 4.1221\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.0005 - val_loss: 3.8068\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.8188 - val_loss: 3.7440\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.5625 - val_loss: 5.3058\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.1194 - val_loss: 4.0502\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.7895 - val_loss: 3.3465\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.6970 - val_loss: 4.2671\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.7570 - val_loss: 4.1330\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.9050 - val_loss: 3.9325\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.2569 - val_loss: 3.4889\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.5645 - val_loss: 4.1619\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.4688 - val_loss: 5.1148\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9172 - val_loss: 4.6670\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.5944 - val_loss: 6.2199\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.4049 - val_loss: 5.7201\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.5751 - val_loss: 3.1639\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4915 - val_loss: 2.7872\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.1078 - val_loss: 3.3984\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4972 - val_loss: 3.6998\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.3999 - val_loss: 2.5718\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.0158 - val_loss: 3.4639\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.0991 - val_loss: 3.4548\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3376 - val_loss: 3.3153\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.1338 - val_loss: 3.8118\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3629 - val_loss: 3.0003\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.2130 - val_loss: 4.0197\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.3449 - val_loss: 5.6693\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5741 - val_loss: 2.5491\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2552 - val_loss: 6.3740\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.2971 - val_loss: 3.5509\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ce6df310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 50 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 58.2049 - val_loss: 24.7009\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42.0554 - val_loss: 30.4401\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29.5854 - val_loss: 34.5746\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25.6176 - val_loss: 20.7620\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20.1303 - val_loss: 18.1920\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.7993 - val_loss: 7.1093\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.3152 - val_loss: 5.4078\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.6128 - val_loss: 3.8125\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.3425 - val_loss: 4.1805\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.9417 - val_loss: 8.3603\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.2666 - val_loss: 6.5169\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.5589 - val_loss: 5.0396\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.0770 - val_loss: 4.4665\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.7446 - val_loss: 4.5765\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.4171 - val_loss: 7.6889\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.1115 - val_loss: 4.2862\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.2636 - val_loss: 6.1265\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.3083 - val_loss: 5.5490\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.4738 - val_loss: 3.2684\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.6160 - val_loss: 7.5118\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.0421 - val_loss: 4.7072\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.2419 - val_loss: 7.8622\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.9024 - val_loss: 3.2838\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.4709 - val_loss: 4.6641\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.7284 - val_loss: 3.4059\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.8834 - val_loss: 3.6370\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.7880 - val_loss: 5.9454\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2643 - val_loss: 3.3050\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.4235 - val_loss: 3.9020\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3493 - val_loss: 5.2928\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4240 - val_loss: 3.2209\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.1003 - val_loss: 4.2272\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.9161 - val_loss: 4.1234\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.7689 - val_loss: 3.1827\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.0540 - val_loss: 3.6336\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4396 - val_loss: 4.7184\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.4273 - val_loss: 3.7146\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.8988 - val_loss: 3.2683\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.1250 - val_loss: 3.1311\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.6390 - val_loss: 3.4766\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2206 - val_loss: 3.3889\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.6474 - val_loss: 3.3171\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.8939 - val_loss: 3.1377\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2024 - val_loss: 3.1861\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.4358 - val_loss: 3.0594\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.2148 - val_loss: 3.3294\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1416 - val_loss: 4.1827\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.0890 - val_loss: 3.0483\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.0451 - val_loss: 3.0216\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.3522 - val_loss: 3.1447\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b4e4c310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 51 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 491142.9375 - val_loss: 99.1273\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 192069.9531 - val_loss: 98.6917\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 35537.7383 - val_loss: 98.5400\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 153859.6719 - val_loss: 101.4418\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 114582.7109 - val_loss: 96.7465\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 129143.9453 - val_loss: 94.6982\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 55917.8477 - val_loss: 98.8662\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 39478.3281 - val_loss: 98.9502\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41548.4883 - val_loss: 95.8964\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 151818.0156 - val_loss: 93.9805\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 120857.5938 - val_loss: 101.6755\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 125685.0781 - val_loss: 101.9354\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 131382.2969 - val_loss: 98.2951\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5458.4365 - val_loss: 99.2211\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 57178.6328 - val_loss: 98.0321\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13981.6777 - val_loss: 99.0431\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 64409.5391 - val_loss: 99.1094\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 34850.8438 - val_loss: 92.5326\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 261206.5781 - val_loss: 90.2773\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 239243.5469 - val_loss: 92.3272\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 143320.0781 - val_loss: 96.9916\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17347.0801 - val_loss: 98.8195\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22940.2539 - val_loss: 97.3776\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 66310.3984 - val_loss: 96.8363\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47992.6523 - val_loss: 100.1719\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 77063.7188 - val_loss: 100.1949\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 49977.4219 - val_loss: 99.1196\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23833.2402 - val_loss: 94.0884\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 210684.5625 - val_loss: 92.1992\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 208246.2188 - val_loss: 94.5557\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 110556.4375 - val_loss: 97.1908\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4298.2305 - val_loss: 98.4995\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1104.8695 - val_loss: 100.0813\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51945.3711 - val_loss: 99.2346\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9839.9590 - val_loss: 97.9207\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 74999.2969 - val_loss: 96.7777\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 55047.0000 - val_loss: 99.3431\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 74383.6484 - val_loss: 100.5609\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 35519.9180 - val_loss: 99.0531\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 49086.8828 - val_loss: 97.2811\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 54699.5430 - val_loss: 97.9310\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 919.7793 - val_loss: 99.8887\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 70725.4141 - val_loss: 100.8167\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 70512.5000 - val_loss: 100.1064\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 44842.3477 - val_loss: 97.2845\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 56413.7773 - val_loss: 97.2811\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 56410.1445 - val_loss: 98.5573\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1757.6656 - val_loss: 100.7171\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 103779.4922 - val_loss: 101.5045\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 96099.8594 - val_loss: 99.7127\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3c050c940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 52 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 155476.7188 - val_loss: 95.4033\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 106586.3984 - val_loss: 94.5292\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 55421.5078 - val_loss: 89.6215\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 110757.1172 - val_loss: 86.6868\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 89007.2109 - val_loss: 95.8594\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 112475.6953 - val_loss: 99.0122\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 100221.1016 - val_loss: 96.2281\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 583.1492 - val_loss: 95.4819\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13273.9922 - val_loss: 93.8726\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 45729.9570 - val_loss: 93.8184\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28675.9629 - val_loss: 98.7894\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 111450.3828 - val_loss: 99.9249\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 102969.8047 - val_loss: 98.1490\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39675.5977 - val_loss: 94.2068\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29644.6621 - val_loss: 94.3600\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 31047.6406 - val_loss: 96.2655\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9029.4932 - val_loss: 95.8530\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8960.0586 - val_loss: 96.5993\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12030.7207 - val_loss: 96.1299\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1116.0972 - val_loss: 97.8104\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44069.0273 - val_loss: 97.2543\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23147.0684 - val_loss: 94.8376\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 55134.8477 - val_loss: 94.7059\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35359.9219 - val_loss: 96.1251\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9145.9004 - val_loss: 96.7766\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2045.5706 - val_loss: 97.1174\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21854.6445 - val_loss: 97.6186\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 21802.8535 - val_loss: 97.1415\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23718.8496 - val_loss: 96.0279\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20252.5527 - val_loss: 97.5882\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 35282.1758 - val_loss: 98.0582\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23009.0059 - val_loss: 96.2649\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29154.7461 - val_loss: 96.2815\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18820.0801 - val_loss: 97.2428\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29014.2402 - val_loss: 98.1509\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5860.9600 - val_loss: 96.5810\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 40219.6914 - val_loss: 95.8800\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38816.7227 - val_loss: 96.6456\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3360.5254 - val_loss: 97.4245\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3544.1921 - val_loss: 97.8672\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9540.3232 - val_loss: 97.2498\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15590.6172 - val_loss: 97.5719\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2954.4026 - val_loss: 99.2998\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 58351.3008 - val_loss: 99.7349\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 42974.3281 - val_loss: 98.7361\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 481.3419 - val_loss: 96.9014\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 48384.0312 - val_loss: 96.0279\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 52068.4492 - val_loss: 97.0544\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22287.9395 - val_loss: 98.8763\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33450.0352 - val_loss: 99.3737\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3bd7d8280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 53 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 86.1709 - val_loss: 48.8139\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31.9966 - val_loss: 4.1662\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27.9183 - val_loss: 26.3921\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24.7080 - val_loss: 39.4532\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23.9134 - val_loss: 24.2945\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.4505 - val_loss: 8.9144\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19.0279 - val_loss: 16.3171\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.7214 - val_loss: 21.8171\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.4316 - val_loss: 10.1502\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.7543 - val_loss: 12.7722\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.3230 - val_loss: 12.9869\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.4486 - val_loss: 6.6316\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.8754 - val_loss: 7.8821\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.2233 - val_loss: 3.9219\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.9042 - val_loss: 3.5922\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.6673 - val_loss: 3.3050\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.4876 - val_loss: 4.2071\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.6731 - val_loss: 3.7690\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.8550 - val_loss: 4.0514\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.6483 - val_loss: 3.3569\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5131 - val_loss: 4.3895\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.3855 - val_loss: 3.8545\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.6001 - val_loss: 3.2571\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.0001 - val_loss: 3.5887\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.5393 - val_loss: 4.3573\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.6192 - val_loss: 3.9118\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.0882 - val_loss: 3.7369\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.8291 - val_loss: 3.7900\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.9373 - val_loss: 3.0030\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3926 - val_loss: 3.2126\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.2518 - val_loss: 3.0569\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.0962 - val_loss: 3.6531\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.9798 - val_loss: 2.8451\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.1838 - val_loss: 3.7381\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.3709 - val_loss: 5.1240\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.3817 - val_loss: 3.7605\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.7675 - val_loss: 4.8697\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.0807 - val_loss: 3.8681\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.8322 - val_loss: 4.5916\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.0527 - val_loss: 4.1493\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.5376 - val_loss: 2.6442\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.4531 - val_loss: 3.6741\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.7978 - val_loss: 3.4031\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.3063 - val_loss: 2.4756\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.6853 - val_loss: 2.5359\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5621 - val_loss: 2.9538\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.4900 - val_loss: 2.9910\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.3223 - val_loss: 2.6890\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5011 - val_loss: 3.4181\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.3228 - val_loss: 2.6989\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3cb128dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 54 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 187237.8750 - val_loss: 109.1385\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 104085.8672 - val_loss: 102.7532\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 43916.7891 - val_loss: 104.7133\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 19875.9160 - val_loss: 103.7104\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29178.8027 - val_loss: 104.1340\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 48668.8750 - val_loss: 104.1322\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15530.5967 - val_loss: 102.5937\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27784.1582 - val_loss: 102.8654\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18634.2012 - val_loss: 99.9630\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 105348.2109 - val_loss: 99.3758\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 57224.2305 - val_loss: 102.5048\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 63866.5664 - val_loss: 102.5241\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27292.2930 - val_loss: 101.3789\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11860.7998 - val_loss: 102.6337\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 58303.6133 - val_loss: 103.2107\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39177.8242 - val_loss: 101.2150\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 51780.0898 - val_loss: 101.1454\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42833.5312 - val_loss: 102.6781\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16950.1172 - val_loss: 101.6881\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15311.6826 - val_loss: 100.7982\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47400.8008 - val_loss: 101.1893\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10170.6455 - val_loss: 101.8489\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17328.1973 - val_loss: 100.8952\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 37354.4883 - val_loss: 101.0018\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3095.2859 - val_loss: 101.2055\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 20211.5859 - val_loss: 100.5370\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28564.2891 - val_loss: 100.4183\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14447.2109 - val_loss: 101.3645\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14013.5508 - val_loss: 101.2183\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7250.5625 - val_loss: 101.3464\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6020.1069 - val_loss: 100.4350\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 53308.4727 - val_loss: 100.4706\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28360.7363 - val_loss: 102.0087\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 35267.9297 - val_loss: 101.1941\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12526.1318 - val_loss: 101.8479\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 23628.2168 - val_loss: 101.1428\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 32309.5488 - val_loss: 101.2217\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20987.3613 - val_loss: 102.3109\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32625.7500 - val_loss: 101.5771\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15920.5127 - val_loss: 101.6429\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1411.0365 - val_loss: 103.1533\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 86194.8359 - val_loss: 103.1161\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 57708.6328 - val_loss: 101.7013\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19903.7246 - val_loss: 100.3335\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18642.3496 - val_loss: 101.1057\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19696.9531 - val_loss: 101.2415\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9439.7080 - val_loss: 100.2185\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51667.6367 - val_loss: 100.4400\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2969.9124 - val_loss: 100.5582\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23613.4922 - val_loss: 100.6397\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3cc167790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 55 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 139846.7500 - val_loss: 78.2510\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 113338.6953 - val_loss: 91.7692\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 92031.5625 - val_loss: 90.8858\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10432.8086 - val_loss: 87.9184\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1463.2531 - val_loss: 90.2281\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 73976.8906 - val_loss: 93.7051\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 68733.8125 - val_loss: 91.8505\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27535.7207 - val_loss: 86.8176\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 113084.0625 - val_loss: 85.5616\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 103301.4141 - val_loss: 89.9182\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32339.8789 - val_loss: 94.8552\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 81460.9844 - val_loss: 95.9963\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 67945.7578 - val_loss: 93.9001\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8476.4814 - val_loss: 93.6915\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19245.7617 - val_loss: 93.9706\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13593.8574 - val_loss: 94.0162\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 561.9572 - val_loss: 93.0358\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 22892.7051 - val_loss: 94.7679\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 22606.5469 - val_loss: 94.8125\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8551.3311 - val_loss: 91.8379\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 67805.2422 - val_loss: 91.9159\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 55734.9531 - val_loss: 93.2192\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34097.5938 - val_loss: 96.8408\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 81893.6484 - val_loss: 98.3973\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 62656.0781 - val_loss: 96.5678\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10096.7842 - val_loss: 95.7246\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16534.8945 - val_loss: 96.4958\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8359.4268 - val_loss: 93.6255\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 90612.4844 - val_loss: 92.5470\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 84037.6172 - val_loss: 95.3223\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13597.8145 - val_loss: 97.6148\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40274.4023 - val_loss: 98.4548\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 39374.9023 - val_loss: 97.2211\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 204.0964 - val_loss: 97.3797\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11339.1797 - val_loss: 96.4017\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19833.3398 - val_loss: 96.7066\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6937.4292 - val_loss: 99.3712\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 45882.3711 - val_loss: 99.5161\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 44681.2383 - val_loss: 98.4400\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3515.5579 - val_loss: 97.2732\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 38198.4570 - val_loss: 96.5118\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 35921.1289 - val_loss: 97.8083\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1015.4230 - val_loss: 97.6311\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8155.9258 - val_loss: 98.4380\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17441.5156 - val_loss: 98.1895\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2749.8496 - val_loss: 96.7383\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 51096.4062 - val_loss: 96.0849\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 46185.7812 - val_loss: 98.0433\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15515.1689 - val_loss: 98.6661\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12097.1240 - val_loss: 97.3675\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3bb021280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 56 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 179ms/step - loss: 211478.7344 - val_loss: 93.0645\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 68243.2656 - val_loss: 112.2615\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 277646.2500 - val_loss: 113.8570\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 208057.0156 - val_loss: 108.6815\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 106787.1406 - val_loss: 100.6879\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 66096.6484 - val_loss: 96.7091\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 49220.8008 - val_loss: 98.6615\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49506.6484 - val_loss: 99.8952\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21791.9707 - val_loss: 97.4049\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 58625.0938 - val_loss: 96.6877\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 54741.9805 - val_loss: 98.6916\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22447.1250 - val_loss: 99.3063\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4356.9033 - val_loss: 96.7598\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 80611.9766 - val_loss: 96.1015\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 75224.5547 - val_loss: 97.3325\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29804.3945 - val_loss: 99.5181\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 44975.3359 - val_loss: 100.5941\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 39546.3008 - val_loss: 100.0150\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12244.4453 - val_loss: 98.7561\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7809.9438 - val_loss: 100.6245\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 68961.8359 - val_loss: 101.3158\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 62397.8281 - val_loss: 99.2769\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23287.7637 - val_loss: 98.4740\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8820.7471 - val_loss: 99.9599\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22813.2402 - val_loss: 100.0740\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 26350.5684 - val_loss: 99.3980\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11907.4482 - val_loss: 98.9821\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15261.3535 - val_loss: 99.5124\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9234.8643 - val_loss: 97.6413\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 63678.6641 - val_loss: 97.0556\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 54112.2305 - val_loss: 97.6774\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10075.1523 - val_loss: 99.4631\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19533.1816 - val_loss: 100.6620\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 41927.2266 - val_loss: 100.3658\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23105.3926 - val_loss: 99.5801\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 418.2310 - val_loss: 97.7724\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 51739.0781 - val_loss: 97.3992\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55962.3633 - val_loss: 97.6685\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 47458.5508 - val_loss: 99.7935\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18186.0684 - val_loss: 100.2117\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22339.6152 - val_loss: 99.6921\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 2718.1626 - val_loss: 98.3324\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31176.1914 - val_loss: 98.3327\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31942.9902 - val_loss: 98.9441\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3165.3389 - val_loss: 100.0525\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15282.8896 - val_loss: 100.2449\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22478.9336 - val_loss: 99.9273\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4475.5054 - val_loss: 99.5499\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 769.8890 - val_loss: 99.3522\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5139.1753 - val_loss: 100.0884\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3bb1839d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 57 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 177ms/step - loss: 74.8060 - val_loss: 46.8076\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 34.3191 - val_loss: 12.9047\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27.3434 - val_loss: 33.8886\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25.8076 - val_loss: 31.3954\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19.9739 - val_loss: 13.0392\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19.0848 - val_loss: 19.0776\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15.5340 - val_loss: 15.6232\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.3226 - val_loss: 10.6501\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.8138 - val_loss: 4.6774\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.9412 - val_loss: 7.9442\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.2737 - val_loss: 4.9062\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.3433 - val_loss: 8.3459\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.4251 - val_loss: 4.5418\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.1520 - val_loss: 7.1090\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.2370 - val_loss: 6.2547\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.9886 - val_loss: 3.5998\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.1153 - val_loss: 4.0789\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.9997 - val_loss: 6.5056\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.9926 - val_loss: 4.0637\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.4638 - val_loss: 3.3840\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 6.4545 - val_loss: 5.0860\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 6.1517 - val_loss: 3.5525\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.1102 - val_loss: 4.8343\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.9450 - val_loss: 3.1864\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.6189 - val_loss: 4.3878\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.0890 - val_loss: 4.6711\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.1622 - val_loss: 3.6456\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.2324 - val_loss: 3.4085\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.7163 - val_loss: 6.3998\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.3876 - val_loss: 4.0162\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.1988 - val_loss: 5.6464\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.2584 - val_loss: 3.9263\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.3736 - val_loss: 5.1214\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.5634 - val_loss: 7.1426\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.7926 - val_loss: 3.7404\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.7426 - val_loss: 3.8897\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.0081 - val_loss: 4.0493\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.2599 - val_loss: 3.1980\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.8411 - val_loss: 3.1011\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.9449 - val_loss: 5.1179\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.2570 - val_loss: 4.3103\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.9207 - val_loss: 3.1468\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.7048 - val_loss: 3.2196\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.0388 - val_loss: 4.4480\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.7800 - val_loss: 4.6246\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.8355 - val_loss: 3.9105\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.9999 - val_loss: 6.2808\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.2511 - val_loss: 3.0262\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5276 - val_loss: 3.8566\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.1078 - val_loss: 6.2538\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d595dee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 58 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 6379234.0000 - val_loss: 98.6049\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3276899.2500 - val_loss: 98.5570\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1774590.1250 - val_loss: 98.4583\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1342109.2500 - val_loss: 98.3900\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 512738.4062 - val_loss: 98.2798\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 568423.2500 - val_loss: 98.1703\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1006520.6250 - val_loss: 97.9764\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1370593.7500 - val_loss: 97.8989\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1400571.6250 - val_loss: 97.7352\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 688592.8125 - val_loss: 97.6143\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1073028.3750 - val_loss: 97.4958\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1510635.7500 - val_loss: 97.4036\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 564301.8125 - val_loss: 97.2691\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 648640.4375 - val_loss: 97.1088\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 830318.3750 - val_loss: 97.0156\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 232315.0469 - val_loss: 96.8887\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 234515.4531 - val_loss: 96.7526\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 245334.9688 - val_loss: 96.6537\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 213248.8281 - val_loss: 96.4969\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 198361.1719 - val_loss: 96.3670\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 254059.4531 - val_loss: 96.2613\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 214116.4844 - val_loss: 96.1746\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 231990.3438 - val_loss: 96.0639\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 249727.1562 - val_loss: 95.9604\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 192980.8594 - val_loss: 95.8741\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 218302.8125 - val_loss: 95.7913\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 218742.5938 - val_loss: 95.7044\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 183664.3750 - val_loss: 95.6241\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 246915.9688 - val_loss: 95.5235\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 186390.4688 - val_loss: 95.4376\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 243979.5312 - val_loss: 95.3734\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 218151.1250 - val_loss: 95.2884\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 193470.4219 - val_loss: 95.2053\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 230998.8906 - val_loss: 95.1405\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 194073.3281 - val_loss: 95.0572\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 181136.0469 - val_loss: 94.9635\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 208772.8281 - val_loss: 94.8922\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 181137.3438 - val_loss: 94.8112\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 464885.5312 - val_loss: 94.7546\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 764095.3750 - val_loss: 94.7200\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 970073.8750 - val_loss: 94.7651\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 674559.2500 - val_loss: 94.7870\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 408381.6875 - val_loss: 94.7912\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 830359.3750 - val_loss: 94.8565\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1156346.6250 - val_loss: 94.8927\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 395465.9062 - val_loss: 94.9422\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 291250.1250 - val_loss: 94.9685\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 351246.6250 - val_loss: 94.9660\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 302229.9062 - val_loss: 94.9621\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 307535.0938 - val_loss: 94.9629\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4212ddb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 59 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 82.2906 - val_loss: 45.9944\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 44.0593 - val_loss: 18.3277\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32.3143 - val_loss: 41.1147\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 31.9905 - val_loss: 37.5979\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26.0611 - val_loss: 16.9044\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24.1561 - val_loss: 20.3762\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19.0297 - val_loss: 20.2818\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.1568 - val_loss: 6.8064\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.2207 - val_loss: 7.4630\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.0526 - val_loss: 5.3932\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.7413 - val_loss: 6.9236\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.5974 - val_loss: 6.6860\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.3120 - val_loss: 8.3039\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.7914 - val_loss: 6.2680\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7805 - val_loss: 5.2068\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.2837 - val_loss: 6.4675\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.7850 - val_loss: 5.5717\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 9.7236 - val_loss: 5.5816\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.5441 - val_loss: 5.2628\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.1514 - val_loss: 5.4200\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.0222 - val_loss: 7.4222\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.6392 - val_loss: 7.7713\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.8445 - val_loss: 3.4845\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.2561 - val_loss: 8.1114\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1333 - val_loss: 6.9340\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.7533 - val_loss: 2.9543\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.6872 - val_loss: 5.1427\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.9568 - val_loss: 11.5351\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3661 - val_loss: 3.9301\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.3974 - val_loss: 3.1837\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.4557 - val_loss: 6.5344\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.1666 - val_loss: 7.2216\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.0112 - val_loss: 5.3083\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.9600 - val_loss: 2.6060\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.1609 - val_loss: 7.2023\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.3561 - val_loss: 4.4185\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.2166 - val_loss: 3.0211\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.4631 - val_loss: 5.7057\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.1534 - val_loss: 6.3790\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.3647 - val_loss: 4.5974\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.7218 - val_loss: 2.7089\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.4412 - val_loss: 1.9190\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.3214 - val_loss: 2.3970\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.4955 - val_loss: 4.0416\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.4823 - val_loss: 5.7382\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 6.1449 - val_loss: 3.2926\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.3852 - val_loss: 1.9623\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.9990 - val_loss: 5.6250\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.2001 - val_loss: 3.0828\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.2133 - val_loss: 4.8650\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3c050c280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 60 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 178ms/step - loss: 55.6807 - val_loss: 34.2525\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 39.4772 - val_loss: 30.0480\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 32.4373 - val_loss: 36.3621\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 28.6791 - val_loss: 33.1719\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 24.0142 - val_loss: 21.2857\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.5291 - val_loss: 10.6811\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.6528 - val_loss: 3.8981\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.6273 - val_loss: 9.6881\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.7440 - val_loss: 7.1856\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.4259 - val_loss: 9.4084\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.7691 - val_loss: 5.8002\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.1644 - val_loss: 6.6581\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.0757 - val_loss: 3.5844\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.8843 - val_loss: 6.4154\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.1639 - val_loss: 3.8162\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.4126 - val_loss: 3.9610\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.5659 - val_loss: 5.0076\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.3858 - val_loss: 4.2141\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.9855 - val_loss: 3.9727\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.5493 - val_loss: 4.9835\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.6911 - val_loss: 4.9851\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.5628 - val_loss: 4.6200\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.4045 - val_loss: 4.2792\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8307 - val_loss: 5.1394\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.2708 - val_loss: 6.1778\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.7435 - val_loss: 6.9683\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.5689 - val_loss: 7.3579\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.9973 - val_loss: 5.3889\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 10.3097 - val_loss: 4.2204\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.3881 - val_loss: 5.0427\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.7353 - val_loss: 4.1945\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.0736 - val_loss: 4.1275\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.8801 - val_loss: 4.0849\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.7953 - val_loss: 4.1341\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.8914 - val_loss: 5.7803\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.3501 - val_loss: 5.0490\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.7554 - val_loss: 5.3000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.0556 - val_loss: 4.0162\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.3648 - val_loss: 4.0492\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.9108 - val_loss: 3.8905\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.2128 - val_loss: 3.9755\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.2563 - val_loss: 3.9313\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.3842 - val_loss: 3.7295\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.8206 - val_loss: 4.2239\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.8714 - val_loss: 3.8790\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.5812 - val_loss: 3.8502\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.7696 - val_loss: 3.6993\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.6217 - val_loss: 3.5971\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.7640 - val_loss: 5.2241\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.9031 - val_loss: 4.3999\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3c1951040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 61 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 135214.4375 - val_loss: 110.6851\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 227353.9688 - val_loss: 114.7382\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 160130.9688 - val_loss: 106.1909\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3743.6377 - val_loss: 97.2982\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 178726.7969 - val_loss: 95.0676\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 152862.3125 - val_loss: 97.2988\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 114273.9062 - val_loss: 103.1488\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 37662.6016 - val_loss: 104.3286\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29602.1289 - val_loss: 101.5905\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 55115.6133 - val_loss: 101.0394\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 33320.4375 - val_loss: 103.0459\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29952.7891 - val_loss: 103.6234\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19756.9629 - val_loss: 102.5481\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 36130.6992 - val_loss: 101.5276\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15182.8408 - val_loss: 103.6047\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 38723.0352 - val_loss: 103.9988\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 38948.4766 - val_loss: 102.6693\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12248.6592 - val_loss: 102.3224\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5104.9937 - val_loss: 101.9375\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16691.4004 - val_loss: 102.4230\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8674.7900 - val_loss: 101.9782\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 18609.1504 - val_loss: 102.1657\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4256.3921 - val_loss: 101.8069\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12556.5234 - val_loss: 102.5301\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10529.4854 - val_loss: 101.7467\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12847.1123 - val_loss: 102.4686\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 15196.9707 - val_loss: 102.2280\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18934.4688 - val_loss: 101.7623\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10487.3643 - val_loss: 104.2752\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 57789.1367 - val_loss: 104.2881\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 60095.2773 - val_loss: 102.8838\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 24962.4434 - val_loss: 100.7653\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 30374.5664 - val_loss: 100.7821\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 27141.7734 - val_loss: 101.3542\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11090.1035 - val_loss: 103.5328\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 49945.8164 - val_loss: 103.5475\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 52599.5117 - val_loss: 102.5313\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 21439.8105 - val_loss: 100.7875\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28100.2363 - val_loss: 100.5109\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 25341.3008 - val_loss: 101.0207\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6235.7607 - val_loss: 101.3912\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3766.0889 - val_loss: 101.7318\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 11116.4531 - val_loss: 101.2236\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2658.6499 - val_loss: 101.9728\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 29813.6094 - val_loss: 102.0680\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 15394.8555 - val_loss: 100.1751\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 38770.0742 - val_loss: 99.7449\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 41364.8086 - val_loss: 100.4748\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 14455.3965 - val_loss: 101.8681\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 29242.3086 - val_loss: 102.0026\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff411c9ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 62 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 75.8557 - val_loss: 40.2047\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 33.2258 - val_loss: 7.4372\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 28.7731 - val_loss: 31.9950\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25.6574 - val_loss: 29.4939\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21.0842 - val_loss: 16.2716\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 19.7662 - val_loss: 23.6072\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.5134 - val_loss: 16.6661\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16.1281 - val_loss: 16.4786\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.0714 - val_loss: 15.7696\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.3402 - val_loss: 11.6839\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 12.3929 - val_loss: 6.9465\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.8386 - val_loss: 7.5551\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.0238 - val_loss: 5.1859\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 10.0590 - val_loss: 4.9970\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.5200 - val_loss: 4.8390\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.5597 - val_loss: 3.9160\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.3983 - val_loss: 3.9883\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.3427 - val_loss: 4.5235\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.4349 - val_loss: 5.5480\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.3382 - val_loss: 9.3878\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.9077 - val_loss: 4.4024\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.7483 - val_loss: 3.9925\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.7253 - val_loss: 4.1152\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.9431 - val_loss: 4.9948\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1786 - val_loss: 4.6076\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.8003 - val_loss: 3.3928\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.8187 - val_loss: 3.8885\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.3186 - val_loss: 3.5870\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.7598 - val_loss: 6.2137\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.1262 - val_loss: 5.7373\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.9705 - val_loss: 6.1045\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.5913 - val_loss: 5.2657\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.0786 - val_loss: 4.0993\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.9772 - val_loss: 2.9179\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.7885 - val_loss: 3.0312\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.6559 - val_loss: 4.9727\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.1649 - val_loss: 2.8630\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.6922 - val_loss: 3.1831\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.4874 - val_loss: 3.3959\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.4367 - val_loss: 2.6734\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.3216 - val_loss: 2.6479\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.5776 - val_loss: 2.7069\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.3066 - val_loss: 3.5887\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 5.0351 - val_loss: 2.5493\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.9153 - val_loss: 2.5543\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.8461 - val_loss: 2.5324\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.0345 - val_loss: 2.5512\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.6810 - val_loss: 2.5294\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.7276 - val_loss: 2.6215\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.7034 - val_loss: 2.7321\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ccf3a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 63 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 7753171.5000 - val_loss: 99.7516\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4668028.5000 - val_loss: 98.3460\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3041313.7500 - val_loss: 97.8964\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3304690.0000 - val_loss: 97.5387\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2867477.5000 - val_loss: 97.4616\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 2766456.7500 - val_loss: 97.0627\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4369148.0000 - val_loss: 97.2051\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2128860.0000 - val_loss: 97.3902\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1527641.8750 - val_loss: 97.2701\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1262094.2500 - val_loss: 97.0943\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1269508.2500 - val_loss: 96.9915\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1102067.1250 - val_loss: 97.0212\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1212899.5000 - val_loss: 96.9443\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1023907.3750 - val_loss: 97.0117\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 378509.9062 - val_loss: 96.9765\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 513473.2500 - val_loss: 96.9278\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 448294.6250 - val_loss: 96.8585\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 392378.0625 - val_loss: 96.7827\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 441519.4688 - val_loss: 96.7023\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 513583.4688 - val_loss: 96.6364\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 422090.9375 - val_loss: 96.5720\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 451970.5312 - val_loss: 96.4921\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 445854.4062 - val_loss: 96.4210\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 475569.6250 - val_loss: 96.3659\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 501635.2500 - val_loss: 96.3046\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 129101.9375 - val_loss: 96.2346\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 118808.9062 - val_loss: 96.1637\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 118264.3281 - val_loss: 96.0938\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 369550.9375 - val_loss: 96.0148\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 444352.0000 - val_loss: 95.9708\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 487548.0625 - val_loss: 95.9273\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 125206.0000 - val_loss: 95.8760\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 526198.0000 - val_loss: 95.7950\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 362548.0312 - val_loss: 95.7437\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 362567.0938 - val_loss: 95.7030\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 274638.3438 - val_loss: 95.6538\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 485339.4062 - val_loss: 95.6089\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1009994.9375 - val_loss: 95.5521\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1385091.0000 - val_loss: 95.5729\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 515348.8438 - val_loss: 95.5739\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 651460.1875 - val_loss: 95.5879\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 624779.7500 - val_loss: 95.5634\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 694897.1250 - val_loss: 95.5570\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 469322.7500 - val_loss: 95.5682\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 709528.0000 - val_loss: 95.5361\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 638466.7500 - val_loss: 95.5365\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 423308.7812 - val_loss: 95.5179\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 737437.1250 - val_loss: 95.4852\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 265207.0938 - val_loss: 95.4683\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 169201.7969 - val_loss: 95.4471\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d82cc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 64 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 187ms/step - loss: 110553.7344 - val_loss: 90.5762\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 93772.6641 - val_loss: 87.5308\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 27618.8652 - val_loss: 92.1901\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47821.2109 - val_loss: 95.6989\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 54657.6328 - val_loss: 95.5575\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9524.9941 - val_loss: 94.9001\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12227.9570 - val_loss: 94.9923\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4082.1501 - val_loss: 95.7301\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 41632.0312 - val_loss: 95.9883\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 25113.5391 - val_loss: 94.3449\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 36160.0234 - val_loss: 94.3811\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 25561.8945 - val_loss: 95.6218\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7057.5791 - val_loss: 95.2767\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3617.1287 - val_loss: 96.2541\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 38712.7266 - val_loss: 96.1199\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19670.3555 - val_loss: 94.5764\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 24775.9453 - val_loss: 94.8781\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15977.3154 - val_loss: 95.7703\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 37212.2930 - val_loss: 96.6159\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12082.2656 - val_loss: 94.8859\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 37345.9453 - val_loss: 94.9020\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 34058.9844 - val_loss: 96.8160\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28485.1191 - val_loss: 96.6767\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 8380.8047 - val_loss: 96.4040\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 26368.2070 - val_loss: 96.9502\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13838.2998 - val_loss: 95.8993\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30124.6875 - val_loss: 95.6724\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21309.6875 - val_loss: 96.4049\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15349.4834 - val_loss: 96.6299\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9224.3613 - val_loss: 95.7988\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 32970.3750 - val_loss: 96.0007\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23856.4766 - val_loss: 97.0529\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12977.5098 - val_loss: 96.9059\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2097.1682 - val_loss: 96.4657\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 35057.8281 - val_loss: 96.0598\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 29798.9961 - val_loss: 97.3996\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 24405.4805 - val_loss: 97.5980\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20957.5898 - val_loss: 97.1555\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3405.5208 - val_loss: 97.2595\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6259.4395 - val_loss: 96.9790\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22450.9648 - val_loss: 96.8139\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10891.7529 - val_loss: 98.0203\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 41822.7812 - val_loss: 98.4082\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 39173.4219 - val_loss: 98.0913\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15597.2021 - val_loss: 96.9607\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 32662.8594 - val_loss: 96.6984\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27093.3438 - val_loss: 97.2240\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 150.4247 - val_loss: 98.0839\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38351.5898 - val_loss: 98.5526\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34325.8828 - val_loss: 98.0696\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3da017c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 65 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 61.7471 - val_loss: 21.1481\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35.0729 - val_loss: 24.1259\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 26.8125 - val_loss: 33.5227\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24.0303 - val_loss: 16.5557\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23.4237 - val_loss: 15.2710\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 19.7331 - val_loss: 19.1881\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.8460 - val_loss: 5.7829\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.7047 - val_loss: 12.7516\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.8890 - val_loss: 4.5929\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.4736 - val_loss: 8.9130\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.9642 - val_loss: 3.8780\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.6741 - val_loss: 9.0538\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.4064 - val_loss: 3.8856\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.7753 - val_loss: 5.0970\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.1485 - val_loss: 6.4248\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.1892 - val_loss: 4.0544\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.2425 - val_loss: 2.9089\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.3746 - val_loss: 5.9104\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.3478 - val_loss: 2.5756\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.6367 - val_loss: 5.3750\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4711 - val_loss: 2.5465\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.5210 - val_loss: 4.3977\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.1504 - val_loss: 4.4902\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.0988 - val_loss: 2.3792\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.3539 - val_loss: 6.3269\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.3280 - val_loss: 2.6576\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.5398 - val_loss: 2.7082\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.1561 - val_loss: 3.4831\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.4199 - val_loss: 2.3395\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.6425 - val_loss: 7.1810\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7.0684 - val_loss: 2.3354\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0162 - val_loss: 4.8417\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.4974 - val_loss: 2.4568\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.7355 - val_loss: 2.2153\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.8064 - val_loss: 5.0157\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.2356 - val_loss: 2.5564\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.1736 - val_loss: 5.0884\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.7359 - val_loss: 2.5321\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.9073 - val_loss: 3.2902\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.0338 - val_loss: 3.0954\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.6120 - val_loss: 3.2442\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.2370 - val_loss: 3.9784\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.1294 - val_loss: 3.1479\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2464 - val_loss: 3.1884\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.8791 - val_loss: 3.7731\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.8539 - val_loss: 2.7840\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.2243 - val_loss: 3.4041\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.9493 - val_loss: 4.1314\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.1123 - val_loss: 3.2125\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.5326 - val_loss: 4.1299\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a6d5ef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 66 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 79.9954 - val_loss: 55.7708\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 37.2489 - val_loss: 18.8905\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 31.7734 - val_loss: 36.7737\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 27.5845 - val_loss: 39.9025\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.5502 - val_loss: 20.2025\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.4533 - val_loss: 20.1664\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.6775 - val_loss: 12.2039\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.5047 - val_loss: 10.3027\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.3284 - val_loss: 11.6600\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.4431 - val_loss: 7.2825\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.8945 - val_loss: 10.7867\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.3774 - val_loss: 10.0532\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.0382 - val_loss: 4.9293\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.1579 - val_loss: 6.3754\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.6315 - val_loss: 7.4443\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.3129 - val_loss: 5.5856\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.3997 - val_loss: 6.0657\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.3671 - val_loss: 7.1179\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.9958 - val_loss: 6.4714\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6875 - val_loss: 5.7751\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.9396 - val_loss: 4.9654\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.5840 - val_loss: 6.7378\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.3763 - val_loss: 7.2944\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.6625 - val_loss: 4.0204\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.2717 - val_loss: 6.7467\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8728 - val_loss: 5.1300\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5699 - val_loss: 4.8919\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.6918 - val_loss: 4.8750\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.7900 - val_loss: 7.3628\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.7697 - val_loss: 2.9764\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.1403 - val_loss: 4.0614\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.7664 - val_loss: 3.3071\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.6564 - val_loss: 4.5511\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.8656 - val_loss: 2.8554\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7861 - val_loss: 2.4528\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.9712 - val_loss: 6.3263\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.1963 - val_loss: 3.8297\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.1427 - val_loss: 2.0424\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.8650 - val_loss: 5.9725\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.3534 - val_loss: 2.1356\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.7444 - val_loss: 2.6453\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.5045 - val_loss: 4.7421\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.9186 - val_loss: 2.0747\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.6280 - val_loss: 1.9944\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.8275 - val_loss: 2.0595\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.8897 - val_loss: 2.9496\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.7469 - val_loss: 2.0408\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.3817 - val_loss: 2.2247\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.3750 - val_loss: 3.1017\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.6462 - val_loss: 2.8899\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a8aaa9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 67 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 73.8904 - val_loss: 43.4920\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 28.9688 - val_loss: 8.5273\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25.3939 - val_loss: 24.3728\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.7621 - val_loss: 24.7391\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.8015 - val_loss: 12.3755\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.6765 - val_loss: 17.2241\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.5466 - val_loss: 10.8825\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.2930 - val_loss: 9.5304\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.0569 - val_loss: 6.3385\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7943 - val_loss: 6.9901\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.6029 - val_loss: 6.7287\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.1339 - val_loss: 6.3626\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.7444 - val_loss: 6.3554\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.9857 - val_loss: 7.2959\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3871 - val_loss: 7.1793\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.1519 - val_loss: 6.4654\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.0948 - val_loss: 6.2127\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.6829 - val_loss: 6.8198\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.2975 - val_loss: 6.8550\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.8643 - val_loss: 6.7536\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.8385 - val_loss: 6.4149\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.6182 - val_loss: 6.2001\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.5456 - val_loss: 6.4769\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3843 - val_loss: 6.3676\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.3073 - val_loss: 6.5994\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6213 - val_loss: 6.5900\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.3121 - val_loss: 6.0230\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.1441 - val_loss: 6.2731\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2159 - val_loss: 6.2341\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.0436 - val_loss: 6.1605\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2407 - val_loss: 6.1532\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.3745 - val_loss: 6.0271\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.8213 - val_loss: 5.9781\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.7141 - val_loss: 5.8224\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.6194 - val_loss: 5.9586\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.1912 - val_loss: 5.7479\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3265 - val_loss: 5.9384\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.9785 - val_loss: 6.2527\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.6325 - val_loss: 7.0633\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.7248 - val_loss: 5.3916\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.7623 - val_loss: 6.4679\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3152 - val_loss: 5.3530\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.5746 - val_loss: 5.2643\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.8547 - val_loss: 5.6765\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.9086 - val_loss: 5.7560\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.3343 - val_loss: 5.4115\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.4853 - val_loss: 5.7894\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.4193 - val_loss: 6.1731\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.5366 - val_loss: 5.2214\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.9054 - val_loss: 5.4926\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ca3325e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 68 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 77.2199 - val_loss: 37.6568\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33.4707 - val_loss: 4.6015\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 27.7880 - val_loss: 25.0228\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21.6263 - val_loss: 32.1506\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20.2451 - val_loss: 19.7551\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.5203 - val_loss: 8.0002\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.2896 - val_loss: 18.1475\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.8102 - val_loss: 10.4890\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.2887 - val_loss: 7.3297\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.1196 - val_loss: 4.3343\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.2922 - val_loss: 3.7819\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.1365 - val_loss: 4.1476\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.3268 - val_loss: 3.6212\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.7598 - val_loss: 3.6043\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.9583 - val_loss: 5.0838\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.1886 - val_loss: 4.4354\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.7741 - val_loss: 4.1765\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.9388 - val_loss: 4.5679\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.1660 - val_loss: 6.6190\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.3612 - val_loss: 4.6051\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.9274 - val_loss: 3.4147\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.2573 - val_loss: 3.6332\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.8827 - val_loss: 3.5934\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.7352 - val_loss: 3.9321\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.7505 - val_loss: 3.9329\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.6866 - val_loss: 5.4802\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.7916 - val_loss: 3.7451\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.8969 - val_loss: 3.9957\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1227 - val_loss: 3.6170\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.6222 - val_loss: 4.9231\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.5448 - val_loss: 4.1347\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.4787 - val_loss: 3.7428\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.5318 - val_loss: 3.5542\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.3296 - val_loss: 3.6882\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.2511 - val_loss: 4.6483\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.6376 - val_loss: 3.8586\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.2964 - val_loss: 3.6802\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.2808 - val_loss: 4.2837\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.5323 - val_loss: 5.4502\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.8993 - val_loss: 3.5709\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.3943 - val_loss: 4.3144\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.0883 - val_loss: 4.8543\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.6751 - val_loss: 3.9471\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.4414 - val_loss: 3.8703\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.1315 - val_loss: 4.3376\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.4346 - val_loss: 4.0539\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1810 - val_loss: 3.8324\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.7810 - val_loss: 3.8830\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.3327 - val_loss: 4.9680\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.4385 - val_loss: 3.3759\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ccf3adc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 69 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 65.7297 - val_loss: 30.4320\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27.3524 - val_loss: 5.7659\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 21.9996 - val_loss: 29.3794\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22.4407 - val_loss: 27.9848\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.1579 - val_loss: 11.1698\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.5438 - val_loss: 11.9783\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.1245 - val_loss: 15.9150\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.3956 - val_loss: 13.0755\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.8307 - val_loss: 12.2975\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.9101 - val_loss: 4.3583\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.5264 - val_loss: 5.2498\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.1726 - val_loss: 5.5097\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.8941 - val_loss: 5.1178\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.1992 - val_loss: 4.3960\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.3540 - val_loss: 5.6653\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.6258 - val_loss: 4.7584\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.6378 - val_loss: 5.0070\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.8171 - val_loss: 4.6249\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.6773 - val_loss: 5.4287\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.9528 - val_loss: 6.8566\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.4773 - val_loss: 5.6403\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.9105 - val_loss: 4.7893\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.2781 - val_loss: 4.6058\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.1132 - val_loss: 4.6681\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.1129 - val_loss: 4.9066\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.0273 - val_loss: 4.7363\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.8549 - val_loss: 5.4883\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.1219 - val_loss: 5.0084\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.8460 - val_loss: 4.6599\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.9012 - val_loss: 5.1640\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.5684 - val_loss: 6.8313\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.6009 - val_loss: 5.1410\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.2727 - val_loss: 4.9357\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.1899 - val_loss: 6.7903\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.3920 - val_loss: 4.8274\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.7670 - val_loss: 4.4462\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.4771 - val_loss: 4.6862\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.4762 - val_loss: 5.0105\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.2210 - val_loss: 4.9775\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.4340 - val_loss: 5.7579\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.7478 - val_loss: 5.2026\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.7274 - val_loss: 4.5992\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.5742 - val_loss: 4.5069\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.6439 - val_loss: 4.9210\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.5048 - val_loss: 5.2074\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3.9322 - val_loss: 4.6792\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.8251 - val_loss: 5.1968\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.4544 - val_loss: 4.5075\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.8466 - val_loss: 4.3541\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.6972 - val_loss: 4.7761\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b90a2ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 70 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 332085.0000 - val_loss: 92.0946\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 299310.0938 - val_loss: 99.3223\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 74704.9766 - val_loss: 101.6283\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 303800.4375 - val_loss: 103.8834\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 152133.3750 - val_loss: 95.0386\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 488374.0000 - val_loss: 93.1643\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 395157.5312 - val_loss: 97.6801\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 86594.5625 - val_loss: 100.5678\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41042.1328 - val_loss: 98.1673\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 141024.9531 - val_loss: 100.6344\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32821.4414 - val_loss: 99.1738\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 51245.8477 - val_loss: 100.8965\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 48939.7266 - val_loss: 100.3304\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 73504.4062 - val_loss: 98.0100\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 109534.4375 - val_loss: 100.7815\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 172460.7969 - val_loss: 101.5737\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 29861.5430 - val_loss: 99.3501\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32833.7109 - val_loss: 99.8093\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3854.4641 - val_loss: 98.7209\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 56480.0273 - val_loss: 99.9961\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 61928.7891 - val_loss: 99.7268\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11500.4189 - val_loss: 101.4230\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 121364.9766 - val_loss: 100.3141\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 45932.3867 - val_loss: 98.1445\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 73102.6328 - val_loss: 100.0452\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 143927.6875 - val_loss: 100.5728\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9619.0146 - val_loss: 97.4449\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 236256.7656 - val_loss: 95.7638\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 233004.8750 - val_loss: 99.6262\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19226.1621 - val_loss: 99.5455\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3339.7808 - val_loss: 99.4677\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17179.0664 - val_loss: 100.5791\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 120406.0625 - val_loss: 101.6465\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 61403.0938 - val_loss: 99.5695\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 115230.0000 - val_loss: 97.9356\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 87910.2656 - val_loss: 99.9804\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 21229.7031 - val_loss: 100.4093\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 28754.8125 - val_loss: 99.9033\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 34251.9062 - val_loss: 101.0526\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 50996.6445 - val_loss: 99.7560\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 40012.1797 - val_loss: 99.3947\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26548.4082 - val_loss: 100.2145\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 26160.4941 - val_loss: 99.1471\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33637.2695 - val_loss: 100.2499\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 61433.9023 - val_loss: 100.0181\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47870.5781 - val_loss: 98.4983\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 54661.5312 - val_loss: 100.7224\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 168262.0469 - val_loss: 101.2378\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 107509.4688 - val_loss: 98.4167\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 192830.5625 - val_loss: 96.9638\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3aba7e040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 71 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 27275.3730 - val_loss: 142.1891\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 541988.0625 - val_loss: 146.6558\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 339931.7188 - val_loss: 127.7801\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 194166.8906 - val_loss: 105.1648\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 123540.1172 - val_loss: 94.6173\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 71964.9922 - val_loss: 101.3250\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 2703.0012 - val_loss: 102.7991\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4469.5566 - val_loss: 100.6797\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 52019.7578 - val_loss: 97.4718\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50571.8008 - val_loss: 99.8029\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 415.4670 - val_loss: 100.5515\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12890.8408 - val_loss: 104.2420\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 30706.8262 - val_loss: 101.4187\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17864.0254 - val_loss: 101.3088\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 45187.8828 - val_loss: 104.5959\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7416.9497 - val_loss: 100.1753\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35508.0742 - val_loss: 96.9015\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 64857.2617 - val_loss: 97.1411\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5412.3643 - val_loss: 103.0554\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 19081.4531 - val_loss: 106.4495\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 78680.8672 - val_loss: 107.0930\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 29675.7168 - val_loss: 101.9819\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11997.8828 - val_loss: 98.3902\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 37987.3945 - val_loss: 100.1555\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4239.3203 - val_loss: 104.3193\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 45932.8477 - val_loss: 104.8447\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38807.6328 - val_loss: 103.3215\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11455.6748 - val_loss: 100.3828\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8945.0645 - val_loss: 103.6819\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 42621.9688 - val_loss: 103.7987\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 21606.6621 - val_loss: 100.9632\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12570.4092 - val_loss: 100.3711\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9082.0586 - val_loss: 104.1252\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 52082.5039 - val_loss: 104.6943\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 33217.3633 - val_loss: 100.8007\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 37376.8047 - val_loss: 98.4495\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14372.8047 - val_loss: 102.1017\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33817.2617 - val_loss: 103.8104\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 31562.9707 - val_loss: 102.1310\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5315.0386 - val_loss: 96.6353\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 71368.5391 - val_loss: 95.0508\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 69244.9922 - val_loss: 98.4264\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18521.7617 - val_loss: 102.4351\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 44498.8047 - val_loss: 104.3894\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 41181.6406 - val_loss: 100.8525\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20434.1133 - val_loss: 99.7387\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6268.1758 - val_loss: 104.4944\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 75683.8125 - val_loss: 106.8019\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 54961.1328 - val_loss: 104.2694\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41193.2617 - val_loss: 97.2470\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4142aef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 72 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 436413.6562 - val_loss: 102.8776\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 131259.7188 - val_loss: 104.3495\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 147608.8281 - val_loss: 101.8471\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 129407.9453 - val_loss: 102.9762\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 155264.8906 - val_loss: 100.1396\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 183348.7188 - val_loss: 102.8518\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 284568.0000 - val_loss: 102.7133\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 163153.3125 - val_loss: 99.9191\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 83445.6719 - val_loss: 101.4760\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 83237.4062 - val_loss: 99.7527\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 377276.6250 - val_loss: 98.3815\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 151292.0625 - val_loss: 100.7898\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 247079.5000 - val_loss: 103.5922\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 277478.1250 - val_loss: 100.5383\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 50350.0430 - val_loss: 100.3399\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16581.1504 - val_loss: 99.9602\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 84581.6719 - val_loss: 100.0751\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24755.0547 - val_loss: 100.4196\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20030.8203 - val_loss: 99.9345\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21460.5156 - val_loss: 100.2157\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19924.5664 - val_loss: 100.1074\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22776.6523 - val_loss: 99.3631\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 123114.5391 - val_loss: 99.6136\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 80889.3984 - val_loss: 101.3063\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 78818.4219 - val_loss: 100.2882\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30107.3711 - val_loss: 100.8754\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37132.6055 - val_loss: 100.4732\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36254.6797 - val_loss: 100.1964\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10406.5996 - val_loss: 100.6266\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 52282.0508 - val_loss: 99.8432\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 132493.8125 - val_loss: 99.8355\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7303.3628 - val_loss: 100.5556\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 68321.7422 - val_loss: 99.7524\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 87749.2500 - val_loss: 99.6843\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25301.3164 - val_loss: 99.8114\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 108600.9297 - val_loss: 99.4247\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9302.3740 - val_loss: 99.1761\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 127377.3438 - val_loss: 99.5315\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 65150.4023 - val_loss: 101.1993\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 200256.4062 - val_loss: 100.8509\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32550.8516 - val_loss: 99.4787\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 75843.9219 - val_loss: 100.5315\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 56239.0859 - val_loss: 100.1958\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 40423.2656 - val_loss: 100.9604\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 67262.8984 - val_loss: 100.3720\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4857.6123 - val_loss: 100.7896\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 65852.2734 - val_loss: 100.4492\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 62657.9883 - val_loss: 100.1164\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 3196.1858 - val_loss: 100.9049\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 85374.6719 - val_loss: 100.3364\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3da0bb5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 73 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 145352.7188 - val_loss: 86.6077\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 63633.5469 - val_loss: 105.9410\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 325966.9062 - val_loss: 109.1822\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 271901.5312 - val_loss: 108.1308\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 193901.2344 - val_loss: 104.0801\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36416.9453 - val_loss: 99.5016\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 158879.0938 - val_loss: 98.1889\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 135986.7812 - val_loss: 99.3026\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 64825.5586 - val_loss: 101.5607\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26355.3379 - val_loss: 102.1799\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 35371.5977 - val_loss: 101.5773\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10875.4453 - val_loss: 101.8080\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17599.9512 - val_loss: 101.6915\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19909.7148 - val_loss: 101.5565\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3044.5774 - val_loss: 102.5714\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 51413.9375 - val_loss: 102.4755\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 46004.7695 - val_loss: 101.8915\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1604.5098 - val_loss: 101.8028\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9889.7471 - val_loss: 101.2255\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 22189.2832 - val_loss: 101.6815\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13523.2686 - val_loss: 101.5724\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1961.8536 - val_loss: 101.8772\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15341.2529 - val_loss: 101.2451\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35124.6641 - val_loss: 101.1295\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14084.4473 - val_loss: 102.5244\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 76107.7656 - val_loss: 102.8883\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 74835.3516 - val_loss: 102.2720\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39664.5742 - val_loss: 100.9564\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 36596.9883 - val_loss: 100.6041\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 32821.5273 - val_loss: 101.3627\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 8457.3848 - val_loss: 101.2284\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7233.5552 - val_loss: 101.5646\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 27327.1641 - val_loss: 101.6486\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17527.6934 - val_loss: 100.4043\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 44059.2266 - val_loss: 100.3616\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35629.7891 - val_loss: 101.1451\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1215.3910 - val_loss: 102.5239\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 77947.7344 - val_loss: 102.7650\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 73711.4609 - val_loss: 101.7943\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18963.5508 - val_loss: 100.8616\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23871.6660 - val_loss: 100.4046\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 22640.4297 - val_loss: 100.8932\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16086.8203 - val_loss: 101.0615\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9074.5234 - val_loss: 99.9776\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 47904.5898 - val_loss: 99.8562\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 40311.8594 - val_loss: 100.8156\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 15718.7783 - val_loss: 101.0154\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1190.1647 - val_loss: 100.9571\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7288.3159 - val_loss: 100.9256\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6632.7998 - val_loss: 100.1703\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff406ec9550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 74 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 72.7161 - val_loss: 47.4368\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 42.4158 - val_loss: 20.5357\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 34.0099 - val_loss: 40.2017\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 30.8923 - val_loss: 32.1297\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 24.9599 - val_loss: 14.7035\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.2534 - val_loss: 21.7669\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.3384 - val_loss: 3.2990\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.4265 - val_loss: 9.2354\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.5154 - val_loss: 3.5688\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.8360 - val_loss: 8.3880\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.5397 - val_loss: 5.9770\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.8892 - val_loss: 6.6887\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.3404 - val_loss: 4.7370\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.0094 - val_loss: 5.1832\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.8432 - val_loss: 6.0155\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.9968 - val_loss: 3.2945\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.6063 - val_loss: 4.3757\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.7461 - val_loss: 6.8543\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.7168 - val_loss: 5.4690\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.3299 - val_loss: 5.0547\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.7176 - val_loss: 3.4264\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.4271 - val_loss: 3.5836\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 6.8662 - val_loss: 4.2696\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6.4377 - val_loss: 6.2411\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.2040 - val_loss: 4.1130\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 5.6191 - val_loss: 4.5127\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5.4322 - val_loss: 3.4907\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.1396 - val_loss: 5.8265\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.5522 - val_loss: 5.8884\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.4320 - val_loss: 3.8304\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.8796 - val_loss: 3.2984\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.4355 - val_loss: 4.7513\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.1312 - val_loss: 3.9496\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.7420 - val_loss: 5.4532\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.6004 - val_loss: 6.9680\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 7.7868 - val_loss: 3.6696\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.3133 - val_loss: 3.5238\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.9248 - val_loss: 3.7473\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.6983 - val_loss: 4.9058\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.7449 - val_loss: 3.3561\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 5.3176 - val_loss: 3.7309\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.3637 - val_loss: 4.1423\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 5.7054 - val_loss: 3.8068\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.4475 - val_loss: 4.0592\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.3805 - val_loss: 3.4474\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.6189 - val_loss: 3.5356\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.3621 - val_loss: 3.8533\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.9859 - val_loss: 3.7558\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.9141 - val_loss: 3.4342\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3.8089 - val_loss: 3.5317\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e06135e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 75 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 86.0724 - val_loss: 54.3762\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41.5327 - val_loss: 32.5426\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 34.2343 - val_loss: 44.8612\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30.1668 - val_loss: 37.8274\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 25.9063 - val_loss: 22.6938\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22.1824 - val_loss: 22.8375\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.9582 - val_loss: 16.1665\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.0305 - val_loss: 12.3615\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.4251 - val_loss: 4.5654\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.0116 - val_loss: 8.1976\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.9744 - val_loss: 4.4992\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.5212 - val_loss: 8.1551\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.1106 - val_loss: 4.1505\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 13.0022 - val_loss: 5.9768\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.8230 - val_loss: 5.1465\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.8711 - val_loss: 5.4205\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.1600 - val_loss: 6.0004\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.6835 - val_loss: 6.9627\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.7848 - val_loss: 6.2566\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.1615 - val_loss: 6.7136\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.4753 - val_loss: 7.3833\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.5009 - val_loss: 6.5040\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.2632 - val_loss: 5.6449\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9024 - val_loss: 6.1590\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.7380 - val_loss: 5.6180\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.9211 - val_loss: 5.0083\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.8582 - val_loss: 5.6016\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.9319 - val_loss: 5.1104\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.7327 - val_loss: 4.7640\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.5705 - val_loss: 5.4277\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.7192 - val_loss: 5.2554\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.4722 - val_loss: 4.9713\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.9980 - val_loss: 4.5461\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 8.4550 - val_loss: 5.0583\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.8919 - val_loss: 4.6041\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.5538 - val_loss: 4.5110\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.6091 - val_loss: 4.6083\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.7371 - val_loss: 4.4955\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.0513 - val_loss: 5.0544\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.6921 - val_loss: 6.3791\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.8309 - val_loss: 5.7647\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.6935 - val_loss: 4.5471\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.8629 - val_loss: 3.2421\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.8498 - val_loss: 3.2605\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.5661 - val_loss: 3.9782\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.6002 - val_loss: 3.6530\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.3641 - val_loss: 4.5096\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.9772 - val_loss: 3.6706\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 6.3701 - val_loss: 3.5119\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.1310 - val_loss: 3.1889\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a6aa8ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 76 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 205ms/step - loss: 66526.4688 - val_loss: 115.2183\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 445194.4062 - val_loss: 115.5764\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 308969.7812 - val_loss: 106.0723\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 74336.2188 - val_loss: 98.6532\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1602.3958 - val_loss: 87.8493\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 262136.7031 - val_loss: 85.5464\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 241580.8750 - val_loss: 89.8420\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 135763.8281 - val_loss: 94.3130\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 37177.5508 - val_loss: 98.8834\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 67181.6094 - val_loss: 100.7441\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 71179.1875 - val_loss: 99.4921\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 24750.1406 - val_loss: 96.9956\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 75367.1016 - val_loss: 95.8951\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 67627.1328 - val_loss: 98.9496\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 35499.6680 - val_loss: 100.1431\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7365.0229 - val_loss: 98.7634\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24137.6758 - val_loss: 97.7308\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 39895.7852 - val_loss: 98.6432\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 383.8911 - val_loss: 98.9474\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 24168.4961 - val_loss: 98.6216\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17581.3672 - val_loss: 100.3618\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37852.1289 - val_loss: 100.4449\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20113.0938 - val_loss: 99.3462\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9277.0576 - val_loss: 99.1386\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4551.4136 - val_loss: 99.9071\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13024.3320 - val_loss: 99.7085\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5584.2480 - val_loss: 98.9311\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19823.1816 - val_loss: 98.9118\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13070.1836 - val_loss: 100.5435\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 33838.1992 - val_loss: 100.3371\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19932.7031 - val_loss: 98.8321\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16720.6680 - val_loss: 99.1132\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9007.0859 - val_loss: 100.4293\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 44766.2578 - val_loss: 100.9883\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24984.0840 - val_loss: 99.0801\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38895.9414 - val_loss: 98.1355\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36718.8008 - val_loss: 99.6146\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14948.2471 - val_loss: 99.8877\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2180.3855 - val_loss: 99.9513\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12875.5352 - val_loss: 99.6123\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5562.6660 - val_loss: 100.0389\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21746.4590 - val_loss: 100.1380\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8808.5859 - val_loss: 98.4877\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 55616.6523 - val_loss: 97.7218\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 44907.2891 - val_loss: 99.5713\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18378.7363 - val_loss: 100.2912\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13636.6895 - val_loss: 99.1093\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21760.7715 - val_loss: 99.2025\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14033.5791 - val_loss: 100.5786\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 35434.6953 - val_loss: 100.8657\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b1adbf70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 77 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 72.3947 - val_loss: 48.2536\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 70.2601 - val_loss: 51.7501\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 48.9733 - val_loss: 55.9773\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 42.7794 - val_loss: 35.9293\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 37.4285 - val_loss: 29.1389\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.4370 - val_loss: 32.5035\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 30.7466 - val_loss: 17.6379\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 27.1998 - val_loss: 15.3235\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 24.7809 - val_loss: 7.2742\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 22.8928 - val_loss: 6.3847\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 20.7023 - val_loss: 6.6221\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20.3305 - val_loss: 7.8420\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.9763 - val_loss: 5.9991\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20.1621 - val_loss: 6.5219\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.2899 - val_loss: 7.0107\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.0958 - val_loss: 6.1285\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.4012 - val_loss: 5.1818\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.0707 - val_loss: 4.9918\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.1572 - val_loss: 5.7733\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.4285 - val_loss: 5.5131\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.1760 - val_loss: 5.7038\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.9986 - val_loss: 5.2328\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.6267 - val_loss: 5.5067\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.0100 - val_loss: 6.4224\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.1876 - val_loss: 4.4196\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.0176 - val_loss: 4.2121\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.5147 - val_loss: 4.8855\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.5314 - val_loss: 5.2058\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.9156 - val_loss: 5.3809\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.9810 - val_loss: 4.0840\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.5761 - val_loss: 6.5451\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 12.1079 - val_loss: 4.0592\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.0052 - val_loss: 4.3726\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.7334 - val_loss: 5.5327\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.2095 - val_loss: 3.8421\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8419 - val_loss: 4.6088\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.7657 - val_loss: 4.0287\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.5761 - val_loss: 5.2705\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.6268 - val_loss: 5.5828\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.7674 - val_loss: 3.4273\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.3676 - val_loss: 3.3990\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.1223 - val_loss: 4.9604\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.4483 - val_loss: 2.9561\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.2602 - val_loss: 3.8290\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.8172 - val_loss: 2.7960\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.3612 - val_loss: 3.3504\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.0223 - val_loss: 4.7368\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.4841 - val_loss: 3.5510\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12.0948 - val_loss: 6.4612\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.7408 - val_loss: 5.6852\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b8229a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 78 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 176ms/step - loss: 59.7980 - val_loss: 32.4930\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 33.1986 - val_loss: 22.6761\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25.4070 - val_loss: 32.8767\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23.9260 - val_loss: 24.1138\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19.9247 - val_loss: 10.7911\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.0091 - val_loss: 13.8951\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.1284 - val_loss: 5.3191\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 12.8428 - val_loss: 2.8963\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 12.0320 - val_loss: 3.5000\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.3953 - val_loss: 2.8858\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.6553 - val_loss: 3.9552\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.1613 - val_loss: 2.8539\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.1019 - val_loss: 4.1739\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.3832 - val_loss: 3.5771\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.3161 - val_loss: 3.1619\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6492 - val_loss: 5.8475\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.6405 - val_loss: 5.0069\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.7431 - val_loss: 3.4250\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.6394 - val_loss: 3.5281\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4270 - val_loss: 3.4829\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.4174 - val_loss: 3.7314\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.9248 - val_loss: 3.6782\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.0118 - val_loss: 3.7582\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.4126 - val_loss: 3.5504\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.5227 - val_loss: 3.3395\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.2275 - val_loss: 4.5940\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.9684 - val_loss: 3.8137\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.6271 - val_loss: 3.9620\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.7582 - val_loss: 5.7784\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.9668 - val_loss: 3.8766\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.3227 - val_loss: 3.9351\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.7548 - val_loss: 3.3348\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.6608 - val_loss: 6.0596\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.4756 - val_loss: 5.6734\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.1843 - val_loss: 5.4249\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.7845 - val_loss: 3.1919\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.8619 - val_loss: 3.3020\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.7421 - val_loss: 3.6662\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.9996 - val_loss: 4.2724\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.0057 - val_loss: 4.5479\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.3491 - val_loss: 4.2048\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.2805 - val_loss: 3.2601\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.3244 - val_loss: 3.2768\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.2945 - val_loss: 3.9672\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 4.5013 - val_loss: 3.2275\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.9686 - val_loss: 3.4593\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.4999 - val_loss: 4.2171\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.2677 - val_loss: 3.9001\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.6069 - val_loss: 2.8276\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.0577 - val_loss: 3.3238\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ccf3a550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 79 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 5370457.5000 - val_loss: 95.2552\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3241839.2500 - val_loss: 96.1742\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1512195.8750 - val_loss: 96.3967\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1259842.3750 - val_loss: 96.8139\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 977650.1875 - val_loss: 96.7685\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 862914.9375 - val_loss: 96.9499\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 235259.8750 - val_loss: 96.9206\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 263005.2500 - val_loss: 96.8631\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 251741.1250 - val_loss: 96.7591\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 303540.5938 - val_loss: 96.6513\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 745240.0000 - val_loss: 96.5249\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 763272.5625 - val_loss: 96.4494\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 743832.6250 - val_loss: 96.3202\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 683082.5000 - val_loss: 96.2751\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 175981.1250 - val_loss: 96.2295\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 245081.6250 - val_loss: 96.1778\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 228030.0312 - val_loss: 96.1071\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 218776.8125 - val_loss: 96.0318\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 237784.3906 - val_loss: 95.9645\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 210730.1250 - val_loss: 95.8952\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 250292.0312 - val_loss: 95.7958\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 233174.3750 - val_loss: 95.7204\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 219941.7656 - val_loss: 95.6651\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 241708.2656 - val_loss: 95.5705\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 205227.0469 - val_loss: 95.4979\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 230919.3438 - val_loss: 95.4487\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 213301.8438 - val_loss: 95.3876\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 226084.7656 - val_loss: 95.3198\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 207701.5625 - val_loss: 95.2591\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 228233.8906 - val_loss: 95.2005\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 211724.4688 - val_loss: 95.1692\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 683047.0000 - val_loss: 95.1287\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 685709.9375 - val_loss: 95.2223\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 575285.9375 - val_loss: 95.2368\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 735605.1875 - val_loss: 95.3081\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 239939.2656 - val_loss: 95.3553\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 448712.9375 - val_loss: 95.3943\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 857142.6875 - val_loss: 95.4246\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1053201.0000 - val_loss: 95.5557\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 498159.9062 - val_loss: 95.6241\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 258886.2344 - val_loss: 95.6726\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 346253.9062 - val_loss: 95.6930\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 218615.8281 - val_loss: 95.6786\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 478109.1562 - val_loss: 95.7122\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 589679.3750 - val_loss: 95.7095\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 149547.9375 - val_loss: 95.7027\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 367354.4688 - val_loss: 95.6555\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 564655.5625 - val_loss: 95.6769\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 343295.5938 - val_loss: 95.6925\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 566490.6250 - val_loss: 95.6790\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a63ae940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 80 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 81.1205 - val_loss: 50.0300\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36.0458 - val_loss: 16.5694\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 33.1327 - val_loss: 34.9457\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27.6183 - val_loss: 36.6877\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 25.0679 - val_loss: 15.3888\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22.4494 - val_loss: 19.8354\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 18.7187 - val_loss: 21.3158\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.6224 - val_loss: 10.2033\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.8986 - val_loss: 6.8229\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.8107 - val_loss: 7.5153\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.2009 - val_loss: 3.5001\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.2012 - val_loss: 3.2563\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.5787 - val_loss: 4.1776\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.0236 - val_loss: 3.7224\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.2848 - val_loss: 5.1130\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.0062 - val_loss: 4.6465\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5203 - val_loss: 8.9862\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.9907 - val_loss: 4.6651\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.1276 - val_loss: 5.7483\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.0932 - val_loss: 4.1094\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7793 - val_loss: 4.6018\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.7094 - val_loss: 4.2648\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1990 - val_loss: 3.9009\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.8606 - val_loss: 5.5064\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.6007 - val_loss: 4.9812\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.7920 - val_loss: 3.6068\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.1877 - val_loss: 3.8705\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.1847 - val_loss: 8.9885\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.5463 - val_loss: 5.5613\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4662 - val_loss: 10.8804\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.5076 - val_loss: 4.8470\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.9025 - val_loss: 7.9930\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.9577 - val_loss: 3.7046\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0460 - val_loss: 4.3715\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.5138 - val_loss: 3.4406\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.5859 - val_loss: 4.4327\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.1899 - val_loss: 3.3701\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.0743 - val_loss: 2.6478\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.0841 - val_loss: 3.4261\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.0034 - val_loss: 3.0372\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.6638 - val_loss: 3.3745\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.6456 - val_loss: 2.9830\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3607 - val_loss: 3.6657\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.5628 - val_loss: 2.6827\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.3392 - val_loss: 2.9187\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.1808 - val_loss: 2.5736\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.6457 - val_loss: 4.0747\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.6776 - val_loss: 3.9996\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.2110 - val_loss: 3.4892\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.1823 - val_loss: 2.8863\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3af848a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 81 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 6082742.5000 - val_loss: 98.2092\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4822727.5000 - val_loss: 98.3800\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4713524.0000 - val_loss: 98.5496\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1549302.7500 - val_loss: 98.3392\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1122052.0000 - val_loss: 98.4139\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 291298.9688 - val_loss: 98.4147\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 421974.1562 - val_loss: 98.3360\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 524329.9375 - val_loss: 98.2438\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 354271.5312 - val_loss: 98.1607\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 730333.0625 - val_loss: 98.0436\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1071942.8750 - val_loss: 98.0217\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1485308.1250 - val_loss: 97.9120\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 599164.8125 - val_loss: 97.8732\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 221668.7969 - val_loss: 97.8145\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 355796.2812 - val_loss: 97.7402\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 434409.3438 - val_loss: 97.6646\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 453200.6875 - val_loss: 97.5936\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 412450.2188 - val_loss: 97.5251\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 402774.0625 - val_loss: 97.4689\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 423803.5312 - val_loss: 97.4236\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 426603.7500 - val_loss: 97.3734\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 372572.3750 - val_loss: 97.3245\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 366732.7812 - val_loss: 97.2756\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 407540.0938 - val_loss: 97.2264\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 409304.5938 - val_loss: 97.2014\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 340250.4062 - val_loss: 97.1602\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 386066.8750 - val_loss: 97.1296\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 401424.5000 - val_loss: 97.0857\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 355783.5312 - val_loss: 97.0435\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 309169.7500 - val_loss: 97.0113\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 437728.2188 - val_loss: 96.9789\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 160752.4375 - val_loss: 96.9452\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 468402.3750 - val_loss: 96.9162\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 107037.3125 - val_loss: 96.8699\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 303608.3438 - val_loss: 96.8189\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 654266.7500 - val_loss: 96.8284\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 844461.0625 - val_loss: 96.7998\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 864497.5000 - val_loss: 96.8559\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 466234.5312 - val_loss: 96.8776\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 134252.1562 - val_loss: 96.8814\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 439951.5312 - val_loss: 96.8645\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 689580.0000 - val_loss: 96.8541\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 187981.5781 - val_loss: 96.8351\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 169892.9375 - val_loss: 96.8073\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 582143.9375 - val_loss: 96.8072\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 515285.3125 - val_loss: 96.7757\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 146802.0312 - val_loss: 96.7645\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 390016.1875 - val_loss: 96.7271\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 151809.6094 - val_loss: 96.7144\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 382267.9062 - val_loss: 96.6747\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff397da18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 82 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 164049.2969 - val_loss: 116.1308\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 242047.7656 - val_loss: 109.8301\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 100302.7812 - val_loss: 103.5788\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 78054.4297 - val_loss: 98.5036\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6065.1470 - val_loss: 102.9845\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 91729.4531 - val_loss: 106.8096\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 112158.8984 - val_loss: 105.7557\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 66726.8828 - val_loss: 100.3890\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 83387.5703 - val_loss: 98.2406\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 68282.3359 - val_loss: 100.6208\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7189.0435 - val_loss: 101.0297\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15321.0889 - val_loss: 101.5285\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7616.9170 - val_loss: 100.5678\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22179.7422 - val_loss: 100.8327\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23957.6680 - val_loss: 101.8853\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16755.9180 - val_loss: 99.9727\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23268.6445 - val_loss: 100.4572\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9608.2061 - val_loss: 102.7401\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 51620.2656 - val_loss: 102.4663\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 25062.5879 - val_loss: 101.1806\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 27301.4219 - val_loss: 99.6245\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32248.3066 - val_loss: 100.4600\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9438.3496 - val_loss: 104.1779\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 115866.0781 - val_loss: 105.3519\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 103917.2266 - val_loss: 103.5306\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 37234.7031 - val_loss: 100.9704\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26503.7852 - val_loss: 99.7038\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 28537.2031 - val_loss: 101.2324\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 28107.7969 - val_loss: 101.3461\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6849.6675 - val_loss: 99.4872\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 51630.4688 - val_loss: 98.9152\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 43545.3984 - val_loss: 100.1216\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8071.3687 - val_loss: 100.6466\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10599.4629 - val_loss: 100.6314\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9661.2646 - val_loss: 100.8605\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4825.0732 - val_loss: 100.1272\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14074.9160 - val_loss: 100.3349\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8219.0186 - val_loss: 101.8193\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 33510.9531 - val_loss: 101.3252\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19848.9902 - val_loss: 99.6909\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 25849.0684 - val_loss: 100.0587\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11240.0791 - val_loss: 100.8815\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 23709.1855 - val_loss: 101.1998\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13926.0049 - val_loss: 100.0919\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14148.3096 - val_loss: 100.2826\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 7024.9180 - val_loss: 101.2281\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42386.1992 - val_loss: 101.8014\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 28656.8184 - val_loss: 99.8401\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 46226.4336 - val_loss: 99.0580\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 38188.8672 - val_loss: 99.6245\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a6af3940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 83 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 52.0098 - val_loss: 6.4187\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.4564 - val_loss: 7.3622\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.4577 - val_loss: 25.5976\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.4846 - val_loss: 14.4458\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.8203 - val_loss: 7.7269\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.6789 - val_loss: 17.3368\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.6803 - val_loss: 15.1313\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.0090 - val_loss: 9.0378\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.0641 - val_loss: 13.4931\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3749 - val_loss: 11.4154\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.6162 - val_loss: 9.3360\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.5028 - val_loss: 9.9980\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.8076 - val_loss: 10.3538\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.9562 - val_loss: 5.0987\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.3846 - val_loss: 7.4059\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.8208 - val_loss: 8.5183\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.9097 - val_loss: 6.6382\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.4579 - val_loss: 3.9294\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.0505 - val_loss: 3.9937\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 4.8248 - val_loss: 4.5725\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.1476 - val_loss: 5.3735\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.8104 - val_loss: 4.2314\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.8578 - val_loss: 3.7041\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.0969 - val_loss: 4.7760\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.9143 - val_loss: 5.7304\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3.9883 - val_loss: 3.7785\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.4134 - val_loss: 3.7971\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.1202 - val_loss: 6.1100\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.2086 - val_loss: 4.7107\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3.7944 - val_loss: 3.8627\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.0355 - val_loss: 4.5898\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.6116 - val_loss: 5.2998\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.6725 - val_loss: 4.0900\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.6675 - val_loss: 5.6805\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.0132 - val_loss: 4.8744\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.6978 - val_loss: 3.6969\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.8659 - val_loss: 4.6797\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.6056 - val_loss: 5.0091\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.4894 - val_loss: 4.6858\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.5248 - val_loss: 4.0221\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.4511 - val_loss: 4.0034\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.4175 - val_loss: 4.4909\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3.4183 - val_loss: 4.2192\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.2272 - val_loss: 5.3044\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.2630 - val_loss: 4.2116\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3.3580 - val_loss: 3.8986\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.6080 - val_loss: 3.8379\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.7671 - val_loss: 6.7712\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.7061 - val_loss: 3.8898\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.0122 - val_loss: 4.1434\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b6545040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 84 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 64.6991 - val_loss: 42.7624\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45.9737 - val_loss: 28.0706\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 37.1730 - val_loss: 36.8791\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.3791 - val_loss: 34.0490\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 27.8060 - val_loss: 19.8912\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.0904 - val_loss: 18.7050\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 19.6028 - val_loss: 9.2343\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.6304 - val_loss: 12.9405\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.0103 - val_loss: 9.7868\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.9234 - val_loss: 14.6929\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.6974 - val_loss: 8.9699\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.3290 - val_loss: 13.0391\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.8272 - val_loss: 9.2198\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.9812 - val_loss: 10.9201\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.6212 - val_loss: 10.3859\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.0904 - val_loss: 10.0147\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.1567 - val_loss: 9.7110\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.9576 - val_loss: 10.0796\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.4156 - val_loss: 10.8595\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.9287 - val_loss: 10.6599\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.5413 - val_loss: 10.5655\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.8613 - val_loss: 10.0319\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.5990 - val_loss: 10.9717\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.8088 - val_loss: 11.5312\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.7317 - val_loss: 10.2251\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.4637 - val_loss: 10.5510\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.3841 - val_loss: 10.4881\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.4250 - val_loss: 10.4873\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.1030 - val_loss: 10.6667\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.1088 - val_loss: 10.2646\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.2618 - val_loss: 10.5393\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.2117 - val_loss: 10.0121\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.8636 - val_loss: 10.5045\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.6250 - val_loss: 10.2442\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.0534 - val_loss: 10.7970\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.6556 - val_loss: 11.2603\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.7718 - val_loss: 10.9554\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.3342 - val_loss: 10.8129\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.0131 - val_loss: 11.3285\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.8231 - val_loss: 10.8448\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.8429 - val_loss: 10.9767\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.8463 - val_loss: 10.8221\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.7774 - val_loss: 11.2268\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.7561 - val_loss: 11.1356\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.5163 - val_loss: 10.3217\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.9632 - val_loss: 11.1346\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.1831 - val_loss: 10.9442\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.8189 - val_loss: 11.7532\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.9965 - val_loss: 11.4056\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.5737 - val_loss: 10.7968\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3e0613310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 85 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 62.4691 - val_loss: 29.4727\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.7523 - val_loss: 10.1092\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28.0478 - val_loss: 31.9885\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25.4584 - val_loss: 31.2042\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22.6102 - val_loss: 19.8855\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20.8500 - val_loss: 12.7038\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19.2613 - val_loss: 16.4997\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.8625 - val_loss: 21.8685\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.2019 - val_loss: 12.8432\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.1280 - val_loss: 13.9210\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.5876 - val_loss: 7.7921\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.5669 - val_loss: 7.1102\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.9712 - val_loss: 10.4002\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4979 - val_loss: 9.3546\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6541 - val_loss: 8.5888\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.3292 - val_loss: 6.4382\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3570 - val_loss: 6.7952\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5.9350 - val_loss: 6.7316\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6082 - val_loss: 6.9483\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.0094 - val_loss: 7.6059\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.4904 - val_loss: 6.6515\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.6258 - val_loss: 6.8680\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.0671 - val_loss: 10.2245\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6211 - val_loss: 7.1236\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.7051 - val_loss: 7.0203\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.3672 - val_loss: 7.9488\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.9812 - val_loss: 6.6429\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.7089 - val_loss: 6.3802\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.7669 - val_loss: 6.8433\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.3567 - val_loss: 6.6479\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.2033 - val_loss: 8.4073\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.8686 - val_loss: 9.1263\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3581 - val_loss: 6.2843\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 4.6491 - val_loss: 6.8135\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.9951 - val_loss: 7.3046\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.8565 - val_loss: 6.3091\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.1873 - val_loss: 6.3786\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.6101 - val_loss: 6.4868\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.7431 - val_loss: 7.6233\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.6660 - val_loss: 7.4483\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.8835 - val_loss: 6.3240\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.9178 - val_loss: 6.3735\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.9447 - val_loss: 7.4873\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3.9082 - val_loss: 6.6690\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.3070 - val_loss: 6.6696\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.3974 - val_loss: 6.7636\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.1580 - val_loss: 6.5593\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.1335 - val_loss: 6.5053\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.1052 - val_loss: 6.6629\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3.0979 - val_loss: 6.8479\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff394c16b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 86 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 86.7322 - val_loss: 61.6136\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.9089 - val_loss: 15.7379\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 30.6345 - val_loss: 30.8139\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25.5903 - val_loss: 33.7066\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 21.4670 - val_loss: 14.3606\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20.5682 - val_loss: 21.9270\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 17.9547 - val_loss: 15.6208\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.7293 - val_loss: 11.5965\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.2985 - val_loss: 9.6010\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.0353 - val_loss: 8.3894\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.2951 - val_loss: 7.8379\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.1298 - val_loss: 7.7307\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.1295 - val_loss: 7.7314\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.7515 - val_loss: 8.6560\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4321 - val_loss: 8.8345\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 8.5010 - val_loss: 8.8002\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2214 - val_loss: 10.1713\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.5627 - val_loss: 8.7944\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.1800 - val_loss: 8.8086\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.8332 - val_loss: 8.6108\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.6957 - val_loss: 8.3638\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.0046 - val_loss: 8.8924\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.3679 - val_loss: 8.2730\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5969 - val_loss: 8.4777\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.2203 - val_loss: 10.0423\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.6785 - val_loss: 8.1366\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.3011 - val_loss: 8.2317\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.1790 - val_loss: 8.4248\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.2300 - val_loss: 7.8334\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4015 - val_loss: 9.5736\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.3085 - val_loss: 8.3166\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.2159 - val_loss: 9.0539\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.9726 - val_loss: 8.1701\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.1743 - val_loss: 7.9319\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.8728 - val_loss: 7.5847\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4924 - val_loss: 10.6240\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.5323 - val_loss: 7.8329\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.2605 - val_loss: 7.4884\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.6132 - val_loss: 7.9088\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.8215 - val_loss: 8.4517\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.1696 - val_loss: 7.1719\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.4240 - val_loss: 9.1783\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.6772 - val_loss: 8.6007\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.0181 - val_loss: 8.6506\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.7388 - val_loss: 8.7946\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.7849 - val_loss: 7.2576\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.0019 - val_loss: 8.2966\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.0504 - val_loss: 7.7744\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.6870 - val_loss: 7.2698\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.5378 - val_loss: 7.7309\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ab559310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 87 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 4781.3096 - val_loss: 119.6395\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 327867.6562 - val_loss: 113.5644\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 179196.5469 - val_loss: 108.7930\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 78843.6172 - val_loss: 101.9458\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 38126.1484 - val_loss: 99.9475\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 45002.1758 - val_loss: 101.4850\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10316.0322 - val_loss: 100.8482\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21579.3496 - val_loss: 100.7355\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4218.7080 - val_loss: 100.9972\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1432.0807 - val_loss: 98.9765\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 65872.2969 - val_loss: 98.6238\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 53523.6445 - val_loss: 101.1465\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 43817.0547 - val_loss: 101.9993\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17227.7715 - val_loss: 99.8938\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 43441.0312 - val_loss: 98.5612\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40153.2188 - val_loss: 100.1625\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18406.8750 - val_loss: 100.8355\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10673.2266 - val_loss: 98.0089\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 85508.3203 - val_loss: 96.8796\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 69064.1719 - val_loss: 98.9245\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9300.3682 - val_loss: 101.3064\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19192.2148 - val_loss: 101.8801\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 37312.3750 - val_loss: 101.2050\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15349.8457 - val_loss: 99.1431\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45676.7266 - val_loss: 98.3764\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 37232.5742 - val_loss: 99.5898\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 827.8784 - val_loss: 99.8694\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10445.0332 - val_loss: 100.1833\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 19106.4121 - val_loss: 100.6530\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4421.9863 - val_loss: 100.2012\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7678.1094 - val_loss: 100.0496\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7234.5928 - val_loss: 100.3454\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7688.0493 - val_loss: 99.8997\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14449.1064 - val_loss: 100.0405\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3779.4844 - val_loss: 99.9716\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16648.7285 - val_loss: 99.8382\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2557.4661 - val_loss: 100.0245\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 26566.3867 - val_loss: 99.2957\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21584.3633 - val_loss: 101.2546\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 30966.9629 - val_loss: 101.4126\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27054.4121 - val_loss: 100.5596\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7955.6187 - val_loss: 98.5670\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39635.6250 - val_loss: 98.4987\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 41075.4180 - val_loss: 99.1653\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8657.5186 - val_loss: 100.2546\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12758.7920 - val_loss: 101.0604\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 25954.0703 - val_loss: 100.6783\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4226.8101 - val_loss: 99.6205\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12128.0176 - val_loss: 99.4847\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17122.7715 - val_loss: 99.7369\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a8284d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 88 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 95544.1250 - val_loss: 84.1944\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 527487.3750 - val_loss: 82.4528\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 329180.4688 - val_loss: 90.7126\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 149719.3750 - val_loss: 99.4478\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 112821.6016 - val_loss: 103.8364\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 91110.2031 - val_loss: 100.2201\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52414.6445 - val_loss: 98.4974\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18346.8906 - val_loss: 99.9459\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35480.8242 - val_loss: 100.2704\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 38779.1992 - val_loss: 98.9602\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3808.1111 - val_loss: 99.3496\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24277.6309 - val_loss: 99.1291\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9546.5186 - val_loss: 96.3003\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 133478.2969 - val_loss: 95.2142\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 130241.9062 - val_loss: 96.4345\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 76331.8828 - val_loss: 98.2860\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 28905.3496 - val_loss: 98.7621\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18303.3691 - val_loss: 97.5206\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 40861.9453 - val_loss: 96.9418\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 30491.7988 - val_loss: 98.2985\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 37998.0742 - val_loss: 98.7286\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 30186.3359 - val_loss: 97.1347\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52202.9453 - val_loss: 96.5730\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 36756.1367 - val_loss: 98.3539\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29911.5859 - val_loss: 98.6421\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29222.2656 - val_loss: 97.5583\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16115.8750 - val_loss: 97.7995\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4187.8491 - val_loss: 97.4226\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15148.2715 - val_loss: 97.8773\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4521.6357 - val_loss: 97.2825\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32727.2129 - val_loss: 97.2375\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12365.0645 - val_loss: 98.4344\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23447.8496 - val_loss: 98.4563\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24847.3984 - val_loss: 97.7953\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 22852.8418 - val_loss: 97.3852\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15062.9355 - val_loss: 99.1333\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 59981.2773 - val_loss: 99.3223\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 57741.1445 - val_loss: 98.2987\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 922.6764 - val_loss: 97.3971\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14157.7939 - val_loss: 96.8689\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 36761.8477 - val_loss: 97.3309\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16615.9629 - val_loss: 98.6543\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52804.8477 - val_loss: 99.0155\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 39774.1602 - val_loss: 98.3306\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12426.7109 - val_loss: 96.7305\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50458.6406 - val_loss: 96.3927\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 55269.2812 - val_loss: 96.7336\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29690.6484 - val_loss: 97.9418\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 21802.5879 - val_loss: 98.3856\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20700.4707 - val_loss: 97.6898\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b8d65160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 89 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 48.9627 - val_loss: 21.0885\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 40.0201 - val_loss: 32.4623\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.2114 - val_loss: 43.0902\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 31.0376 - val_loss: 28.1016\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27.3902 - val_loss: 20.2721\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23.6983 - val_loss: 24.2177\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21.2006 - val_loss: 16.6573\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.9751 - val_loss: 16.4233\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.8677 - val_loss: 8.4198\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.0046 - val_loss: 7.1480\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.2563 - val_loss: 6.8530\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.2526 - val_loss: 6.7663\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9067 - val_loss: 7.7008\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.0767 - val_loss: 9.7128\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.4266 - val_loss: 7.5777\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.3202 - val_loss: 6.9847\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.0917 - val_loss: 8.2778\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.9494 - val_loss: 6.9591\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.7184 - val_loss: 7.2043\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.9519 - val_loss: 10.0809\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.3051 - val_loss: 6.4342\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.3124 - val_loss: 6.8647\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.6281 - val_loss: 8.6391\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.9545 - val_loss: 6.1872\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.9820 - val_loss: 7.4374\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6887 - val_loss: 7.5419\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4525 - val_loss: 7.1762\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.3567 - val_loss: 6.6454\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.0306 - val_loss: 6.4163\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.3146 - val_loss: 7.4085\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.9753 - val_loss: 6.5283\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8753 - val_loss: 6.9724\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.6652 - val_loss: 6.2131\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.4275 - val_loss: 7.3923\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.6734 - val_loss: 7.6920\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.5449 - val_loss: 6.7838\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.4838 - val_loss: 6.0073\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.6140 - val_loss: 6.3726\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.6355 - val_loss: 8.1124\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.9890 - val_loss: 6.3734\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.3755 - val_loss: 6.1891\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.3593 - val_loss: 6.1032\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1580 - val_loss: 6.2004\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.9578 - val_loss: 5.8190\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.0667 - val_loss: 5.6265\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.7459 - val_loss: 6.0303\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 7.6354 - val_loss: 5.5223\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.3638 - val_loss: 5.8055\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.6679 - val_loss: 5.4355\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.0110 - val_loss: 6.4463\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3cb1bda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 90 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 12178.6328 - val_loss: 73.8811\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 340478.4062 - val_loss: 80.7685\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 173575.8438 - val_loss: 85.5933\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 49776.8906 - val_loss: 95.2507\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27730.2988 - val_loss: 98.0509\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 81721.8750 - val_loss: 97.9244\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26422.4102 - val_loss: 94.6725\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15283.6221 - val_loss: 94.3915\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 27772.4570 - val_loss: 96.5567\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13067.3760 - val_loss: 95.6491\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13755.6377 - val_loss: 96.8043\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 27661.8066 - val_loss: 96.6877\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 3237.0376 - val_loss: 96.9123\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27174.7246 - val_loss: 96.7500\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9648.8447 - val_loss: 93.3987\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 84851.2422 - val_loss: 92.5843\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 71280.9219 - val_loss: 95.4713\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9719.9043 - val_loss: 99.4142\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 70930.6172 - val_loss: 100.1403\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 71722.0625 - val_loss: 98.7315\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 42881.2188 - val_loss: 95.0862\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39955.1914 - val_loss: 94.8653\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 35609.7695 - val_loss: 96.5114\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12349.5029 - val_loss: 97.2218\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 474.8404 - val_loss: 94.8683\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 70094.2734 - val_loss: 93.8431\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 40106.7812 - val_loss: 95.8587\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4745.1821 - val_loss: 97.6755\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13105.0439 - val_loss: 96.5875\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24856.5996 - val_loss: 96.5315\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3258.6663 - val_loss: 98.2205\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36321.3086 - val_loss: 99.0114\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 33751.4414 - val_loss: 97.3111\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8072.2983 - val_loss: 97.6412\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9835.2783 - val_loss: 97.3710\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16471.8965 - val_loss: 97.1001\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1006.8242 - val_loss: 97.0600\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 21497.9531 - val_loss: 96.9252\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8776.3379 - val_loss: 98.9552\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 50166.3477 - val_loss: 99.6906\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 39582.9922 - val_loss: 98.6045\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21890.7051 - val_loss: 95.6849\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 70710.8594 - val_loss: 94.5027\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 61671.9609 - val_loss: 96.6560\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10803.1924 - val_loss: 99.0141\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 41934.6328 - val_loss: 99.8716\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 40455.0703 - val_loss: 99.1462\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 25238.9473 - val_loss: 96.0450\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 74077.9141 - val_loss: 95.0834\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 40431.3242 - val_loss: 98.2069\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3afdd2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 91 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 81.0202 - val_loss: 57.4367\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 60.0644 - val_loss: 56.9239\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 44.4292 - val_loss: 42.2704\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 36.1157 - val_loss: 26.8426\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23.0433 - val_loss: 13.2455\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18.6117 - val_loss: 8.2653\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.1153 - val_loss: 7.6958\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.6004 - val_loss: 10.3798\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.5114 - val_loss: 7.2326\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.2177 - val_loss: 7.0946\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.2753 - val_loss: 7.8862\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.5657 - val_loss: 7.4020\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.9107 - val_loss: 7.0499\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.7123 - val_loss: 8.0325\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.2103 - val_loss: 6.6511\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.2760 - val_loss: 6.7445\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.5109 - val_loss: 6.5191\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.0580 - val_loss: 6.5760\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.7083 - val_loss: 7.3354\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.6110 - val_loss: 6.1106\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.6914 - val_loss: 6.2215\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.2723 - val_loss: 6.1445\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.7241 - val_loss: 5.8785\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.4503 - val_loss: 6.2008\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.5378 - val_loss: 5.7297\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.7819 - val_loss: 6.1708\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.9306 - val_loss: 5.8183\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.8625 - val_loss: 5.7241\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.4458 - val_loss: 6.6100\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.7260 - val_loss: 5.7528\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.8024 - val_loss: 5.5194\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.2999 - val_loss: 6.1487\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.1373 - val_loss: 5.6223\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.7605 - val_loss: 5.4338\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.8292 - val_loss: 5.1774\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.8937 - val_loss: 5.3402\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.7306 - val_loss: 5.4091\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9195 - val_loss: 5.2061\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.7666 - val_loss: 5.0662\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.6355 - val_loss: 5.1014\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.7619 - val_loss: 5.0492\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.5249 - val_loss: 6.2523\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.1621 - val_loss: 5.6451\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.4622 - val_loss: 5.3052\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.7190 - val_loss: 6.2853\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.7204 - val_loss: 5.0307\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.7583 - val_loss: 4.9067\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.5931 - val_loss: 4.9469\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.0115 - val_loss: 4.8772\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.1152 - val_loss: 4.8529\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ac0a4040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 92 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 73.7953 - val_loss: 37.2728\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 31.8673 - val_loss: 3.6068\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29.6466 - val_loss: 23.8345\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22.3223 - val_loss: 26.2183\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 20.6903 - val_loss: 10.9868\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.1560 - val_loss: 13.2253\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17.5224 - val_loss: 14.6912\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 16.3843 - val_loss: 9.4566\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.9959 - val_loss: 8.7591\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13.4760 - val_loss: 6.3249\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 12.3910 - val_loss: 4.2422\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 11.5997 - val_loss: 4.4661\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.0393 - val_loss: 9.6547\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.9881 - val_loss: 6.8621\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.9945 - val_loss: 9.0488\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.8914 - val_loss: 4.5304\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.3603 - val_loss: 5.2647\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.2865 - val_loss: 4.5708\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.8956 - val_loss: 4.6941\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.6358 - val_loss: 5.6632\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.3599 - val_loss: 4.6641\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.2842 - val_loss: 5.8449\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.8462 - val_loss: 4.7319\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.6167 - val_loss: 4.6355\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.4951 - val_loss: 5.0098\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.2392 - val_loss: 4.6582\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.7896 - val_loss: 4.4374\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7531 - val_loss: 4.4782\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.9472 - val_loss: 4.3896\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.7142 - val_loss: 7.4715\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 6.2567 - val_loss: 4.6820\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.7915 - val_loss: 7.1792\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.2038 - val_loss: 5.4624\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.3645 - val_loss: 4.2198\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.8089 - val_loss: 5.3160\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.6781 - val_loss: 4.2133\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.5700 - val_loss: 4.1207\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.5700 - val_loss: 5.0576\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.4627 - val_loss: 5.2587\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.0453 - val_loss: 4.4797\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.5318 - val_loss: 4.2304\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.1305 - val_loss: 3.5163\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.1179 - val_loss: 5.4904\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.3135 - val_loss: 6.8473\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 5.4165 - val_loss: 3.3941\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.9416 - val_loss: 3.4124\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.1243 - val_loss: 4.5720\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.8006 - val_loss: 7.2000\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.2515 - val_loss: 3.7212\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.0354 - val_loss: 3.3051\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a0d12af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 93 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 55.3031 - val_loss: 29.7682\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 41.8046 - val_loss: 34.6744\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 34.1652 - val_loss: 39.2757\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 30.6768 - val_loss: 18.2908\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24.4833 - val_loss: 11.0346\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21.5297 - val_loss: 7.8918\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.0390 - val_loss: 9.0972\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 20.4451 - val_loss: 10.2231\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.8830 - val_loss: 5.5391\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.2307 - val_loss: 9.1974\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.5764 - val_loss: 5.1344\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.5031 - val_loss: 3.5149\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.6033 - val_loss: 5.1192\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.1289 - val_loss: 3.7145\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.7583 - val_loss: 5.0221\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.7324 - val_loss: 3.7706\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.1332 - val_loss: 4.3172\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.6089 - val_loss: 4.1668\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.3368 - val_loss: 4.6933\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.6440 - val_loss: 4.0524\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.7118 - val_loss: 3.2530\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.4576 - val_loss: 3.9976\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.4704 - val_loss: 4.5064\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 10.9352 - val_loss: 3.1833\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.2361 - val_loss: 4.4861\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10.0347 - val_loss: 3.4049\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 9.6648 - val_loss: 3.3248\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.1340 - val_loss: 6.0231\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.8764 - val_loss: 3.2482\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.3592 - val_loss: 4.3246\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 9.0889 - val_loss: 4.5215\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.6196 - val_loss: 3.5133\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.9042 - val_loss: 4.5599\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.9270 - val_loss: 4.5236\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.8060 - val_loss: 3.4304\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.0015 - val_loss: 5.7127\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.7802 - val_loss: 5.2228\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.9468 - val_loss: 2.6396\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2512 - val_loss: 4.9002\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.7608 - val_loss: 3.6000\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.3888 - val_loss: 6.2389\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.1505 - val_loss: 3.1297\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.2857 - val_loss: 2.8673\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 7.2862 - val_loss: 4.1395\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.0033 - val_loss: 3.3491\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 6.7794 - val_loss: 2.4490\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.5004 - val_loss: 3.1251\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.7603 - val_loss: 3.0209\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.6467 - val_loss: 3.3150\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.8766 - val_loss: 3.2564\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3af7f3670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 94 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 43.2994 - val_loss: 8.7046\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 30.8782 - val_loss: 20.9135\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 24.8655 - val_loss: 25.3530\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21.5837 - val_loss: 8.5278\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 19.0602 - val_loss: 7.7305\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 14.4989 - val_loss: 11.4775\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.5092 - val_loss: 9.0400\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.3169 - val_loss: 8.5740\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 10.5940 - val_loss: 8.5382\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.1547 - val_loss: 7.6459\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 9.8493 - val_loss: 10.3704\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.2047 - val_loss: 9.5765\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.5497 - val_loss: 7.1757\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.8661 - val_loss: 6.2030\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.1076 - val_loss: 6.8291\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.5430 - val_loss: 6.9632\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5122 - val_loss: 6.2250\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.2821 - val_loss: 6.0305\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5030 - val_loss: 5.7798\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8970 - val_loss: 5.6660\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.9945 - val_loss: 5.4135\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.1569 - val_loss: 5.5141\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.3980 - val_loss: 5.7430\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.6318 - val_loss: 5.8397\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5732 - val_loss: 6.1938\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.5375 - val_loss: 5.9092\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6584 - val_loss: 4.9299\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.6630 - val_loss: 6.0175\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7316 - val_loss: 5.4307\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.6459 - val_loss: 4.9532\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.4375 - val_loss: 4.6286\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5720 - val_loss: 5.3060\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.8141 - val_loss: 5.4938\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.0785 - val_loss: 5.3076\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.9542 - val_loss: 5.5833\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.9917 - val_loss: 5.2160\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.1311 - val_loss: 5.0627\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.4846 - val_loss: 4.3089\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.8902 - val_loss: 4.2250\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.4114 - val_loss: 4.0911\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.3139 - val_loss: 4.1840\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.2878 - val_loss: 4.0360\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3008 - val_loss: 4.0155\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.4281 - val_loss: 4.0772\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5154 - val_loss: 3.8603\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.3710 - val_loss: 4.4039\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.4071 - val_loss: 4.9682\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.2615 - val_loss: 3.8309\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.1887 - val_loss: 3.8817\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.0396 - val_loss: 3.8995\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3c1951160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 95 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 170ms/step - loss: 86.5017 - val_loss: 54.3114\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 51.0362 - val_loss: 37.7073\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 42.3468 - val_loss: 49.3578\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 37.8782 - val_loss: 36.3779\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 32.9983 - val_loss: 31.6535\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 29.7498 - val_loss: 33.4932\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.9737 - val_loss: 20.5761\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20.7164 - val_loss: 10.0264\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.0985 - val_loss: 14.5012\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19.7319 - val_loss: 5.2045\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20.3497 - val_loss: 10.9778\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.8699 - val_loss: 6.7949\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16.9586 - val_loss: 8.8490\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.0948 - val_loss: 7.0957\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.3729 - val_loss: 5.1434\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 18.8882 - val_loss: 6.2827\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.1744 - val_loss: 5.4107\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.5764 - val_loss: 5.5970\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.7048 - val_loss: 5.2794\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.5432 - val_loss: 6.0441\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.4597 - val_loss: 5.1504\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.0490 - val_loss: 5.7461\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 13.7553 - val_loss: 4.8994\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.4470 - val_loss: 7.2554\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.8091 - val_loss: 5.8100\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.3639 - val_loss: 5.7725\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 13.6074 - val_loss: 4.9396\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.7365 - val_loss: 5.9593\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.8248 - val_loss: 5.4865\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.8912 - val_loss: 5.1729\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.5307 - val_loss: 5.0585\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.3174 - val_loss: 4.7640\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.6441 - val_loss: 5.7499\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.1652 - val_loss: 5.1333\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.8228 - val_loss: 5.2041\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 11.7078 - val_loss: 4.9131\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 11.7203 - val_loss: 5.9436\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 11.8227 - val_loss: 4.8521\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.0642 - val_loss: 5.4687\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.9734 - val_loss: 4.9502\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.2138 - val_loss: 6.0241\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.8213 - val_loss: 6.7347\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.1492 - val_loss: 6.4776\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.9947 - val_loss: 6.0573\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.6805 - val_loss: 4.7324\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.9237 - val_loss: 4.9395\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.3630 - val_loss: 5.2168\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0232 - val_loss: 4.7670\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.0767 - val_loss: 4.6835\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.9870 - val_loss: 4.6079\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3dbfbaca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 96 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 198ms/step - loss: 58.4852 - val_loss: 26.0228\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 27.4210 - val_loss: 12.1294\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19.5754 - val_loss: 35.9419\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20.7109 - val_loss: 23.0697\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.3134 - val_loss: 16.0711\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15.3991 - val_loss: 24.5697\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 14.9490 - val_loss: 22.1677\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.5168 - val_loss: 15.5051\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.5360 - val_loss: 18.6149\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.1146 - val_loss: 12.4492\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1304 - val_loss: 10.2269\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.2360 - val_loss: 3.4645\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.8896 - val_loss: 9.7669\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.1115 - val_loss: 9.8719\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.8566 - val_loss: 6.6195\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.5570 - val_loss: 6.8485\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.3455 - val_loss: 7.2812\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.3008 - val_loss: 5.9902\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.1131 - val_loss: 3.7654\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.3515 - val_loss: 4.1468\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.1213 - val_loss: 7.2555\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 6.9640 - val_loss: 3.3485\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6.3615 - val_loss: 3.3599\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 6.1793 - val_loss: 3.2072\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.9698 - val_loss: 5.0709\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.4897 - val_loss: 3.8981\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.6906 - val_loss: 3.3564\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.3699 - val_loss: 3.9351\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.3415 - val_loss: 5.3965\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.2166 - val_loss: 3.3733\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.9836 - val_loss: 3.4996\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 4.8260 - val_loss: 4.5690\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4.9351 - val_loss: 4.0509\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.8203 - val_loss: 3.6519\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7816 - val_loss: 4.7613\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.6609 - val_loss: 5.1665\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.7066 - val_loss: 4.0203\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.8974 - val_loss: 4.4191\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.5636 - val_loss: 4.6214\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.5443 - val_loss: 4.1895\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9130 - val_loss: 4.1308\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.4220 - val_loss: 4.6319\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.7151 - val_loss: 4.8052\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.6436 - val_loss: 3.3256\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.7789 - val_loss: 3.3958\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.9449 - val_loss: 5.4313\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.8715 - val_loss: 4.4867\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4.4110 - val_loss: 3.6659\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.2773 - val_loss: 4.1348\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.2350 - val_loss: 3.8495\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ab559820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 97 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 69.6825 - val_loss: 39.8975\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 25.9887 - val_loss: 13.9119\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24.2185 - val_loss: 12.2692\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.7340 - val_loss: 24.2650\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.5161 - val_loss: 10.8767\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.5636 - val_loss: 3.1251\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.3267 - val_loss: 10.5354\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.5434 - val_loss: 6.1304\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.5241 - val_loss: 3.3745\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.4302 - val_loss: 2.4396\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.2998 - val_loss: 2.8147\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.6978 - val_loss: 3.8272\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.3943 - val_loss: 2.9424\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 5.2010 - val_loss: 6.6588\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 5.3786 - val_loss: 4.7809\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 4.7529 - val_loss: 3.5372\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 4.8982 - val_loss: 2.9444\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 4.9143 - val_loss: 2.5912\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.9162 - val_loss: 7.3486\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5.0476 - val_loss: 4.5806\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 4.4450 - val_loss: 3.4096\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4.3905 - val_loss: 3.4426\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.4170 - val_loss: 2.9922\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.2183 - val_loss: 4.4143\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.1288 - val_loss: 4.6185\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.3729 - val_loss: 5.7104\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.0150 - val_loss: 4.4407\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.8321 - val_loss: 7.7855\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.5591 - val_loss: 3.1075\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4.1504 - val_loss: 4.5670\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3.9713 - val_loss: 7.8216\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5.4399 - val_loss: 3.4125\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4.5712 - val_loss: 3.2444\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.6568 - val_loss: 4.4522\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.9762 - val_loss: 6.2244\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.1534 - val_loss: 6.8208\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.1970 - val_loss: 3.1895\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.8001 - val_loss: 6.7319\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.8813 - val_loss: 6.5944\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.2817 - val_loss: 2.6881\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4.0957 - val_loss: 4.0039\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.8015 - val_loss: 3.9189\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.4585 - val_loss: 5.4433\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.6039 - val_loss: 5.9238\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.8887 - val_loss: 3.6974\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.9022 - val_loss: 4.3338\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3.5278 - val_loss: 5.6657\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.8426 - val_loss: 5.8715\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.2515 - val_loss: 6.3591\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3.3585 - val_loss: 5.6602\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff397a1a670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 98 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 156ms/step - loss: 97.0534 - val_loss: 49.5515\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 50.4130 - val_loss: 21.7185\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 43.1992 - val_loss: 27.2097\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 32.4930 - val_loss: 39.0414\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 26.4774 - val_loss: 16.9054\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23.2824 - val_loss: 14.4069\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.9175 - val_loss: 19.8741\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.3140 - val_loss: 11.2002\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.7201 - val_loss: 12.7145\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.2348 - val_loss: 11.0604\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.1769 - val_loss: 11.5406\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.3149 - val_loss: 12.3877\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.2036 - val_loss: 11.1995\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.7723 - val_loss: 11.1479\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.5216 - val_loss: 10.9781\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.3931 - val_loss: 10.8396\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.1913 - val_loss: 10.6163\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.1824 - val_loss: 11.5841\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.2114 - val_loss: 10.6602\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.3869 - val_loss: 10.8391\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.6159 - val_loss: 10.4958\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.5510 - val_loss: 10.6953\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.1161 - val_loss: 10.3428\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.5263 - val_loss: 10.6909\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.0747 - val_loss: 10.3308\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.9094 - val_loss: 11.7217\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.0760 - val_loss: 10.2091\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.3380 - val_loss: 11.7521\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.9733 - val_loss: 9.8846\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.6504 - val_loss: 9.8665\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.3569 - val_loss: 9.9732\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.6274 - val_loss: 9.7209\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.4255 - val_loss: 10.0762\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.8449 - val_loss: 9.7089\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.8462 - val_loss: 10.3298\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.5470 - val_loss: 9.3742\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.3773 - val_loss: 9.9299\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.6850 - val_loss: 9.7567\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.3879 - val_loss: 10.1432\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.1502 - val_loss: 9.4002\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.0787 - val_loss: 9.4857\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1767 - val_loss: 9.2849\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.8902 - val_loss: 8.9818\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.8935 - val_loss: 10.0774\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.5721 - val_loss: 9.1758\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.9274 - val_loss: 8.9305\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.0979 - val_loss: 8.7838\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.8177 - val_loss: 8.6995\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.2665 - val_loss: 8.5326\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4597 - val_loss: 8.5485\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3aa948ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 99 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 100306.4219 - val_loss: 113.7868\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 275150.2812 - val_loss: 118.3149\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 187794.7188 - val_loss: 108.9480\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33762.1133 - val_loss: 104.8252\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9545.4346 - val_loss: 104.7374\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5662.1895 - val_loss: 105.8691\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32917.7930 - val_loss: 104.0245\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17520.8496 - val_loss: 103.6488\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1381.2733 - val_loss: 107.3559\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 120511.0391 - val_loss: 108.5829\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 99497.4531 - val_loss: 104.0960\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17654.6621 - val_loss: 99.6705\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 102077.3281 - val_loss: 97.4927\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 95976.3594 - val_loss: 100.1252\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12119.6611 - val_loss: 102.9121\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 66552.7578 - val_loss: 103.8946\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58963.4219 - val_loss: 102.9963\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12384.3223 - val_loss: 101.0938\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 58258.3867 - val_loss: 99.8530\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 49668.3359 - val_loss: 101.6005\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20100.0137 - val_loss: 102.3416\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1443.5621 - val_loss: 101.9346\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18482.1191 - val_loss: 101.9893\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11656.1895 - val_loss: 101.2195\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1836.2502 - val_loss: 102.1515\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 36903.1211 - val_loss: 102.7993\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32162.4375 - val_loss: 101.1268\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8358.5127 - val_loss: 101.4119\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3225.5254 - val_loss: 101.0120\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25202.2539 - val_loss: 100.6785\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7850.7705 - val_loss: 101.5246\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4516.0107 - val_loss: 102.0263\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21554.7617 - val_loss: 101.5390\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5028.0640 - val_loss: 99.6778\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 63787.9414 - val_loss: 99.1171\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 58991.4258 - val_loss: 100.5736\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4546.5635 - val_loss: 101.9600\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35018.7773 - val_loss: 102.6138\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 35340.3672 - val_loss: 101.8385\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2613.6147 - val_loss: 101.3538\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22560.1250 - val_loss: 101.8240\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16693.1465 - val_loss: 99.9105\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40753.5430 - val_loss: 99.6761\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 38037.6758 - val_loss: 100.1933\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24484.1836 - val_loss: 102.0836\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26946.2930 - val_loss: 102.1455\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 30436.6387 - val_loss: 101.8446\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 724.4456 - val_loss: 100.1601\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41349.5586 - val_loss: 99.2949\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 45090.7383 - val_loss: 100.1206\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3aa69c8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 100 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 85.9500 - val_loss: 63.3111\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35.4162 - val_loss: 7.4360\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23.4325 - val_loss: 21.3157\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.3610 - val_loss: 31.5208\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.7896 - val_loss: 15.8645\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 15.7416 - val_loss: 12.9691\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.0501 - val_loss: 23.1352\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.7506 - val_loss: 19.9988\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.5991 - val_loss: 11.0100\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.8690 - val_loss: 14.6261\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.7510 - val_loss: 16.2884\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.3530 - val_loss: 10.7105\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0211 - val_loss: 11.8559\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.0680 - val_loss: 6.9909\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3348 - val_loss: 6.5921\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.2270 - val_loss: 10.0887\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.8589 - val_loss: 5.0805\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.9916 - val_loss: 4.5650\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.2681 - val_loss: 4.2453\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.6766 - val_loss: 5.1369\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4.8138 - val_loss: 4.0068\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.8046 - val_loss: 5.1683\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.1946 - val_loss: 5.9860\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.3462 - val_loss: 3.9537\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4.7781 - val_loss: 3.9102\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4.4015 - val_loss: 7.1049\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.6085 - val_loss: 5.0805\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.8977 - val_loss: 4.5578\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3.7936 - val_loss: 4.2754\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.8562 - val_loss: 4.5307\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.6911 - val_loss: 3.9116\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.5158 - val_loss: 3.8521\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.3627 - val_loss: 3.8170\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 3.3411 - val_loss: 3.8616\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.2398 - val_loss: 3.7100\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.2613 - val_loss: 3.6915\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.2339 - val_loss: 3.7200\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.1629 - val_loss: 3.8499\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.4434 - val_loss: 4.3056\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.4299 - val_loss: 3.5704\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.0564 - val_loss: 4.1062\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.3979 - val_loss: 3.7475\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3.2785 - val_loss: 4.6133\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 3.1892 - val_loss: 4.2296\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3.4931 - val_loss: 3.8669\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3.4419 - val_loss: 5.2944\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.5775 - val_loss: 4.0150\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3.0508 - val_loss: 3.7199\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.3768 - val_loss: 4.5038\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.4015 - val_loss: 4.3023\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff411c0db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 101 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 52.8304 - val_loss: 24.6674\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 40.0360 - val_loss: 31.1465\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 31.2250 - val_loss: 43.4862\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29.9374 - val_loss: 32.3105\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25.7451 - val_loss: 20.6282\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 22.9852 - val_loss: 25.3833\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.4894 - val_loss: 6.8700\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.4720 - val_loss: 13.1551\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 15.1903 - val_loss: 3.4497\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.4372 - val_loss: 9.4106\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.3935 - val_loss: 2.4204\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.5928 - val_loss: 2.9583\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.1410 - val_loss: 4.7364\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.4675 - val_loss: 2.5002\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.7971 - val_loss: 3.1598\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.4703 - val_loss: 2.6432\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.8897 - val_loss: 5.7126\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.3990 - val_loss: 3.4756\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.1190 - val_loss: 3.7452\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6715 - val_loss: 3.4363\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.1638 - val_loss: 2.6232\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.1695 - val_loss: 3.4677\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.5103 - val_loss: 3.8902\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.0747 - val_loss: 3.8001\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0715 - val_loss: 2.2050\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.4909 - val_loss: 2.6354\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.2708 - val_loss: 3.7009\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.2800 - val_loss: 3.1957\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.9845 - val_loss: 3.6759\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.3051 - val_loss: 4.2009\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.4807 - val_loss: 3.1647\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.5874 - val_loss: 1.7929\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.5567 - val_loss: 2.4861\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.9787 - val_loss: 4.3500\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.4993 - val_loss: 2.9852\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0907 - val_loss: 3.9261\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.0573 - val_loss: 2.5379\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.0901 - val_loss: 1.8225\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.6301 - val_loss: 3.5232\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.1560 - val_loss: 2.4350\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.1730 - val_loss: 1.5467\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.9052 - val_loss: 2.7530\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.1178 - val_loss: 2.3658\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8783 - val_loss: 3.4908\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.5770 - val_loss: 3.8116\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.1538 - val_loss: 2.2683\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5.4997 - val_loss: 1.4579\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 5.2690 - val_loss: 1.6385\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.3940 - val_loss: 3.1842\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5.4942 - val_loss: 1.6314\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3bf36b3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 102 finished\n"
     ]
    }
   ],
   "source": [
    "zipcodes = nv_zipcodes\n",
    "dict_mape2 = {}\n",
    "dict_pred2 = {}\n",
    "\n",
    "for zipcode in range(len(zipcodes)):\n",
    "\n",
    "    # init a RMM model\n",
    "    rnn_model2 = Sequential()\n",
    "    # add 4 layers of RNN and a last layer\n",
    "\n",
    "    # we define shape on first layer, (60,1) because we use 60 inputs per prediction\n",
    "    rnn_model2.add(LSTM(units= 60, return_sequences = True, input_shape=((60,1))))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # another layer\n",
    "    rnn_model2.add(LSTM(units= 30, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # return_sequence is False because we want only 1 output after this layer\n",
    "    #rnn_model.add(LSTM(units= 60, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # last layer \n",
    "\n",
    "    rnn_model2.add(Dense(units=1))\n",
    "\n",
    "    # compile - because this is a regression model we want to minimize MSE\n",
    "\n",
    "    rnn_model2.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "\n",
    "    # We get only the specific column(Zipcode from our train and test datas)\n",
    "    train_data = train.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    test_data = test.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # We are using normalizaion rather than standascaler. \n",
    "    # In a upward trending timeseries it is better to not start from negative\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Because we are using 60 previous values to model and predict the next value, \n",
    "    # We set X_train from arrays of 60 for each y_train value\n",
    "    # Same idea for test data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(train_data_scaled)):\n",
    "        X_train.append(train_data_scaled[i-60:i])\n",
    "        y_train.append(train_data_scaled[i])\n",
    "\n",
    "    data_total = pd.concat((train.iloc[:,zipcode:zipcode+1], test.iloc[:,zipcode:zipcode+1]),axis=0)\n",
    "    inputs = data_total[len(train)-60:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(60,len(inputs)):\n",
    "        X_test.append(inputs[i-60:i])\n",
    "        y_test.append(inputs[i])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(test_data)\n",
    "\n",
    "    # We need numpy arrays for our model\n",
    "    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # We fit our data to our zipcode specific data\n",
    "    rnn_model2.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, scaler.transform(y_test)))\n",
    "\n",
    "    # Make predictions on the data\n",
    "\n",
    "    y_hat_raw = rnn_model2.predict(X_test)\n",
    "    y_hat = scaler.inverse_transform(y_hat_raw)\n",
    "\n",
    "    # Use the score on unseen test data to calculate the MAPE\n",
    "\n",
    "    dict_mape2[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_test)/y_test))      \n",
    "\n",
    "    # We get the last 60 values from our test data which is basically last 60 values in the data set\n",
    "    last_60 = df_time_series.iloc[-60:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # Before we use our data we scale it\n",
    "    last_60 = scaler.transform(last_60)\n",
    "    \n",
    "    # Our input should be in (x,60,1) format\n",
    "    x_new_pred = last_60[-60:].reshape(1,60,1)\n",
    "\n",
    "    # make a prediction, add to the last_60 for the next prediction and \n",
    "    y_pred = rnn_model2.predict(x_new_pred)\n",
    "\n",
    "    # We add our predition to our list of predictions for zipcode specific predictions list\n",
    "    dict_pred2[zipcodes[zipcode]]=scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(f'Iteration number {zipcode} finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_keys2 = list(dict_mape2.keys())\n",
    "rnn_mape2 = list(dict_mape2.values())\n",
    "rnn_pred2 = []\n",
    "rnn_dict2 = {}\n",
    "for zipcode in dict_pred.keys():\n",
    "    rnn_pred2.append(dict_pred2[zipcode].astype(int)[0][0])\n",
    "for zc in rnn_keys2:\n",
    "    a = []\n",
    "    a.append(dict_mape2[zc])\n",
    "    a.append(dict_pred2[zc].astype(float)[0][0])\n",
    "    a.append('RNN_2_Layers')\n",
    "    rnn_dict2[zc] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.212287749143073"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_mape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 52016.1211 - val_loss: 113.7216\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50165.5117 - val_loss: 115.7706\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28076.3262 - val_loss: 112.3766\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 67557.5391 - val_loss: 107.6866\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 70017.3672 - val_loss: 109.9577\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2236.9082 - val_loss: 114.7591\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 102063.4922 - val_loss: 115.2341\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28462.8789 - val_loss: 112.9223\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22563.2441 - val_loss: 110.8390\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5614.8491 - val_loss: 114.0143\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47058.4102 - val_loss: 114.2548\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 78794.3516 - val_loss: 112.5830\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13589.6221 - val_loss: 109.8695\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 73464.8359 - val_loss: 108.2823\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 77026.4922 - val_loss: 111.4532\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10647.3154 - val_loss: 112.1064\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 21921.5098 - val_loss: 112.8268\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22997.9023 - val_loss: 112.3221\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15800.5186 - val_loss: 110.6962\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22597.2461 - val_loss: 111.0348\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16261.1035 - val_loss: 112.0585\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3033.6504 - val_loss: 112.8024\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 51667.0234 - val_loss: 110.8046\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53352.3047 - val_loss: 110.5692\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5845.7441 - val_loss: 112.0803\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53403.2227 - val_loss: 112.5464\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19734.9492 - val_loss: 110.4680\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41878.3594 - val_loss: 110.4630\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39695.1328 - val_loss: 111.9713\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16500.2676 - val_loss: 112.2014\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13606.1035 - val_loss: 110.2662\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17293.4785 - val_loss: 110.0774\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12915.3467 - val_loss: 111.7061\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8780.6719 - val_loss: 113.3724\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 119497.3516 - val_loss: 114.0390\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 76402.6094 - val_loss: 112.7641\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6116.4072 - val_loss: 111.0494\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14942.3672 - val_loss: 107.2647\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 117723.0781 - val_loss: 106.4797\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 134208.4531 - val_loss: 107.6763\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 106358.2734 - val_loss: 109.6935\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6351.2544 - val_loss: 111.2612\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 79465.3984 - val_loss: 112.1776\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64971.8555 - val_loss: 109.8241\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3442.4568 - val_loss: 109.3410\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5156.3711 - val_loss: 109.9686\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22490.7559 - val_loss: 110.2738\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24553.9434 - val_loss: 109.2532\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4726.9253 - val_loss: 109.3929\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3887.8240 - val_loss: 110.3253\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ca332b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 0 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 82861.4531 - val_loss: 106.2994\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 305459.0938 - val_loss: 104.8370\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 97951.6875 - val_loss: 100.9208\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 131291.0469 - val_loss: 109.6119\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 256069.1094 - val_loss: 108.5155\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 158430.4531 - val_loss: 101.4966\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 182884.5625 - val_loss: 99.7648\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 149248.0781 - val_loss: 102.9883\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53814.1055 - val_loss: 106.5610\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 99782.2422 - val_loss: 103.1034\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 113790.4062 - val_loss: 102.5235\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 50189.6445 - val_loss: 104.0331\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 88457.4688 - val_loss: 103.7098\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 79864.3203 - val_loss: 103.5948\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38720.7617 - val_loss: 102.6712\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 142841.3906 - val_loss: 102.6711\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50588.0078 - val_loss: 102.1904\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 76271.1484 - val_loss: 104.0602\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 58114.1836 - val_loss: 102.9291\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31765.9707 - val_loss: 103.5097\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 51994.6055 - val_loss: 102.3861\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 72709.8516 - val_loss: 102.9717\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44948.1172 - val_loss: 104.2285\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33931.8828 - val_loss: 102.7929\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 82238.2500 - val_loss: 102.7784\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 55508.8438 - val_loss: 105.1266\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 100676.3125 - val_loss: 103.9150\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9006.3867 - val_loss: 100.1532\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 310690.9688 - val_loss: 99.4771\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 288636.0312 - val_loss: 102.2627\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 83999.8984 - val_loss: 104.9792\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 92669.1016 - val_loss: 104.6680\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43583.8203 - val_loss: 103.7082\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17037.5352 - val_loss: 104.8016\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43612.8789 - val_loss: 103.8455\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26106.6309 - val_loss: 103.3412\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 82409.6172 - val_loss: 104.7379\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18901.7148 - val_loss: 104.2072\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57308.0781 - val_loss: 102.6904\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 96705.5547 - val_loss: 103.5754\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30813.1914 - val_loss: 102.7906\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50375.4141 - val_loss: 103.5749\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29881.8711 - val_loss: 103.4649\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 63238.8242 - val_loss: 102.5919\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46003.0273 - val_loss: 104.0300\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 63061.2383 - val_loss: 103.4782\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24081.1699 - val_loss: 103.8337\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32795.9297 - val_loss: 104.0405\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17363.5020 - val_loss: 103.6140\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12747.0186 - val_loss: 101.1110\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3aa965820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 1 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 97ms/step - loss: 92.3927 - val_loss: 77.4427\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 58.2944 - val_loss: 46.3274\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 50.5866 - val_loss: 40.0130\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40.2457 - val_loss: 41.2794\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.3071 - val_loss: 35.6276\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.8754 - val_loss: 22.5384\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.3981 - val_loss: 21.4953\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24.2371 - val_loss: 21.2741\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.0914 - val_loss: 11.1481\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.4439 - val_loss: 11.5743\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.9095 - val_loss: 7.7519\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18.4876 - val_loss: 3.5213\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.0627 - val_loss: 10.7026\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.7387 - val_loss: 4.7030\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.6657 - val_loss: 3.5200\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.9738 - val_loss: 6.3724\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.5278 - val_loss: 7.3521\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.5672 - val_loss: 2.9835\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.3503 - val_loss: 7.8770\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.4916 - val_loss: 5.0221\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.9902 - val_loss: 2.2744\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.3175 - val_loss: 6.5476\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.1784 - val_loss: 2.7625\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.1377 - val_loss: 3.3061\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.9745 - val_loss: 3.1463\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.2133 - val_loss: 4.4820\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.7228 - val_loss: 4.0227\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.6647 - val_loss: 3.7730\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2597 - val_loss: 7.6001\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0500 - val_loss: 3.3529\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6145 - val_loss: 3.2266\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1572 - val_loss: 5.8173\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3258 - val_loss: 2.7407\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3799 - val_loss: 4.5479\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9550 - val_loss: 5.9800\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.5853 - val_loss: 2.0207\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.0106 - val_loss: 2.8651\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2763 - val_loss: 4.2410\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5468 - val_loss: 4.9998\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6615 - val_loss: 5.2602\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1118 - val_loss: 1.9287\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0187 - val_loss: 4.8128\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3566 - val_loss: 1.7868\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5559 - val_loss: 4.3230\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.5712 - val_loss: 4.0962\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.6751 - val_loss: 1.8247\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.4916 - val_loss: 4.0146\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8835 - val_loss: 4.8604\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0929 - val_loss: 3.3193\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8369 - val_loss: 3.7323\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39df18700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 2 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 105.5995 - val_loss: 83.9538\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55.6670 - val_loss: 36.0232\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.3928 - val_loss: 3.3714\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31.4017 - val_loss: 23.1069\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23.7547 - val_loss: 33.7671\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22.1733 - val_loss: 26.8822\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.8571 - val_loss: 17.0674\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.4085 - val_loss: 15.5303\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.5451 - val_loss: 16.5138\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.3225 - val_loss: 13.2624\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.8601 - val_loss: 9.9043\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.4305 - val_loss: 7.5976\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.8109 - val_loss: 5.8258\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.8532 - val_loss: 7.6243\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.7909 - val_loss: 5.6992\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8347 - val_loss: 4.2262\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.6325 - val_loss: 6.1206\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.3505 - val_loss: 6.3080\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4488 - val_loss: 3.2964\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5817 - val_loss: 5.4725\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7914 - val_loss: 2.4871\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.3288 - val_loss: 5.1443\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4460 - val_loss: 2.6315\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8373 - val_loss: 4.1032\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6746 - val_loss: 2.4943\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7000 - val_loss: 4.6714\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4369 - val_loss: 2.3371\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2187 - val_loss: 5.4778\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3077 - val_loss: 2.3989\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9467 - val_loss: 4.1677\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8891 - val_loss: 3.7674\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6682 - val_loss: 2.4987\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2496 - val_loss: 4.6047\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5338 - val_loss: 2.3341\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2974 - val_loss: 2.9870\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0524 - val_loss: 2.4802\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9259 - val_loss: 2.4968\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2323 - val_loss: 3.3843\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4117 - val_loss: 2.3577\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8667 - val_loss: 2.3261\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7093 - val_loss: 2.3322\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8940 - val_loss: 3.0518\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3249 - val_loss: 2.4289\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.6542 - val_loss: 5.8593\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.3546 - val_loss: 3.0121\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9486 - val_loss: 3.4936\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8306 - val_loss: 2.3033\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2271 - val_loss: 3.0031\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5527 - val_loss: 2.6701\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1172 - val_loss: 3.2618\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a388d3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 3 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 95.0896 - val_loss: 82.5611\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 62.7207 - val_loss: 56.2026\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54.4244 - val_loss: 43.2023\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45.5065 - val_loss: 42.0068\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35.7674 - val_loss: 32.2355\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.9332 - val_loss: 17.8591\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26.0486 - val_loss: 22.8261\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23.2187 - val_loss: 12.5077\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.5543 - val_loss: 10.0472\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.5906 - val_loss: 9.0675\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.8221 - val_loss: 6.6978\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.5569 - val_loss: 5.5098\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.0355 - val_loss: 5.0084\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4418 - val_loss: 5.1018\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.8226 - val_loss: 6.6006\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.1741 - val_loss: 4.0012\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.9933 - val_loss: 4.4393\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.1454 - val_loss: 5.7220\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.9636 - val_loss: 3.6205\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.9065 - val_loss: 7.4568\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.6554 - val_loss: 3.4675\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.4320 - val_loss: 5.7136\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4374 - val_loss: 5.2671\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.5791 - val_loss: 3.3429\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.4110 - val_loss: 6.2194\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.3620 - val_loss: 3.6686\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.4538 - val_loss: 3.8164\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.9706 - val_loss: 5.8806\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.7459 - val_loss: 4.3151\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.9645 - val_loss: 3.7773\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2638 - val_loss: 4.2242\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9884 - val_loss: 4.3943\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8200 - val_loss: 3.3389\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8350 - val_loss: 3.7408\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5437 - val_loss: 5.4926\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5798 - val_loss: 3.6810\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9483 - val_loss: 3.4303\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1301 - val_loss: 3.8884\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.1351 - val_loss: 3.3129\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.0297 - val_loss: 4.7024\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9321 - val_loss: 4.7519\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1249 - val_loss: 3.3193\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6607 - val_loss: 3.0523\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6157 - val_loss: 4.0028\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8482 - val_loss: 3.4952\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3261 - val_loss: 3.8332\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2628 - val_loss: 3.2125\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8055 - val_loss: 3.2076\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.5932 - val_loss: 3.6881\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.0265 - val_loss: 3.1051\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff385420940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 4 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 108711.4688 - val_loss: 85.9681\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45410.4414 - val_loss: 97.6191\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 138629.7031 - val_loss: 98.9095\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 125903.0234 - val_loss: 96.0263\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 80462.6250 - val_loss: 91.1485\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48961.9453 - val_loss: 89.3191\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32416.5820 - val_loss: 94.1193\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 62341.8477 - val_loss: 94.1818\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 41399.5742 - val_loss: 93.2249\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7606.7803 - val_loss: 90.8237\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56459.4922 - val_loss: 88.4690\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 99361.6016 - val_loss: 90.6911\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25070.3555 - val_loss: 94.6096\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 66109.9688 - val_loss: 96.2258\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20797.2324 - val_loss: 94.3882\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 178.4835 - val_loss: 92.4415\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12552.1064 - val_loss: 94.1527\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3126.4233 - val_loss: 96.2067\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 89146.9922 - val_loss: 98.7198\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 110681.1562 - val_loss: 96.4018\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5200.7910 - val_loss: 94.9614\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 685.5500 - val_loss: 96.3519\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 79430.7344 - val_loss: 97.3870\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30220.0469 - val_loss: 95.9571\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39950.4688 - val_loss: 92.5256\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 78878.9141 - val_loss: 91.5869\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 63403.8086 - val_loss: 92.3094\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1876.4601 - val_loss: 92.9273\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42772.8906 - val_loss: 93.8246\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6545.1421 - val_loss: 93.9161\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43906.0117 - val_loss: 93.0302\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35453.3125 - val_loss: 94.8404\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9918.0869 - val_loss: 94.8679\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12556.9131 - val_loss: 93.4213\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40143.1250 - val_loss: 92.9698\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9732.4580 - val_loss: 94.8498\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14829.6943 - val_loss: 95.4548\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20232.3457 - val_loss: 94.3681\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29682.4941 - val_loss: 94.2073\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6291.9624 - val_loss: 95.7654\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25266.4473 - val_loss: 96.8362\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37447.5586 - val_loss: 95.9804\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6590.7988 - val_loss: 94.2174\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5182.1445 - val_loss: 90.5707\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 87659.3594 - val_loss: 89.5215\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 131691.8906 - val_loss: 90.5891\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46776.5234 - val_loss: 92.2092\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28159.0293 - val_loss: 94.5710\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10654.0303 - val_loss: 95.7717\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5306.7329 - val_loss: 94.4103\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff420c99550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 5 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 78879.6484 - val_loss: 98.5519\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 77862.2734 - val_loss: 96.2649\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1272.2100 - val_loss: 96.3632\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60652.2227 - val_loss: 98.3564\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 54441.6875 - val_loss: 97.5147\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 38751.7773 - val_loss: 92.6957\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 100402.8828 - val_loss: 90.8049\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 73532.2109 - val_loss: 93.0099\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30944.5156 - val_loss: 95.3083\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14799.7695 - val_loss: 100.5302\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 126459.1016 - val_loss: 101.7026\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 111011.7266 - val_loss: 100.6256\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 63913.9531 - val_loss: 99.1935\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9935.1533 - val_loss: 95.3028\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 131161.2656 - val_loss: 93.0796\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 81937.9922 - val_loss: 95.1369\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 58784.7500 - val_loss: 99.2657\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12988.1992 - val_loss: 102.9463\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 98894.5234 - val_loss: 103.8784\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 92931.1328 - val_loss: 103.7319\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 107056.9062 - val_loss: 101.0129\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46110.6953 - val_loss: 98.3871\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 50260.5781 - val_loss: 97.2956\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57728.1523 - val_loss: 98.2857\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12763.3174 - val_loss: 100.0632\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31455.5430 - val_loss: 100.5303\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19316.0820 - val_loss: 99.6874\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7276.5674 - val_loss: 99.6985\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11807.6436 - val_loss: 99.3795\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25336.9355 - val_loss: 99.5363\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5755.3613 - val_loss: 100.9029\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35147.5469 - val_loss: 100.7982\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29812.8711 - val_loss: 99.7192\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23205.5996 - val_loss: 99.3866\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35702.6758 - val_loss: 100.5251\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40248.9023 - val_loss: 100.3326\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8961.3525 - val_loss: 99.1905\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33527.2148 - val_loss: 99.0115\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8001.9390 - val_loss: 99.7946\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7024.0649 - val_loss: 100.7342\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25041.6816 - val_loss: 100.3023\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12963.0195 - val_loss: 99.6352\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16977.2441 - val_loss: 99.3309\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6102.2822 - val_loss: 99.1447\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17667.4375 - val_loss: 99.9758\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 4058.9934 - val_loss: 99.5195\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23194.6270 - val_loss: 99.7014\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26971.2852 - val_loss: 101.1047\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49314.7930 - val_loss: 101.3696\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32159.8164 - val_loss: 100.4853\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a6adaaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 6 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 92.9540 - val_loss: 80.1879\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 62.1068 - val_loss: 48.4270\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54.7315 - val_loss: 38.8638\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.7162 - val_loss: 38.6406\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.7375 - val_loss: 19.5008\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28.0183 - val_loss: 15.2523\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25.9393 - val_loss: 9.8335\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24.3440 - val_loss: 5.8605\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.1264 - val_loss: 13.0183\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.4221 - val_loss: 4.0523\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.4755 - val_loss: 6.7937\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17.7614 - val_loss: 4.1463\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16.6109 - val_loss: 3.2454\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.6992 - val_loss: 8.4225\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.7096 - val_loss: 3.8187\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.6156 - val_loss: 5.9683\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.7200 - val_loss: 9.0834\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15.2353 - val_loss: 3.3366\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.2746 - val_loss: 7.5159\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.8885 - val_loss: 8.2867\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.4580 - val_loss: 3.6391\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.6919 - val_loss: 5.8733\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.2297 - val_loss: 1.7102\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.7499 - val_loss: 2.1288\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.8542 - val_loss: 6.6790\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.5464 - val_loss: 2.8723\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.3123 - val_loss: 4.4664\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.4090 - val_loss: 2.7416\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.9231 - val_loss: 2.5407\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.0510 - val_loss: 5.2473\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.5347 - val_loss: 2.3756\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.3405 - val_loss: 2.5833\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8649 - val_loss: 6.0706\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5710 - val_loss: 4.3746\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.1291 - val_loss: 2.5621\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4760 - val_loss: 4.7654\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.0932 - val_loss: 4.9793\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8540 - val_loss: 5.1770\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4026 - val_loss: 4.2185\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.4878 - val_loss: 2.9432\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6710 - val_loss: 3.8096\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1526 - val_loss: 5.4762\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4653 - val_loss: 4.0658\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1078 - val_loss: 3.6170\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4200 - val_loss: 7.5904\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.4202 - val_loss: 4.2872\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0999 - val_loss: 1.9484\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9549 - val_loss: 4.9099\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3796 - val_loss: 4.8640\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9934 - val_loss: 2.9682\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3c078f430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 7 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 58645.6445 - val_loss: 104.2456\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 83680.5312 - val_loss: 99.8450\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25700.8789 - val_loss: 92.7860\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45246.4062 - val_loss: 92.9083\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29691.6406 - val_loss: 96.1928\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12278.1318 - val_loss: 100.5234\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 75759.8516 - val_loss: 100.9375\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 48691.0742 - val_loss: 97.4674\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14121.4043 - val_loss: 92.3779\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 100529.2969 - val_loss: 90.6138\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 103615.1250 - val_loss: 93.3810\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45706.9648 - val_loss: 97.2080\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 63709.5312 - val_loss: 97.6137\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 38675.2109 - val_loss: 95.3356\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18553.7559 - val_loss: 95.3212\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17342.3340 - val_loss: 95.4280\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28550.5098 - val_loss: 94.3040\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6640.9468 - val_loss: 96.7335\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28309.8711 - val_loss: 96.9581\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35519.9180 - val_loss: 95.2250\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19472.8809 - val_loss: 92.6877\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 88513.3984 - val_loss: 91.5466\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 56465.9414 - val_loss: 92.2923\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 52006.6445 - val_loss: 96.5113\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33642.7109 - val_loss: 97.2439\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45656.6914 - val_loss: 96.8313\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37012.0195 - val_loss: 94.2505\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16744.9707 - val_loss: 93.6407\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39531.9727 - val_loss: 94.2058\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3026.1399 - val_loss: 96.4948\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 57163.4609 - val_loss: 97.1532\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43819.6133 - val_loss: 96.4415\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 57037.2383 - val_loss: 94.2712\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31016.4941 - val_loss: 93.6198\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43163.2148 - val_loss: 94.9104\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10175.2598 - val_loss: 94.8636\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4983.0610 - val_loss: 95.5133\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17836.5996 - val_loss: 95.1572\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 643.0485 - val_loss: 95.8078\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30606.7461 - val_loss: 95.8052\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6569.8184 - val_loss: 94.9510\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37921.9062 - val_loss: 94.8036\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10689.6689 - val_loss: 93.9095\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9351.9111 - val_loss: 93.7393\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31492.5430 - val_loss: 94.8349\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1741.4137 - val_loss: 96.8988\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 62702.0508 - val_loss: 97.2833\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 59075.4805 - val_loss: 96.0083\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28695.5586 - val_loss: 94.3657\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15888.3623 - val_loss: 93.5461\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d595d280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 8 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 87.4612 - val_loss: 71.9657\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 61.4513 - val_loss: 48.5621\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52.0775 - val_loss: 49.2336\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.6507 - val_loss: 41.5136\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34.9033 - val_loss: 26.9173\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.1728 - val_loss: 25.9366\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26.9039 - val_loss: 21.0996\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24.3195 - val_loss: 13.5265\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.4751 - val_loss: 9.7057\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.5489 - val_loss: 5.6460\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.3075 - val_loss: 5.8983\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19.1614 - val_loss: 5.2276\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17.8478 - val_loss: 3.6456\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.1790 - val_loss: 4.7776\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15.2100 - val_loss: 4.1872\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.5224 - val_loss: 3.6663\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.4167 - val_loss: 4.0130\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.9732 - val_loss: 4.8886\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.3319 - val_loss: 8.5572\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.3519 - val_loss: 3.4665\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15.0759 - val_loss: 6.0194\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.5813 - val_loss: 3.9194\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.5801 - val_loss: 4.2415\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.3344 - val_loss: 3.0378\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.9523 - val_loss: 3.3233\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.5550 - val_loss: 3.3425\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.6183 - val_loss: 3.4190\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.9850 - val_loss: 5.2679\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.9667 - val_loss: 3.3853\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2473 - val_loss: 4.8046\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.2583 - val_loss: 2.7426\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.1240 - val_loss: 2.5676\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5015 - val_loss: 6.3333\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.4458 - val_loss: 4.2881\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.7542 - val_loss: 3.2610\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.5390 - val_loss: 2.4532\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.6343 - val_loss: 3.9519\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1306 - val_loss: 2.6023\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.8334 - val_loss: 3.2039\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5420 - val_loss: 3.2250\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9786 - val_loss: 2.9695\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.2037 - val_loss: 2.6659\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.8548 - val_loss: 3.2639\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4311 - val_loss: 3.1271\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.8377 - val_loss: 5.0964\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.5565 - val_loss: 2.8303\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8094 - val_loss: 2.4147\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.0660 - val_loss: 3.3978\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.4173 - val_loss: 5.0380\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.3712 - val_loss: 2.4562\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3aa69caf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 9 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 18192.9922 - val_loss: 89.1753\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 232140.7344 - val_loss: 85.3432\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 194276.7969 - val_loss: 91.7700\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 92369.0156 - val_loss: 98.7116\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24326.0059 - val_loss: 100.0740\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33629.9102 - val_loss: 97.6699\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36639.3398 - val_loss: 97.2771\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32940.5820 - val_loss: 99.1027\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9592.4258 - val_loss: 99.0741\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13064.8564 - val_loss: 100.2386\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28588.0293 - val_loss: 99.7449\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15842.0742 - val_loss: 97.0381\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25352.3379 - val_loss: 97.5819\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 519.5812 - val_loss: 96.4958\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 59678.4258 - val_loss: 95.8879\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51523.4961 - val_loss: 100.3631\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49342.6797 - val_loss: 101.5197\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 49149.1797 - val_loss: 100.0821\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9408.9971 - val_loss: 97.8583\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 54827.2695 - val_loss: 96.3440\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 79023.9375 - val_loss: 98.0050\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 51061.5742 - val_loss: 100.5798\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49120.2070 - val_loss: 101.4475\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31429.5723 - val_loss: 99.1212\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16842.0996 - val_loss: 98.8567\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9415.3135 - val_loss: 99.6768\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11567.3135 - val_loss: 99.0279\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13233.7344 - val_loss: 99.7185\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18527.6719 - val_loss: 99.3908\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3717.3589 - val_loss: 99.4792\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10673.7578 - val_loss: 102.7632\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49748.9492 - val_loss: 103.0455\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46904.3789 - val_loss: 102.4311\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53319.5742 - val_loss: 99.5477\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 43164.4609 - val_loss: 98.4613\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37766.0234 - val_loss: 101.4914\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 50712.5859 - val_loss: 102.6990\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 72181.9219 - val_loss: 100.7046\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18597.3066 - val_loss: 100.6302\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7310.6636 - val_loss: 101.2098\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 61320.3086 - val_loss: 102.3754\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 49201.5664 - val_loss: 100.5830\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9659.8838 - val_loss: 98.4796\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 63700.1445 - val_loss: 98.0531\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 52464.4883 - val_loss: 99.1776\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25849.4805 - val_loss: 101.3829\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30375.2988 - val_loss: 102.2257\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12563.9834 - val_loss: 100.9336\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8733.4248 - val_loss: 99.8290\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14544.9834 - val_loss: 100.2916\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ba0e94c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 10 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 49845.1250 - val_loss: 125.5590\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56221.8359 - val_loss: 122.0271\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49047.2227 - val_loss: 124.4425\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14937.1299 - val_loss: 122.7948\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6281.8999 - val_loss: 125.5510\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 76135.7891 - val_loss: 124.3209\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45215.3672 - val_loss: 126.7413\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 131680.5469 - val_loss: 127.8920\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50730.8242 - val_loss: 123.8158\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15139.5146 - val_loss: 125.2120\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51850.7617 - val_loss: 123.9725\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11297.1904 - val_loss: 123.3681\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 44504.5938 - val_loss: 123.4448\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29242.7832 - val_loss: 119.7781\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 104760.1719 - val_loss: 120.5544\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 44708.6133 - val_loss: 123.3553\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 68746.1719 - val_loss: 122.7038\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30290.9941 - val_loss: 121.9507\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42633.4414 - val_loss: 123.2458\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47494.2812 - val_loss: 121.5498\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46566.9023 - val_loss: 120.1939\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13184.0342 - val_loss: 121.7693\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47163.1367 - val_loss: 120.9312\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 79752.3828 - val_loss: 119.6104\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36128.9883 - val_loss: 122.3395\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 127868.3281 - val_loss: 123.4921\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 53388.6602 - val_loss: 120.1690\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27250.7891 - val_loss: 118.8885\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61666.8008 - val_loss: 119.5261\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28165.1484 - val_loss: 120.8813\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47331.8867 - val_loss: 120.1394\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28092.9277 - val_loss: 118.7524\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18151.9238 - val_loss: 119.2594\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7359.4771 - val_loss: 121.3577\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 123632.8828 - val_loss: 121.3149\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 52125.7500 - val_loss: 118.3376\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 64117.0742 - val_loss: 117.0875\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 78225.5234 - val_loss: 118.9274\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36494.8320 - val_loss: 119.1086\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36514.0820 - val_loss: 117.2217\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45527.5039 - val_loss: 116.6937\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42231.7109 - val_loss: 118.4090\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41155.7852 - val_loss: 121.2557\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 124036.7734 - val_loss: 121.7187\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 121986.0234 - val_loss: 119.2155\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25745.3691 - val_loss: 114.9790\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 168376.5781 - val_loss: 113.2929\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 172784.5000 - val_loss: 113.6402\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 88588.3516 - val_loss: 115.6376\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31076.5957 - val_loss: 118.0427\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff407a55b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 11 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 295048.1875 - val_loss: 84.5062\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 70526.1484 - val_loss: 92.5880\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 190890.5625 - val_loss: 91.9581\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 59757.7617 - val_loss: 85.8962\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 98936.1016 - val_loss: 84.2721\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 84590.0312 - val_loss: 87.4943\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 43936.6523 - val_loss: 91.2254\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 87146.0469 - val_loss: 90.4572\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38961.8086 - val_loss: 87.4558\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25924.1426 - val_loss: 87.0771\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 95743.5703 - val_loss: 88.9444\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36230.7148 - val_loss: 92.6308\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 85443.4844 - val_loss: 92.0116\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22517.1797 - val_loss: 90.1819\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 55542.7617 - val_loss: 88.8133\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 59119.3164 - val_loss: 90.3656\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42432.5703 - val_loss: 93.4954\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 72454.9219 - val_loss: 92.5533\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 19128.9844 - val_loss: 91.3925\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16096.5020 - val_loss: 91.8056\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29544.0430 - val_loss: 90.7489\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36790.1211 - val_loss: 92.8667\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 58392.1055 - val_loss: 95.4538\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 113998.6719 - val_loss: 92.2389\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45697.4102 - val_loss: 87.8432\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 304519.1250 - val_loss: 86.3574\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 189810.5469 - val_loss: 90.1113\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22981.7734 - val_loss: 93.6743\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 86313.2422 - val_loss: 94.6844\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 120419.4375 - val_loss: 92.9587\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57606.7227 - val_loss: 91.3294\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15694.9014 - val_loss: 90.9128\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37050.7891 - val_loss: 92.8264\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31831.8262 - val_loss: 93.2214\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40853.1367 - val_loss: 92.0102\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 100607.8516 - val_loss: 90.6149\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 45597.4492 - val_loss: 92.8991\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 56341.8008 - val_loss: 94.2792\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 59556.3555 - val_loss: 93.1676\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5417.3550 - val_loss: 91.4650\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 105019.1328 - val_loss: 91.6841\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43915.2266 - val_loss: 94.0140\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29832.8164 - val_loss: 94.9725\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 50186.0703 - val_loss: 92.9470\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35056.3867 - val_loss: 92.8924\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22371.1016 - val_loss: 95.2605\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41889.1719 - val_loss: 95.1798\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 63064.1836 - val_loss: 93.8321\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23495.9219 - val_loss: 93.5351\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 3690.0757 - val_loss: 93.1906\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39bcd0940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 12 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 252533.8906 - val_loss: 115.3250\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 310243.4062 - val_loss: 106.5240\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43714.9648 - val_loss: 102.6130\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33493.6055 - val_loss: 105.3136\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24424.1309 - val_loss: 101.1066\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 103491.9219 - val_loss: 101.3554\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 60555.9492 - val_loss: 104.2478\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27621.1777 - val_loss: 103.8503\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28117.6504 - val_loss: 100.9680\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 87282.1641 - val_loss: 101.2593\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 40707.6641 - val_loss: 103.3899\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 49890.1758 - val_loss: 101.4599\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47745.6914 - val_loss: 102.0776\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17384.7676 - val_loss: 103.0511\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48964.8555 - val_loss: 104.4146\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 66073.0469 - val_loss: 101.8347\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 115285.1719 - val_loss: 101.0126\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 86213.7266 - val_loss: 106.5653\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 144368.5000 - val_loss: 108.1562\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 108640.6953 - val_loss: 104.5039\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16030.8633 - val_loss: 102.0631\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 80431.2812 - val_loss: 102.6124\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 65200.1133 - val_loss: 104.2690\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25570.6172 - val_loss: 103.8075\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11711.8828 - val_loss: 103.6514\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30933.4531 - val_loss: 101.9506\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 84077.5000 - val_loss: 101.7068\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38978.0078 - val_loss: 104.1089\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 62600.9258 - val_loss: 102.7392\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 83941.6172 - val_loss: 102.3051\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46985.7578 - val_loss: 105.6147\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 153151.3125 - val_loss: 106.1004\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 125809.8047 - val_loss: 104.9455\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 26598.7227 - val_loss: 101.1726\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 145435.4688 - val_loss: 99.9541\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 167723.7656 - val_loss: 101.6629\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 54219.8047 - val_loss: 103.8746\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50086.5273 - val_loss: 104.8764\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47948.6836 - val_loss: 103.0492\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46102.9258 - val_loss: 102.6701\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51954.4766 - val_loss: 105.6406\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 63475.9062 - val_loss: 105.5115\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32533.7070 - val_loss: 103.4734\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39775.5195 - val_loss: 100.6767\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 148027.4531 - val_loss: 101.1756\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23920.2246 - val_loss: 104.4608\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 108418.6562 - val_loss: 105.7556\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 117220.9766 - val_loss: 103.7516\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18514.0605 - val_loss: 102.2877\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37901.4453 - val_loss: 102.7641\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39ea9d8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 13 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 7501.8198 - val_loss: 76.9998\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 217830.3906 - val_loss: 78.8565\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 164353.4375 - val_loss: 84.1907\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25104.4141 - val_loss: 89.9364\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2088.4268 - val_loss: 91.1723\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15266.4014 - val_loss: 90.5361\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24990.2148 - val_loss: 90.8361\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8048.6157 - val_loss: 90.7118\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14579.8008 - val_loss: 90.4441\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29698.1094 - val_loss: 92.7002\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31822.0684 - val_loss: 91.5168\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2055.0142 - val_loss: 92.2056\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12467.3564 - val_loss: 92.5877\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23587.2148 - val_loss: 88.2588\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30635.3516 - val_loss: 88.0604\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 51328.3672 - val_loss: 89.4125\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29153.8262 - val_loss: 91.9244\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11643.6729 - val_loss: 95.4156\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 92539.2734 - val_loss: 96.2529\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 104347.2031 - val_loss: 95.3384\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39888.0391 - val_loss: 92.8915\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23560.0703 - val_loss: 91.2354\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11573.6973 - val_loss: 91.6158\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31175.0332 - val_loss: 92.0554\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9256.6230 - val_loss: 91.4181\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21315.7676 - val_loss: 91.5946\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20986.3945 - val_loss: 92.1949\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37088.0273 - val_loss: 91.7768\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25870.6270 - val_loss: 94.3851\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44350.4648 - val_loss: 95.0748\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 58720.8164 - val_loss: 93.0495\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 338.8977 - val_loss: 93.1305\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2442.1660 - val_loss: 92.0576\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41935.9297 - val_loss: 92.7280\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14750.0645 - val_loss: 94.5563\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47133.3164 - val_loss: 95.0726\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34712.6680 - val_loss: 94.0413\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10674.8857 - val_loss: 90.9599\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 59087.0859 - val_loss: 91.0412\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31171.9512 - val_loss: 92.3723\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30842.8418 - val_loss: 93.8705\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39640.3164 - val_loss: 95.5899\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10821.4541 - val_loss: 93.2570\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13639.4473 - val_loss: 93.7537\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28099.0039 - val_loss: 93.5288\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28336.5371 - val_loss: 93.4588\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8613.6328 - val_loss: 94.8066\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23802.3262 - val_loss: 94.3623\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12467.6533 - val_loss: 92.9061\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48922.6133 - val_loss: 91.6363\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff385e32550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 14 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 18107.6953 - val_loss: 95.0182\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 159334.6250 - val_loss: 97.1848\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 92024.1484 - val_loss: 101.6879\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47078.5117 - val_loss: 101.9829\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13282.2197 - val_loss: 96.4662\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 92453.1406 - val_loss: 95.8276\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 72947.5234 - val_loss: 99.1629\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43563.3203 - val_loss: 100.7323\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11820.1758 - val_loss: 96.9346\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 76884.5781 - val_loss: 95.3687\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 91194.6484 - val_loss: 97.4953\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1799.7443 - val_loss: 98.5012\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5578.0776 - val_loss: 99.7346\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28352.5859 - val_loss: 99.4837\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22077.9160 - val_loss: 99.9192\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 701.7153 - val_loss: 99.8955\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32998.8047 - val_loss: 98.9073\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11389.2510 - val_loss: 100.1868\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58046.3086 - val_loss: 101.9293\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45174.1719 - val_loss: 100.7478\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3302.7595 - val_loss: 98.8730\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44364.4531 - val_loss: 98.2986\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29398.8906 - val_loss: 98.9232\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49307.0195 - val_loss: 100.8556\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43789.8438 - val_loss: 101.0178\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47517.7500 - val_loss: 100.5424\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23924.8281 - val_loss: 98.1572\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 59432.6836 - val_loss: 97.3438\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 68455.5469 - val_loss: 97.8032\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 52069.1523 - val_loss: 98.8168\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15458.3369 - val_loss: 99.4914\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29790.4219 - val_loss: 99.1110\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24653.0332 - val_loss: 99.2587\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12334.7686 - val_loss: 100.1187\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27997.1406 - val_loss: 100.7140\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40318.1914 - val_loss: 99.7191\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17116.0840 - val_loss: 97.0110\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 108343.4609 - val_loss: 95.9213\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 89202.6016 - val_loss: 97.8813\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 34181.3203 - val_loss: 100.2953\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 60067.6914 - val_loss: 101.2477\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56795.9531 - val_loss: 100.1943\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3226.3936 - val_loss: 98.9449\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12225.7314 - val_loss: 97.6972\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 74137.3516 - val_loss: 97.4827\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23699.8379 - val_loss: 98.3209\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32799.0508 - val_loss: 99.5968\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18002.8301 - val_loss: 98.7096\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41074.4258 - val_loss: 98.1038\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10690.2266 - val_loss: 99.1630\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38bbf8430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 15 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 151405.9531 - val_loss: 104.6690\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 132336.7656 - val_loss: 100.3025\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42980.2227 - val_loss: 94.3825\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 189979.7031 - val_loss: 94.5498\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 91844.0703 - val_loss: 99.5006\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30575.7832 - val_loss: 100.9523\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33742.3242 - val_loss: 98.7867\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 85954.4531 - val_loss: 98.7879\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32083.9219 - val_loss: 101.7459\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 102016.2812 - val_loss: 102.0026\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 41871.3047 - val_loss: 100.2506\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16390.3203 - val_loss: 98.2960\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 74454.6875 - val_loss: 99.2245\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 51335.5859 - val_loss: 99.3560\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41219.5430 - val_loss: 100.9146\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36545.2031 - val_loss: 99.3766\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 55852.1055 - val_loss: 99.3140\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8335.0498 - val_loss: 101.6877\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 125377.9375 - val_loss: 103.6784\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 83467.2500 - val_loss: 101.5231\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 74186.6641 - val_loss: 98.9858\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 64954.0469 - val_loss: 99.7757\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11188.5225 - val_loss: 99.7362\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40042.8672 - val_loss: 99.1950\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17737.4199 - val_loss: 100.4632\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30537.1973 - val_loss: 100.2310\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 32949.1016 - val_loss: 100.2155\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11263.7559 - val_loss: 98.6055\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 92117.5625 - val_loss: 98.6831\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45459.3398 - val_loss: 101.6569\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 83817.8125 - val_loss: 102.4508\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84869.7266 - val_loss: 101.4010\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42480.2656 - val_loss: 98.7094\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 71787.8281 - val_loss: 98.2005\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 61049.6992 - val_loss: 100.7983\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 45275.9688 - val_loss: 101.5843\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40527.6172 - val_loss: 100.8630\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 85438.9219 - val_loss: 98.5132\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 78377.8125 - val_loss: 99.5858\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18631.6211 - val_loss: 100.5768\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13086.6982 - val_loss: 100.7331\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 30822.4434 - val_loss: 100.6538\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16743.8027 - val_loss: 99.3613\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64836.6641 - val_loss: 100.1332\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33744.7422 - val_loss: 101.7161\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 71419.0078 - val_loss: 102.5306\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 91404.4531 - val_loss: 100.8275\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11285.5078 - val_loss: 100.4856\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13423.1367 - val_loss: 100.0908\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47600.0938 - val_loss: 100.6292\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b8afec10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 16 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 69.9769 - val_loss: 52.2136\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37.4879 - val_loss: 26.1757\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.7943 - val_loss: 26.0378\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24.0180 - val_loss: 25.2306\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.2612 - val_loss: 11.6447\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19.1258 - val_loss: 8.6783\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.3530 - val_loss: 5.1506\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17.4052 - val_loss: 5.2904\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.7985 - val_loss: 5.4460\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.0814 - val_loss: 8.1153\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.0151 - val_loss: 1.9931\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.7544 - val_loss: 6.7142\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.3781 - val_loss: 2.2752\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.8078 - val_loss: 3.5083\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.1219 - val_loss: 2.8033\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.9214 - val_loss: 2.3954\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.5116 - val_loss: 2.4305\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.8988 - val_loss: 1.9819\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.1447 - val_loss: 2.3957\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.2906 - val_loss: 1.8757\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.3133 - val_loss: 3.1043\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.7465 - val_loss: 1.8911\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.4363 - val_loss: 2.9832\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8995 - val_loss: 2.1514\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7195 - val_loss: 3.6662\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.9187 - val_loss: 2.0816\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9643 - val_loss: 2.8543\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.5301 - val_loss: 5.9988\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.2304 - val_loss: 2.2280\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.3640 - val_loss: 3.2304\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.3187 - val_loss: 1.8713\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5070 - val_loss: 1.8196\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6658 - val_loss: 4.7371\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2220 - val_loss: 4.3133\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4530 - val_loss: 3.3144\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.5077 - val_loss: 2.1990\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7311 - val_loss: 1.7213\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6957 - val_loss: 6.2663\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3871 - val_loss: 2.0143\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5473 - val_loss: 4.3352\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7922 - val_loss: 1.7725\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.4895 - val_loss: 2.9972\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.0758 - val_loss: 2.4898\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.0695 - val_loss: 5.2888\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.0289 - val_loss: 2.0335\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0525 - val_loss: 4.9875\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0715 - val_loss: 2.1748\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2745 - val_loss: 1.9863\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4646 - val_loss: 3.2484\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.0094 - val_loss: 1.7862\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38bb745e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 17 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 73.7993 - val_loss: 53.9913\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 33.4685 - val_loss: 13.9960\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.9281 - val_loss: 27.4064\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22.2934 - val_loss: 36.4365\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21.9943 - val_loss: 28.3153\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.3331 - val_loss: 16.8363\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.4415 - val_loss: 15.0788\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.4617 - val_loss: 18.9503\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.5024 - val_loss: 15.1473\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.6588 - val_loss: 8.4965\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.7434 - val_loss: 12.3380\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.9945 - val_loss: 3.9980\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.5334 - val_loss: 8.7317\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.5725 - val_loss: 4.4254\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0479 - val_loss: 3.2800\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.2272 - val_loss: 6.5412\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6878 - val_loss: 1.7243\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.6397 - val_loss: 1.9175\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.2089 - val_loss: 2.3733\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.0146 - val_loss: 2.7391\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.8112 - val_loss: 2.0800\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9010 - val_loss: 2.7370\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5764 - val_loss: 1.8850\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7403 - val_loss: 2.7611\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7995 - val_loss: 1.8307\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4361 - val_loss: 2.2656\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.5126 - val_loss: 3.1407\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1224 - val_loss: 1.9713\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.4114 - val_loss: 3.6565\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3478 - val_loss: 2.0177\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9352 - val_loss: 4.4725\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1745 - val_loss: 2.5166\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.0621 - val_loss: 5.1105\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5876 - val_loss: 2.0535\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8233 - val_loss: 5.1907\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3409 - val_loss: 2.0722\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7385 - val_loss: 2.3427\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5342 - val_loss: 2.4700\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.2937 - val_loss: 2.7768\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0176 - val_loss: 1.8467\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8984 - val_loss: 2.6193\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.4801 - val_loss: 2.2289\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3733 - val_loss: 2.5112\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.1031 - val_loss: 2.1554\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.8828 - val_loss: 3.8996\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.3710 - val_loss: 1.7170\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.4505 - val_loss: 4.3837\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9166 - val_loss: 1.6908\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3867 - val_loss: 2.8561\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0603 - val_loss: 1.6193\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b23623a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 18 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 159658.7031 - val_loss: 95.3737\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8037.4062 - val_loss: 105.5957\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 170116.4688 - val_loss: 107.7192\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 129215.3438 - val_loss: 105.1128\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 85311.7578 - val_loss: 100.4782\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 52447.4961 - val_loss: 97.3774\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52220.2266 - val_loss: 99.2963\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14283.3916 - val_loss: 100.4744\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27029.0156 - val_loss: 98.2266\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46722.2812 - val_loss: 98.7122\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13213.0420 - val_loss: 100.3812\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 46198.1484 - val_loss: 100.2926\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23677.4746 - val_loss: 97.3302\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 61360.5977 - val_loss: 97.3865\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33827.6484 - val_loss: 99.3826\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1242.6794 - val_loss: 98.9755\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6722.5225 - val_loss: 97.3572\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 95057.4375 - val_loss: 96.6542\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 71976.2031 - val_loss: 98.6739\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6784.6880 - val_loss: 99.7065\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 35161.7812 - val_loss: 98.7914\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36397.4727 - val_loss: 99.0601\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24081.9629 - val_loss: 100.9554\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10578.4219 - val_loss: 101.7079\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47473.2773 - val_loss: 100.1049\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18166.6621 - val_loss: 99.4216\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9153.1611 - val_loss: 102.2873\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 107495.8438 - val_loss: 103.1631\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 109934.2266 - val_loss: 101.5065\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28589.9141 - val_loss: 99.7911\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16595.4941 - val_loss: 99.5289\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7839.0483 - val_loss: 100.5039\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30636.9844 - val_loss: 100.3710\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 61621.7227 - val_loss: 100.7431\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13445.6484 - val_loss: 99.9333\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 781.4397 - val_loss: 100.5680\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28858.6211 - val_loss: 100.1008\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14840.0029 - val_loss: 98.2851\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46913.1016 - val_loss: 98.0155\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 41953.8555 - val_loss: 99.1312\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 429.2679 - val_loss: 101.6614\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36959.1250 - val_loss: 102.2896\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 78057.5625 - val_loss: 100.9114\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30478.8184 - val_loss: 100.1949\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17990.0684 - val_loss: 99.1827\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27761.9375 - val_loss: 99.3936\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 32106.1504 - val_loss: 101.0179\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 78811.7109 - val_loss: 101.3413\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42350.5820 - val_loss: 100.3728\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4187.6641 - val_loss: 98.6834\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff408989160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 19 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 52885.9688 - val_loss: 88.0715\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 93871.4844 - val_loss: 94.6592\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 106284.6484 - val_loss: 88.1653\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 75666.2344 - val_loss: 85.9027\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24562.7461 - val_loss: 89.7509\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 92470.0469 - val_loss: 93.0900\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 77562.3906 - val_loss: 91.4434\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14908.1631 - val_loss: 88.8270\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53978.7617 - val_loss: 86.3817\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 84402.3750 - val_loss: 87.1167\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17323.0469 - val_loss: 89.6413\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36050.9570 - val_loss: 90.4930\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36940.6289 - val_loss: 89.6290\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16751.8008 - val_loss: 88.0639\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12777.2393 - val_loss: 88.9902\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31323.0332 - val_loss: 90.7991\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38979.6641 - val_loss: 88.7666\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1614.5751 - val_loss: 89.3676\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26339.2109 - val_loss: 90.9569\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 61152.9883 - val_loss: 90.5284\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18706.5410 - val_loss: 89.4642\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21263.1387 - val_loss: 88.7665\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14768.3750 - val_loss: 90.3544\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40013.0898 - val_loss: 90.6280\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4670.8955 - val_loss: 89.7509\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35532.0000 - val_loss: 85.2848\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 83681.0781 - val_loss: 84.2548\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 137201.9375 - val_loss: 86.1252\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 86826.5625 - val_loss: 89.7477\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10550.2627 - val_loss: 91.2035\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7645.2983 - val_loss: 92.6133\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17141.8809 - val_loss: 92.9086\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21870.6699 - val_loss: 90.4125\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49770.7812 - val_loss: 89.6465\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6223.2534 - val_loss: 91.5387\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15365.5625 - val_loss: 95.6460\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 96290.3047 - val_loss: 95.8543\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 84490.6016 - val_loss: 94.6018\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 49152.2500 - val_loss: 91.7349\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3392.6160 - val_loss: 88.4272\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 112447.5000 - val_loss: 87.5490\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 109710.6562 - val_loss: 89.1735\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40790.3633 - val_loss: 91.4162\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 41795.5859 - val_loss: 91.8629\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5721.8081 - val_loss: 92.8787\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32928.7695 - val_loss: 92.0407\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12263.5166 - val_loss: 90.9758\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13702.4385 - val_loss: 91.2853\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16750.6738 - val_loss: 92.1922\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 69975.3203 - val_loss: 93.0188\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b1adba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 20 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 49034.7617 - val_loss: 89.3765\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 106040.3359 - val_loss: 94.0409\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33415.7148 - val_loss: 101.2117\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 130475.0234 - val_loss: 103.5104\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 87372.7422 - val_loss: 99.4370\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6953.0947 - val_loss: 93.4809\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 119314.5938 - val_loss: 92.2478\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 108690.9375 - val_loss: 94.3879\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48728.3398 - val_loss: 99.9047\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5971.0171 - val_loss: 106.9281\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 175189.5000 - val_loss: 108.2109\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 159109.0469 - val_loss: 104.5332\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 78372.3359 - val_loss: 99.9766\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13543.3359 - val_loss: 93.9017\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 104713.6016 - val_loss: 92.0205\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 124712.3281 - val_loss: 92.9169\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 107292.3438 - val_loss: 98.1256\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27865.0234 - val_loss: 99.9436\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 31768.3125 - val_loss: 98.1407\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35685.0078 - val_loss: 97.5725\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25183.7676 - val_loss: 99.1423\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28908.7012 - val_loss: 99.8908\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30535.1816 - val_loss: 98.8141\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 774.3408 - val_loss: 95.1786\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 92129.0781 - val_loss: 93.8552\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 113800.4453 - val_loss: 95.6523\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 60536.8750 - val_loss: 98.6490\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14748.3652 - val_loss: 98.9232\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7719.0376 - val_loss: 97.7274\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19802.7734 - val_loss: 96.9190\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12674.8584 - val_loss: 98.8391\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 43863.8242 - val_loss: 99.3334\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48214.5469 - val_loss: 97.5957\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 31024.3379 - val_loss: 94.6421\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 87446.5547 - val_loss: 94.4816\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 89417.3984 - val_loss: 97.2666\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13816.4229 - val_loss: 97.9098\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33167.0820 - val_loss: 99.2011\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6859.9399 - val_loss: 101.8430\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 70816.0625 - val_loss: 102.3606\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38247.2031 - val_loss: 100.1274\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10672.9541 - val_loss: 99.3751\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10546.0645 - val_loss: 101.9332\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 68237.0859 - val_loss: 102.1313\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18147.9082 - val_loss: 100.6543\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19044.7656 - val_loss: 97.7524\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57079.4336 - val_loss: 96.5029\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55603.5938 - val_loss: 97.5077\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8202.3516 - val_loss: 99.7683\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39465.9102 - val_loss: 101.2041\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff397da1f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 21 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 82.7649 - val_loss: 69.1894\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47.6352 - val_loss: 33.3969\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42.0804 - val_loss: 33.8935\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.6849 - val_loss: 36.6507\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27.3494 - val_loss: 25.3386\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.8592 - val_loss: 15.7355\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 21.4882 - val_loss: 18.1878\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.6765 - val_loss: 9.8110\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.5659 - val_loss: 6.9166\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.6529 - val_loss: 2.8691\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.9447 - val_loss: 3.4554\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.1437 - val_loss: 3.2417\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.3687 - val_loss: 4.9281\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.2999 - val_loss: 3.8678\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.1213 - val_loss: 2.9424\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.8373 - val_loss: 2.9007\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.9136 - val_loss: 3.5385\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.2396 - val_loss: 2.5956\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9318 - val_loss: 4.7512\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.8324 - val_loss: 3.7962\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7696 - val_loss: 3.1757\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.0589 - val_loss: 4.1403\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.1853 - val_loss: 3.1010\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9792 - val_loss: 2.7816\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.8239 - val_loss: 3.0161\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.0014 - val_loss: 3.5872\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6553 - val_loss: 4.3414\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.1201 - val_loss: 2.5227\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.2921 - val_loss: 2.8410\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9451 - val_loss: 3.4945\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.1637 - val_loss: 5.0178\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0323 - val_loss: 2.7598\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2798 - val_loss: 2.4091\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9716 - val_loss: 4.4368\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5946 - val_loss: 3.7056\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6918 - val_loss: 2.5675\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2547 - val_loss: 3.3812\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4231 - val_loss: 4.2606\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.0801 - val_loss: 6.1657\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9207 - val_loss: 3.1757\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7558 - val_loss: 2.4073\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.5684 - val_loss: 4.1401\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3397 - val_loss: 4.0356\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.0011 - val_loss: 2.3104\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1422 - val_loss: 2.9228\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.3355 - val_loss: 4.0183\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.3005 - val_loss: 3.1561\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7144 - val_loss: 2.9859\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2250 - val_loss: 2.5214\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3157 - val_loss: 2.9733\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3c073b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 22 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 103ms/step - loss: 19463.5469 - val_loss: 91.0752\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 318681.9062 - val_loss: 85.5921\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 292907.8750 - val_loss: 95.9530\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 52934.8398 - val_loss: 101.9167\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15121.0068 - val_loss: 104.8852\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45321.3438 - val_loss: 105.4409\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32177.7129 - val_loss: 102.5980\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44295.3320 - val_loss: 102.7745\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27697.9746 - val_loss: 103.4643\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10402.0820 - val_loss: 107.6846\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 104849.6328 - val_loss: 109.5870\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 74631.5938 - val_loss: 107.5539\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34776.2461 - val_loss: 103.7118\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8218.2480 - val_loss: 102.3580\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8161.3115 - val_loss: 104.2555\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4652.0112 - val_loss: 108.2202\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 114432.9844 - val_loss: 108.1700\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 55604.0742 - val_loss: 107.5094\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 97833.3984 - val_loss: 103.3770\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11171.7529 - val_loss: 102.8645\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5321.2437 - val_loss: 101.1325\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 68924.1016 - val_loss: 100.7315\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39803.6875 - val_loss: 103.5792\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42237.4023 - val_loss: 105.3084\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16129.8252 - val_loss: 103.6761\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13419.2441 - val_loss: 100.0714\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 95276.6875 - val_loss: 99.5279\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 81559.1875 - val_loss: 100.8750\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44262.5977 - val_loss: 103.1797\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20859.5156 - val_loss: 103.8647\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7499.4570 - val_loss: 103.2642\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35476.7930 - val_loss: 102.2878\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12740.0615 - val_loss: 102.8851\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 353.0996 - val_loss: 105.0895\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 47157.0234 - val_loss: 105.7398\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26425.0586 - val_loss: 104.4086\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2361.4163 - val_loss: 104.1154\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8678.1299 - val_loss: 106.5292\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 81569.7031 - val_loss: 107.3795\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 78498.8516 - val_loss: 106.8296\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44917.7969 - val_loss: 103.6452\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29985.4375 - val_loss: 102.9620\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16176.1582 - val_loss: 104.3231\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 49853.0938 - val_loss: 104.6060\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14166.6807 - val_loss: 101.5036\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 87040.0625 - val_loss: 101.2692\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 54851.7344 - val_loss: 102.2496\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21460.6660 - val_loss: 104.7481\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41801.7461 - val_loss: 105.7062\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29882.6777 - val_loss: 105.1134\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3d919eb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 23 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 78.4705 - val_loss: 57.4172\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.7411 - val_loss: 19.3551\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.4478 - val_loss: 29.1980\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.6116 - val_loss: 37.8046\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.4539 - val_loss: 27.9927\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.8913 - val_loss: 14.5287\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18.3193 - val_loss: 18.1163\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.4447 - val_loss: 20.3853\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.2138 - val_loss: 8.4676\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.4569 - val_loss: 6.9614\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.2426 - val_loss: 8.5445\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.9749 - val_loss: 3.0609\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.4432 - val_loss: 4.3323\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4810 - val_loss: 6.5112\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.6093 - val_loss: 4.7617\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2008 - val_loss: 7.0415\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.2610 - val_loss: 4.6752\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.3538 - val_loss: 6.7222\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 11.1570 - val_loss: 4.3588\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.4647 - val_loss: 3.0529\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.3962 - val_loss: 7.2260\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2060 - val_loss: 3.6772\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9419 - val_loss: 6.3421\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.6482 - val_loss: 4.2124\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8381 - val_loss: 3.4300\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1690 - val_loss: 3.5032\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.3832 - val_loss: 4.3248\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.0043 - val_loss: 2.4247\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3105 - val_loss: 4.0727\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4509 - val_loss: 3.0344\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7228 - val_loss: 4.2312\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9133 - val_loss: 3.3868\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2394 - val_loss: 2.2302\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5523 - val_loss: 6.1488\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9706 - val_loss: 2.0952\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7714 - val_loss: 4.2553\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9654 - val_loss: 4.2942\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7612 - val_loss: 1.9102\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9832 - val_loss: 3.3070\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.4456 - val_loss: 3.3344\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7198 - val_loss: 2.0553\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6370 - val_loss: 4.4420\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.4317 - val_loss: 2.3673\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0000 - val_loss: 3.7576\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.2927 - val_loss: 2.0637\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.1244 - val_loss: 3.2073\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9856 - val_loss: 1.7485\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8774 - val_loss: 2.4133\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.5600 - val_loss: 3.2229\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2363 - val_loss: 3.0818\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3978d3b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 24 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 4754542.5000 - val_loss: 100.8427\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3142801.2500 - val_loss: 98.9424\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1975029.8750 - val_loss: 97.6935\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1701693.2500 - val_loss: 96.7033\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1310726.2500 - val_loss: 95.7193\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 913776.3125 - val_loss: 94.5716\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1017526.8125 - val_loss: 93.5327\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 538472.4375 - val_loss: 92.6557\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 472668.3750 - val_loss: 91.5568\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 459797.2500 - val_loss: 90.5780\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 440862.1562 - val_loss: 89.5560\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 482154.9375 - val_loss: 88.6077\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 388154.8438 - val_loss: 87.4751\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 354406.2500 - val_loss: 86.5658\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 310453.8750 - val_loss: 85.4649\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 277429.7188 - val_loss: 84.4249\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 162913.6250 - val_loss: 83.4925\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 237591.2969 - val_loss: 82.5770\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 153445.0469 - val_loss: 81.5495\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 120282.7734 - val_loss: 80.7066\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 118573.3047 - val_loss: 79.8112\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 166850.3750 - val_loss: 78.8707\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 196919.5469 - val_loss: 78.0345\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 188162.3125 - val_loss: 77.1162\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 288729.4062 - val_loss: 76.0588\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 269475.2812 - val_loss: 75.1838\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 307057.0938 - val_loss: 74.3573\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 278468.4688 - val_loss: 73.6684\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 144207.3906 - val_loss: 72.7528\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 199611.3906 - val_loss: 71.8148\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 298635.5625 - val_loss: 70.9405\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 296863.7188 - val_loss: 70.0474\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 251641.3750 - val_loss: 69.3586\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 206839.3906 - val_loss: 68.6120\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 268252.3750 - val_loss: 67.6492\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 229262.2656 - val_loss: 66.8782\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 287203.4688 - val_loss: 66.1995\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 300303.7500 - val_loss: 65.3186\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 195114.6406 - val_loss: 64.5402\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 259018.7656 - val_loss: 63.8418\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 523650.6250 - val_loss: 63.3397\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 409916.8438 - val_loss: 62.6279\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 316282.5938 - val_loss: 62.0376\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 466935.9375 - val_loss: 61.4698\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 455720.5312 - val_loss: 60.8811\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 242180.7344 - val_loss: 60.1738\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 180697.0781 - val_loss: 59.6066\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 111299.1953 - val_loss: 58.9599\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 210828.7656 - val_loss: 58.2740\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 221906.7969 - val_loss: 57.6283\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38719a550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 25 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 181719.0000 - val_loss: 96.6776\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 150645.5938 - val_loss: 109.5762\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 95955.6016 - val_loss: 112.2983\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 86024.5000 - val_loss: 110.8595\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 73114.9922 - val_loss: 105.3625\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56963.0273 - val_loss: 102.9332\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56433.4531 - val_loss: 103.9540\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20006.7832 - val_loss: 106.0852\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53375.5234 - val_loss: 106.9398\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 64844.0078 - val_loss: 105.7047\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26047.6699 - val_loss: 102.3908\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 44574.5117 - val_loss: 101.2850\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34086.2031 - val_loss: 102.9497\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1144.9117 - val_loss: 104.9598\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14837.4473 - val_loss: 105.0470\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57162.4023 - val_loss: 103.1898\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21051.9434 - val_loss: 103.9836\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15898.2021 - val_loss: 105.0355\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 46753.9258 - val_loss: 106.6156\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44996.4609 - val_loss: 104.9987\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13493.0234 - val_loss: 104.7363\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12478.7842 - val_loss: 104.3077\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5847.0488 - val_loss: 104.0814\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12776.9639 - val_loss: 103.1120\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12372.1602 - val_loss: 104.1356\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10602.7256 - val_loss: 103.2677\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21448.8496 - val_loss: 101.3146\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 80278.0312 - val_loss: 101.3097\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 81231.3516 - val_loss: 102.3211\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11518.2393 - val_loss: 103.8994\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24117.3457 - val_loss: 104.9353\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 39414.4258 - val_loss: 103.8534\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20144.2871 - val_loss: 102.1596\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 25781.1504 - val_loss: 101.0484\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 27521.2930 - val_loss: 103.0947\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19994.8965 - val_loss: 103.5719\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19221.1934 - val_loss: 101.9901\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18963.2832 - val_loss: 102.2369\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9339.0312 - val_loss: 103.7325\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53382.1250 - val_loss: 103.5362\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 41214.1680 - val_loss: 101.5846\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24567.4609 - val_loss: 100.9053\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24273.6094 - val_loss: 102.7878\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 63891.9219 - val_loss: 103.3334\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36061.0156 - val_loss: 102.1171\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5817.5547 - val_loss: 102.2702\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10567.8926 - val_loss: 101.0654\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18375.0781 - val_loss: 101.5844\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9742.8379 - val_loss: 103.3839\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 49642.9609 - val_loss: 102.9606\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39187d040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 26 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 89179.3125 - val_loss: 98.2662\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 72493.3750 - val_loss: 99.0284\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48352.5508 - val_loss: 93.6147\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50687.7930 - val_loss: 94.1134\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15432.9424 - val_loss: 95.4885\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10914.4043 - val_loss: 102.2539\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 174177.7969 - val_loss: 105.2678\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 158802.6250 - val_loss: 102.3997\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 94289.2344 - val_loss: 99.0784\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8834.2871 - val_loss: 94.5798\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 70274.1094 - val_loss: 94.3701\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57160.6836 - val_loss: 96.2437\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17785.1973 - val_loss: 98.7598\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6590.4448 - val_loss: 98.7669\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24097.5020 - val_loss: 99.3675\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36869.7344 - val_loss: 100.2145\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42341.8789 - val_loss: 99.1673\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13344.0752 - val_loss: 96.8257\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 50398.5234 - val_loss: 96.2085\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 83133.6094 - val_loss: 98.3937\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12446.8184 - val_loss: 101.0673\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 81013.3047 - val_loss: 101.7953\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 84044.3359 - val_loss: 100.2932\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13619.1221 - val_loss: 96.6560\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 86520.4844 - val_loss: 94.6917\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 77280.7500 - val_loss: 95.2864\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 60624.8828 - val_loss: 98.7849\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27771.6445 - val_loss: 100.0360\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9192.8154 - val_loss: 99.5157\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3775.9387 - val_loss: 99.8972\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12614.6514 - val_loss: 99.7071\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9781.2939 - val_loss: 97.0683\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 67514.3516 - val_loss: 96.8395\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 56143.7812 - val_loss: 97.7516\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 84470.9297 - val_loss: 100.8177\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 866.1929 - val_loss: 100.8240\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20485.0742 - val_loss: 100.2414\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19592.1777 - val_loss: 98.9057\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37386.7109 - val_loss: 100.5203\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42220.8242 - val_loss: 100.3579\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 387.4154 - val_loss: 100.6597\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6839.8462 - val_loss: 100.0328\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3933.2524 - val_loss: 100.2413\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33035.9961 - val_loss: 100.4342\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29988.8457 - val_loss: 100.5856\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21617.3398 - val_loss: 99.4024\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15517.9590 - val_loss: 99.4557\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 64834.7500 - val_loss: 99.6876\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22969.2832 - val_loss: 99.7515\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4381.2275 - val_loss: 101.8825\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3931a95e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 27 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 9941.4854 - val_loss: 120.6143\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 293470.7500 - val_loss: 119.9956\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 220839.2031 - val_loss: 112.2173\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 104044.2969 - val_loss: 105.5231\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 50924.7109 - val_loss: 104.7745\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55621.4922 - val_loss: 106.3924\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14980.5127 - val_loss: 107.1306\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24871.5234 - val_loss: 107.6928\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 44608.6758 - val_loss: 108.5779\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11139.8340 - val_loss: 105.1143\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 84584.4766 - val_loss: 104.2632\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34739.4688 - val_loss: 105.2989\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37115.6602 - val_loss: 109.7761\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 156662.4688 - val_loss: 111.1593\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 120396.0234 - val_loss: 109.1329\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 28265.7402 - val_loss: 106.5647\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2291.7915 - val_loss: 102.7580\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 140460.4531 - val_loss: 101.2100\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 117110.8047 - val_loss: 103.8601\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 62136.3086 - val_loss: 108.0319\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 66621.2188 - val_loss: 109.4457\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61021.9258 - val_loss: 107.8284\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4363.2080 - val_loss: 104.4026\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 75551.9297 - val_loss: 104.0570\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60315.3633 - val_loss: 105.3592\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4813.4331 - val_loss: 107.6735\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 72609.7500 - val_loss: 109.1676\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 63670.0508 - val_loss: 108.2417\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38460.0742 - val_loss: 104.3441\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 89395.2734 - val_loss: 102.6000\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 96463.4531 - val_loss: 103.0691\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28592.3125 - val_loss: 105.8596\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5812.3569 - val_loss: 107.0091\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14097.6973 - val_loss: 106.7057\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27284.9844 - val_loss: 106.4359\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4484.4868 - val_loss: 108.3848\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 52947.8828 - val_loss: 108.7047\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51676.5078 - val_loss: 107.3201\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14407.0527 - val_loss: 105.0677\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39300.1406 - val_loss: 104.6768\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 63482.4414 - val_loss: 105.3966\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4848.0317 - val_loss: 105.6674\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20720.6348 - val_loss: 105.5072\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43008.4375 - val_loss: 107.8594\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 58088.8633 - val_loss: 108.1763\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 43246.8555 - val_loss: 106.9851\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 55232.8828 - val_loss: 105.7160\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 64524.3828 - val_loss: 104.7678\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10325.3037 - val_loss: 105.9812\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14142.4062 - val_loss: 107.4078\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff391c7d670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 28 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 124297.7266 - val_loss: 83.9541\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31753.5371 - val_loss: 91.5283\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 85471.8516 - val_loss: 88.2282\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20934.7969 - val_loss: 89.4560\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42978.5039 - val_loss: 88.9271\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11947.5264 - val_loss: 82.0555\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 135294.4219 - val_loss: 82.8624\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 90789.5156 - val_loss: 87.8905\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12085.6416 - val_loss: 88.8516\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13969.8535 - val_loss: 89.8792\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 30481.6250 - val_loss: 89.9865\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1683.1188 - val_loss: 91.4971\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11888.6172 - val_loss: 88.9518\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24427.9277 - val_loss: 89.1676\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23080.0195 - val_loss: 89.6470\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 65809.3281 - val_loss: 89.7304\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14521.8633 - val_loss: 93.5799\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58246.5742 - val_loss: 95.2690\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 75188.5703 - val_loss: 91.9545\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54900.8867 - val_loss: 91.8725\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17513.6230 - val_loss: 91.3051\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33013.7656 - val_loss: 90.0969\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 33037.2109 - val_loss: 93.0141\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29766.0527 - val_loss: 93.7820\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8376.0596 - val_loss: 92.0763\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 21198.1328 - val_loss: 85.1317\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 165626.9531 - val_loss: 82.5670\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 193740.2812 - val_loss: 84.7849\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 82630.0156 - val_loss: 88.8684\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 62848.1641 - val_loss: 96.6684\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 97726.8750 - val_loss: 98.8110\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 136332.2656 - val_loss: 97.8449\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50277.8125 - val_loss: 95.4589\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 33085.5859 - val_loss: 91.0981\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46479.6211 - val_loss: 90.6263\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71578.4297 - val_loss: 91.1321\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55557.8555 - val_loss: 94.7211\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3156.8030 - val_loss: 95.9078\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 76649.6172 - val_loss: 94.6992\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 37144.3633 - val_loss: 94.9303\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1759.0660 - val_loss: 94.3117\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5436.8916 - val_loss: 95.1840\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6016.6260 - val_loss: 95.7705\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3258.5796 - val_loss: 92.7991\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 90191.9375 - val_loss: 91.3121\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 78686.5625 - val_loss: 94.5319\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37117.0273 - val_loss: 95.8615\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10958.4385 - val_loss: 95.9702\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10208.5752 - val_loss: 94.5782\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52043.1133 - val_loss: 95.6502\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38719d820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 29 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 56008.7773 - val_loss: 72.7392\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55757.6133 - val_loss: 79.0504\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48126.3867 - val_loss: 77.2886\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21391.4395 - val_loss: 76.7951\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7208.3867 - val_loss: 81.0749\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 76227.9766 - val_loss: 81.4112\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61523.8438 - val_loss: 80.0990\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6534.1807 - val_loss: 80.2976\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31303.3359 - val_loss: 80.1477\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15042.3623 - val_loss: 79.5787\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 609.3886 - val_loss: 79.5137\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22900.3789 - val_loss: 81.4160\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44750.4922 - val_loss: 81.7017\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16289.8984 - val_loss: 78.2139\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 75963.7422 - val_loss: 77.5367\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37246.8125 - val_loss: 81.0957\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19131.6738 - val_loss: 81.9542\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29435.3184 - val_loss: 80.1130\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29257.8418 - val_loss: 80.3498\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 36718.9688 - val_loss: 82.5160\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24208.8184 - val_loss: 83.6154\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21506.1113 - val_loss: 82.0662\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6254.1948 - val_loss: 81.9358\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3881.6401 - val_loss: 83.7537\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8329.1064 - val_loss: 83.2737\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17826.7559 - val_loss: 80.7728\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23235.8164 - val_loss: 80.5417\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66850.5312 - val_loss: 82.6293\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13119.1641 - val_loss: 84.0787\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15225.9473 - val_loss: 81.2708\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 72975.5234 - val_loss: 80.1181\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39107.4023 - val_loss: 84.3701\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39863.1562 - val_loss: 85.5212\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16734.8965 - val_loss: 83.5134\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10633.9785 - val_loss: 80.2895\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57462.8164 - val_loss: 80.3683\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 81906.2422 - val_loss: 81.4042\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 117893.9219 - val_loss: 84.9558\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3885.7146 - val_loss: 88.8007\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 86487.4453 - val_loss: 89.4545\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 114433.2656 - val_loss: 87.4414\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 86519.6719 - val_loss: 84.5056\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 29115.1816 - val_loss: 83.7977\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4492.0029 - val_loss: 86.4698\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49980.8906 - val_loss: 86.8010\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15734.5918 - val_loss: 85.1635\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16602.6406 - val_loss: 82.6222\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 88686.3984 - val_loss: 81.5456\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 112040.1484 - val_loss: 83.7126\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6562.2534 - val_loss: 83.4723\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a0d12af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 30 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 31198.4512 - val_loss: 118.8627\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 200580.3594 - val_loss: 114.6348\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 150615.6094 - val_loss: 109.7999\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16244.8193 - val_loss: 102.9008\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 82683.5703 - val_loss: 98.3660\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 86199.4922 - val_loss: 98.3415\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30727.6680 - val_loss: 102.0166\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51134.6016 - val_loss: 105.4541\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55257.3828 - val_loss: 102.6493\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17652.6133 - val_loss: 101.7292\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45444.5078 - val_loss: 102.9994\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24274.9141 - val_loss: 99.2243\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 68091.8594 - val_loss: 98.1029\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 129351.5625 - val_loss: 100.5988\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6447.2773 - val_loss: 101.4405\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16599.6191 - val_loss: 102.6096\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18981.3301 - val_loss: 102.9880\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16833.4121 - val_loss: 102.6399\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4180.6729 - val_loss: 101.7466\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2200.1895 - val_loss: 102.7756\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17696.8027 - val_loss: 101.1202\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 63793.6328 - val_loss: 100.8184\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34544.4375 - val_loss: 105.0069\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 88915.3906 - val_loss: 106.4988\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27948.8086 - val_loss: 105.3303\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46550.9180 - val_loss: 102.2647\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17717.0137 - val_loss: 100.7454\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7995.3452 - val_loss: 102.5874\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3465.3589 - val_loss: 102.3574\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 152.7718 - val_loss: 99.2800\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 95235.1016 - val_loss: 99.7237\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 85586.6016 - val_loss: 101.9036\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 18902.5527 - val_loss: 106.0668\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 88439.8125 - val_loss: 106.2273\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39860.2500 - val_loss: 104.7760\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17437.8457 - val_loss: 103.0820\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20185.3652 - val_loss: 101.9725\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27839.4512 - val_loss: 103.0786\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25203.6875 - val_loss: 102.4640\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4042.6267 - val_loss: 102.6641\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8681.3369 - val_loss: 102.3107\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37401.8828 - val_loss: 102.6507\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24241.1309 - val_loss: 102.6928\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7304.4604 - val_loss: 103.3535\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 40621.3398 - val_loss: 103.5328\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23986.1367 - val_loss: 101.0535\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 81689.8828 - val_loss: 100.4354\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45369.9727 - val_loss: 102.7533\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6057.4971 - val_loss: 104.7683\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55543.0859 - val_loss: 105.3519\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3dbfbac10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 31 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 69.2515 - val_loss: 51.5274\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.6453 - val_loss: 33.6564\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39.7654 - val_loss: 35.4660\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.5438 - val_loss: 36.5948\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.0851 - val_loss: 22.9775\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.3970 - val_loss: 17.6484\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 22.0700 - val_loss: 16.5935\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20.3056 - val_loss: 6.6195\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.8247 - val_loss: 4.9626\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16.7839 - val_loss: 5.9142\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.1136 - val_loss: 3.1461\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.0744 - val_loss: 4.6328\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.5686 - val_loss: 4.3712\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.1530 - val_loss: 4.9469\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.8461 - val_loss: 3.9269\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.1046 - val_loss: 4.7357\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.7769 - val_loss: 2.6363\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.4927 - val_loss: 4.4189\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.1066 - val_loss: 4.6178\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.6562 - val_loss: 4.6994\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6506 - val_loss: 2.5751\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2397 - val_loss: 4.5453\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4294 - val_loss: 3.2491\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.6438 - val_loss: 4.4077\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8265 - val_loss: 3.3937\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8999 - val_loss: 2.7258\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4221 - val_loss: 2.9474\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9996 - val_loss: 3.6584\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.3198 - val_loss: 5.3168\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.4447 - val_loss: 3.7887\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.6492 - val_loss: 2.6405\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.9789 - val_loss: 3.4595\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2908 - val_loss: 4.0102\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.9087 - val_loss: 3.9859\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9157 - val_loss: 2.1576\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4741 - val_loss: 4.5803\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2172 - val_loss: 4.1656\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2844 - val_loss: 3.7397\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2426 - val_loss: 2.7495\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8307 - val_loss: 3.1342\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3208 - val_loss: 4.0036\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8997 - val_loss: 4.1739\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2839 - val_loss: 2.9873\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.1586 - val_loss: 1.9320\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1093 - val_loss: 5.6698\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8485 - val_loss: 2.0933\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5920 - val_loss: 3.0846\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6313 - val_loss: 5.9532\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8278 - val_loss: 3.5768\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8864 - val_loss: 5.2698\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3bff14af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 32 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 77.9342 - val_loss: 61.8215\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42.2766 - val_loss: 33.4163\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 39.7548 - val_loss: 31.4489\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.4335 - val_loss: 33.0460\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 26.2543 - val_loss: 22.1960\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.6944 - val_loss: 8.9927\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.9763 - val_loss: 14.3950\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.6771 - val_loss: 7.4364\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.3678 - val_loss: 8.4366\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.1399 - val_loss: 6.8351\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.4874 - val_loss: 4.5769\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.5237 - val_loss: 6.7620\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4389 - val_loss: 5.3998\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.1200 - val_loss: 6.1479\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.7291 - val_loss: 2.9768\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.6181 - val_loss: 4.0948\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 12.7754 - val_loss: 4.8766\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.2243 - val_loss: 3.6293\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.8265 - val_loss: 6.0548\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.4812 - val_loss: 3.0023\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.3462 - val_loss: 2.5620\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.5514 - val_loss: 2.4555\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.3006 - val_loss: 3.1316\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8874 - val_loss: 6.4300\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.3416 - val_loss: 2.9413\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.6139 - val_loss: 3.5553\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.2446 - val_loss: 3.6485\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1492 - val_loss: 3.1605\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6817 - val_loss: 2.4936\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2201 - val_loss: 3.6557\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4142 - val_loss: 2.3872\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0943 - val_loss: 4.7197\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.0986 - val_loss: 2.5835\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.6543 - val_loss: 4.2407\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7917 - val_loss: 2.2916\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.2476 - val_loss: 4.0110\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0048 - val_loss: 3.6338\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.1803 - val_loss: 2.9494\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.0479 - val_loss: 3.9540\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1637 - val_loss: 3.4705\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0058 - val_loss: 2.5165\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2807 - val_loss: 3.8618\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2141 - val_loss: 2.8592\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4454 - val_loss: 3.8033\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9389 - val_loss: 2.1015\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.0085 - val_loss: 2.8054\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9786 - val_loss: 1.9820\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7233 - val_loss: 2.8136\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6749 - val_loss: 1.9386\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3217 - val_loss: 3.5484\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40a26c8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 33 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 90.6061 - val_loss: 76.5646\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48.6837 - val_loss: 35.6912\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.5656 - val_loss: 22.0415\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.4811 - val_loss: 32.4239\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.5237 - val_loss: 35.0338\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23.4110 - val_loss: 20.9592\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.3030 - val_loss: 10.6533\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17.9869 - val_loss: 19.0971\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15.2687 - val_loss: 4.5972\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.4016 - val_loss: 3.4917\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14.6912 - val_loss: 7.3646\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.2977 - val_loss: 3.0769\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.0608 - val_loss: 3.5775\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.8096 - val_loss: 3.8735\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.9557 - val_loss: 3.1310\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.7449 - val_loss: 3.0514\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.5335 - val_loss: 3.4772\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.7148 - val_loss: 3.0134\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10.1654 - val_loss: 2.7438\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.2810 - val_loss: 5.2700\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.0268 - val_loss: 2.5690\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.1605 - val_loss: 3.4710\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7796 - val_loss: 3.4407\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3757 - val_loss: 2.8322\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7347 - val_loss: 2.9430\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8728 - val_loss: 4.2785\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.4262 - val_loss: 1.7531\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3138 - val_loss: 4.0241\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1859 - val_loss: 1.8677\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5849 - val_loss: 5.3519\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1047 - val_loss: 2.0487\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2017 - val_loss: 4.6211\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6490 - val_loss: 1.7909\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3271 - val_loss: 4.5200\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1062 - val_loss: 2.8641\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3225 - val_loss: 1.9274\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4094 - val_loss: 5.0469\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5720 - val_loss: 1.8095\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.1354 - val_loss: 5.6572\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2576 - val_loss: 1.8637\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.3533 - val_loss: 4.9465\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1837 - val_loss: 1.7331\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7163 - val_loss: 3.4279\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5803 - val_loss: 2.8734\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.7661 - val_loss: 1.8217\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3802 - val_loss: 4.0268\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.4991 - val_loss: 1.7114\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0697 - val_loss: 4.2611\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1251 - val_loss: 2.0130\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.8337 - val_loss: 1.7300\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff388969820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 34 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 184316.2031 - val_loss: 107.1357\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 67290.6641 - val_loss: 112.6314\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 88886.6406 - val_loss: 113.0294\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 68382.1953 - val_loss: 107.4100\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 101952.6641 - val_loss: 106.5049\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30326.4805 - val_loss: 108.2061\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32045.2012 - val_loss: 103.6293\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 141114.2656 - val_loss: 103.6997\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 51993.5391 - val_loss: 106.7189\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45369.7266 - val_loss: 106.2181\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36727.8867 - val_loss: 105.6923\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15053.0244 - val_loss: 106.3817\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31245.3906 - val_loss: 105.9955\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 89872.7969 - val_loss: 105.7855\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36009.0938 - val_loss: 107.8729\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48381.2891 - val_loss: 108.6797\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47597.2578 - val_loss: 104.8033\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 149859.4688 - val_loss: 104.0589\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 114981.9844 - val_loss: 105.9277\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6318.1108 - val_loss: 106.8858\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 725.5626 - val_loss: 107.8776\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 54472.9688 - val_loss: 107.5745\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36064.2891 - val_loss: 104.7530\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39816.9336 - val_loss: 105.0433\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 10636.1016 - val_loss: 108.2971\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 149325.2344 - val_loss: 108.4047\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 121910.6953 - val_loss: 106.5613\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3594.7559 - val_loss: 104.7505\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22208.2773 - val_loss: 106.1796\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 38137.3477 - val_loss: 106.6054\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1918.6617 - val_loss: 105.2404\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32523.2559 - val_loss: 105.6413\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25071.5156 - val_loss: 105.1503\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37338.4258 - val_loss: 104.3829\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21466.7969 - val_loss: 105.1606\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 28977.7793 - val_loss: 104.2068\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8403.9492 - val_loss: 103.8614\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55482.3281 - val_loss: 104.8214\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41589.6523 - val_loss: 106.2203\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 67281.3516 - val_loss: 104.1849\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12232.5029 - val_loss: 104.3409\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 27208.9531 - val_loss: 103.2105\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43554.5820 - val_loss: 100.9822\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 69674.9297 - val_loss: 102.3310\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45491.2383 - val_loss: 104.3790\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 64073.1367 - val_loss: 103.3946\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10863.7188 - val_loss: 104.1719\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29047.2891 - val_loss: 103.9676\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21921.2832 - val_loss: 104.4444\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42459.6016 - val_loss: 104.3222\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff408c00700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 35 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 92.2922 - val_loss: 71.1944\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.2649 - val_loss: 24.8610\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.5281 - val_loss: 14.2349\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23.0948 - val_loss: 29.2526\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.8827 - val_loss: 29.2090\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16.4780 - val_loss: 16.2397\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.5646 - val_loss: 10.6365\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.7182 - val_loss: 17.6316\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 13.9179 - val_loss: 13.1956\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.8771 - val_loss: 5.5770\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.1770 - val_loss: 12.8365\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2040 - val_loss: 9.5299\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2520 - val_loss: 6.4465\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2621 - val_loss: 6.7687\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4979 - val_loss: 5.7723\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3836 - val_loss: 5.6141\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.0919 - val_loss: 7.4184\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.1999 - val_loss: 3.5880\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6556 - val_loss: 5.3937\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9587 - val_loss: 5.4319\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9187 - val_loss: 4.3731\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7847 - val_loss: 3.4750\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8451 - val_loss: 6.3218\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7754 - val_loss: 3.6722\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.6989 - val_loss: 3.1009\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.0309 - val_loss: 4.4676\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3280 - val_loss: 3.9990\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6472 - val_loss: 3.2335\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9015 - val_loss: 2.4429\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6910 - val_loss: 2.4469\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.3362 - val_loss: 3.5243\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7134 - val_loss: 2.2050\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7245 - val_loss: 4.6028\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7605 - val_loss: 3.4502\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0662 - val_loss: 2.4545\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9075 - val_loss: 2.2542\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2074 - val_loss: 4.1417\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.1186 - val_loss: 3.6481\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.9094 - val_loss: 2.5435\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1652 - val_loss: 2.0318\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.7951 - val_loss: 2.6840\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6679 - val_loss: 2.5272\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3584 - val_loss: 2.9689\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.7479 - val_loss: 2.1478\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1569 - val_loss: 3.4359\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7242 - val_loss: 2.8462\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9157 - val_loss: 5.0192\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.4018 - val_loss: 2.4543\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0218 - val_loss: 2.4552\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6286 - val_loss: 2.0050\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3911efc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 36 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 6454.6201 - val_loss: 104.8494\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 283533.4062 - val_loss: 102.1067\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 200994.7188 - val_loss: 106.3642\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 105261.1875 - val_loss: 113.2210\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42361.6719 - val_loss: 116.8634\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54986.4453 - val_loss: 116.0023\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16433.2754 - val_loss: 111.4322\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 45192.9141 - val_loss: 110.0626\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 47991.7812 - val_loss: 111.3075\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3888.7754 - val_loss: 113.5707\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35320.1914 - val_loss: 113.8868\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30881.0234 - val_loss: 112.0072\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19374.3340 - val_loss: 111.6207\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15450.0342 - val_loss: 113.1115\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31015.4844 - val_loss: 113.3273\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42212.2930 - val_loss: 111.0835\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30436.2656 - val_loss: 110.7952\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 506.4196 - val_loss: 112.0821\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37244.0859 - val_loss: 113.1146\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66698.1953 - val_loss: 112.2058\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 176.3009 - val_loss: 111.8537\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 45466.9023 - val_loss: 111.0550\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3850.8425 - val_loss: 109.3791\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71408.1484 - val_loss: 107.9134\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64524.3945 - val_loss: 108.6426\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18368.9395 - val_loss: 110.7094\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38484.1562 - val_loss: 110.9014\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3127.3013 - val_loss: 111.3385\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57879.6133 - val_loss: 111.7671\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36054.0703 - val_loss: 110.2448\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 14360.9541 - val_loss: 106.7848\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 103399.3047 - val_loss: 106.2642\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 105855.8281 - val_loss: 107.1749\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 85851.8672 - val_loss: 108.8924\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18302.6934 - val_loss: 110.4610\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9149.9297 - val_loss: 113.0273\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 104976.7031 - val_loss: 114.1698\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 109230.3203 - val_loss: 112.1826\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 42802.1797 - val_loss: 110.1362\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3093.9290 - val_loss: 108.3966\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14790.3242 - val_loss: 109.3332\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22173.9160 - val_loss: 108.8178\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9851.7217 - val_loss: 109.0111\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9473.6592 - val_loss: 108.3454\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 963.8651 - val_loss: 106.8637\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 57504.5117 - val_loss: 107.1570\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 42099.5742 - val_loss: 108.2609\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23659.9707 - val_loss: 108.3235\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7302.0986 - val_loss: 108.6665\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32126.9414 - val_loss: 108.7733\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39166c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 37 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 88.3535 - val_loss: 68.1318\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38.8218 - val_loss: 11.7276\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.4999 - val_loss: 12.2808\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.3156 - val_loss: 29.2809\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.2007 - val_loss: 27.6739\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 17.0522 - val_loss: 15.1823\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.8879 - val_loss: 12.4119\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.3922 - val_loss: 18.6205\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.3836 - val_loss: 18.4873\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.5859 - val_loss: 12.6613\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.7495 - val_loss: 11.2694\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.6436 - val_loss: 9.7829\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.6036 - val_loss: 11.8353\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.7703 - val_loss: 11.2531\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3407 - val_loss: 6.9640\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2201 - val_loss: 6.0405\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5825 - val_loss: 4.5708\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.0814 - val_loss: 2.9181\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7232 - val_loss: 4.9905\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4526 - val_loss: 2.8177\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7680 - val_loss: 2.8868\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2227 - val_loss: 2.3608\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3116 - val_loss: 3.4739\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0903 - val_loss: 4.0905\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6367 - val_loss: 3.2994\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8469 - val_loss: 3.9080\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.1553 - val_loss: 2.1825\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2319 - val_loss: 6.8164\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8235 - val_loss: 2.0941\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2126 - val_loss: 4.2298\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5363 - val_loss: 2.3346\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5118 - val_loss: 3.3796\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2625 - val_loss: 2.0925\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5620 - val_loss: 2.3682\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9295 - val_loss: 2.0745\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4146 - val_loss: 2.9311\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.3597 - val_loss: 2.8244\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4207 - val_loss: 2.8942\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.2319 - val_loss: 1.9839\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2768 - val_loss: 2.3130\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9006 - val_loss: 2.9793\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6481 - val_loss: 2.0463\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8734 - val_loss: 3.6600\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.3238 - val_loss: 1.9226\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1382 - val_loss: 2.1147\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 6.0400 - val_loss: 1.9740\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 5.6225 - val_loss: 1.9073\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.6747 - val_loss: 4.1093\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9441 - val_loss: 2.5099\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9442 - val_loss: 1.9176\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37741f430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 38 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 2s 391ms/step - loss: 106.6492 - val_loss: 88.8689\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 58.6450 - val_loss: 49.4876\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 46.4259 - val_loss: 36.7340\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38.3308 - val_loss: 40.4452\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30.7453 - val_loss: 30.3787\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25.2802 - val_loss: 17.7301\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21.4491 - val_loss: 22.7441\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.4469 - val_loss: 8.4443\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.7074 - val_loss: 10.2661\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.4527 - val_loss: 9.4303\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.2777 - val_loss: 3.7910\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.0766 - val_loss: 10.5699\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.6351 - val_loss: 4.4676\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.1807 - val_loss: 8.2138\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.8128 - val_loss: 5.5880\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.6027 - val_loss: 3.5470\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.4302 - val_loss: 6.4506\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.0012 - val_loss: 3.5210\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5844 - val_loss: 4.7805\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.4724 - val_loss: 4.0074\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.6325 - val_loss: 5.0647\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6998 - val_loss: 3.8720\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2570 - val_loss: 4.8659\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.0073 - val_loss: 5.2977\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1513 - val_loss: 6.2497\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3598 - val_loss: 3.5096\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6473 - val_loss: 3.7254\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5423 - val_loss: 4.1912\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.5464 - val_loss: 3.6516\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7624 - val_loss: 3.2852\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4397 - val_loss: 5.5144\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0904 - val_loss: 4.8424\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.9834 - val_loss: 3.4136\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.7152 - val_loss: 3.6776\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6089 - val_loss: 5.5205\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6148 - val_loss: 5.6466\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.8675 - val_loss: 3.0294\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7757 - val_loss: 4.6529\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1457 - val_loss: 2.9399\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2373 - val_loss: 4.4106\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5973 - val_loss: 4.4972\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.6637 - val_loss: 3.5830\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0501 - val_loss: 4.3204\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8645 - val_loss: 4.8644\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.6770 - val_loss: 3.7659\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3571 - val_loss: 3.4179\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8596 - val_loss: 3.7493\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9508 - val_loss: 4.0341\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0125 - val_loss: 4.1352\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8676 - val_loss: 3.1303\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3daaeb040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 39 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 100758.8516 - val_loss: 115.2853\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 73958.2031 - val_loss: 127.4238\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 357271.0000 - val_loss: 128.5520\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 233499.8438 - val_loss: 120.2054\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24106.0215 - val_loss: 117.5736\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42250.8633 - val_loss: 116.7827\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 46422.6875 - val_loss: 118.0269\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 100423.7969 - val_loss: 116.9192\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40921.6680 - val_loss: 114.3907\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 60302.0469 - val_loss: 113.3850\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29676.8164 - val_loss: 115.0302\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47855.2773 - val_loss: 116.5882\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 189850.0625 - val_loss: 115.9908\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 130938.5234 - val_loss: 111.4745\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57586.7109 - val_loss: 110.3897\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51203.6094 - val_loss: 110.5780\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11954.6904 - val_loss: 109.1253\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 29341.5391 - val_loss: 111.1494\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 138325.6250 - val_loss: 110.0980\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 76408.7266 - val_loss: 106.7955\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 112324.6016 - val_loss: 105.2824\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44643.8203 - val_loss: 107.6341\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 91976.3672 - val_loss: 108.7160\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39388.5430 - val_loss: 107.1491\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22531.5273 - val_loss: 107.7017\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41085.3242 - val_loss: 107.2812\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13334.5010 - val_loss: 107.1167\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44848.4453 - val_loss: 107.0156\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36489.8945 - val_loss: 105.0159\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 76045.1016 - val_loss: 107.2325\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30835.0254 - val_loss: 108.4850\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20275.4473 - val_loss: 105.4262\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 145330.3750 - val_loss: 104.1101\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 155569.8281 - val_loss: 106.2256\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 39183.3047 - val_loss: 109.5838\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 90940.0156 - val_loss: 109.9444\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 80535.8594 - val_loss: 108.5815\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23435.3965 - val_loss: 106.3502\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29336.6309 - val_loss: 105.9944\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34404.6914 - val_loss: 107.5036\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35520.6914 - val_loss: 107.2752\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 59512.4883 - val_loss: 105.2937\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66407.9766 - val_loss: 106.7590\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29351.6152 - val_loss: 109.3514\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 94138.2734 - val_loss: 110.0099\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 88358.9844 - val_loss: 108.8246\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 60230.8672 - val_loss: 105.9411\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34560.0078 - val_loss: 106.4334\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14939.6904 - val_loss: 107.6081\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 69128.3672 - val_loss: 107.0037\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38b297040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 40 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 63.6651 - val_loss: 44.6762\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48.4798 - val_loss: 37.1273\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.1502 - val_loss: 21.0504\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35.4370 - val_loss: 13.5179\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.5670 - val_loss: 22.3841\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.3280 - val_loss: 20.5226\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27.2481 - val_loss: 9.3108\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24.5417 - val_loss: 5.3931\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23.8533 - val_loss: 12.7211\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 20.2416 - val_loss: 4.6320\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21.8250 - val_loss: 6.4799\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.5117 - val_loss: 6.9806\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.7795 - val_loss: 6.6938\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.2574 - val_loss: 7.5906\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 15.6798 - val_loss: 4.2540\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4400 - val_loss: 5.9278\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.5936 - val_loss: 8.1005\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.8948 - val_loss: 3.3298\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.6595 - val_loss: 5.2584\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.1741 - val_loss: 6.6756\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1810 - val_loss: 5.3148\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.1941 - val_loss: 3.5763\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.8816 - val_loss: 4.5991\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.3570 - val_loss: 3.6022\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.5997 - val_loss: 7.0688\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.5419 - val_loss: 3.2135\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.7283 - val_loss: 4.9414\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.1288 - val_loss: 6.6549\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4677 - val_loss: 2.8622\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.4809 - val_loss: 5.3237\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9732 - val_loss: 4.1139\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.1853 - val_loss: 4.0270\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.1365 - val_loss: 5.4299\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8762 - val_loss: 5.3159\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1687 - val_loss: 4.6660\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2379 - val_loss: 2.4824\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5991 - val_loss: 4.2024\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.5603 - val_loss: 5.4595\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8092 - val_loss: 3.5079\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1195 - val_loss: 4.0576\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4423 - val_loss: 4.4825\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7738 - val_loss: 4.8130\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4194 - val_loss: 2.3887\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5791 - val_loss: 3.9911\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8483 - val_loss: 3.6444\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8571 - val_loss: 3.6051\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9813 - val_loss: 4.2251\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9128 - val_loss: 2.5665\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2354 - val_loss: 3.0110\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1543 - val_loss: 6.0495\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3947a94c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 41 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 215861.5625 - val_loss: 85.9586\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 120025.3047 - val_loss: 96.3312\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 75559.0312 - val_loss: 98.2554\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 80588.1406 - val_loss: 97.1630\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20573.5293 - val_loss: 93.9475\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 59364.7227 - val_loss: 92.0222\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58767.2031 - val_loss: 93.6878\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14081.7568 - val_loss: 96.7459\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 48821.8008 - val_loss: 97.3380\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49443.4336 - val_loss: 96.3185\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8705.3926 - val_loss: 93.8557\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 79919.4922 - val_loss: 92.7103\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 51834.4492 - val_loss: 94.9864\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25471.5312 - val_loss: 98.4012\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 75189.9297 - val_loss: 98.9220\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 86628.3516 - val_loss: 97.2007\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15626.7021 - val_loss: 95.4865\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 42640.6484 - val_loss: 94.8365\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13667.9141 - val_loss: 95.7630\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19224.6504 - val_loss: 98.5479\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 53175.5586 - val_loss: 98.7493\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 63236.1172 - val_loss: 97.3592\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24200.5410 - val_loss: 95.4511\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 80632.1484 - val_loss: 94.5125\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57547.1445 - val_loss: 96.3280\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13366.3203 - val_loss: 98.3708\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 100327.8750 - val_loss: 99.0874\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 75206.5703 - val_loss: 97.2835\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11340.3203 - val_loss: 95.9915\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48501.3281 - val_loss: 94.8603\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 49913.1211 - val_loss: 95.4622\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16119.8193 - val_loss: 96.7856\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54825.5000 - val_loss: 97.2984\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1874.7822 - val_loss: 97.0993\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11119.9043 - val_loss: 96.6890\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16182.2930 - val_loss: 96.6540\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 16095.6680 - val_loss: 96.6020\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15038.3721 - val_loss: 96.3269\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9307.3740 - val_loss: 96.2435\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19382.4238 - val_loss: 96.9085\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 17484.8281 - val_loss: 96.5810\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13021.3721 - val_loss: 96.5456\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33098.5156 - val_loss: 96.9745\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7026.1406 - val_loss: 96.0463\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17546.9023 - val_loss: 96.5165\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5309.1265 - val_loss: 95.7548\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28563.6719 - val_loss: 95.6644\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10641.9795 - val_loss: 96.3820\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28957.2363 - val_loss: 96.2079\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24980.7402 - val_loss: 97.7689\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39bcd0ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 42 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 18406.4570 - val_loss: 99.6344\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 235769.9688 - val_loss: 97.6121\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 167104.0000 - val_loss: 93.1506\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 95455.5078 - val_loss: 86.8938\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21753.5664 - val_loss: 86.9883\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23733.8066 - val_loss: 88.3160\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5994.3232 - val_loss: 87.9567\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8598.0928 - val_loss: 89.8959\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 37687.2969 - val_loss: 88.9537\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3201.7668 - val_loss: 88.8638\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 459.3812 - val_loss: 89.3804\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24087.6973 - val_loss: 90.3560\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20971.4863 - val_loss: 90.3608\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11281.6533 - val_loss: 86.6566\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 92521.5625 - val_loss: 84.9632\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 49078.4062 - val_loss: 88.6292\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 58304.3633 - val_loss: 91.8157\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 38880.9258 - val_loss: 90.9290\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4820.4907 - val_loss: 92.0477\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22580.4512 - val_loss: 90.6783\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15322.3467 - val_loss: 89.0132\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61224.9805 - val_loss: 88.4762\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42375.7344 - val_loss: 89.6491\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4281.4375 - val_loss: 90.3520\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34451.3008 - val_loss: 90.3076\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7413.4937 - val_loss: 91.0107\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1080.2172 - val_loss: 88.6070\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 76453.0469 - val_loss: 87.6195\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 50031.2812 - val_loss: 91.7341\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15734.8047 - val_loss: 91.9915\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18081.5137 - val_loss: 89.9236\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50060.6719 - val_loss: 89.6323\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32859.7266 - val_loss: 91.4903\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 47426.3867 - val_loss: 93.0093\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31033.1348 - val_loss: 89.8323\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66151.5156 - val_loss: 88.5821\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34367.9219 - val_loss: 90.8041\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24601.6074 - val_loss: 91.2685\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15993.3252 - val_loss: 90.1131\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36527.0352 - val_loss: 89.8655\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29298.1250 - val_loss: 91.1861\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30154.7441 - val_loss: 92.2833\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13876.9395 - val_loss: 90.6355\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55875.3359 - val_loss: 89.3135\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40076.4844 - val_loss: 91.6447\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14379.9736 - val_loss: 92.1364\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33686.1367 - val_loss: 91.1601\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25240.8633 - val_loss: 91.0031\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12095.0195 - val_loss: 92.7005\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28759.5059 - val_loss: 92.5353\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3bd634ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 43 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 89.2868 - val_loss: 70.6639\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48.2791 - val_loss: 33.0745\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44.9887 - val_loss: 34.3543\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 36.3154 - val_loss: 41.9946\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31.6127 - val_loss: 38.1301\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.8515 - val_loss: 26.8214\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.0651 - val_loss: 20.3867\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.9299 - val_loss: 23.8090\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20.0566 - val_loss: 18.4804\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.3187 - val_loss: 9.3314\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4761 - val_loss: 9.3841\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.1601 - val_loss: 4.9607\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.3893 - val_loss: 8.0542\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.1638 - val_loss: 4.4677\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.0914 - val_loss: 5.8287\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4313 - val_loss: 3.5323\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.1782 - val_loss: 6.4990\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.0231 - val_loss: 4.6870\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.6505 - val_loss: 4.1569\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.9310 - val_loss: 4.5351\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9096 - val_loss: 1.7742\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.1045 - val_loss: 3.7843\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.0189 - val_loss: 3.5822\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9412 - val_loss: 2.8906\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.8181 - val_loss: 2.0160\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6549 - val_loss: 1.8263\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1100 - val_loss: 2.6223\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7428 - val_loss: 2.2605\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.3610 - val_loss: 4.6347\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3387 - val_loss: 2.9373\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9384 - val_loss: 2.4714\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2933 - val_loss: 2.1367\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8445 - val_loss: 3.8845\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4849 - val_loss: 2.5937\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4613 - val_loss: 1.6541\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.2385 - val_loss: 2.7581\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3631 - val_loss: 4.3011\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3184 - val_loss: 4.6231\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.5843 - val_loss: 1.5335\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2466 - val_loss: 3.9929\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8597 - val_loss: 1.5909\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1246 - val_loss: 4.8424\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5209 - val_loss: 1.6189\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7084 - val_loss: 2.0784\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5870 - val_loss: 2.3097\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4873 - val_loss: 3.9243\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8424 - val_loss: 1.6159\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2526 - val_loss: 4.5965\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4022 - val_loss: 2.0987\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 7.4750 - val_loss: 2.3269\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a58dad30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 44 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 85.6371 - val_loss: 64.1759\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61.7604 - val_loss: 36.4964\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47.9813 - val_loss: 34.1161\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 35.5584 - val_loss: 32.8323\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29.2040 - val_loss: 22.2039\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.0016 - val_loss: 12.8624\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24.8953 - val_loss: 15.4147\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.5917 - val_loss: 13.9394\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18.7678 - val_loss: 4.0314\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.0534 - val_loss: 4.6771\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.8669 - val_loss: 4.1464\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.3659 - val_loss: 5.9233\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.8710 - val_loss: 5.4068\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.5531 - val_loss: 3.9616\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.9957 - val_loss: 6.5212\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.0554 - val_loss: 5.2757\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.7327 - val_loss: 6.9409\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.9668 - val_loss: 4.1545\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.6278 - val_loss: 6.3137\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.4122 - val_loss: 4.9452\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.3118 - val_loss: 6.2861\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.0767 - val_loss: 5.1584\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8142 - val_loss: 5.3276\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.8694 - val_loss: 3.7330\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.0528 - val_loss: 5.5219\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.2320 - val_loss: 4.2954\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.3217 - val_loss: 5.9241\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9135 - val_loss: 5.5407\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6536 - val_loss: 3.7258\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9809 - val_loss: 6.0820\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5991 - val_loss: 3.6557\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.2260 - val_loss: 6.2610\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.1290 - val_loss: 4.8299\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1893 - val_loss: 3.5906\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8377 - val_loss: 5.1105\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7133 - val_loss: 3.7391\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0011 - val_loss: 4.5189\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6213 - val_loss: 4.4335\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.0111 - val_loss: 4.7460\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8915 - val_loss: 4.2697\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4743 - val_loss: 4.8103\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3055 - val_loss: 4.1062\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7430 - val_loss: 4.3748\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0182 - val_loss: 3.5588\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4290 - val_loss: 5.3516\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4888 - val_loss: 4.4826\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3609 - val_loss: 3.3048\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9218 - val_loss: 7.8745\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.7484 - val_loss: 3.3978\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.3374 - val_loss: 4.3300\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a0d12e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 45 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 167546.9062 - val_loss: 78.1776\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47594.1523 - val_loss: 89.9409\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 165977.0156 - val_loss: 95.6954\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 155881.9844 - val_loss: 93.0433\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 60625.1055 - val_loss: 90.9415\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 25482.0801 - val_loss: 85.4666\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 101988.9688 - val_loss: 83.6258\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 89947.2500 - val_loss: 85.7356\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43587.4023 - val_loss: 87.7363\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20933.9043 - val_loss: 91.5382\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33894.4141 - val_loss: 92.1194\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 60804.3477 - val_loss: 91.5034\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24731.3320 - val_loss: 89.2873\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12283.2627 - val_loss: 88.4906\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 462.0206 - val_loss: 89.3911\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16275.4756 - val_loss: 89.0553\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6738.6309 - val_loss: 86.5132\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 81474.7266 - val_loss: 86.4036\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 72490.4688 - val_loss: 87.7047\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13590.0518 - val_loss: 91.9693\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27081.1758 - val_loss: 92.8529\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 56025.4023 - val_loss: 91.7660\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17290.7012 - val_loss: 90.3829\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34438.7031 - val_loss: 89.4275\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28676.8027 - val_loss: 90.1819\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21682.9609 - val_loss: 93.1446\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 77640.8516 - val_loss: 93.7809\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71179.2812 - val_loss: 93.6589\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 79599.0625 - val_loss: 92.1229\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18032.3594 - val_loss: 89.9079\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 63644.7031 - val_loss: 89.8513\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18673.3340 - val_loss: 91.5129\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 62658.4492 - val_loss: 93.6895\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20154.2734 - val_loss: 94.8928\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4323.9336 - val_loss: 96.0338\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 63395.7695 - val_loss: 95.8992\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30488.7363 - val_loss: 94.3064\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7567.6602 - val_loss: 91.3415\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 60222.0977 - val_loss: 90.8211\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55923.2617 - val_loss: 92.1690\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7908.6372 - val_loss: 94.0238\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21952.6992 - val_loss: 94.3224\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47811.3516 - val_loss: 93.8764\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8954.8779 - val_loss: 93.1453\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16826.7559 - val_loss: 93.5040\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 74338.8594 - val_loss: 94.0337\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47816.1992 - val_loss: 92.9321\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8866.1328 - val_loss: 92.8272\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17888.4844 - val_loss: 94.4204\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58733.3086 - val_loss: 95.0209\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38603f1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 46 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 193431.5312 - val_loss: 86.4206\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 70578.9844 - val_loss: 97.6538\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 161432.9688 - val_loss: 101.6538\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 148769.0938 - val_loss: 100.1599\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 101741.8984 - val_loss: 94.7789\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 35604.7656 - val_loss: 93.8918\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32925.5312 - val_loss: 95.7059\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10920.0215 - val_loss: 94.9458\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12536.7666 - val_loss: 95.6261\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11777.0859 - val_loss: 95.4173\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2332.7410 - val_loss: 96.2502\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38866.5391 - val_loss: 96.2009\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2547.1416 - val_loss: 94.4710\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 60831.8555 - val_loss: 93.4240\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24595.7461 - val_loss: 94.4284\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21365.3496 - val_loss: 96.6493\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 85625.5938 - val_loss: 97.5439\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 92332.1562 - val_loss: 95.7335\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14901.5625 - val_loss: 93.6144\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 62068.7031 - val_loss: 93.3084\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 89317.8984 - val_loss: 93.6935\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 609.9868 - val_loss: 95.3304\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22317.7031 - val_loss: 96.5821\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 54700.4102 - val_loss: 96.0626\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8849.3877 - val_loss: 94.8387\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3746.7681 - val_loss: 94.8732\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38172.5117 - val_loss: 95.9462\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40839.4297 - val_loss: 95.9537\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10511.1748 - val_loss: 94.9374\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61570.1758 - val_loss: 95.4028\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6314.2305 - val_loss: 96.8359\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2209.5479 - val_loss: 97.3601\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 640.3018 - val_loss: 95.7668\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 82627.3281 - val_loss: 95.2197\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 60901.8945 - val_loss: 96.2078\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10406.1865 - val_loss: 98.1345\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45271.6680 - val_loss: 98.6830\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57703.8477 - val_loss: 97.5237\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30591.3594 - val_loss: 97.5304\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10913.9971 - val_loss: 96.8892\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34209.7266 - val_loss: 97.5050\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30068.5488 - val_loss: 97.5553\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7597.5708 - val_loss: 97.1775\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2578.7432 - val_loss: 97.6285\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29911.7832 - val_loss: 97.3317\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5474.8818 - val_loss: 97.6051\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19017.3105 - val_loss: 97.4161\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3388.1167 - val_loss: 96.0273\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 68146.6016 - val_loss: 95.5677\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51623.5195 - val_loss: 96.7700\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ce6aa9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 47 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - val_loss: 96.2311\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b7becc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 48 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 53702.0312 - val_loss: 88.0717\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 98598.1484 - val_loss: 87.4198\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53209.0625 - val_loss: 93.8294\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 58078.5742 - val_loss: 94.4762\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 72687.4141 - val_loss: 90.3149\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 76991.4609 - val_loss: 89.0426\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19133.1582 - val_loss: 93.0912\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3685.9695 - val_loss: 93.7157\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10859.3955 - val_loss: 91.4382\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45998.3594 - val_loss: 91.9569\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3079.3000 - val_loss: 92.0996\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 58999.8555 - val_loss: 92.9172\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15012.6689 - val_loss: 92.0484\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51572.9258 - val_loss: 92.4801\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1416.1949 - val_loss: 91.4776\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37968.5781 - val_loss: 91.3562\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38680.6133 - val_loss: 96.1662\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 98585.3438 - val_loss: 97.4845\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 84997.4375 - val_loss: 95.4407\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43460.2148 - val_loss: 91.5232\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45251.9883 - val_loss: 91.3297\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24211.5605 - val_loss: 93.8557\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36236.0781 - val_loss: 94.5019\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 2510.6643 - val_loss: 94.4100\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13841.9619 - val_loss: 92.3272\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20786.5684 - val_loss: 91.7131\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37492.8320 - val_loss: 95.5932\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26411.1094 - val_loss: 96.0523\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5032.4653 - val_loss: 93.9225\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9074.5186 - val_loss: 94.4326\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17070.9219 - val_loss: 93.2917\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11698.7529 - val_loss: 93.1109\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13481.7695 - val_loss: 93.4913\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1599.0770 - val_loss: 95.3979\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 45625.3711 - val_loss: 96.0731\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17074.2148 - val_loss: 92.1014\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51809.9766 - val_loss: 91.8322\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 59339.8281 - val_loss: 92.5156\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 31845.7402 - val_loss: 97.0904\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 28521.3906 - val_loss: 98.3559\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 118269.4453 - val_loss: 97.9377\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28138.0586 - val_loss: 96.0727\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22710.6680 - val_loss: 92.6499\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 84851.4766 - val_loss: 91.6303\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 52333.0195 - val_loss: 92.8073\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27375.0547 - val_loss: 95.2226\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19981.7812 - val_loss: 96.3115\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29403.3555 - val_loss: 93.5798\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 57449.4414 - val_loss: 92.7255\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 58390.9883 - val_loss: 94.9758\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37a0d7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 49 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 83.6205 - val_loss: 66.3334\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48.5071 - val_loss: 37.6629\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45.6919 - val_loss: 35.7339\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33.6741 - val_loss: 39.3260\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.3603 - val_loss: 24.7820\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.7781 - val_loss: 11.6655\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.8589 - val_loss: 14.8548\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.0258 - val_loss: 4.4762\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.8537 - val_loss: 8.3836\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.0104 - val_loss: 3.4597\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.9552 - val_loss: 4.9267\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.3288 - val_loss: 4.9522\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.7902 - val_loss: 3.2888\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.0196 - val_loss: 3.7471\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.3593 - val_loss: 4.1802\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.8766 - val_loss: 6.4664\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.4953 - val_loss: 4.0192\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.4012 - val_loss: 3.4460\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.7490 - val_loss: 5.0255\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4005 - val_loss: 3.0046\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6706 - val_loss: 4.7993\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.6035 - val_loss: 4.2087\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.6845 - val_loss: 3.3560\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.0449 - val_loss: 2.8322\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.5441 - val_loss: 3.8974\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.6746 - val_loss: 4.5303\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.8366 - val_loss: 5.2272\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9576 - val_loss: 2.7359\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.4985 - val_loss: 3.6163\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6756 - val_loss: 2.7311\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5990 - val_loss: 3.8768\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9336 - val_loss: 2.7010\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8114 - val_loss: 2.8021\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.6758 - val_loss: 3.1510\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0990 - val_loss: 3.8968\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.0462 - val_loss: 3.7249\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.4714 - val_loss: 3.1119\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2086 - val_loss: 5.0539\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7366 - val_loss: 2.8285\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.2444 - val_loss: 3.8868\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0788 - val_loss: 3.1667\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6037 - val_loss: 5.6985\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.4967 - val_loss: 2.6311\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 9.3668 - val_loss: 3.2989\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1304 - val_loss: 3.7396\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3489 - val_loss: 2.5665\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1381 - val_loss: 5.6908\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8813 - val_loss: 2.9694\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1097 - val_loss: 2.6332\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8283 - val_loss: 3.9037\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37e2164c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 50 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 75.9512 - val_loss: 58.7903\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37.6462 - val_loss: 22.7437\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34.4864 - val_loss: 23.7047\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.8974 - val_loss: 30.5296\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23.9938 - val_loss: 23.2550\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 19.4367 - val_loss: 16.1333\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.2296 - val_loss: 16.1143\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.5827 - val_loss: 11.8911\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.3128 - val_loss: 4.6849\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.8477 - val_loss: 5.5345\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.7283 - val_loss: 3.5213\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.1695 - val_loss: 7.6026\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.7807 - val_loss: 5.2269\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5609 - val_loss: 8.5945\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.5993 - val_loss: 5.3636\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1249 - val_loss: 5.3606\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6037 - val_loss: 3.5571\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.6124 - val_loss: 7.4069\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2001 - val_loss: 3.3738\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8956 - val_loss: 5.2908\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7433 - val_loss: 3.4296\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8934 - val_loss: 8.0897\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8480 - val_loss: 3.4352\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0769 - val_loss: 6.1229\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7142 - val_loss: 3.3824\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7235 - val_loss: 5.5926\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2686 - val_loss: 3.3931\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3064 - val_loss: 5.4543\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7406 - val_loss: 3.8181\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3791 - val_loss: 4.2855\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5092 - val_loss: 5.6932\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0346 - val_loss: 3.3168\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8900 - val_loss: 6.5508\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8933 - val_loss: 3.3567\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1687 - val_loss: 5.3572\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6374 - val_loss: 3.9359\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4373 - val_loss: 3.6402\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9741 - val_loss: 4.9928\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9072 - val_loss: 3.4439\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2222 - val_loss: 3.6363\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1136 - val_loss: 3.6438\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3087 - val_loss: 3.3224\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7912 - val_loss: 3.5071\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7905 - val_loss: 4.3324\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0947 - val_loss: 3.6225\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5601 - val_loss: 3.5017\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7374 - val_loss: 3.3893\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2167 - val_loss: 5.3265\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1920 - val_loss: 3.4107\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5918 - val_loss: 5.0455\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37fd8a550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 51 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 176791.4062 - val_loss: 98.5928\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 400391.6562 - val_loss: 96.2703\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 322773.3438 - val_loss: 105.5253\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26168.5547 - val_loss: 115.4924\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 320061.7500 - val_loss: 118.2338\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 277561.4062 - val_loss: 115.2709\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 160706.4062 - val_loss: 110.1359\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20233.4844 - val_loss: 108.8817\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24765.6152 - val_loss: 106.7289\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 71696.2734 - val_loss: 107.2066\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35267.3750 - val_loss: 110.1084\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 117581.5938 - val_loss: 111.5078\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28238.5625 - val_loss: 107.3327\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 166891.1094 - val_loss: 106.5599\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34430.4492 - val_loss: 107.2007\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2824.9783 - val_loss: 112.3717\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 206777.4688 - val_loss: 113.4809\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 136493.2031 - val_loss: 111.9452\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17346.2188 - val_loss: 108.4380\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21583.2090 - val_loss: 107.1592\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71364.5391 - val_loss: 109.3576\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16757.6992 - val_loss: 108.1842\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10581.2070 - val_loss: 108.3354\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66800.3438 - val_loss: 110.2354\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 92619.0000 - val_loss: 107.4291\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7046.9351 - val_loss: 106.8736\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39928.8359 - val_loss: 108.6269\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 134408.6875 - val_loss: 109.2419\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 96984.9297 - val_loss: 106.0879\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45001.8555 - val_loss: 104.1408\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 155717.6406 - val_loss: 105.6673\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24036.2539 - val_loss: 106.3691\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 69178.1250 - val_loss: 106.7208\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 58255.1055 - val_loss: 110.1863\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 82757.9844 - val_loss: 110.7947\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 109177.7344 - val_loss: 109.4678\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27758.3594 - val_loss: 106.6444\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25924.1680 - val_loss: 105.9464\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61194.9531 - val_loss: 107.3213\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5575.8979 - val_loss: 107.2163\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18117.0820 - val_loss: 108.4123\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48297.0195 - val_loss: 111.0761\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 56745.0391 - val_loss: 111.1716\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 99128.6797 - val_loss: 109.8695\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9584.5146 - val_loss: 107.2514\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 122211.1016 - val_loss: 104.6111\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22085.2539 - val_loss: 105.1963\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3233.3728 - val_loss: 105.9843\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 111784.1875 - val_loss: 105.2360\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14361.5557 - val_loss: 107.9161\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37c893dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 52 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 180818.6250 - val_loss: 88.1180\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 3215.7405 - val_loss: 88.7926\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24925.0059 - val_loss: 93.4763\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 48479.8008 - val_loss: 92.0449\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9976.3711 - val_loss: 87.5922\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 106794.5938 - val_loss: 85.6297\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 97297.8594 - val_loss: 89.9011\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11290.6436 - val_loss: 94.9076\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46157.0547 - val_loss: 95.7060\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 68617.6875 - val_loss: 93.8496\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15707.0479 - val_loss: 89.5092\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 84584.0938 - val_loss: 88.2058\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 85239.6719 - val_loss: 90.7970\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13520.1191 - val_loss: 95.8119\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 113926.6328 - val_loss: 97.8873\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 91932.9688 - val_loss: 93.9245\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14693.8623 - val_loss: 89.4802\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 99470.6875 - val_loss: 88.1869\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 89901.3281 - val_loss: 90.5593\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25941.8828 - val_loss: 93.5366\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1464.1870 - val_loss: 97.9660\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 123588.9609 - val_loss: 99.3299\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 124731.6875 - val_loss: 98.7512\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 76781.9297 - val_loss: 96.5060\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 25044.4531 - val_loss: 93.5056\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15696.9092 - val_loss: 92.7972\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34320.4414 - val_loss: 94.4452\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11717.3779 - val_loss: 94.2310\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19501.4629 - val_loss: 94.1355\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16030.8916 - val_loss: 94.8272\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2040.9092 - val_loss: 92.8229\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28784.9863 - val_loss: 93.1017\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40301.5742 - val_loss: 95.4900\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25280.7871 - val_loss: 95.5313\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22332.1152 - val_loss: 93.5577\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48492.5117 - val_loss: 93.1914\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41918.3711 - val_loss: 95.3401\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28386.1406 - val_loss: 96.1922\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9768.6211 - val_loss: 95.0868\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31517.9531 - val_loss: 93.7682\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54995.8672 - val_loss: 94.0640\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26233.3066 - val_loss: 96.0897\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71272.6875 - val_loss: 97.0828\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52849.8828 - val_loss: 95.8172\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38813.4219 - val_loss: 94.7002\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22232.2559 - val_loss: 93.4270\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55074.2383 - val_loss: 94.3941\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20554.7891 - val_loss: 95.4820\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 66175.6016 - val_loss: 96.7168\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37527.4062 - val_loss: 95.8829\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37c893790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 53 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 40.1007 - val_loss: 12.4833\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22.9718 - val_loss: 4.1122\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.3497 - val_loss: 21.2021\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.1286 - val_loss: 18.9175\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.3740 - val_loss: 7.9346\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.5659 - val_loss: 6.7938\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.8587 - val_loss: 11.2993\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.8577 - val_loss: 6.8569\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.1133 - val_loss: 8.3230\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.0632 - val_loss: 2.6608\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.2850 - val_loss: 3.5841\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.1377 - val_loss: 3.2458\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.3576 - val_loss: 3.9392\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.6899 - val_loss: 3.3301\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.4931 - val_loss: 3.6250\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.5446 - val_loss: 3.0231\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1208 - val_loss: 3.2495\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8775 - val_loss: 2.6800\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3695 - val_loss: 2.9447\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7513 - val_loss: 2.5702\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2331 - val_loss: 3.4093\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5318 - val_loss: 2.8609\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.9426 - val_loss: 2.6487\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5814 - val_loss: 3.8556\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.5902 - val_loss: 2.5587\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1060 - val_loss: 3.0834\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4301 - val_loss: 2.5139\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6149 - val_loss: 2.6371\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4606 - val_loss: 2.1056\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2432 - val_loss: 2.1232\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7051 - val_loss: 4.1902\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.4783 - val_loss: 2.7315\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3735 - val_loss: 4.4525\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9093 - val_loss: 2.5050\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1657 - val_loss: 2.7854\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5888 - val_loss: 2.0988\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7617 - val_loss: 4.2219\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1502 - val_loss: 2.7819\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0252 - val_loss: 2.7793\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7932 - val_loss: 2.2915\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.8756 - val_loss: 2.1651\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3572 - val_loss: 2.2296\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7702 - val_loss: 2.0716\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2860 - val_loss: 2.0317\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.6287 - val_loss: 2.0979\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5243 - val_loss: 3.7915\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6734 - val_loss: 2.1892\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3367 - val_loss: 2.2985\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4808 - val_loss: 2.7045\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7586 - val_loss: 1.9923\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38719d4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 54 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 123295.6328 - val_loss: 94.7552\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 143159.3438 - val_loss: 97.3780\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 81780.5156 - val_loss: 90.2726\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 168223.0156 - val_loss: 90.3401\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 87851.9453 - val_loss: 94.9242\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36831.3242 - val_loss: 94.0983\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28703.0586 - val_loss: 93.1955\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38838.8633 - val_loss: 94.1501\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37963.7227 - val_loss: 94.7745\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21340.1426 - val_loss: 92.7187\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 75296.3984 - val_loss: 92.1918\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53104.6133 - val_loss: 94.7281\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 84907.3828 - val_loss: 95.0445\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29735.8555 - val_loss: 92.5970\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 80796.8359 - val_loss: 92.2263\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16100.7002 - val_loss: 93.0191\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12807.6348 - val_loss: 93.8505\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11920.6562 - val_loss: 94.4080\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44289.7617 - val_loss: 94.4913\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19836.2207 - val_loss: 94.8390\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33222.3438 - val_loss: 94.5160\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10508.7939 - val_loss: 95.1578\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24185.2793 - val_loss: 95.3325\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21560.8574 - val_loss: 94.9257\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14458.2744 - val_loss: 98.3699\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 219025.0469 - val_loss: 99.5941\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 128144.1484 - val_loss: 95.6169\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41560.0938 - val_loss: 92.3039\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 117268.8125 - val_loss: 92.8002\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54868.1523 - val_loss: 96.1788\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 99510.5547 - val_loss: 97.4041\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 41355.7656 - val_loss: 94.6167\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50484.8828 - val_loss: 93.0795\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 77070.3984 - val_loss: 94.2828\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24919.9531 - val_loss: 95.7725\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19292.2539 - val_loss: 94.8391\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 32986.4062 - val_loss: 94.9286\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11604.6650 - val_loss: 94.5727\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 39444.6055 - val_loss: 95.4442\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40698.7930 - val_loss: 96.7746\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 70816.0156 - val_loss: 96.1617\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45863.1250 - val_loss: 94.3450\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 47398.1758 - val_loss: 95.1779\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2449.4709 - val_loss: 96.1436\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31123.7402 - val_loss: 95.6039\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20346.4023 - val_loss: 94.1123\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 71050.0547 - val_loss: 95.1324\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26752.0332 - val_loss: 95.9889\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14369.5312 - val_loss: 95.5920\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23089.8027 - val_loss: 92.2235\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a0d12430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 55 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 197675.7656 - val_loss: 88.7351\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4830.3140 - val_loss: 99.8018\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 127668.2266 - val_loss: 104.3872\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 142696.0312 - val_loss: 102.1252\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 73971.3047 - val_loss: 97.4098\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3208.5723 - val_loss: 90.8949\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 90874.9609 - val_loss: 90.1549\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 103269.1953 - val_loss: 91.3164\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 79261.7344 - val_loss: 96.1049\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38282.5938 - val_loss: 98.1029\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42642.1875 - val_loss: 95.8499\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30025.8125 - val_loss: 94.7243\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12437.8838 - val_loss: 95.2389\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10738.3467 - val_loss: 95.4877\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6602.4888 - val_loss: 94.3921\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39726.7734 - val_loss: 94.5606\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18781.0449 - val_loss: 96.0268\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46717.7188 - val_loss: 97.7290\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47083.7031 - val_loss: 95.9000\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21511.5098 - val_loss: 95.4317\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11726.6211 - val_loss: 95.3524\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9885.2881 - val_loss: 95.8294\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 965.6675 - val_loss: 97.5909\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 38117.0117 - val_loss: 97.3814\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41065.5664 - val_loss: 96.4053\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49349.3555 - val_loss: 95.5981\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8958.2529 - val_loss: 95.3488\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8595.4219 - val_loss: 94.8537\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6689.7056 - val_loss: 95.8065\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32298.6719 - val_loss: 96.3314\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 480.4452 - val_loss: 96.9861\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 36547.3125 - val_loss: 96.3409\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16950.4844 - val_loss: 94.8519\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15843.6895 - val_loss: 94.4529\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27941.1504 - val_loss: 96.4255\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15458.1973 - val_loss: 96.0834\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5941.8892 - val_loss: 94.4525\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 65357.0781 - val_loss: 93.8635\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 55566.4336 - val_loss: 97.4391\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 41473.3359 - val_loss: 98.9228\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 56066.8945 - val_loss: 96.3954\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25812.7832 - val_loss: 96.7599\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 544.2863 - val_loss: 98.4343\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 61895.9492 - val_loss: 97.7054\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45343.1914 - val_loss: 95.1898\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13421.7217 - val_loss: 95.5507\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13449.9629 - val_loss: 97.5474\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52852.3281 - val_loss: 97.5495\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14932.0908 - val_loss: 96.0895\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27016.2559 - val_loss: 94.8449\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3aa69cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 56 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 114857.8828 - val_loss: 91.2899\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19404.2871 - val_loss: 93.9959\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9047.2910 - val_loss: 99.2308\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 80585.9766 - val_loss: 98.4946\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11672.0518 - val_loss: 94.8883\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 68872.6406 - val_loss: 90.4067\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28389.1816 - val_loss: 93.9343\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5541.3628 - val_loss: 100.5913\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 89256.5312 - val_loss: 101.7711\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 93358.1719 - val_loss: 100.5360\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61662.5859 - val_loss: 95.3966\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12410.2793 - val_loss: 95.0290\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11158.4678 - val_loss: 96.9342\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40835.9062 - val_loss: 97.2179\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 67690.4766 - val_loss: 95.2470\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 45797.5742 - val_loss: 93.6434\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 50122.7891 - val_loss: 97.1951\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57189.9688 - val_loss: 98.1095\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 52203.0781 - val_loss: 95.8716\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 29308.2969 - val_loss: 95.9004\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1134.3441 - val_loss: 95.6302\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9991.3389 - val_loss: 92.6977\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 70320.0000 - val_loss: 93.0120\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64769.8750 - val_loss: 94.9526\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31679.9609 - val_loss: 97.2173\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22721.0000 - val_loss: 97.7298\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21569.7363 - val_loss: 97.4742\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24123.2305 - val_loss: 96.1753\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20671.9570 - val_loss: 98.1708\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 59372.8555 - val_loss: 99.1528\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53735.2148 - val_loss: 97.5138\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33075.9258 - val_loss: 97.3119\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1209.3712 - val_loss: 98.9051\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30125.6094 - val_loss: 98.9509\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36554.3555 - val_loss: 97.1740\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6136.3325 - val_loss: 94.3002\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 81670.0234 - val_loss: 94.2062\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 67573.7734 - val_loss: 95.6605\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1224.1749 - val_loss: 97.9124\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 45126.1914 - val_loss: 99.2016\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13576.2568 - val_loss: 97.3871\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 40993.8633 - val_loss: 96.2392\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 143.0913 - val_loss: 95.7800\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 51301.0000 - val_loss: 96.3811\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12126.2529 - val_loss: 98.3290\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10953.2373 - val_loss: 102.8252\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 91840.9922 - val_loss: 103.7267\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 133023.0781 - val_loss: 103.0659\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 82600.2188 - val_loss: 101.5816\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21224.3730 - val_loss: 98.5261\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ab929790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 57 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 67.6282 - val_loss: 49.1643\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.7552 - val_loss: 12.2547\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.1713 - val_loss: 23.5980\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.1325 - val_loss: 31.3361\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.1232 - val_loss: 23.3549\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.2272 - val_loss: 11.9573\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.2968 - val_loss: 15.0325\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.9381 - val_loss: 16.2420\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.5713 - val_loss: 10.4508\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9555 - val_loss: 5.7315\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.3782 - val_loss: 3.3526\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4660 - val_loss: 5.6645\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.1654 - val_loss: 3.5662\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7630 - val_loss: 5.4140\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1056 - val_loss: 3.3176\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9330 - val_loss: 5.9011\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5131 - val_loss: 3.2242\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2500 - val_loss: 7.8938\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6800 - val_loss: 3.6593\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3493 - val_loss: 5.7429\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1311 - val_loss: 3.3591\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9439 - val_loss: 3.8503\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2216 - val_loss: 4.4457\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9757 - val_loss: 3.4219\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0056 - val_loss: 4.8769\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.5429 - val_loss: 3.7744\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7534 - val_loss: 3.9216\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1637 - val_loss: 4.1735\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5887 - val_loss: 3.1960\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5694 - val_loss: 4.2161\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4775 - val_loss: 3.3931\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.5881 - val_loss: 3.9659\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1467 - val_loss: 3.5239\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6132 - val_loss: 4.4221\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0978 - val_loss: 3.5207\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1936 - val_loss: 4.3136\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2016 - val_loss: 4.1152\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7567 - val_loss: 3.7701\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6178 - val_loss: 3.3487\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.0296 - val_loss: 3.3602\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8135 - val_loss: 4.5307\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3709 - val_loss: 3.3284\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2835 - val_loss: 3.3600\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2424 - val_loss: 3.3648\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0261 - val_loss: 3.7462\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.2061 - val_loss: 3.6221\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8247 - val_loss: 3.6541\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8504 - val_loss: 3.2461\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6819 - val_loss: 3.5314\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0008 - val_loss: 3.3518\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff397fa0310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 58 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 5337910.0000 - val_loss: 95.3042\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4472230.5000 - val_loss: 94.2959\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3901277.0000 - val_loss: 93.1734\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2869674.0000 - val_loss: 91.9318\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1896136.0000 - val_loss: 91.0289\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1351623.7500 - val_loss: 90.2370\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1045536.6250 - val_loss: 89.5419\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 527832.1875 - val_loss: 88.6549\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 642624.7500 - val_loss: 87.9187\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 446925.0938 - val_loss: 87.1114\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 333786.0938 - val_loss: 86.2082\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 271435.2500 - val_loss: 85.3270\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 257417.1875 - val_loss: 84.5518\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 340999.5000 - val_loss: 83.7007\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 311235.6875 - val_loss: 82.8837\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 176168.6094 - val_loss: 82.0047\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 112981.5781 - val_loss: 81.1788\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 191693.3750 - val_loss: 80.3506\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 264161.8750 - val_loss: 79.4612\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 254782.2031 - val_loss: 78.5538\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 173983.7656 - val_loss: 77.7280\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 170363.4531 - val_loss: 77.0710\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 139098.5156 - val_loss: 76.2472\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 115636.0938 - val_loss: 75.4498\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 142716.2031 - val_loss: 74.6582\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 94495.1797 - val_loss: 73.9228\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 294579.7812 - val_loss: 73.0570\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 243120.0312 - val_loss: 72.2499\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 244615.0000 - val_loss: 71.5021\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 125044.7344 - val_loss: 70.7581\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 132234.3438 - val_loss: 70.0801\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 183960.2812 - val_loss: 69.2896\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 310532.5625 - val_loss: 68.5216\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 273105.5625 - val_loss: 67.7557\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 193476.1094 - val_loss: 67.0526\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 174842.2656 - val_loss: 66.2868\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 269216.0000 - val_loss: 65.5493\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 234066.2656 - val_loss: 64.8517\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 282577.6562 - val_loss: 64.2646\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 197651.2969 - val_loss: 63.6753\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 127242.4609 - val_loss: 63.1200\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 132430.7344 - val_loss: 62.4566\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 147653.9219 - val_loss: 61.8763\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 129297.8125 - val_loss: 61.2631\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 135751.4531 - val_loss: 60.7763\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 100994.5391 - val_loss: 60.2446\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 171647.1875 - val_loss: 59.6821\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 309986.4062 - val_loss: 59.1219\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 225441.2656 - val_loss: 58.5563\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 179829.8125 - val_loss: 58.0159\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38e00fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 59 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 90.4111 - val_loss: 71.6436\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 46.5595 - val_loss: 30.9651\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.7218 - val_loss: 21.1593\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28.2050 - val_loss: 30.6520\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.4732 - val_loss: 28.1009\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.4776 - val_loss: 17.4054\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.8151 - val_loss: 15.7611\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.5408 - val_loss: 14.3991\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.9791 - val_loss: 8.3403\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.5340 - val_loss: 8.9431\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.5594 - val_loss: 8.7920\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.9928 - val_loss: 6.2425\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.8663 - val_loss: 9.7202\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.9318 - val_loss: 7.3605\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.8121 - val_loss: 8.8386\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.5754 - val_loss: 8.2149\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.8250 - val_loss: 4.4023\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.3241 - val_loss: 7.2625\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9399 - val_loss: 4.5245\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.4741 - val_loss: 8.8594\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3971 - val_loss: 4.3463\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5610 - val_loss: 7.6124\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8497 - val_loss: 4.2428\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.0019 - val_loss: 5.6294\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7799 - val_loss: 5.6086\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7922 - val_loss: 4.6288\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8749 - val_loss: 5.5473\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6568 - val_loss: 3.7180\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.3128 - val_loss: 7.1607\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4095 - val_loss: 4.0497\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7113 - val_loss: 5.0821\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4696 - val_loss: 3.9776\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7113 - val_loss: 5.3033\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5897 - val_loss: 5.3954\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4987 - val_loss: 3.1835\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1240 - val_loss: 5.7152\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8135 - val_loss: 3.3217\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4822 - val_loss: 5.1352\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8690 - val_loss: 3.3801\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.4521 - val_loss: 4.9003\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.6275 - val_loss: 3.9945\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5862 - val_loss: 3.2290\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4566 - val_loss: 4.9063\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8791 - val_loss: 3.5340\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2101 - val_loss: 2.1217\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0907 - val_loss: 4.8179\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5324 - val_loss: 2.4057\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.8796 - val_loss: 3.4383\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5363 - val_loss: 3.9704\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5420 - val_loss: 2.7969\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4155181f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 60 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 89.9749 - val_loss: 70.8454\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41.3306 - val_loss: 24.1797\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 40.1962 - val_loss: 29.9694\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.9910 - val_loss: 34.7681\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.6520 - val_loss: 28.9639\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.6858 - val_loss: 15.4236\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.4848 - val_loss: 16.7518\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.1530 - val_loss: 9.0315\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4265 - val_loss: 10.3444\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.6689 - val_loss: 6.1116\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.9581 - val_loss: 5.8785\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.2433 - val_loss: 8.7483\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.3004 - val_loss: 7.9362\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4562 - val_loss: 6.3456\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.7391 - val_loss: 3.5471\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.6173 - val_loss: 8.6595\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.2189 - val_loss: 3.6554\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.8608 - val_loss: 5.2704\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.7075 - val_loss: 6.0251\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.7582 - val_loss: 4.4583\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1135 - val_loss: 4.0926\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.6927 - val_loss: 3.6260\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5516 - val_loss: 3.1066\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.2564 - val_loss: 3.6737\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4118 - val_loss: 4.0764\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2499 - val_loss: 3.6804\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5740 - val_loss: 3.1469\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2262 - val_loss: 3.9348\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0066 - val_loss: 3.1352\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.7172 - val_loss: 3.6751\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5901 - val_loss: 3.6442\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2197 - val_loss: 4.4223\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.7186 - val_loss: 2.5493\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2528 - val_loss: 3.0011\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6606 - val_loss: 3.5718\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4051 - val_loss: 4.4747\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.1263 - val_loss: 2.6745\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 8.7101 - val_loss: 3.4960\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3007 - val_loss: 2.7416\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4171 - val_loss: 3.1877\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4810 - val_loss: 2.9487\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3296 - val_loss: 3.1083\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7914 - val_loss: 2.5745\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5840 - val_loss: 4.1957\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1518 - val_loss: 2.9321\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3515 - val_loss: 2.1560\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.6495 - val_loss: 2.9918\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.2366 - val_loss: 2.5312\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2473 - val_loss: 4.4035\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4561 - val_loss: 2.2296\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3769170d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 61 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 2413.5378 - val_loss: 79.9775\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 316381.5000 - val_loss: 77.9782\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 182070.0312 - val_loss: 84.4383\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 49023.5469 - val_loss: 90.0147\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 83572.3047 - val_loss: 94.8063\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 71896.2344 - val_loss: 92.7218\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17776.1953 - val_loss: 88.6585\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 111883.8047 - val_loss: 87.0773\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 53440.9258 - val_loss: 90.1849\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8976.4707 - val_loss: 91.9786\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33705.4102 - val_loss: 92.0938\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16842.4199 - val_loss: 92.1298\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 55464.1523 - val_loss: 90.9515\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3997.2988 - val_loss: 91.9269\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21269.0176 - val_loss: 93.0655\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42101.1562 - val_loss: 92.2716\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18326.7383 - val_loss: 91.4537\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 34293.9844 - val_loss: 92.7379\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14189.3193 - val_loss: 93.5197\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34184.2070 - val_loss: 90.1643\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61472.2812 - val_loss: 89.3408\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 67642.9062 - val_loss: 90.5568\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29261.9512 - val_loss: 94.0451\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25233.1816 - val_loss: 94.4709\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16584.3418 - val_loss: 93.8903\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13374.3887 - val_loss: 90.8464\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 78262.0156 - val_loss: 89.6640\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 47032.5000 - val_loss: 92.6611\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7340.0615 - val_loss: 93.0980\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6506.5361 - val_loss: 91.8347\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 34870.9570 - val_loss: 91.6699\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30636.2871 - val_loss: 93.0024\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7303.5610 - val_loss: 93.6103\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4910.2271 - val_loss: 92.2017\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47534.1016 - val_loss: 91.2492\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20805.2129 - val_loss: 93.6555\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6765.2173 - val_loss: 94.0115\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3013.7922 - val_loss: 95.7150\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 34871.9062 - val_loss: 95.2711\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 57420.9492 - val_loss: 92.7980\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22319.1074 - val_loss: 89.4464\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51219.9219 - val_loss: 89.1938\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 37566.3164 - val_loss: 90.8594\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35568.3477 - val_loss: 93.1312\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 66596.9844 - val_loss: 94.9252\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33562.7578 - val_loss: 93.1182\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29593.1152 - val_loss: 91.7634\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 22235.1504 - val_loss: 93.5075\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11959.4268 - val_loss: 95.5382\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 84573.8516 - val_loss: 96.4497\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff381517e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 62 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 66.8147 - val_loss: 41.6475\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.6965 - val_loss: 7.4895\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.1544 - val_loss: 27.3337\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.5591 - val_loss: 27.7349\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.0308 - val_loss: 16.7732\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.1895 - val_loss: 16.2104\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.1578 - val_loss: 19.6985\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.8159 - val_loss: 14.7664\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.0943 - val_loss: 11.0392\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.6039 - val_loss: 12.2519\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.3860 - val_loss: 8.6713\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.7827 - val_loss: 7.7503\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.5553 - val_loss: 4.3294\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.3127 - val_loss: 8.5631\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.0666 - val_loss: 4.0388\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.4339 - val_loss: 6.3945\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.8536 - val_loss: 4.9583\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3882 - val_loss: 4.2945\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4274 - val_loss: 6.3229\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6351 - val_loss: 3.8688\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2560 - val_loss: 4.1873\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.3224 - val_loss: 3.8080\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0375 - val_loss: 3.8691\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9794 - val_loss: 3.3928\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3660 - val_loss: 3.0536\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4377 - val_loss: 3.7754\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5485 - val_loss: 4.3139\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0892 - val_loss: 2.8291\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5562 - val_loss: 3.8349\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5535 - val_loss: 3.2425\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4711 - val_loss: 3.0994\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5854 - val_loss: 2.9722\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0645 - val_loss: 6.8460\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2496 - val_loss: 3.1504\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7714 - val_loss: 4.8726\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9139 - val_loss: 4.0649\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5883 - val_loss: 3.7910\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2202 - val_loss: 2.9175\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7118 - val_loss: 3.7077\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2904 - val_loss: 5.8299\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4170 - val_loss: 2.8720\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.5653 - val_loss: 5.0061\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1330 - val_loss: 2.6941\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7279 - val_loss: 4.3839\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9476 - val_loss: 2.5656\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1098 - val_loss: 2.7818\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5492 - val_loss: 4.4866\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8244 - val_loss: 2.5917\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9507 - val_loss: 6.2483\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2296 - val_loss: 3.7195\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff383c79af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 63 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 5116575.5000 - val_loss: 99.6130\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4377720.0000 - val_loss: 97.6943\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3459467.2500 - val_loss: 96.7337\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2233500.7500 - val_loss: 95.6809\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2136095.7500 - val_loss: 94.9566\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1334711.1250 - val_loss: 94.1570\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 958244.5000 - val_loss: 93.1806\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 558849.6875 - val_loss: 92.2655\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 517781.7812 - val_loss: 91.3907\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 248061.6250 - val_loss: 90.5796\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 288328.4062 - val_loss: 89.6498\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 300068.4375 - val_loss: 88.8669\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 199248.2969 - val_loss: 87.9423\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 192203.0000 - val_loss: 87.1379\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 244192.2969 - val_loss: 86.3045\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 229373.3125 - val_loss: 85.3585\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 163827.6250 - val_loss: 84.5247\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 134107.6250 - val_loss: 83.5765\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 197069.5000 - val_loss: 82.6067\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 261540.2031 - val_loss: 81.6135\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 167678.4375 - val_loss: 80.6430\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 241569.6875 - val_loss: 79.7919\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 203174.2969 - val_loss: 78.9468\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 211742.4219 - val_loss: 78.1714\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 253234.9531 - val_loss: 77.3311\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 259615.6875 - val_loss: 76.5435\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 296219.4062 - val_loss: 75.7028\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 258009.6250 - val_loss: 74.9413\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 195571.6250 - val_loss: 74.1227\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 134657.8750 - val_loss: 73.3677\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 214594.2500 - val_loss: 72.6730\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 213623.2031 - val_loss: 71.8933\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 252810.0781 - val_loss: 71.0338\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 139619.5469 - val_loss: 70.2450\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 166398.8906 - val_loss: 69.5232\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 264127.2500 - val_loss: 68.8792\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 238419.8750 - val_loss: 68.1561\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 205511.1094 - val_loss: 67.4307\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 137290.5781 - val_loss: 66.8358\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 128226.1562 - val_loss: 66.2076\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 117805.2891 - val_loss: 65.5691\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 88547.8594 - val_loss: 64.8260\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 84582.5312 - val_loss: 64.1994\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 337068.7812 - val_loss: 63.6110\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 518895.6875 - val_loss: 63.0769\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 353718.0625 - val_loss: 62.4833\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 387448.9375 - val_loss: 62.0400\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 472891.7812 - val_loss: 61.6009\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 403244.2812 - val_loss: 61.2354\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 411350.0000 - val_loss: 60.8782\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b8229310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 64 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 10776.8750 - val_loss: 84.2543\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 327173.5625 - val_loss: 85.4631\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 172427.5469 - val_loss: 90.9107\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 86745.2266 - val_loss: 97.8191\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48848.4883 - val_loss: 100.3015\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 62258.1250 - val_loss: 98.6453\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 41752.1836 - val_loss: 98.6022\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41256.5039 - val_loss: 99.1122\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15945.3799 - val_loss: 96.4912\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 120490.3125 - val_loss: 95.3926\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 89436.9688 - val_loss: 96.5244\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54879.7031 - val_loss: 97.7609\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13025.9326 - val_loss: 100.6964\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 132873.5000 - val_loss: 101.7516\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 122382.5000 - val_loss: 101.0998\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 71202.0781 - val_loss: 99.8366\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4498.7207 - val_loss: 98.9532\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11586.6016 - val_loss: 98.1249\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 78202.5000 - val_loss: 97.9787\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28114.8594 - val_loss: 99.5235\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56097.8477 - val_loss: 99.9391\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42720.1328 - val_loss: 98.8250\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 425.9488 - val_loss: 96.9864\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 74601.4844 - val_loss: 96.6887\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 60722.0742 - val_loss: 97.9963\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33547.6250 - val_loss: 99.0927\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12907.5547 - val_loss: 101.5035\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 110971.5156 - val_loss: 102.2556\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 105307.1719 - val_loss: 100.8284\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54442.1836 - val_loss: 98.9782\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9059.7852 - val_loss: 98.9481\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13741.3711 - val_loss: 98.2662\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7646.5986 - val_loss: 98.7523\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8250.6934 - val_loss: 100.3017\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 71201.2656 - val_loss: 100.8399\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44328.8984 - val_loss: 99.5606\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19100.8184 - val_loss: 98.5314\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5504.4150 - val_loss: 98.4715\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24143.3887 - val_loss: 98.3717\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 994.7244 - val_loss: 98.1140\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43995.3594 - val_loss: 98.0956\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 45646.8633 - val_loss: 99.6344\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36340.7383 - val_loss: 99.7777\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30501.9668 - val_loss: 99.1449\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8272.1123 - val_loss: 96.9890\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34964.4883 - val_loss: 96.4124\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 80038.9453 - val_loss: 96.7882\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 39028.5977 - val_loss: 98.0541\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 27436.3516 - val_loss: 98.7140\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 35340.5508 - val_loss: 98.1772\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4038b24c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 65 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 57.5620 - val_loss: 31.0872\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 30.1467 - val_loss: 5.1858\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.1158 - val_loss: 21.9527\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 20.5421 - val_loss: 26.9790\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20.7081 - val_loss: 19.6804\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 19.7732 - val_loss: 11.7075\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.3904 - val_loss: 14.3037\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.8316 - val_loss: 15.1837\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.6281 - val_loss: 11.7898\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.0885 - val_loss: 7.9744\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.0838 - val_loss: 12.3063\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.5343 - val_loss: 4.3380\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.8692 - val_loss: 7.3873\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.8516 - val_loss: 4.8989\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.9209 - val_loss: 3.4391\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.2529 - val_loss: 7.7054\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7866 - val_loss: 2.4715\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.3908 - val_loss: 5.8086\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3876 - val_loss: 4.9132\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.1120 - val_loss: 2.9271\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6324 - val_loss: 6.4706\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0769 - val_loss: 2.1047\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.0298 - val_loss: 3.8500\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5047 - val_loss: 3.6115\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5204 - val_loss: 3.3585\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0847 - val_loss: 3.0756\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8006 - val_loss: 1.9639\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3549 - val_loss: 3.9982\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.8524 - val_loss: 1.9778\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3338 - val_loss: 3.2814\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8263 - val_loss: 2.0281\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3921 - val_loss: 3.9551\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3080 - val_loss: 5.5103\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1418 - val_loss: 3.2960\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5346 - val_loss: 2.5088\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1116 - val_loss: 3.0088\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9659 - val_loss: 3.0690\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1614 - val_loss: 3.2472\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5196 - val_loss: 5.5455\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.3098 - val_loss: 2.0328\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7120 - val_loss: 5.0650\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4571 - val_loss: 2.6412\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.7466 - val_loss: 3.4236\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2399 - val_loss: 3.6752\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4444 - val_loss: 3.8404\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7391 - val_loss: 3.2998\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3476 - val_loss: 2.8484\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6614 - val_loss: 3.3066\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2174 - val_loss: 3.2299\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1863 - val_loss: 3.4891\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3767ca550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 66 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 79.4773 - val_loss: 59.8755\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36.1910 - val_loss: 20.3681\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.1065 - val_loss: 33.2451\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28.8585 - val_loss: 43.0704\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 26.8933 - val_loss: 32.7040\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21.7224 - val_loss: 18.5087\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 21.7389 - val_loss: 19.8387\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.6987 - val_loss: 24.9397\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18.3109 - val_loss: 17.2175\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.2848 - val_loss: 14.9573\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.1861 - val_loss: 14.1336\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.8708 - val_loss: 8.8713\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.3066 - val_loss: 13.0580\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.9192 - val_loss: 5.7743\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.1729 - val_loss: 11.2273\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4392 - val_loss: 7.1925\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.5068 - val_loss: 10.1340\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.9305 - val_loss: 5.7980\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.4401 - val_loss: 12.4225\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4203 - val_loss: 9.7597\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.7820 - val_loss: 6.5514\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.5557 - val_loss: 8.3167\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.4390 - val_loss: 8.7250\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.1957 - val_loss: 6.4706\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0188 - val_loss: 7.0301\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.4771 - val_loss: 6.4800\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.7667 - val_loss: 6.1455\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6228 - val_loss: 5.6709\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.0894 - val_loss: 6.9008\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.9372 - val_loss: 3.2532\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.3433 - val_loss: 6.7080\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.5743 - val_loss: 3.7387\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.0372 - val_loss: 6.6744\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7031 - val_loss: 7.6465\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.2888 - val_loss: 1.9297\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5879 - val_loss: 8.4307\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8696 - val_loss: 3.8198\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2458 - val_loss: 3.1669\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8889 - val_loss: 7.5777\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7024 - val_loss: 2.9499\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0906 - val_loss: 6.1230\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8545 - val_loss: 2.2004\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6347 - val_loss: 5.6532\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8897 - val_loss: 2.6841\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7329 - val_loss: 7.2490\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1619 - val_loss: 2.6330\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.0606 - val_loss: 3.4730\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7713 - val_loss: 3.5843\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8646 - val_loss: 3.5471\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8894 - val_loss: 6.3842\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3af7f3af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 67 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 78.9784 - val_loss: 56.6392\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.6673 - val_loss: 8.6772\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.3754 - val_loss: 7.7264\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.7920 - val_loss: 23.5655\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 19.9020 - val_loss: 27.9618\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.0159 - val_loss: 15.6582\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.0681 - val_loss: 7.4359\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.3695 - val_loss: 8.7316\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.0814 - val_loss: 14.6432\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.1607 - val_loss: 8.9485\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.7257 - val_loss: 6.4104\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.7608 - val_loss: 6.8964\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.3262 - val_loss: 5.8874\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9326 - val_loss: 5.6839\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.5810 - val_loss: 5.5715\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.4694 - val_loss: 5.5804\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2911 - val_loss: 6.2351\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.7954 - val_loss: 5.5520\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.7277 - val_loss: 5.7773\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6620 - val_loss: 5.8768\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4648 - val_loss: 5.4064\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9673 - val_loss: 7.7675\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.7214 - val_loss: 5.1859\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8489 - val_loss: 5.8458\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9857 - val_loss: 5.5742\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.5537 - val_loss: 5.1454\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.2065 - val_loss: 7.8394\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.8048 - val_loss: 5.2170\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.3533 - val_loss: 5.2193\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.4580 - val_loss: 5.8177\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.4674 - val_loss: 5.3079\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.2886 - val_loss: 7.5600\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1446 - val_loss: 5.2936\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.2965 - val_loss: 5.2086\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4904 - val_loss: 5.2317\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.6333 - val_loss: 5.3368\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0782 - val_loss: 6.5100\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7019 - val_loss: 4.9948\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3063 - val_loss: 5.7850\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1811 - val_loss: 5.1307\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6061 - val_loss: 7.1443\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7068 - val_loss: 5.3229\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0584 - val_loss: 5.5535\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8116 - val_loss: 5.0834\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2386 - val_loss: 4.9767\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.7369 - val_loss: 5.9579\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0108 - val_loss: 5.1630\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0476 - val_loss: 6.1215\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6300 - val_loss: 5.2347\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0459 - val_loss: 6.0959\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40c0eb820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 68 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 65.9080 - val_loss: 39.8964\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21.6867 - val_loss: 3.9742\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.4925 - val_loss: 6.6104\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 16.0508 - val_loss: 22.2216\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.0373 - val_loss: 19.5679\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.6826 - val_loss: 10.0773\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.0147 - val_loss: 6.9598\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.6329 - val_loss: 10.0726\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.5004 - val_loss: 9.6003\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.5937 - val_loss: 6.9633\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1503 - val_loss: 5.2814\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.2235 - val_loss: 4.8549\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.9424 - val_loss: 3.0976\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8909 - val_loss: 3.6469\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3545 - val_loss: 5.6441\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1717 - val_loss: 3.2437\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8474 - val_loss: 5.4666\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0956 - val_loss: 3.4424\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1321 - val_loss: 6.0700\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6670 - val_loss: 3.2853\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.9112 - val_loss: 3.0757\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8396 - val_loss: 3.8576\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5798 - val_loss: 3.1406\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7955 - val_loss: 3.1952\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.2358 - val_loss: 4.1322\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3039 - val_loss: 3.4791\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.5986 - val_loss: 4.5554\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1875 - val_loss: 3.1840\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5057 - val_loss: 3.7790\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2077 - val_loss: 3.2378\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1124 - val_loss: 4.1818\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.3710 - val_loss: 3.7779\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.7212 - val_loss: 3.4457\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5309 - val_loss: 3.1945\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.2416 - val_loss: 4.2935\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.5625 - val_loss: 3.4117\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0174 - val_loss: 4.4133\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.0653 - val_loss: 3.1891\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5.4143 - val_loss: 3.6896\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5167 - val_loss: 3.2941\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.1304 - val_loss: 3.5808\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9119 - val_loss: 3.6799\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2725 - val_loss: 4.3172\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1349 - val_loss: 3.3379\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.2612 - val_loss: 4.5080\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8640 - val_loss: 3.2438\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.7919 - val_loss: 4.3282\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.6589 - val_loss: 3.2004\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.3513 - val_loss: 3.2274\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6856 - val_loss: 3.2748\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a8aaa8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 69 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 69.3769 - val_loss: 42.9653\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.1604 - val_loss: 7.2652\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.8506 - val_loss: 8.6334\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.0753 - val_loss: 23.8264\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 17.8143 - val_loss: 21.9120\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.6280 - val_loss: 10.5244\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.2165 - val_loss: 5.5449\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.1768 - val_loss: 11.8798\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.0150 - val_loss: 10.1605\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.2283 - val_loss: 5.3225\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.9497 - val_loss: 6.6326\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.1416 - val_loss: 3.6974\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.0364 - val_loss: 5.2254\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5328 - val_loss: 3.8959\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8639 - val_loss: 4.4312\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.5265 - val_loss: 3.9953\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1170 - val_loss: 3.8095\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6371 - val_loss: 3.7864\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2414 - val_loss: 4.3067\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7867 - val_loss: 3.9623\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0274 - val_loss: 4.2727\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8902 - val_loss: 4.3914\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7825 - val_loss: 4.9110\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9483 - val_loss: 4.0537\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3428 - val_loss: 4.2548\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.1176 - val_loss: 4.0965\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.1536 - val_loss: 4.0954\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6812 - val_loss: 4.1438\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3495 - val_loss: 3.9417\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.8215 - val_loss: 3.9675\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0692 - val_loss: 5.2945\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5877 - val_loss: 4.8238\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3213 - val_loss: 5.2984\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1766 - val_loss: 3.8427\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.9758 - val_loss: 3.9657\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5361 - val_loss: 4.1302\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4526 - val_loss: 3.8662\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.4477 - val_loss: 4.4474\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3847 - val_loss: 3.9296\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8611 - val_loss: 5.0384\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0331 - val_loss: 4.1063\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.9649 - val_loss: 5.0111\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3824 - val_loss: 4.1845\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0755 - val_loss: 4.2299\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.5897 - val_loss: 4.0403\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6079 - val_loss: 4.4130\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5746 - val_loss: 3.9950\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.7441 - val_loss: 3.8355\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5734 - val_loss: 3.7095\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.6288 - val_loss: 3.9451\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff397da1f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 70 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 279913.1250 - val_loss: 97.2112\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 302658.5938 - val_loss: 108.2195\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1014310.4375 - val_loss: 111.0249\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 517710.0625 - val_loss: 97.6932\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 101065.1250 - val_loss: 88.6579\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 881045.1875 - val_loss: 90.9744\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 238329.1250 - val_loss: 96.7777\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 127330.7734 - val_loss: 101.4979\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 254688.6875 - val_loss: 97.9828\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 185926.7344 - val_loss: 100.6557\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 90621.1641 - val_loss: 101.5282\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48014.3945 - val_loss: 102.6568\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 295179.9062 - val_loss: 100.0711\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 77932.5234 - val_loss: 100.4108\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 222360.8438 - val_loss: 103.9557\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 180321.3281 - val_loss: 99.5588\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 156810.8750 - val_loss: 98.4061\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 187749.1094 - val_loss: 106.2366\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 470289.3125 - val_loss: 107.7999\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 321931.5938 - val_loss: 105.4397\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 148311.5312 - val_loss: 100.1747\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 135299.2344 - val_loss: 97.9738\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 203938.0938 - val_loss: 100.5528\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 187850.8438 - val_loss: 104.0041\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 205329.1406 - val_loss: 102.5063\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 145630.0156 - val_loss: 98.6784\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 115734.1719 - val_loss: 98.9306\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32074.7969 - val_loss: 102.0654\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 284072.6250 - val_loss: 104.8236\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 234355.7656 - val_loss: 102.2710\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 162553.5312 - val_loss: 97.4599\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 415554.0312 - val_loss: 94.8787\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 386121.4688 - val_loss: 98.6827\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 78289.5781 - val_loss: 101.6581\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 89798.9062 - val_loss: 101.3173\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 76703.5312 - val_loss: 101.8909\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 104083.4219 - val_loss: 103.5026\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 220561.0625 - val_loss: 101.7007\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 192662.2812 - val_loss: 99.3897\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 187063.1875 - val_loss: 100.0407\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42565.1133 - val_loss: 102.7908\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 127196.1328 - val_loss: 102.6002\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 144002.9531 - val_loss: 100.5951\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 87828.1875 - val_loss: 97.7867\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 158540.0625 - val_loss: 96.9257\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 156396.7031 - val_loss: 100.0419\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 81117.5703 - val_loss: 101.8522\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51003.3516 - val_loss: 100.5041\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 96583.7109 - val_loss: 96.4139\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 309737.5625 - val_loss: 95.7030\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff387144280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 71 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 54648.7656 - val_loss: 127.3270\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 185864.7969 - val_loss: 134.9990\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 100969.5312 - val_loss: 125.1480\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 43179.6602 - val_loss: 109.0694\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 114287.6016 - val_loss: 104.6037\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 86419.0312 - val_loss: 108.3893\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 53937.2891 - val_loss: 117.2493\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 61134.4141 - val_loss: 121.2122\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35289.7930 - val_loss: 115.3093\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 44176.6914 - val_loss: 107.0626\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 94471.6094 - val_loss: 107.6985\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 75555.2734 - val_loss: 112.5392\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37631.1523 - val_loss: 120.3120\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 36452.2930 - val_loss: 120.5819\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42361.4180 - val_loss: 118.4455\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14207.4297 - val_loss: 116.1093\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 629.8841 - val_loss: 112.0532\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 79272.4766 - val_loss: 110.4978\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18327.0820 - val_loss: 116.5558\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 694.6696 - val_loss: 120.2101\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 55359.4258 - val_loss: 118.8226\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 894.5635 - val_loss: 114.1138\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14374.3340 - val_loss: 113.8571\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8697.2998 - val_loss: 115.3106\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6052.3335 - val_loss: 118.2120\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 35785.5391 - val_loss: 116.6685\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27256.4941 - val_loss: 113.6025\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25800.8047 - val_loss: 116.2741\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28171.3711 - val_loss: 122.0333\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 64520.9727 - val_loss: 124.1350\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 89879.6484 - val_loss: 121.8347\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35483.5312 - val_loss: 113.5571\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47763.4883 - val_loss: 111.9554\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13681.3271 - val_loss: 116.1743\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 42097.1367 - val_loss: 117.8746\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 64882.0664 - val_loss: 111.0884\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47527.5195 - val_loss: 109.5186\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42802.1758 - val_loss: 113.8312\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17382.5898 - val_loss: 115.1157\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5505.3809 - val_loss: 113.3622\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9648.5479 - val_loss: 120.4731\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 95503.9297 - val_loss: 120.6608\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 35296.3711 - val_loss: 119.4236\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30705.9863 - val_loss: 112.0126\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52902.0469 - val_loss: 108.3132\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38075.1055 - val_loss: 112.3667\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 52801.4062 - val_loss: 116.4468\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9866.0439 - val_loss: 117.4635\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 57332.5781 - val_loss: 115.4751\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41570.0820 - val_loss: 108.8504\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3768790d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 72 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 1073339.1250 - val_loss: 94.2475\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 249620.4219 - val_loss: 102.9324\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 334670.9688 - val_loss: 104.2440\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 533864.6250 - val_loss: 102.4696\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 64591.6445 - val_loss: 98.7759\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 323468.9375 - val_loss: 96.5101\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 425294.4375 - val_loss: 98.0320\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 92896.0391 - val_loss: 101.8248\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 395732.2812 - val_loss: 102.8200\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 249256.0312 - val_loss: 101.4764\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 166421.8594 - val_loss: 100.0269\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 141554.9062 - val_loss: 99.9253\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 62732.4062 - val_loss: 102.5452\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 299647.5000 - val_loss: 102.3837\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 186610.7969 - val_loss: 101.2212\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 47362.8281 - val_loss: 99.8828\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 209046.7344 - val_loss: 99.9655\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 132944.7031 - val_loss: 100.7841\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 94774.5156 - val_loss: 100.9923\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 81997.6094 - val_loss: 100.0511\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 33222.0938 - val_loss: 98.8986\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 158296.3594 - val_loss: 99.7027\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 112256.4844 - val_loss: 102.2410\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 387103.8125 - val_loss: 103.2846\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 228169.5469 - val_loss: 101.0058\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 127757.9844 - val_loss: 97.6558\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 348917.6250 - val_loss: 96.5278\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 352238.4375 - val_loss: 97.5086\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 226474.0469 - val_loss: 99.8970\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 152250.5000 - val_loss: 102.1471\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 218393.8594 - val_loss: 101.6660\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 213300.6250 - val_loss: 99.9694\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 82949.4688 - val_loss: 99.1946\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 196933.0938 - val_loss: 99.2942\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 87640.3047 - val_loss: 100.3937\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 121147.5156 - val_loss: 102.1210\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 182988.4688 - val_loss: 102.0525\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 100022.7031 - val_loss: 101.1349\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 56784.1250 - val_loss: 101.0423\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37422.5430 - val_loss: 101.7469\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16032.2568 - val_loss: 102.5360\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 80735.2734 - val_loss: 102.1975\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 56522.7695 - val_loss: 102.1340\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 76437.2812 - val_loss: 102.8778\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 80074.6562 - val_loss: 103.1480\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 77281.8125 - val_loss: 102.8643\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 75019.0078 - val_loss: 102.4209\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56668.6328 - val_loss: 101.7440\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 110428.4844 - val_loss: 101.1647\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 57455.2891 - val_loss: 101.8813\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b1cef160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 73 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 29476.8086 - val_loss: 103.4130\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 280314.4688 - val_loss: 104.5356\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 207809.8750 - val_loss: 100.2119\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 93147.7422 - val_loss: 93.8336\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49027.4883 - val_loss: 93.7963\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 63247.8555 - val_loss: 96.3020\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1139.2803 - val_loss: 99.0927\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 92234.2188 - val_loss: 100.2048\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 71764.3516 - val_loss: 99.1050\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 40771.7500 - val_loss: 96.2577\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43091.4844 - val_loss: 96.0709\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 42366.2969 - val_loss: 97.0193\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12912.6689 - val_loss: 100.2182\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 75865.0312 - val_loss: 101.0126\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 50017.9336 - val_loss: 100.1827\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 48893.9414 - val_loss: 98.1740\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22965.3184 - val_loss: 97.0061\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 50703.1328 - val_loss: 97.9130\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6633.1665 - val_loss: 98.7183\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2244.8921 - val_loss: 98.8998\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10875.5586 - val_loss: 100.4987\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 69092.6250 - val_loss: 101.1104\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 53728.9062 - val_loss: 100.1072\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3443.2964 - val_loss: 97.8262\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 109768.8203 - val_loss: 96.9201\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 108273.9922 - val_loss: 97.7737\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64875.2422 - val_loss: 99.5031\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9578.6143 - val_loss: 101.6522\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 80905.8047 - val_loss: 102.3101\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 87151.5234 - val_loss: 101.3919\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15952.8721 - val_loss: 100.0333\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16915.5879 - val_loss: 99.6610\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43434.1758 - val_loss: 99.9058\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 30332.1211 - val_loss: 100.1552\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18026.7383 - val_loss: 99.8294\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17073.8887 - val_loss: 99.2511\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30213.1387 - val_loss: 99.8379\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13753.4307 - val_loss: 99.7128\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30618.3555 - val_loss: 100.3986\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19033.4141 - val_loss: 99.8505\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13554.6533 - val_loss: 100.2757\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4130.2720 - val_loss: 99.8587\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2308.6335 - val_loss: 98.4538\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 70055.9141 - val_loss: 98.6353\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 30839.4902 - val_loss: 99.4193\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 4393.7329 - val_loss: 99.3782\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7098.4878 - val_loss: 100.1993\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41675.1523 - val_loss: 100.0370\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10291.4521 - val_loss: 100.0194\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14339.7529 - val_loss: 99.7828\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff381399790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 74 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 96.7010 - val_loss: 81.0126\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 54.7987 - val_loss: 42.9407\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40.8137 - val_loss: 19.7160\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.2090 - val_loss: 30.1003\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 27.6960 - val_loss: 37.1350\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 27.2058 - val_loss: 29.3017\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20.4773 - val_loss: 12.7879\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.4517 - val_loss: 13.9599\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 16.1427 - val_loss: 15.5237\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.4890 - val_loss: 4.1431\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.5094 - val_loss: 8.4445\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.2791 - val_loss: 5.7483\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.1591 - val_loss: 3.8466\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 10.0445 - val_loss: 7.3178\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8815 - val_loss: 3.8524\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.4394 - val_loss: 5.1506\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6859 - val_loss: 6.1781\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5678 - val_loss: 4.0285\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.2108 - val_loss: 6.6136\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.4065 - val_loss: 5.2434\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5231 - val_loss: 5.8593\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.1411 - val_loss: 5.9592\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 9.4289 - val_loss: 4.9614\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.8510 - val_loss: 5.6330\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1583 - val_loss: 5.7525\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.4377 - val_loss: 5.2060\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1259 - val_loss: 4.9458\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9291 - val_loss: 5.7767\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.7013 - val_loss: 3.9101\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.3024 - val_loss: 6.5950\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5976 - val_loss: 4.0031\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3806 - val_loss: 5.5748\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.3127 - val_loss: 4.8588\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.1994 - val_loss: 3.6129\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6699 - val_loss: 4.8338\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9202 - val_loss: 3.6807\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.1611 - val_loss: 5.4132\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0805 - val_loss: 3.8808\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.7223 - val_loss: 5.5823\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5842 - val_loss: 4.0211\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.5134 - val_loss: 6.1854\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.7047 - val_loss: 4.0529\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9134 - val_loss: 5.8695\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.2954 - val_loss: 3.6670\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5895 - val_loss: 3.7613\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9003 - val_loss: 3.6892\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8940 - val_loss: 4.4221\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.0028 - val_loss: 4.7787\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.3121 - val_loss: 3.9654\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6770 - val_loss: 4.1463\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff367d40280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 75 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 89.2364 - val_loss: 74.6446\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 40.5694 - val_loss: 36.0498\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 38.0755 - val_loss: 33.8366\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 28.7076 - val_loss: 44.6971\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29.4813 - val_loss: 38.9975\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 24.8881 - val_loss: 23.7553\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 22.7368 - val_loss: 19.7922\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20.5965 - val_loss: 24.4189\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18.6991 - val_loss: 12.1854\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.2579 - val_loss: 12.1065\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.1880 - val_loss: 12.7932\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.3139 - val_loss: 3.1024\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.9810 - val_loss: 5.8655\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.5684 - val_loss: 5.0056\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.3588 - val_loss: 4.3468\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.5388 - val_loss: 6.4963\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.2725 - val_loss: 3.4954\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.2132 - val_loss: 5.8260\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.9748 - val_loss: 4.6692\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.7174 - val_loss: 6.0199\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.9702 - val_loss: 4.9230\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.6996 - val_loss: 4.5635\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.9208 - val_loss: 3.8876\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.4594 - val_loss: 5.3163\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.8158 - val_loss: 4.3568\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.0971 - val_loss: 3.6242\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.7977 - val_loss: 5.0056\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.2705 - val_loss: 3.0940\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.5876 - val_loss: 4.8690\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2526 - val_loss: 3.6269\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7770 - val_loss: 3.5269\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.6230 - val_loss: 3.7439\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.1720 - val_loss: 2.9969\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.2286 - val_loss: 5.7475\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.6104 - val_loss: 3.3011\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.8773 - val_loss: 6.6737\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1825 - val_loss: 4.8829\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.1543 - val_loss: 3.2223\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2010 - val_loss: 3.2342\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.4515 - val_loss: 2.7677\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6112 - val_loss: 3.7797\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7651 - val_loss: 3.1441\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.2241 - val_loss: 3.4531\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8753 - val_loss: 2.6212\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.3661 - val_loss: 2.7937\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.9117 - val_loss: 3.7026\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4528 - val_loss: 3.3042\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7603 - val_loss: 3.0747\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.6763 - val_loss: 3.3870\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0528 - val_loss: 2.9842\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff36a8171f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 76 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 160059.7344 - val_loss: 91.1665\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20721.7500 - val_loss: 94.5631\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25812.7656 - val_loss: 94.3213\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14086.3818 - val_loss: 94.8941\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11993.0977 - val_loss: 93.0610\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 60641.4688 - val_loss: 92.4148\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 18724.2402 - val_loss: 94.9403\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16925.1484 - val_loss: 95.5935\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19690.5859 - val_loss: 93.2942\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36466.1836 - val_loss: 93.4490\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 27490.8672 - val_loss: 96.5665\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 37975.9453 - val_loss: 97.3631\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 58139.9258 - val_loss: 93.4676\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 57396.5977 - val_loss: 92.2241\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 43989.4414 - val_loss: 96.0721\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53530.6328 - val_loss: 97.0674\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 24199.9316 - val_loss: 94.0490\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 67287.9922 - val_loss: 92.7714\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 27829.3027 - val_loss: 96.6359\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 51108.9219 - val_loss: 98.1738\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 44936.7812 - val_loss: 96.4795\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19848.2891 - val_loss: 93.7147\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 62218.5117 - val_loss: 93.2024\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 64998.8164 - val_loss: 93.9755\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 20024.5059 - val_loss: 96.1844\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 21453.2832 - val_loss: 96.8976\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19863.3359 - val_loss: 96.1089\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23921.2734 - val_loss: 95.2601\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9203.6436 - val_loss: 95.4516\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36217.3906 - val_loss: 95.9182\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15807.3311 - val_loss: 94.9964\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12619.1719 - val_loss: 93.0715\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 55942.7227 - val_loss: 93.1380\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 30706.2031 - val_loss: 94.0231\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7440.1333 - val_loss: 97.1258\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63021.9688 - val_loss: 98.3789\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 72444.0547 - val_loss: 97.8229\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22759.7676 - val_loss: 95.2008\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25569.5098 - val_loss: 94.3406\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30726.5859 - val_loss: 95.3522\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8584.2715 - val_loss: 97.5755\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36557.9258 - val_loss: 98.8578\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 51453.1602 - val_loss: 97.4855\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 35472.8008 - val_loss: 97.1241\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23018.8730 - val_loss: 96.2075\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15070.7734 - val_loss: 96.6991\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8498.9004 - val_loss: 96.8597\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 38555.4766 - val_loss: 94.9038\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 54918.5039 - val_loss: 94.2103\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 61325.3555 - val_loss: 96.3982\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a4c31820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 77 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 105ms/step - loss: 95.7685 - val_loss: 81.5760\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 69.6598 - val_loss: 63.7034\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57.6105 - val_loss: 57.5866\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 44.6859 - val_loss: 45.0735\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39.6243 - val_loss: 34.8885\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.0420 - val_loss: 27.4891\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30.4891 - val_loss: 22.5438\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.6810 - val_loss: 21.5139\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 25.6853 - val_loss: 7.5127\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 23.6498 - val_loss: 7.9645\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 21.5302 - val_loss: 6.0762\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.6832 - val_loss: 3.5499\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 20.7399 - val_loss: 8.4769\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 20.4193 - val_loss: 4.7201\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 20.2808 - val_loss: 9.8073\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19.5854 - val_loss: 4.3231\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.4511 - val_loss: 5.4969\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16.6382 - val_loss: 3.5413\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.4881 - val_loss: 3.2864\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.2046 - val_loss: 5.5674\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.0082 - val_loss: 4.2622\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.5468 - val_loss: 4.2165\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.9511 - val_loss: 5.0947\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.4601 - val_loss: 5.7656\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.0615 - val_loss: 3.4514\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.9031 - val_loss: 4.0489\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.4347 - val_loss: 4.9516\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.4263 - val_loss: 4.7656\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.6615 - val_loss: 4.4025\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.0130 - val_loss: 4.4241\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.7909 - val_loss: 4.1587\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.2578 - val_loss: 6.6066\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.0282 - val_loss: 5.6263\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.9709 - val_loss: 3.7720\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.1287 - val_loss: 4.4860\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.1091 - val_loss: 4.7723\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.9481 - val_loss: 4.4287\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.3276 - val_loss: 3.5028\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.9220 - val_loss: 5.2980\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.3750 - val_loss: 4.5153\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.9583 - val_loss: 4.1327\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.7271 - val_loss: 3.8982\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.8890 - val_loss: 3.7088\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.4902 - val_loss: 5.1477\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.0448 - val_loss: 3.4004\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.4743 - val_loss: 5.9101\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.5873 - val_loss: 4.8530\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5610 - val_loss: 3.7769\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.4065 - val_loss: 4.4849\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.8064 - val_loss: 5.6518\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37fdb4040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 78 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 75.8869 - val_loss: 52.0267\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.0276 - val_loss: 5.8276\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33.8061 - val_loss: 16.3688\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 23.3135 - val_loss: 30.9467\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 23.2667 - val_loss: 29.7447\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 20.9764 - val_loss: 18.8963\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 19.3499 - val_loss: 10.9171\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 17.5802 - val_loss: 14.2805\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.6953 - val_loss: 16.5628\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 14.5788 - val_loss: 13.2767\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.8507 - val_loss: 8.4366\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.7421 - val_loss: 7.7558\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.9275 - val_loss: 8.9153\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.6882 - val_loss: 3.2507\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.9182 - val_loss: 6.3858\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0963 - val_loss: 3.0872\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1614 - val_loss: 3.1936\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1488 - val_loss: 4.7113\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.3211 - val_loss: 2.8321\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.5228 - val_loss: 5.3531\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2925 - val_loss: 4.9599\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.5525 - val_loss: 4.5908\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7778 - val_loss: 5.4421\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.9369 - val_loss: 3.3120\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5941 - val_loss: 4.9288\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.4820 - val_loss: 3.3754\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.6896 - val_loss: 3.7587\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.4691 - val_loss: 3.6226\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6790 - val_loss: 3.7834\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1750 - val_loss: 3.5671\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.0720 - val_loss: 3.7035\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1903 - val_loss: 5.0220\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5029 - val_loss: 3.6392\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1637 - val_loss: 4.2030\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.7015 - val_loss: 3.5762\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.2613 - val_loss: 3.7376\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6018 - val_loss: 5.4080\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9189 - val_loss: 3.7072\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1484 - val_loss: 4.7493\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9835 - val_loss: 5.2439\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.3491 - val_loss: 4.5242\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2945 - val_loss: 3.8729\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.1896 - val_loss: 4.7092\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9771 - val_loss: 4.1045\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3224 - val_loss: 3.4942\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0817 - val_loss: 3.3512\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8232 - val_loss: 3.5047\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1445 - val_loss: 3.3262\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4796 - val_loss: 3.2878\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1930 - val_loss: 4.1760\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37a0d7d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 79 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 5739426.0000 - val_loss: 98.1003\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4684089.0000 - val_loss: 96.0584\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3835863.5000 - val_loss: 94.8663\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2502844.5000 - val_loss: 93.0619\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2025224.0000 - val_loss: 92.1096\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1166325.3750 - val_loss: 91.0126\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 948337.3750 - val_loss: 89.7535\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 579104.6250 - val_loss: 88.6113\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 515013.9062 - val_loss: 87.4494\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 532112.7500 - val_loss: 86.0984\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 431360.4062 - val_loss: 84.9973\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 393747.9062 - val_loss: 83.7827\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 521500.5938 - val_loss: 82.3919\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 500549.5312 - val_loss: 81.2291\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 390589.7500 - val_loss: 79.8470\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 530827.1875 - val_loss: 78.6191\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 479514.7812 - val_loss: 77.4550\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 491093.0625 - val_loss: 76.4975\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 451331.2188 - val_loss: 75.5022\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 446692.6250 - val_loss: 74.4826\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 465013.2500 - val_loss: 73.4123\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 362743.1250 - val_loss: 72.3047\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 346157.6250 - val_loss: 71.4804\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 293376.9062 - val_loss: 70.3495\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 424205.4062 - val_loss: 69.3106\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 317343.8438 - val_loss: 68.4952\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 264410.9375 - val_loss: 67.4673\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 208621.8594 - val_loss: 66.4278\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 263486.9062 - val_loss: 65.5841\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 162245.0000 - val_loss: 64.6969\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 135494.2344 - val_loss: 63.7527\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 109007.7734 - val_loss: 62.9577\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 142493.5000 - val_loss: 62.2054\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 135001.1875 - val_loss: 61.4719\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 82574.4688 - val_loss: 60.6598\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 115192.0234 - val_loss: 59.8457\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 135460.1562 - val_loss: 59.0848\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 150628.3906 - val_loss: 58.2818\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 124152.6172 - val_loss: 57.5408\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 108154.7422 - val_loss: 56.7380\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 127317.1953 - val_loss: 55.9477\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 137257.9531 - val_loss: 55.1770\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 126367.3516 - val_loss: 54.4841\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 129794.4375 - val_loss: 53.7289\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 277014.0938 - val_loss: 53.1208\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 222716.7656 - val_loss: 52.4546\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 250117.6094 - val_loss: 51.7091\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 302651.3750 - val_loss: 51.1491\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 178453.9531 - val_loss: 50.5185\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 153175.5469 - val_loss: 50.0168\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38772ef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 80 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 60.2672 - val_loss: 36.0035\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.6568 - val_loss: 13.7783\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26.1598 - val_loss: 29.0230\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 23.2388 - val_loss: 30.5552\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.6177 - val_loss: 19.9066\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 19.7698 - val_loss: 15.2535\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.5410 - val_loss: 17.6860\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.1938 - val_loss: 15.5224\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.1135 - val_loss: 11.7868\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.7694 - val_loss: 13.2407\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.8090 - val_loss: 7.7643\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.0203 - val_loss: 9.0599\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.8513 - val_loss: 3.4919\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.6855 - val_loss: 3.9523\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.2040 - val_loss: 4.1560\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.4979 - val_loss: 2.8563\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1582 - val_loss: 4.6563\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.6316 - val_loss: 2.2546\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6963 - val_loss: 2.1824\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.2077 - val_loss: 3.0033\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5530 - val_loss: 2.8036\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.8185 - val_loss: 2.3145\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4718 - val_loss: 2.2100\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.7777 - val_loss: 3.3364\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.0249 - val_loss: 2.7723\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.3714 - val_loss: 2.2273\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2444 - val_loss: 2.8147\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.2849 - val_loss: 2.2339\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.0050 - val_loss: 2.4872\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.9813 - val_loss: 2.0030\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8611 - val_loss: 2.1175\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.7300 - val_loss: 1.7313\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.1472 - val_loss: 2.4461\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.5477 - val_loss: 2.2091\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.2091 - val_loss: 3.5479\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2687 - val_loss: 1.9474\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6610 - val_loss: 2.2923\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5769 - val_loss: 5.5343\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.8184 - val_loss: 6.5157\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4109 - val_loss: 1.7558\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.1010 - val_loss: 1.6081\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.1547 - val_loss: 3.8023\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9076 - val_loss: 2.0566\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.9475 - val_loss: 2.3103\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.6036 - val_loss: 1.6278\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.0848 - val_loss: 1.6384\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2093 - val_loss: 1.8040\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.8956 - val_loss: 2.8445\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.7488 - val_loss: 1.6153\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2466 - val_loss: 2.1331\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39df188b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 81 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 5126374.0000 - val_loss: 96.3903\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4021345.7500 - val_loss: 95.2325\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 3377126.5000 - val_loss: 94.3371\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2931078.5000 - val_loss: 93.5297\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1919450.7500 - val_loss: 92.8088\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 859143.8125 - val_loss: 92.0167\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 710034.0625 - val_loss: 91.2663\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 678844.8125 - val_loss: 90.4458\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 442540.4688 - val_loss: 89.8015\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 606763.3750 - val_loss: 89.0800\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 586653.3125 - val_loss: 88.2771\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 381004.6562 - val_loss: 87.4914\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 320651.4375 - val_loss: 86.7026\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 294252.2188 - val_loss: 85.9563\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 235453.0469 - val_loss: 85.2778\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 115290.5625 - val_loss: 84.4938\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 154290.4688 - val_loss: 83.6753\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 208869.0312 - val_loss: 82.8770\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 248683.4688 - val_loss: 82.0380\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 123793.1328 - val_loss: 81.2583\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 148054.8438 - val_loss: 80.4671\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 280304.5312 - val_loss: 79.7259\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 245827.8906 - val_loss: 78.9765\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 131592.9375 - val_loss: 78.0813\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 131300.6094 - val_loss: 77.2999\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 117634.5234 - val_loss: 76.5443\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 274847.9375 - val_loss: 75.7442\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 218237.9531 - val_loss: 75.0529\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 155294.3438 - val_loss: 74.3555\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 115905.7891 - val_loss: 73.7110\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 128272.1172 - val_loss: 73.0237\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 158493.6250 - val_loss: 72.2991\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 313750.6250 - val_loss: 71.5543\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 279655.4062 - val_loss: 70.9288\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 258058.7344 - val_loss: 70.2001\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 176862.0625 - val_loss: 69.5535\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 137992.9844 - val_loss: 68.9156\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 135256.2969 - val_loss: 68.2028\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 105044.4766 - val_loss: 67.6754\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 126675.0000 - val_loss: 67.0383\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 262550.9375 - val_loss: 66.3360\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 208603.0938 - val_loss: 65.8287\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 179111.0625 - val_loss: 65.1766\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 136541.2188 - val_loss: 64.6001\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 92650.8828 - val_loss: 64.0719\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 170046.7344 - val_loss: 63.4928\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 284279.5938 - val_loss: 62.9809\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 378725.6250 - val_loss: 62.5371\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 532928.1250 - val_loss: 62.2170\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 448293.3125 - val_loss: 61.9240\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3aae191f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 82 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 184665.0625 - val_loss: 89.8165\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 116252.1953 - val_loss: 102.9592\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 41390.4062 - val_loss: 104.2619\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 69483.3906 - val_loss: 101.5624\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 21669.7559 - val_loss: 100.9623\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18551.4160 - val_loss: 99.7084\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11989.9453 - val_loss: 99.6831\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1556.0674 - val_loss: 100.3088\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 77007.3359 - val_loss: 98.8076\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5790.1924 - val_loss: 102.8503\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 32403.2656 - val_loss: 102.7222\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23270.4629 - val_loss: 101.8339\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17369.5293 - val_loss: 101.1952\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13317.2432 - val_loss: 98.9912\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55302.4258 - val_loss: 99.5341\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12650.9639 - val_loss: 102.6502\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14376.0459 - val_loss: 102.2101\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7161.0947 - val_loss: 102.8379\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 65876.7500 - val_loss: 102.2496\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35989.8047 - val_loss: 99.4674\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49018.0586 - val_loss: 99.0768\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16090.1416 - val_loss: 100.7275\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49837.5977 - val_loss: 101.4736\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 27000.0781 - val_loss: 99.2430\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29200.0879 - val_loss: 99.4334\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 4873.8945 - val_loss: 98.9616\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12754.9717 - val_loss: 100.0111\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13457.3096 - val_loss: 99.2989\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24828.4414 - val_loss: 100.1725\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7637.7983 - val_loss: 102.7294\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34575.5469 - val_loss: 102.3072\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26828.2441 - val_loss: 100.7177\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11416.6758 - val_loss: 100.7482\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1820.6548 - val_loss: 99.5052\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 29830.7930 - val_loss: 99.6670\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14850.9502 - val_loss: 102.1933\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 74430.1016 - val_loss: 102.7839\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 91071.8516 - val_loss: 100.3580\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 24604.9805 - val_loss: 99.8593\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9745.2402 - val_loss: 99.9789\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 33002.1836 - val_loss: 99.7308\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26593.1738 - val_loss: 100.7190\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29113.5098 - val_loss: 102.6857\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 46269.4727 - val_loss: 101.2383\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 24722.0859 - val_loss: 100.7622\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31196.8691 - val_loss: 100.6029\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 25310.9629 - val_loss: 99.9119\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8109.9746 - val_loss: 101.5062\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23382.9297 - val_loss: 101.4643\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5723.9150 - val_loss: 99.6299\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40a26caf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 83 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 83.2416 - val_loss: 62.0232\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 38.4152 - val_loss: 7.1123\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 21.2504 - val_loss: 5.6794\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.0436 - val_loss: 19.4859\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.4995 - val_loss: 17.0378\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 10.4813 - val_loss: 7.6574\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.3597 - val_loss: 9.0746\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.0793 - val_loss: 13.7935\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.5534 - val_loss: 12.3575\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.1647 - val_loss: 8.0628\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8438 - val_loss: 8.9501\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.6143 - val_loss: 12.1421\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6178 - val_loss: 8.8630\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.7530 - val_loss: 6.3864\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.1827 - val_loss: 8.0093\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.6681 - val_loss: 4.6417\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 6.9879 - val_loss: 5.4000\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.5740 - val_loss: 5.1658\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.2040 - val_loss: 3.4886\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3278 - val_loss: 6.5757\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7862 - val_loss: 3.5247\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5030 - val_loss: 3.7850\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1222 - val_loss: 3.4980\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.3186 - val_loss: 3.5858\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8669 - val_loss: 3.4272\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3272 - val_loss: 10.3022\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8136 - val_loss: 3.9018\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.6155 - val_loss: 8.6391\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.6684 - val_loss: 4.3507\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.5427 - val_loss: 3.3271\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3505 - val_loss: 5.8418\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.5774 - val_loss: 3.2644\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.3094 - val_loss: 5.3784\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2918 - val_loss: 3.2579\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.8787 - val_loss: 3.9358\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4.9763 - val_loss: 3.7036\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.7611 - val_loss: 4.5498\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.1736 - val_loss: 3.2709\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.7129 - val_loss: 3.3544\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.3829 - val_loss: 5.2330\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.2344 - val_loss: 3.3524\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.5529 - val_loss: 6.3749\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5924 - val_loss: 3.6981\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.4623 - val_loss: 3.2252\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.0142 - val_loss: 3.2393\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0367 - val_loss: 3.2359\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.1357 - val_loss: 3.3762\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.7852 - val_loss: 3.1167\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.9515 - val_loss: 3.0814\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.7685 - val_loss: 4.3677\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff408c009d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 84 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 84.7815 - val_loss: 69.7717\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 42.7252 - val_loss: 31.3656\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 40.1199 - val_loss: 23.3478\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 31.7163 - val_loss: 30.6987\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 28.1822 - val_loss: 28.2055\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 22.9711 - val_loss: 13.6429\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19.6289 - val_loss: 12.1000\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18.1401 - val_loss: 10.7991\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17.3435 - val_loss: 9.6496\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 18.4967 - val_loss: 9.5320\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 17.5143 - val_loss: 10.0327\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.5924 - val_loss: 9.1494\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.6634 - val_loss: 9.5387\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 16.8461 - val_loss: 8.4294\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.4259 - val_loss: 9.1827\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.1182 - val_loss: 10.2565\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.3911 - val_loss: 8.7633\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.6425 - val_loss: 12.2994\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.5324 - val_loss: 9.9842\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.5650 - val_loss: 8.6359\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.8916 - val_loss: 9.7088\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.1788 - val_loss: 8.7628\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.3752 - val_loss: 9.3583\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.2540 - val_loss: 9.9328\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.8141 - val_loss: 9.4416\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.4129 - val_loss: 8.5494\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.9030 - val_loss: 8.5041\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.5141 - val_loss: 8.6087\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.9385 - val_loss: 9.4242\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14.1657 - val_loss: 9.2996\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.7242 - val_loss: 8.5052\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.9649 - val_loss: 9.5443\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.1340 - val_loss: 8.7960\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.8993 - val_loss: 8.5072\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.9068 - val_loss: 8.9014\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.9014 - val_loss: 8.3763\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.8796 - val_loss: 9.0943\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.1192 - val_loss: 9.0685\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.4796 - val_loss: 9.9716\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.6594 - val_loss: 8.2655\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.1476 - val_loss: 8.6241\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.3702 - val_loss: 9.6485\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.7815 - val_loss: 9.0341\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.4333 - val_loss: 10.0347\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.8500 - val_loss: 8.9466\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.3425 - val_loss: 8.5340\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.1133 - val_loss: 9.3128\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.3747 - val_loss: 9.3302\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 12.8000 - val_loss: 8.5756\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.7936 - val_loss: 8.3196\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff415518ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 85 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 79.3679 - val_loss: 55.3233\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 32.2434 - val_loss: 9.1772\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26.9316 - val_loss: 11.9503\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18.5899 - val_loss: 22.8439\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18.6223 - val_loss: 23.2670\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16.8006 - val_loss: 16.3973\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 15.0472 - val_loss: 12.7256\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.6868 - val_loss: 13.8114\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 13.2340 - val_loss: 13.4241\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 12.0669 - val_loss: 10.5537\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 11.5704 - val_loss: 11.2401\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.4672 - val_loss: 9.2575\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.2744 - val_loss: 9.8353\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.2793 - val_loss: 5.8882\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.6890 - val_loss: 8.0407\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.5412 - val_loss: 5.2751\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.2635 - val_loss: 7.5563\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.8312 - val_loss: 5.4600\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7108 - val_loss: 8.2199\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.5191 - val_loss: 5.2480\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.9928 - val_loss: 5.1230\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.1629 - val_loss: 6.2737\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.1503 - val_loss: 5.1829\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 7.0771 - val_loss: 7.0585\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4468 - val_loss: 5.4814\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.9986 - val_loss: 5.7582\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.6342 - val_loss: 5.4227\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.8186 - val_loss: 5.2801\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.3834 - val_loss: 5.3502\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.0315 - val_loss: 6.5202\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3778 - val_loss: 5.4390\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7932 - val_loss: 6.4211\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0076 - val_loss: 5.4443\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8233 - val_loss: 6.4981\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.9531 - val_loss: 5.5910\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.5365 - val_loss: 5.9941\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0661 - val_loss: 5.5883\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.2937 - val_loss: 6.1155\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1788 - val_loss: 5.7532\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.5719 - val_loss: 6.8902\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.1887 - val_loss: 5.5017\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5.1264 - val_loss: 6.6138\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.8686 - val_loss: 5.4949\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5.6398 - val_loss: 5.4375\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.0810 - val_loss: 5.4095\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5.0824 - val_loss: 5.5306\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.4917 - val_loss: 6.2672\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.4811 - val_loss: 5.7028\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.0711 - val_loss: 5.7432\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.3682 - val_loss: 5.6080\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff387c06a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 86 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 99.5490 - val_loss: 77.7801\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 50.4065 - val_loss: 35.0671\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 31.2370 - val_loss: 11.6302\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 27.3228 - val_loss: 24.7425\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23.1291 - val_loss: 31.6527\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21.9951 - val_loss: 24.7156\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18.5086 - val_loss: 13.9042\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.9282 - val_loss: 13.2072\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.2854 - val_loss: 19.0329\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 15.9745 - val_loss: 15.2087\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.7220 - val_loss: 6.6313\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.7754 - val_loss: 11.3711\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.9456 - val_loss: 8.6867\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.2668 - val_loss: 7.2139\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.2604 - val_loss: 8.2921\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.9485 - val_loss: 8.6018\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.7854 - val_loss: 8.4930\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.4980 - val_loss: 8.1033\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.1905 - val_loss: 7.8978\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.3425 - val_loss: 7.5389\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.6548 - val_loss: 7.6364\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2939 - val_loss: 7.7219\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.1535 - val_loss: 7.7858\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2128 - val_loss: 8.0570\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.8785 - val_loss: 8.1755\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.2715 - val_loss: 8.2588\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.6733 - val_loss: 8.1685\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6759 - val_loss: 8.1029\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6908 - val_loss: 8.0178\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.1544 - val_loss: 7.7878\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.2988 - val_loss: 7.7414\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5512 - val_loss: 7.7706\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2558 - val_loss: 7.8961\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8750 - val_loss: 7.7457\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.1074 - val_loss: 7.7579\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.8988 - val_loss: 7.8270\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.9698 - val_loss: 7.8357\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.4349 - val_loss: 8.0500\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.5396 - val_loss: 7.8666\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.1144 - val_loss: 7.7744\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.9776 - val_loss: 7.6065\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.0738 - val_loss: 7.4391\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3705 - val_loss: 7.9279\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.7405 - val_loss: 7.5414\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1254 - val_loss: 7.5237\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5501 - val_loss: 7.9945\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6960 - val_loss: 7.7530\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.5697 - val_loss: 7.4303\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.9133 - val_loss: 6.9167\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.8843 - val_loss: 6.5521\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b8229b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 87 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 121779.3516 - val_loss: 88.2766\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 78470.9375 - val_loss: 87.6373\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24717.6035 - val_loss: 80.4178\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 114615.3281 - val_loss: 79.1081\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 87674.5625 - val_loss: 84.6250\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 34739.4922 - val_loss: 87.2052\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6436.0229 - val_loss: 85.2616\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 16473.0508 - val_loss: 84.0842\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 29125.8379 - val_loss: 85.8537\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17598.9766 - val_loss: 85.4885\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31546.8711 - val_loss: 87.0249\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 18133.5879 - val_loss: 86.6626\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15076.6123 - val_loss: 87.6644\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37136.7266 - val_loss: 87.4352\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5078.8594 - val_loss: 87.5372\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9458.8965 - val_loss: 87.3605\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17662.7031 - val_loss: 87.5574\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37568.2305 - val_loss: 87.9403\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6619.4780 - val_loss: 84.4319\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 84634.8438 - val_loss: 83.3814\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 31690.7988 - val_loss: 86.7796\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28463.2539 - val_loss: 87.9254\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32386.8809 - val_loss: 84.6130\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 63467.2188 - val_loss: 84.1878\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 65797.2734 - val_loss: 85.9450\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29629.5625 - val_loss: 89.5878\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 54102.6445 - val_loss: 90.7269\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13313.2480 - val_loss: 88.0901\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 29486.8164 - val_loss: 87.2188\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 18397.3594 - val_loss: 88.1658\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 33274.5742 - val_loss: 87.9561\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16921.4453 - val_loss: 90.4446\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9586.3447 - val_loss: 90.0822\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 20123.5215 - val_loss: 89.0758\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 18127.3496 - val_loss: 87.1801\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 63281.2695 - val_loss: 88.0530\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 14985.0557 - val_loss: 89.3918\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2440.7732 - val_loss: 91.4420\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 79418.4844 - val_loss: 91.9062\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 66319.0781 - val_loss: 89.8522\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13982.3799 - val_loss: 85.5650\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 98207.3984 - val_loss: 83.4901\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 87786.1641 - val_loss: 85.6522\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 30301.3262 - val_loss: 90.6096\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 37820.9688 - val_loss: 93.4872\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51910.8984 - val_loss: 92.9984\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14293.9932 - val_loss: 89.7052\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 68163.9531 - val_loss: 87.7830\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 47604.8594 - val_loss: 89.7786\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 27327.0156 - val_loss: 93.2882\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff36b3ed5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 88 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 124513.9375 - val_loss: 97.4516\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 145523.9219 - val_loss: 98.6888\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 100306.6250 - val_loss: 93.6748\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 60935.2500 - val_loss: 91.4810\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47822.4766 - val_loss: 95.3533\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 60232.8672 - val_loss: 96.1780\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62037.9883 - val_loss: 94.6210\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 23368.1777 - val_loss: 90.2478\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 97042.5391 - val_loss: 89.3105\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 80876.1562 - val_loss: 90.7146\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54158.4180 - val_loss: 94.3576\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14213.8916 - val_loss: 95.3053\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 25674.1230 - val_loss: 94.3352\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13584.3564 - val_loss: 93.9649\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3613.4446 - val_loss: 96.9558\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 131632.1875 - val_loss: 98.0287\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 73186.3984 - val_loss: 95.4902\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16956.8594 - val_loss: 92.7159\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 91977.1094 - val_loss: 90.2699\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 89484.4844 - val_loss: 92.8672\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40113.3477 - val_loss: 95.8297\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57344.3086 - val_loss: 96.2076\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 28914.1914 - val_loss: 95.7254\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13210.0908 - val_loss: 92.9379\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 81866.4375 - val_loss: 91.9832\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83978.4766 - val_loss: 93.3306\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24435.8008 - val_loss: 94.6491\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18982.3730 - val_loss: 95.2489\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13167.2461 - val_loss: 94.6860\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1185.1653 - val_loss: 94.6619\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 19613.3066 - val_loss: 94.4740\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 19210.9199 - val_loss: 93.7971\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12389.0234 - val_loss: 94.3031\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17249.7656 - val_loss: 95.1702\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17085.0059 - val_loss: 94.2546\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15516.5957 - val_loss: 94.2720\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13241.1377 - val_loss: 94.1052\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 60204.3086 - val_loss: 93.2992\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 28014.5723 - val_loss: 94.7117\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1341.7711 - val_loss: 95.3031\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 49407.6172 - val_loss: 94.1417\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39153.3516 - val_loss: 94.3187\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9719.0654 - val_loss: 95.5818\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 44642.5469 - val_loss: 95.9480\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 37672.4688 - val_loss: 94.8674\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55809.2188 - val_loss: 94.4749\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 16665.5684 - val_loss: 95.3237\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 50669.8789 - val_loss: 95.8471\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 58312.9336 - val_loss: 95.3157\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5333.5332 - val_loss: 94.2379\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff36e32d280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 89 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 80.0877 - val_loss: 63.4778\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 38.0979 - val_loss: 24.0324\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 29.7010 - val_loss: 17.6531\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24.4974 - val_loss: 25.0542\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 21.2452 - val_loss: 23.8695\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.9684 - val_loss: 15.9035\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16.9336 - val_loss: 14.1846\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.8701 - val_loss: 12.6580\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.4475 - val_loss: 8.2855\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.6976 - val_loss: 7.4512\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.7140 - val_loss: 8.5738\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.6215 - val_loss: 6.2409\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.3774 - val_loss: 5.1153\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.0429 - val_loss: 9.5061\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.5396 - val_loss: 5.3108\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.9006 - val_loss: 7.7048\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.7026 - val_loss: 7.9568\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.3428 - val_loss: 6.0027\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.5720 - val_loss: 7.8274\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.0236 - val_loss: 5.6228\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.6365 - val_loss: 6.8398\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.8993 - val_loss: 7.8238\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.8210 - val_loss: 4.9512\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.0643 - val_loss: 6.4506\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.4462 - val_loss: 5.5823\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.5068 - val_loss: 7.3090\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.4959 - val_loss: 5.3392\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.8871 - val_loss: 6.2522\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.1037 - val_loss: 5.2373\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.3965 - val_loss: 5.1220\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.9143 - val_loss: 5.3438\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.6591 - val_loss: 5.5165\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.8314 - val_loss: 6.3761\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.6601 - val_loss: 5.2901\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.0974 - val_loss: 5.5559\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 9.5604 - val_loss: 7.4140\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.3757 - val_loss: 4.4715\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.1124 - val_loss: 6.8716\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.6115 - val_loss: 4.7473\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5755 - val_loss: 6.4998\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.9569 - val_loss: 4.6576\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0234 - val_loss: 5.2041\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7086 - val_loss: 6.2446\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.1511 - val_loss: 4.4103\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.7445 - val_loss: 6.3319\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.4046 - val_loss: 5.3877\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.3695 - val_loss: 4.5866\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.9837 - val_loss: 5.0690\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.3338 - val_loss: 6.1183\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.1043 - val_loss: 4.3789\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a6adaaf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 90 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 51799.9570 - val_loss: 113.4593\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 199095.2031 - val_loss: 116.7130\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 152112.2969 - val_loss: 107.6994\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26676.5664 - val_loss: 104.2252\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44039.8828 - val_loss: 110.5443\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 78091.4219 - val_loss: 111.6110\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45351.9961 - val_loss: 108.4230\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 26377.7344 - val_loss: 107.6499\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6099.4492 - val_loss: 111.4540\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 66643.9375 - val_loss: 111.8189\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 41162.6289 - val_loss: 109.9561\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3283.5173 - val_loss: 109.8526\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 34291.6055 - val_loss: 108.9707\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16127.6484 - val_loss: 108.2906\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24803.5645 - val_loss: 108.5527\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 47388.8398 - val_loss: 106.8209\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 50978.0820 - val_loss: 109.9753\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22287.1816 - val_loss: 108.5121\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6759.7173 - val_loss: 105.1469\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 67819.9375 - val_loss: 103.6845\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 43373.9141 - val_loss: 107.7536\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 5942.9907 - val_loss: 114.0059\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 101273.1406 - val_loss: 114.9601\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 103601.0781 - val_loss: 113.9732\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 48358.7500 - val_loss: 109.0625\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 34851.7617 - val_loss: 105.9981\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2073.0320 - val_loss: 103.6262\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 85405.7969 - val_loss: 102.7585\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56467.0664 - val_loss: 107.4300\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12136.3467 - val_loss: 108.6035\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1018.9002 - val_loss: 107.7636\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23095.8906 - val_loss: 104.9905\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 78085.8750 - val_loss: 104.3992\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 32172.0254 - val_loss: 104.9831\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 33001.1680 - val_loss: 108.9509\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 48755.8359 - val_loss: 111.0476\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 53959.2734 - val_loss: 107.9826\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13995.2744 - val_loss: 106.8354\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 26291.0469 - val_loss: 109.7194\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 72120.1484 - val_loss: 109.8363\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 66112.0547 - val_loss: 108.4803\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 28144.7246 - val_loss: 104.6053\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 75623.1953 - val_loss: 103.6870\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 88241.3594 - val_loss: 104.7375\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 22568.9805 - val_loss: 106.5173\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15232.2314 - val_loss: 109.4828\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 63090.8555 - val_loss: 109.6833\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 70212.4766 - val_loss: 109.3242\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 52875.8984 - val_loss: 106.6759\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 22590.8184 - val_loss: 105.4019\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3687d3b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 91 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 99.6179 - val_loss: 82.0107\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 79.4009 - val_loss: 59.2906\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 65.6971 - val_loss: 56.8830\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48.0892 - val_loss: 50.0134\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.8064 - val_loss: 38.3981\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.5455 - val_loss: 29.6531\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 24.5148 - val_loss: 14.1862\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 19.4896 - val_loss: 13.0701\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18.8000 - val_loss: 6.8028\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.7789 - val_loss: 8.9726\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15.5073 - val_loss: 9.7622\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.0164 - val_loss: 6.7601\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15.2988 - val_loss: 7.2894\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.9748 - val_loss: 7.3942\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.8238 - val_loss: 5.7308\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.6836 - val_loss: 7.1172\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.3978 - val_loss: 5.9329\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.3577 - val_loss: 6.0203\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.8631 - val_loss: 6.4127\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.2029 - val_loss: 5.8863\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.1606 - val_loss: 5.3817\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.2385 - val_loss: 5.9062\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.2259 - val_loss: 8.1072\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 13.9569 - val_loss: 5.3203\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.6630 - val_loss: 5.1286\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.8286 - val_loss: 5.9765\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 12.1860 - val_loss: 5.5381\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.5634 - val_loss: 5.4481\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.5806 - val_loss: 5.8903\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.4790 - val_loss: 6.2276\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.3448 - val_loss: 5.4218\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.1360 - val_loss: 7.6558\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.1263 - val_loss: 4.8289\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.8910 - val_loss: 5.1736\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.0868 - val_loss: 4.9394\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.6514 - val_loss: 6.5721\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.0509 - val_loss: 5.5166\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.3342 - val_loss: 7.1237\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.7696 - val_loss: 5.9115\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.7395 - val_loss: 4.8462\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.5717 - val_loss: 6.8860\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.4606 - val_loss: 4.5901\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.3060 - val_loss: 5.0956\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 12.2160 - val_loss: 5.4782\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.1602 - val_loss: 4.6165\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 13.0368 - val_loss: 5.1044\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.3963 - val_loss: 5.8696\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.2046 - val_loss: 5.1158\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.7408 - val_loss: 5.2870\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 12.1511 - val_loss: 4.5682\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3824f54c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 92 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 89.3679 - val_loss: 68.0637\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 42.8993 - val_loss: 16.9635\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30.5249 - val_loss: 16.2219\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 24.1069 - val_loss: 28.7592\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22.9758 - val_loss: 23.5728\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21.3955 - val_loss: 13.6308\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.7841 - val_loss: 16.2002\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.9881 - val_loss: 11.4286\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.6364 - val_loss: 8.8317\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.3805 - val_loss: 9.6744\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.9023 - val_loss: 7.0655\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.5489 - val_loss: 4.5201\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.6533 - val_loss: 4.0859\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.0420 - val_loss: 4.3102\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 11.3195 - val_loss: 4.4327\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.7451 - val_loss: 4.4433\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.9340 - val_loss: 6.1037\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.7366 - val_loss: 4.9552\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5225 - val_loss: 4.8611\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.2712 - val_loss: 4.3769\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10.3868 - val_loss: 4.3957\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.9411 - val_loss: 4.5589\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.3992 - val_loss: 4.5904\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.5332 - val_loss: 4.6461\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.4832 - val_loss: 4.4422\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2626 - val_loss: 4.6429\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.9648 - val_loss: 4.5040\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.9328 - val_loss: 4.7079\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1893 - val_loss: 4.5428\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.4679 - val_loss: 5.0319\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.2693 - val_loss: 4.6420\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.4637 - val_loss: 5.4159\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3510 - val_loss: 4.9046\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.8154 - val_loss: 5.3210\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.9629 - val_loss: 4.1826\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.3136 - val_loss: 4.0868\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4651 - val_loss: 4.1077\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.3053 - val_loss: 4.3748\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.3683 - val_loss: 4.6158\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.2844 - val_loss: 4.1027\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6.4626 - val_loss: 4.0695\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.8102 - val_loss: 3.9712\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8979 - val_loss: 3.8399\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.7112 - val_loss: 5.2035\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.3228 - val_loss: 3.7747\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5819 - val_loss: 4.0176\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.2307 - val_loss: 3.9224\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 7.5310 - val_loss: 3.5571\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.0832 - val_loss: 3.5244\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6779 - val_loss: 4.7955\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38e00fb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 93 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 65.7094 - val_loss: 46.5610\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 44.4733 - val_loss: 31.0783\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.2648 - val_loss: 37.8198\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 31.8893 - val_loss: 35.7212\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 27.2482 - val_loss: 21.8286\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22.5008 - val_loss: 14.2289\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 20.7791 - val_loss: 16.3232\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.7801 - val_loss: 7.2858\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 17.6873 - val_loss: 9.8348\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 18.6905 - val_loss: 9.9482\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.2337 - val_loss: 4.5623\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 15.8488 - val_loss: 7.6465\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 15.1851 - val_loss: 5.8091\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.3739 - val_loss: 5.3283\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.6192 - val_loss: 3.7877\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.2748 - val_loss: 5.0225\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.8270 - val_loss: 3.4791\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.0893 - val_loss: 3.3388\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.4523 - val_loss: 3.9047\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.6831 - val_loss: 3.2407\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.4192 - val_loss: 2.9322\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.7063 - val_loss: 7.5733\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.2138 - val_loss: 3.0830\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.5997 - val_loss: 3.6359\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.8158 - val_loss: 4.2232\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.1342 - val_loss: 2.9384\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.6382 - val_loss: 5.6553\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.1209 - val_loss: 2.8961\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.4354 - val_loss: 2.6907\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.4050 - val_loss: 5.8882\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.1608 - val_loss: 4.2683\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.6429 - val_loss: 2.8493\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.8392 - val_loss: 2.8926\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.2760 - val_loss: 2.6745\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6994 - val_loss: 4.1111\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.4021 - val_loss: 4.6539\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.8924 - val_loss: 3.0962\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.5951 - val_loss: 3.7545\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.1846 - val_loss: 2.6805\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.7684 - val_loss: 2.4954\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.3646 - val_loss: 4.2567\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7973 - val_loss: 2.3949\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.4599 - val_loss: 2.9522\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.2077 - val_loss: 2.7155\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.3220 - val_loss: 3.1928\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.1159 - val_loss: 4.7474\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.5028 - val_loss: 3.2501\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.7491 - val_loss: 2.6807\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.0880 - val_loss: 3.8058\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.5650 - val_loss: 2.7181\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3978fa0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 94 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 108.2857 - val_loss: 88.5946\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 65.6073 - val_loss: 42.2812\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.6102 - val_loss: 10.1763\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 32.0570 - val_loss: 26.5425\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 29.4395 - val_loss: 32.0896\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 27.9627 - val_loss: 23.7761\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 22.9478 - val_loss: 10.5075\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 21.2285 - val_loss: 7.8487\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 20.3386 - val_loss: 7.4680\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.0793 - val_loss: 7.6871\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 16.3346 - val_loss: 11.3157\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 14.9322 - val_loss: 6.6339\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.0907 - val_loss: 6.9773\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.9478 - val_loss: 6.7717\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.9966 - val_loss: 6.3701\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.7712 - val_loss: 6.1886\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.7310 - val_loss: 6.2623\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.6980 - val_loss: 7.3109\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.8338 - val_loss: 6.1928\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.4377 - val_loss: 6.0572\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 9.2580 - val_loss: 5.9781\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9859 - val_loss: 7.3085\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.5387 - val_loss: 5.5482\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.3456 - val_loss: 6.3480\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.8109 - val_loss: 5.3249\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.3094 - val_loss: 5.6777\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.0719 - val_loss: 5.2480\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.6500 - val_loss: 6.4833\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7772 - val_loss: 5.1617\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1387 - val_loss: 5.1908\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.3515 - val_loss: 5.6295\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8491 - val_loss: 6.3612\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.2469 - val_loss: 5.0623\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8827 - val_loss: 4.9150\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.8127 - val_loss: 5.1476\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.9132 - val_loss: 4.8926\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.9780 - val_loss: 4.6804\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7108 - val_loss: 4.5925\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.0158 - val_loss: 4.9020\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.5187 - val_loss: 4.4963\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.2554 - val_loss: 4.5371\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.9127 - val_loss: 4.4596\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.9101 - val_loss: 4.3497\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8126 - val_loss: 6.1302\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.3402 - val_loss: 4.5583\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1728 - val_loss: 4.2114\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.3179 - val_loss: 4.3156\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.5629 - val_loss: 4.2018\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7172 - val_loss: 4.2252\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.1303 - val_loss: 4.0567\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3ab523940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 95 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 83.9144 - val_loss: 61.0937\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 45.8547 - val_loss: 20.6826\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 41.1399 - val_loss: 23.4094\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 31.3287 - val_loss: 34.2070\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 28.7113 - val_loss: 30.7082\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 24.3251 - val_loss: 19.1940\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 22.3623 - val_loss: 18.9174\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 19.1800 - val_loss: 16.7986\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 17.2844 - val_loss: 7.8813\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 17.2451 - val_loss: 9.3751\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.4083 - val_loss: 5.0563\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 15.9674 - val_loss: 9.4099\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.0998 - val_loss: 5.5847\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 15.0420 - val_loss: 8.5556\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.5735 - val_loss: 7.7013\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.0683 - val_loss: 6.0858\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.7913 - val_loss: 7.7800\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.5979 - val_loss: 5.0112\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.6678 - val_loss: 5.6324\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.2585 - val_loss: 6.6096\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.0626 - val_loss: 4.9089\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 13.4066 - val_loss: 6.4912\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.3597 - val_loss: 4.6500\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 13.4559 - val_loss: 4.9742\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.7891 - val_loss: 6.3131\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 12.6359 - val_loss: 4.7077\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.2883 - val_loss: 6.0401\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12.5412 - val_loss: 6.1350\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.9247 - val_loss: 4.3198\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.7291 - val_loss: 8.5478\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.1203 - val_loss: 4.7056\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.8916 - val_loss: 4.8480\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.1160 - val_loss: 6.1606\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.0964 - val_loss: 4.2714\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.2261 - val_loss: 6.8476\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.4983 - val_loss: 5.0735\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.1202 - val_loss: 4.7992\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.0690 - val_loss: 6.1176\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.0200 - val_loss: 5.0886\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.9199 - val_loss: 4.0900\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 11.1900 - val_loss: 4.3579\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 11.6280 - val_loss: 4.3952\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.4527 - val_loss: 4.4178\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.5554 - val_loss: 4.5310\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.1817 - val_loss: 4.0464\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.8562 - val_loss: 5.2950\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.2837 - val_loss: 4.2266\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.7869 - val_loss: 3.9426\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.9404 - val_loss: 4.0196\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.6420 - val_loss: 5.5564\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39784bd30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 96 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 97.2750 - val_loss: 75.6122\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 47.6084 - val_loss: 29.5537\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25.2295 - val_loss: 4.3384\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 22.2242 - val_loss: 23.6669\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.5511 - val_loss: 31.8651\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.2114 - val_loss: 23.1808\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.7589 - val_loss: 16.3018\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.3490 - val_loss: 19.3127\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.6602 - val_loss: 19.3681\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.0189 - val_loss: 14.6309\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5494 - val_loss: 12.3388\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9848 - val_loss: 13.2883\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.6385 - val_loss: 6.9595\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.1406 - val_loss: 9.1673\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.9903 - val_loss: 5.3332\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.7210 - val_loss: 6.5869\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.5542 - val_loss: 4.3267\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8459 - val_loss: 7.4098\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.7402 - val_loss: 4.1730\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5362 - val_loss: 6.1756\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.0960 - val_loss: 4.4321\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.5391 - val_loss: 4.7204\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6038 - val_loss: 5.2549\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.4931 - val_loss: 3.9620\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8208 - val_loss: 5.9406\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9287 - val_loss: 4.2190\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9725 - val_loss: 4.2586\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.5253 - val_loss: 3.8162\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.7388 - val_loss: 4.0680\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.9491 - val_loss: 3.5789\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2846 - val_loss: 3.3232\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2989 - val_loss: 4.4051\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0962 - val_loss: 3.2872\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2257 - val_loss: 3.3944\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.3607 - val_loss: 3.6460\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8423 - val_loss: 3.9848\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.6780 - val_loss: 2.9915\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6672 - val_loss: 4.3894\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.0082 - val_loss: 2.8776\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9559 - val_loss: 2.9925\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7539 - val_loss: 4.8564\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0315 - val_loss: 2.7465\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.2521 - val_loss: 3.5489\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.3134 - val_loss: 3.4226\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1548 - val_loss: 2.7394\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0524 - val_loss: 3.5826\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8154 - val_loss: 2.7740\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.1722 - val_loss: 3.0005\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6339 - val_loss: 2.6721\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4944 - val_loss: 2.8312\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38772e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 97 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 80.9162 - val_loss: 59.1615\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 37.9665 - val_loss: 15.1470\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 18.3535 - val_loss: 4.8434\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 17.5630 - val_loss: 10.4880\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.6733 - val_loss: 16.7540\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14.0060 - val_loss: 10.3800\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.9810 - val_loss: 5.1764\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.6899 - val_loss: 4.0869\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.5494 - val_loss: 4.7139\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.2882 - val_loss: 2.3048\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9397 - val_loss: 4.1075\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.9170 - val_loss: 2.6769\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0268 - val_loss: 2.4995\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.7884 - val_loss: 2.9584\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5386 - val_loss: 2.6350\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.4295 - val_loss: 2.8227\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1579 - val_loss: 2.4893\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.7387 - val_loss: 2.5858\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9897 - val_loss: 4.3210\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8008 - val_loss: 3.1091\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5219 - val_loss: 3.1260\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.2390 - val_loss: 2.5504\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.8937 - val_loss: 2.7500\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.2189 - val_loss: 2.6166\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2642 - val_loss: 3.0149\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2718 - val_loss: 3.4055\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.2864 - val_loss: 3.7588\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2144 - val_loss: 4.0391\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2442 - val_loss: 4.6263\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3732 - val_loss: 4.0685\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4724 - val_loss: 3.2222\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9708 - val_loss: 3.7873\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3719 - val_loss: 3.7490\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9520 - val_loss: 3.7652\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8492 - val_loss: 2.8480\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.5871 - val_loss: 2.8903\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.7582 - val_loss: 2.8959\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.9642 - val_loss: 2.6494\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0594 - val_loss: 2.9674\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.2946 - val_loss: 3.0986\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7699 - val_loss: 3.0242\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.1209 - val_loss: 2.7153\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.4878 - val_loss: 2.6780\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3333 - val_loss: 2.6170\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.6620 - val_loss: 3.5805\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4468 - val_loss: 3.5560\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.3034 - val_loss: 2.5444\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.3489 - val_loss: 2.8700\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.9200 - val_loss: 2.8215\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6332 - val_loss: 3.8362\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37a0d7e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 98 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 88ms/step - loss: 96.6628 - val_loss: 73.7590\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 54.6655 - val_loss: 30.0415\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 47.4209 - val_loss: 21.4933\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 37.6997 - val_loss: 25.8359\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 30.3498 - val_loss: 32.5421\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24.8243 - val_loss: 19.7655\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 22.8833 - val_loss: 15.4374\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 19.2560 - val_loss: 22.7743\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 18.6478 - val_loss: 16.4786\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 16.2145 - val_loss: 12.4781\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.7374 - val_loss: 12.9444\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.7722 - val_loss: 15.3482\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 16.3030 - val_loss: 13.7169\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.6500 - val_loss: 12.0041\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.9276 - val_loss: 13.9053\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.8685 - val_loss: 12.2815\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 16.2000 - val_loss: 11.5918\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.8353 - val_loss: 13.1860\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.4966 - val_loss: 11.4249\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.7036 - val_loss: 12.5393\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14.2560 - val_loss: 10.9521\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 14.8155 - val_loss: 10.5661\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.7895 - val_loss: 13.7582\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 14.4676 - val_loss: 10.4300\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13.4720 - val_loss: 11.2691\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.0140 - val_loss: 12.0990\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 13.4637 - val_loss: 10.0293\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.2928 - val_loss: 11.8444\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.0664 - val_loss: 10.0519\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13.5406 - val_loss: 9.9718\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.3365 - val_loss: 10.2345\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 11.8804 - val_loss: 9.7562\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.7468 - val_loss: 9.7001\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.9589 - val_loss: 10.5492\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.1886 - val_loss: 9.4981\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.9414 - val_loss: 11.9464\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.0571 - val_loss: 9.6532\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.6128 - val_loss: 9.4484\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.2630 - val_loss: 9.7096\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.6228 - val_loss: 9.4140\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.7867 - val_loss: 9.6069\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.6610 - val_loss: 9.1488\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.2784 - val_loss: 9.1403\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5348 - val_loss: 8.9969\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.9880 - val_loss: 9.9841\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.6039 - val_loss: 10.1397\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5570 - val_loss: 8.6486\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6118 - val_loss: 9.9740\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 10.5663 - val_loss: 8.4276\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.8429 - val_loss: 8.5120\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37c893d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 99 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 99ms/step - loss: 156336.5156 - val_loss: 87.3354\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 30250.5781 - val_loss: 92.4357\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11877.7480 - val_loss: 85.0936\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 183842.1094 - val_loss: 82.2021\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 109118.6016 - val_loss: 85.6186\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45970.7852 - val_loss: 90.0170\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10129.5781 - val_loss: 96.7786\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 157662.3125 - val_loss: 99.2640\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 165742.9531 - val_loss: 95.6030\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 86420.8125 - val_loss: 91.2992\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11542.8623 - val_loss: 90.2239\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3925.7168 - val_loss: 89.8210\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 55382.8555 - val_loss: 88.3764\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 56768.7891 - val_loss: 90.7850\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 40795.8633 - val_loss: 91.7501\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 25297.4219 - val_loss: 90.2761\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26440.8887 - val_loss: 90.4016\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 41757.8242 - val_loss: 92.1818\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 48031.6719 - val_loss: 92.1258\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5553.1035 - val_loss: 89.8366\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 24491.7715 - val_loss: 89.7729\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8094.9146 - val_loss: 91.7753\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6778.4458 - val_loss: 91.0465\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 54973.2969 - val_loss: 91.7986\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4382.8486 - val_loss: 90.3304\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 44409.1172 - val_loss: 90.7814\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16013.2139 - val_loss: 90.3241\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12513.1846 - val_loss: 91.3777\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28251.8184 - val_loss: 91.7765\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15220.6543 - val_loss: 88.8093\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 55744.5781 - val_loss: 87.8863\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 69584.7812 - val_loss: 91.3434\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 26740.7637 - val_loss: 95.3118\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 76084.8125 - val_loss: 95.8639\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 97013.8438 - val_loss: 93.9209\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 70548.3438 - val_loss: 90.7045\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3359.8438 - val_loss: 87.2265\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 111245.8125 - val_loss: 86.6229\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 111156.0156 - val_loss: 88.0361\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 82122.4844 - val_loss: 90.7210\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 14822.0547 - val_loss: 96.0560\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 32757.2168 - val_loss: 97.2351\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 102705.5859 - val_loss: 96.1222\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 41812.2734 - val_loss: 92.4590\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17283.5449 - val_loss: 92.5142\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4265.8491 - val_loss: 93.6648\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 26909.8691 - val_loss: 93.2025\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 13465.5068 - val_loss: 93.9608\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11250.6328 - val_loss: 94.1088\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6334.4282 - val_loss: 91.6042\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3f26295e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 100 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 93.5032 - val_loss: 73.1823\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 48.8175 - val_loss: 22.9179\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 21.3405 - val_loss: 5.2324\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.2168 - val_loss: 20.9668\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 12.4113 - val_loss: 18.5780\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 12.0778 - val_loss: 11.4702\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.2044 - val_loss: 10.7196\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.3700 - val_loss: 13.7211\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.0938 - val_loss: 9.4096\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.4192 - val_loss: 7.2944\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.6636 - val_loss: 10.3432\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 8.8853 - val_loss: 6.2341\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0617 - val_loss: 7.7363\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7009 - val_loss: 5.5016\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.3821 - val_loss: 8.1653\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.2469 - val_loss: 3.8994\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.1279 - val_loss: 6.5897\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.8087 - val_loss: 4.6923\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.2450 - val_loss: 4.2153\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 6.6064 - val_loss: 4.4917\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.1433 - val_loss: 4.2711\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1658 - val_loss: 3.9702\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.3637 - val_loss: 4.8504\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8538 - val_loss: 4.4507\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 6.2604 - val_loss: 3.9562\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.7714 - val_loss: 4.0321\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.2670 - val_loss: 5.1228\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.9519 - val_loss: 4.1546\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.0993 - val_loss: 4.6105\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.2811 - val_loss: 4.1171\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.8103 - val_loss: 4.9985\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.2798 - val_loss: 4.2554\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7403 - val_loss: 4.2692\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.8948 - val_loss: 3.9630\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8292 - val_loss: 4.5686\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 5.5190 - val_loss: 3.8770\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.0782 - val_loss: 4.4408\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.4283 - val_loss: 3.8875\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.9700 - val_loss: 3.8278\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8786 - val_loss: 5.4721\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 5.7685 - val_loss: 4.4478\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0967 - val_loss: 6.2434\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.8229 - val_loss: 3.7552\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.5454 - val_loss: 4.3609\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.1426 - val_loss: 4.0528\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.0009 - val_loss: 3.9078\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1856 - val_loss: 3.8568\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2573 - val_loss: 4.0106\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.8061 - val_loss: 3.9922\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1605 - val_loss: 3.7383\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff36d31e1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 101 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 64.7432 - val_loss: 35.4764\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 39.0502 - val_loss: 19.7115\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 31.6602 - val_loss: 36.4627\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 28.6439 - val_loss: 33.8906\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 23.2405 - val_loss: 20.3098\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 21.4445 - val_loss: 10.5806\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 19.5221 - val_loss: 17.6504\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 18.6000 - val_loss: 18.3584\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16.0268 - val_loss: 4.5491\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.3951 - val_loss: 7.8440\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.0638 - val_loss: 9.5189\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11.5350 - val_loss: 1.2661\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12.2438 - val_loss: 4.5905\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.1113 - val_loss: 5.8766\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 10.5267 - val_loss: 5.3182\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 11.2124 - val_loss: 6.6901\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 10.5849 - val_loss: 4.1660\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.0961 - val_loss: 3.2132\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 9.4026 - val_loss: 4.6609\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9192 - val_loss: 2.1458\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 9.5871 - val_loss: 1.4760\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.4136 - val_loss: 2.9886\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.4672 - val_loss: 1.2880\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.2215 - val_loss: 3.6273\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.0904 - val_loss: 3.0436\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.5694 - val_loss: 2.4149\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.0316 - val_loss: 3.6184\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 8.2217 - val_loss: 3.3968\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.1889 - val_loss: 1.3210\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.0053 - val_loss: 5.4554\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.7180 - val_loss: 1.9319\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7249 - val_loss: 4.2781\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.1294 - val_loss: 2.2243\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.4595 - val_loss: 2.5043\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4458 - val_loss: 1.5356\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.6952 - val_loss: 2.7397\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.3261 - val_loss: 1.8489\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.5540 - val_loss: 2.2563\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.8097 - val_loss: 3.9604\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.8698 - val_loss: 1.6545\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.5736 - val_loss: 5.8275\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.1549 - val_loss: 1.4604\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6938 - val_loss: 2.2720\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.7776 - val_loss: 3.1881\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.4840 - val_loss: 1.6811\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.2403 - val_loss: 5.0439\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.6442 - val_loss: 1.9457\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.5553 - val_loss: 3.4140\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6.7172 - val_loss: 1.3551\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3995 - val_loss: 2.8013\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3726e5670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 102 finished\n"
     ]
    }
   ],
   "source": [
    "zipcodes = nv_zipcodes\n",
    "dict_mape3 = {}\n",
    "dict_pred3 = {}\n",
    "\n",
    "for zipcode in range(len(zipcodes)):\n",
    "\n",
    "    # init a RMM model\n",
    "    rnn_model = Sequential()\n",
    "    # add 4 layers of RNN and a last layer\n",
    "\n",
    "    # we define shape on first layer, (60,1) because we use 60 inputs per prediction\n",
    "    rnn_model.add(LSTM(units= 60, return_sequences = False, input_shape=((60,1))))\n",
    "    rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # 3 other layers\n",
    "    #rnn_model.add(LSTM(units= 30, return_sequences = True))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # return_sequence is False because we want only 1 output after this layer\n",
    "    #rnn_model.add(LSTM(units= 60, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # last layer \n",
    "\n",
    "    rnn_model.add(Dense(units=1))\n",
    "\n",
    "    # compile - because this is a regression model we want to minimize MSE\n",
    "\n",
    "    rnn_model.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "\n",
    "    # We get only the specific column(Zipcode from our train and test datas)\n",
    "    train_data = train.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    test_data = test.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # We are using normalizaion rather than standascaler. \n",
    "    # In a upward trending timeseries it is better to not start from negative\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Because we are using 60 previous values to model and predict the next value, \n",
    "    # We set X_train from arrays of 60 for each y_train value\n",
    "    # Same idea for test data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(train_data_scaled)):\n",
    "        X_train.append(train_data_scaled[i-60:i])\n",
    "        y_train.append(train_data_scaled[i])\n",
    "\n",
    "    data_total = pd.concat((train.iloc[:,zipcode:zipcode+1], test.iloc[:,zipcode:zipcode+1]),axis=0)\n",
    "    inputs = data_total[len(train)-60:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(60,len(inputs)):\n",
    "        X_test.append(inputs[i-60:i])\n",
    "        y_test.append(inputs[i])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(test_data)\n",
    "\n",
    "    # We need numpy arrays for our model\n",
    "    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # We fit our data to our zipcode specific data\n",
    "    rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, scaler.transform(y_test)))\n",
    "\n",
    "    # Make predictions on the data\n",
    "\n",
    "    y_hat_raw = rnn_model.predict(X_test)\n",
    "    y_hat = scaler.inverse_transform(y_hat_raw)\n",
    "\n",
    "    # Use the score on unseen test data to calculate the MAPE\n",
    "\n",
    "    dict_mape3[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_test)/y_test))      \n",
    "\n",
    "    # We get the last 60 values from our test data which is basically last 60 values in the data set\n",
    "    last_60 = df_time_series.iloc[-60:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # Before we use our data we scale it\n",
    "    last_60 = scaler.transform(last_60)\n",
    "    \n",
    "    # Our input should be in (x,60,1) format\n",
    "    x_new_pred = last_60[-60:].reshape(1,60,1)\n",
    "\n",
    "    # make a prediction, add to the last_60 for the next prediction and \n",
    "    y_pred = rnn_model.predict(x_new_pred)\n",
    "\n",
    "    # We add our predition to our list of predictions for zipcode specific predictions list\n",
    "    dict_pred3[zipcodes[zipcode]]=scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(f'Iteration number {zipcode} finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_keys3 = list(dict_mape3.keys())\n",
    "rnn_mape3 = list(dict_mape3.values())\n",
    "rnn_pred3 = []\n",
    "rnn_dict3 = {}\n",
    "for zipcode in dict_pred.keys():\n",
    "    rnn_pred3.append(dict_pred3[zipcode].astype(int)[0][0])\n",
    "for zc in rnn_keys3:\n",
    "    a = []\n",
    "    a.append(dict_mape3[zc])\n",
    "    a.append(dict_pred3[zc].astype(float)[0][0])\n",
    "    a.append('RNN_w/_D.o.')\n",
    "    rnn_dict3[zc] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.207220495854976"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_mape3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 120376.3125 - val_loss: 106.5844\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 128602.9219 - val_loss: 102.4333\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28528.5820 - val_loss: 95.7532\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 178816.7500 - val_loss: 93.3238\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 140741.4062 - val_loss: 97.4497\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 21366.5996 - val_loss: 99.2259\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 50175.6719 - val_loss: 94.9737\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 146838.5625 - val_loss: 94.1921\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 111833.3828 - val_loss: 95.6333\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 62347.4688 - val_loss: 99.2063\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29855.0859 - val_loss: 98.8211\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9175.8135 - val_loss: 97.5979\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 46176.9180 - val_loss: 96.3742\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41672.7617 - val_loss: 96.9001\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9819.0811 - val_loss: 98.2496\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13994.3467 - val_loss: 99.6007\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47413.5547 - val_loss: 99.7074\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51109.8828 - val_loss: 97.5722\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 76273.4297 - val_loss: 96.7886\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18731.1016 - val_loss: 98.9310\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34518.8477 - val_loss: 98.1781\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26972.6719 - val_loss: 98.2404\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29373.8594 - val_loss: 98.2316\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12794.7988 - val_loss: 97.9945\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11387.5967 - val_loss: 97.0386\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10388.7891 - val_loss: 94.5278\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 135371.6719 - val_loss: 95.7278\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9641.2031 - val_loss: 97.2024\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10648.5234 - val_loss: 98.1952\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23854.1406 - val_loss: 97.0507\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50501.1680 - val_loss: 97.5175\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 56773.4727 - val_loss: 97.2066\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18684.4766 - val_loss: 97.6949\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 41485.7695 - val_loss: 98.5082\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 64474.7422 - val_loss: 100.1858\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38215.1406 - val_loss: 97.6503\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7055.8027 - val_loss: 94.8477\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 90447.1328 - val_loss: 94.9180\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65510.5391 - val_loss: 96.9231\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36907.2539 - val_loss: 97.5477\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32864.1094 - val_loss: 97.5727\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40744.6719 - val_loss: 97.4862\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24762.9629 - val_loss: 98.4905\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 41176.3242 - val_loss: 98.1322\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31189.0293 - val_loss: 98.1061\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3584.4512 - val_loss: 100.0101\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 65780.5547 - val_loss: 101.1662\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51236.6641 - val_loss: 98.6931\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19839.6426 - val_loss: 97.4776\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72911.5234 - val_loss: 99.5910\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39df189d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 0 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 190ms/step - loss: 396031.2500 - val_loss: 97.6208\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 226665.8906 - val_loss: 107.3244\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 297643.5625 - val_loss: 98.2474\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 371360.3438 - val_loss: 95.0830\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 188389.9688 - val_loss: 100.5129\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 72011.1562 - val_loss: 106.5475\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 297637.5938 - val_loss: 104.4390\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 175253.5312 - val_loss: 100.2747\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 128736.5391 - val_loss: 100.8827\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 45103.0508 - val_loss: 101.9733\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 59485.5664 - val_loss: 100.5963\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 73442.6641 - val_loss: 103.1122\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 160463.2656 - val_loss: 101.4470\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 192070.0781 - val_loss: 98.1653\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 140374.7969 - val_loss: 100.4356\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 31928.5430 - val_loss: 103.2205\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 151960.0781 - val_loss: 101.5006\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 23927.5293 - val_loss: 101.3622\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 22876.9316 - val_loss: 101.3856\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 119849.6562 - val_loss: 103.9638\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 122680.4375 - val_loss: 101.5129\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 32463.0586 - val_loss: 100.7893\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 98686.9531 - val_loss: 101.3214\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 54024.7070 - val_loss: 101.9526\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 53322.2500 - val_loss: 102.8917\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 49338.3398 - val_loss: 101.0058\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 96743.2109 - val_loss: 101.3384\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83419.2734 - val_loss: 102.0789\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 103698.1328 - val_loss: 102.3403\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45440.9258 - val_loss: 102.5951\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 126100.5391 - val_loss: 102.7278\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79608.1484 - val_loss: 101.3497\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 82448.2344 - val_loss: 102.0647\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70852.8828 - val_loss: 102.2317\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 128296.9766 - val_loss: 101.1686\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 83379.9141 - val_loss: 104.1609\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 119786.9453 - val_loss: 103.7441\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58392.5977 - val_loss: 101.8766\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 104733.3984 - val_loss: 103.6083\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55601.1328 - val_loss: 104.7418\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 100408.1641 - val_loss: 104.5411\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 75365.9375 - val_loss: 102.9867\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34000.1523 - val_loss: 102.6549\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 140798.9219 - val_loss: 103.4681\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40777.5508 - val_loss: 103.6047\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68761.0234 - val_loss: 101.9424\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 87741.6016 - val_loss: 102.5121\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 168971.0312 - val_loss: 104.2333\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85384.6562 - val_loss: 101.2881\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45592.8945 - val_loss: 101.3164\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff36837eee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 1 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 71.0536 - val_loss: 49.5275\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50.9274 - val_loss: 49.0071\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.1340 - val_loss: 46.9907\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.9943 - val_loss: 32.9581\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.4853 - val_loss: 31.5198\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30.4475 - val_loss: 26.1558\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28.2723 - val_loss: 18.9004\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25.5115 - val_loss: 9.3965\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23.3486 - val_loss: 9.4566\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25.5156 - val_loss: 7.6727\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23.7768 - val_loss: 6.1964\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23.0720 - val_loss: 15.9811\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21.9593 - val_loss: 2.9009\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19.9903 - val_loss: 12.4878\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19.3073 - val_loss: 5.3661\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20.0330 - val_loss: 4.5994\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18.7586 - val_loss: 9.8427\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.3881 - val_loss: 3.4152\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19.0975 - val_loss: 3.1243\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.4591 - val_loss: 9.1167\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18.0053 - val_loss: 3.8526\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.0340 - val_loss: 7.0283\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.1409 - val_loss: 4.3014\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.3101 - val_loss: 4.9394\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.3872 - val_loss: 9.3230\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.5200 - val_loss: 3.6613\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.1471 - val_loss: 5.2240\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.0091 - val_loss: 5.3848\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.4086 - val_loss: 3.5274\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.5104 - val_loss: 7.3693\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.5433 - val_loss: 4.6650\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.3622 - val_loss: 4.0342\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.7821 - val_loss: 6.7968\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.2243 - val_loss: 2.7746\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.0971 - val_loss: 7.1092\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.5906 - val_loss: 1.9444\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.6060 - val_loss: 6.8238\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.5071 - val_loss: 3.2063\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.1588 - val_loss: 4.9424\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.5883 - val_loss: 6.2747\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.8671 - val_loss: 3.2057\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.1924 - val_loss: 2.0217\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.4169 - val_loss: 5.2007\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.1083 - val_loss: 6.3364\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.9631 - val_loss: 4.4044\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9463 - val_loss: 4.9077\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.2383 - val_loss: 4.7214\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.4968 - val_loss: 6.5121\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.4375 - val_loss: 3.7885\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3709 - val_loss: 5.7775\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39450b9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 2 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 86.2702 - val_loss: 59.4408\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.7303 - val_loss: 6.4402\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33.4337 - val_loss: 20.4971\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23.7685 - val_loss: 35.8972\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25.2953 - val_loss: 27.9944\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20.9104 - val_loss: 15.8056\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20.9602 - val_loss: 17.1829\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.0582 - val_loss: 22.4891\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18.6334 - val_loss: 11.9483\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.0916 - val_loss: 15.6622\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.7673 - val_loss: 6.5885\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.4897 - val_loss: 6.3357\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.4917 - val_loss: 2.7322\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.3820 - val_loss: 10.3856\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.8450 - val_loss: 3.1696\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.3844 - val_loss: 9.3027\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.5348 - val_loss: 2.8445\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.9089 - val_loss: 6.7069\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.2374 - val_loss: 2.9877\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.7480 - val_loss: 4.9027\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.7527 - val_loss: 5.8714\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3011 - val_loss: 3.9070\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.2923 - val_loss: 3.2242\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3855 - val_loss: 2.8059\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3984 - val_loss: 2.7447\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6690 - val_loss: 3.0757\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5821 - val_loss: 4.6691\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.7350 - val_loss: 3.1334\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.0089 - val_loss: 3.5431\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.1500 - val_loss: 4.5594\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1594 - val_loss: 3.9674\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.9670 - val_loss: 3.6456\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1165 - val_loss: 2.7368\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6344 - val_loss: 5.1321\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.7092 - val_loss: 2.9247\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1427 - val_loss: 6.6966\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2874 - val_loss: 3.0856\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.0460 - val_loss: 5.5680\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.7948 - val_loss: 3.7992\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.2955 - val_loss: 2.8010\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.9560 - val_loss: 5.1700\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9650 - val_loss: 3.2561\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.0890 - val_loss: 8.5240\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.8467 - val_loss: 3.0327\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.2850 - val_loss: 5.8067\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.3401 - val_loss: 2.8854\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.4203 - val_loss: 4.7951\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.8729 - val_loss: 4.2114\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.9534 - val_loss: 5.1779\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4786 - val_loss: 4.0355\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a58da9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 3 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 167ms/step - loss: 68.3727 - val_loss: 49.4648\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 59.4507 - val_loss: 44.3898\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 45.2841 - val_loss: 56.1035\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38.8692 - val_loss: 33.8083\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35.9570 - val_loss: 17.8872\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 28.2808 - val_loss: 28.0208\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25.5214 - val_loss: 12.2227\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 23.9526 - val_loss: 10.7123\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 22.6787 - val_loss: 5.5544\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.2380 - val_loss: 7.7806\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19.6061 - val_loss: 9.6415\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.0472 - val_loss: 6.1483\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.0701 - val_loss: 5.8439\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.2760 - val_loss: 6.9845\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.1897 - val_loss: 6.9975\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.9846 - val_loss: 7.5737\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.7933 - val_loss: 5.3245\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.7635 - val_loss: 6.8798\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.3270 - val_loss: 5.9257\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.3289 - val_loss: 8.0307\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.4646 - val_loss: 5.1812\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.6373 - val_loss: 6.7274\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.0891 - val_loss: 6.6416\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.8747 - val_loss: 11.4971\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.9733 - val_loss: 5.2959\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.2038 - val_loss: 7.1164\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.9886 - val_loss: 6.6394\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.2764 - val_loss: 9.1275\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.5825 - val_loss: 3.8807\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.6790 - val_loss: 7.6043\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.2616 - val_loss: 6.8111\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.9081 - val_loss: 4.6241\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.9257 - val_loss: 5.8018\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.4038 - val_loss: 5.4118\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.3954 - val_loss: 7.8752\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.8701 - val_loss: 6.3593\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.8607 - val_loss: 4.0777\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.9115 - val_loss: 7.7613\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.8070 - val_loss: 4.2725\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.3113 - val_loss: 5.6872\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.9292 - val_loss: 6.1885\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.8038 - val_loss: 5.6108\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.9209 - val_loss: 6.0144\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.8491 - val_loss: 6.0675\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.4398 - val_loss: 8.0779\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.8975 - val_loss: 5.4656\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.3715 - val_loss: 5.0888\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.5298 - val_loss: 4.2094\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.0920 - val_loss: 7.7833\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.9573 - val_loss: 4.0235\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff388923940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 4 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 195595.3438 - val_loss: 83.3267\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 90175.9453 - val_loss: 99.8648\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 196148.2188 - val_loss: 102.8688\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 140991.9375 - val_loss: 100.4246\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 97844.6484 - val_loss: 95.4840\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44699.3555 - val_loss: 93.1484\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 58984.8750 - val_loss: 95.9241\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33231.3242 - val_loss: 96.1607\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21809.8008 - val_loss: 94.3247\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18092.8066 - val_loss: 94.0400\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2234.1086 - val_loss: 94.6685\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 33181.2734 - val_loss: 97.5457\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 110743.6016 - val_loss: 97.8230\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84903.6406 - val_loss: 96.0804\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14348.1201 - val_loss: 95.5206\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82138.2891 - val_loss: 97.1061\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72712.9688 - val_loss: 95.5825\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15836.1367 - val_loss: 93.6954\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26680.0020 - val_loss: 92.7909\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 53298.8086 - val_loss: 94.5718\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19840.3828 - val_loss: 96.9366\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 95940.1406 - val_loss: 98.4257\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 81007.5781 - val_loss: 96.9508\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9241.4814 - val_loss: 96.1205\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 405.6774 - val_loss: 96.0427\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48789.2695 - val_loss: 95.1381\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12969.3193 - val_loss: 96.3419\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15328.1953 - val_loss: 97.0272\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21112.5293 - val_loss: 95.7869\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3577.7061 - val_loss: 95.7315\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8472.6328 - val_loss: 96.8455\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18609.3457 - val_loss: 96.2930\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24710.8184 - val_loss: 97.9422\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32760.5098 - val_loss: 97.4765\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21665.9355 - val_loss: 94.8370\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42456.5938 - val_loss: 95.1889\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26741.7402 - val_loss: 97.2360\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25286.2246 - val_loss: 96.9308\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38416.5508 - val_loss: 97.5340\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19205.8965 - val_loss: 96.8216\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3881.2451 - val_loss: 97.0624\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39314.1523 - val_loss: 97.5500\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 29336.3164 - val_loss: 97.2492\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 35317.5586 - val_loss: 96.4709\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9562.9365 - val_loss: 94.9144\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 84332.5000 - val_loss: 94.3276\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 80898.2969 - val_loss: 96.3798\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6000.1089 - val_loss: 98.4882\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 51416.0781 - val_loss: 99.5315\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 55951.4023 - val_loss: 98.0420\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a20605e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 5 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 82962.8281 - val_loss: 93.4681\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 288535.3750 - val_loss: 93.4843\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 249705.6094 - val_loss: 97.5134\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 53270.1719 - val_loss: 108.4098\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45110.0508 - val_loss: 110.6257\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 59024.0742 - val_loss: 109.5665\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 49545.2773 - val_loss: 103.7517\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 71111.0859 - val_loss: 102.3545\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24266.8633 - val_loss: 104.2752\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19289.6895 - val_loss: 103.8194\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 39471.9258 - val_loss: 103.3346\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33679.8945 - val_loss: 107.8839\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 186862.9531 - val_loss: 110.1543\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 145374.1250 - val_loss: 106.5028\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21475.8965 - val_loss: 103.0607\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23693.4707 - val_loss: 98.1039\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 156132.8906 - val_loss: 96.8273\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 193912.5469 - val_loss: 99.4913\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 121648.3281 - val_loss: 102.8275\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 41196.6250 - val_loss: 106.6694\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27721.1641 - val_loss: 107.0902\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 79140.4375 - val_loss: 106.0133\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58070.1992 - val_loss: 104.1210\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26201.1172 - val_loss: 102.7319\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35554.4922 - val_loss: 103.6890\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31959.6016 - val_loss: 103.7292\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 23245.0996 - val_loss: 102.5289\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 44853.8633 - val_loss: 104.6175\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 34735.6484 - val_loss: 104.9322\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25936.9746 - val_loss: 103.3197\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 5479.7017 - val_loss: 100.1966\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 174878.7969 - val_loss: 98.6207\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 126982.1016 - val_loss: 100.7843\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 83088.7422 - val_loss: 103.0460\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 2198.6125 - val_loss: 103.3944\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23521.7285 - val_loss: 102.7279\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2809.6016 - val_loss: 101.3081\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26794.5938 - val_loss: 100.4761\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 80683.8203 - val_loss: 100.6133\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47689.4805 - val_loss: 102.0410\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 56913.0312 - val_loss: 103.1310\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6115.3418 - val_loss: 101.0069\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 70569.2812 - val_loss: 100.6349\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 60408.8008 - val_loss: 101.5387\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8366.8975 - val_loss: 102.9547\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29921.1934 - val_loss: 104.1715\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 84139.1250 - val_loss: 103.3720\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4676.4761 - val_loss: 102.3300\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8174.2617 - val_loss: 101.6551\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 27183.9785 - val_loss: 102.4526\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff36e32de50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 6 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 173ms/step - loss: 86.2217 - val_loss: 66.1637\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 58.6620 - val_loss: 46.8092\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48.5588 - val_loss: 47.8702\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39.0254 - val_loss: 31.8754\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 32.2464 - val_loss: 23.3010\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 29.9365 - val_loss: 13.7827\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27.1325 - val_loss: 13.9519\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.8823 - val_loss: 7.1343\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25.1977 - val_loss: 7.2040\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20.8705 - val_loss: 7.6602\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21.2831 - val_loss: 4.4915\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.7234 - val_loss: 13.2713\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 19.4296 - val_loss: 3.9997\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20.2070 - val_loss: 7.0284\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.4320 - val_loss: 6.5232\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.2406 - val_loss: 4.9048\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.6070 - val_loss: 6.1887\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.4143 - val_loss: 6.6767\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.8176 - val_loss: 3.6905\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.2818 - val_loss: 10.6457\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.5161 - val_loss: 5.2156\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.8469 - val_loss: 6.0131\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.2443 - val_loss: 4.5018\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.5260 - val_loss: 4.8255\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.0177 - val_loss: 3.9273\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.7185 - val_loss: 5.4428\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.9203 - val_loss: 13.1315\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.3502 - val_loss: 2.5099\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.0199 - val_loss: 6.9850\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.4766 - val_loss: 4.6940\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.2568 - val_loss: 3.8829\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.6014 - val_loss: 6.6097\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.0006 - val_loss: 2.8383\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.6719 - val_loss: 3.6569\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.4235 - val_loss: 6.8188\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.7368 - val_loss: 3.7914\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.1287 - val_loss: 5.0215\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.2549 - val_loss: 4.1476\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.0582 - val_loss: 2.7640\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.7150 - val_loss: 6.6724\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.1440 - val_loss: 3.3337\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.3848 - val_loss: 1.8918\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.1120 - val_loss: 7.3517\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.9592 - val_loss: 1.9138\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.2794 - val_loss: 9.0813\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.4929 - val_loss: 1.6982\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.5890 - val_loss: 12.1818\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.2503 - val_loss: 3.0039\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.8701 - val_loss: 5.4702\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.8542 - val_loss: 2.7034\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff35b8b73a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 7 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 210739.1875 - val_loss: 81.3218\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12622.6211 - val_loss: 101.6729\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 381581.4688 - val_loss: 110.3346\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 271839.7500 - val_loss: 104.4205\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 156511.3750 - val_loss: 98.5415\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21254.6641 - val_loss: 92.5878\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 95110.3750 - val_loss: 92.5887\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 109461.5859 - val_loss: 94.2280\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 51884.4922 - val_loss: 98.9127\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 72779.1406 - val_loss: 101.2558\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 54645.7969 - val_loss: 99.4543\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 17208.3281 - val_loss: 94.4335\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 55769.8438 - val_loss: 93.6833\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 108513.2031 - val_loss: 95.7893\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24370.3477 - val_loss: 99.2175\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 74160.0469 - val_loss: 99.5515\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16546.6797 - val_loss: 98.6971\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29791.2012 - val_loss: 95.1099\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 116997.7344 - val_loss: 94.1974\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 87187.0469 - val_loss: 97.4761\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30727.2793 - val_loss: 101.0214\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 89217.0234 - val_loss: 102.5138\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 56750.0078 - val_loss: 99.3826\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 77910.2266 - val_loss: 94.6815\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 131359.8438 - val_loss: 93.1926\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 147487.7969 - val_loss: 96.0332\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 54582.2344 - val_loss: 99.5679\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42805.5430 - val_loss: 100.2169\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7262.7749 - val_loss: 99.1495\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21086.8184 - val_loss: 96.8380\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 84121.3828 - val_loss: 96.6304\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 73736.5000 - val_loss: 98.8879\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1854.8695 - val_loss: 98.9597\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11591.2559 - val_loss: 101.0968\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38597.7617 - val_loss: 100.8545\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 25745.1270 - val_loss: 98.5403\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 35533.9766 - val_loss: 98.6143\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 70802.7422 - val_loss: 99.8767\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 59194.4023 - val_loss: 102.0548\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 54619.2773 - val_loss: 99.4683\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9594.0361 - val_loss: 98.9142\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 48220.3945 - val_loss: 99.9292\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36312.7617 - val_loss: 100.5103\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12246.6484 - val_loss: 98.7050\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19461.9297 - val_loss: 97.4853\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47008.2305 - val_loss: 97.5155\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24514.2988 - val_loss: 100.2171\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15729.5234 - val_loss: 104.9352\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 63390.8242 - val_loss: 105.9098\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 145148.9531 - val_loss: 103.5947\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a8aaa3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 8 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 203ms/step - loss: 74.7473 - val_loss: 57.4222\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 61.4035 - val_loss: 55.3757\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52.6735 - val_loss: 56.7839\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 43.7106 - val_loss: 31.4688\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39.8099 - val_loss: 29.9641\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31.2224 - val_loss: 23.5314\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 27.0446 - val_loss: 11.6866\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28.0172 - val_loss: 10.5615\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 25.1295 - val_loss: 7.4633\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24.1393 - val_loss: 7.2937\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24.7816 - val_loss: 7.1398\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22.9406 - val_loss: 5.7401\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23.2301 - val_loss: 6.2334\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 20.2699 - val_loss: 8.1415\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 21.6828 - val_loss: 5.6726\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20.9472 - val_loss: 6.5857\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20.1097 - val_loss: 6.1454\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.6546 - val_loss: 5.8106\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.9884 - val_loss: 7.0448\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 18.7206 - val_loss: 7.0022\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17.7706 - val_loss: 6.8035\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.2086 - val_loss: 5.4900\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 20.4938 - val_loss: 5.0892\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 17.2924 - val_loss: 7.8995\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.0577 - val_loss: 6.1212\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.8051 - val_loss: 7.5401\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 17.6657 - val_loss: 4.8995\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.6981 - val_loss: 7.6007\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.7126 - val_loss: 5.2852\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.5622 - val_loss: 4.4840\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 15.5653 - val_loss: 7.3327\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.3714 - val_loss: 5.6709\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.6439 - val_loss: 4.8982\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.7741 - val_loss: 4.6820\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.8392 - val_loss: 5.7062\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.5710 - val_loss: 4.4921\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.0055 - val_loss: 4.1630\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.5014 - val_loss: 6.0219\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.1000 - val_loss: 3.7469\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.6802 - val_loss: 8.5756\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.6199 - val_loss: 5.6647\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.5311 - val_loss: 3.7342\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.0614 - val_loss: 3.5443\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.6309 - val_loss: 6.2026\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.7236 - val_loss: 6.1607\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.1172 - val_loss: 7.1079\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.9463 - val_loss: 2.8442\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.9527 - val_loss: 3.7189\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.8582 - val_loss: 3.6679\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.5425 - val_loss: 4.0388\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff368126f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 9 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 40338.1211 - val_loss: 116.0638\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 127917.3516 - val_loss: 120.3921\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 202576.2969 - val_loss: 106.4056\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 61807.4805 - val_loss: 102.4921\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 109138.9375 - val_loss: 105.5297\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 2626.4734 - val_loss: 107.5572\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21332.5996 - val_loss: 105.3651\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13287.9580 - val_loss: 105.3905\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 112565.5391 - val_loss: 106.0717\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 40970.6875 - val_loss: 105.1379\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36683.2539 - val_loss: 105.7313\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 46564.7734 - val_loss: 106.7077\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12924.8115 - val_loss: 103.2384\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 112541.7500 - val_loss: 102.3647\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 43937.8398 - val_loss: 105.6556\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 101385.6406 - val_loss: 106.0981\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9778.9150 - val_loss: 102.5739\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16701.6699 - val_loss: 102.7365\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 68931.1562 - val_loss: 105.8485\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 69468.0547 - val_loss: 106.3512\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22821.7715 - val_loss: 103.0573\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 34770.4883 - val_loss: 98.8611\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 214666.7031 - val_loss: 97.8676\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 196551.9844 - val_loss: 101.1873\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 89349.4297 - val_loss: 104.4904\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21449.3809 - val_loss: 105.6929\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29387.8691 - val_loss: 103.0238\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10681.5371 - val_loss: 103.1924\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3101.1492 - val_loss: 104.9653\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 45641.2383 - val_loss: 104.3913\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 52330.1562 - val_loss: 101.3601\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 58246.8672 - val_loss: 100.4744\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 125871.5547 - val_loss: 101.7268\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 45070.6914 - val_loss: 102.5133\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 44367.2617 - val_loss: 102.6848\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7051.2705 - val_loss: 105.2279\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 145306.7969 - val_loss: 105.4215\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 74986.2422 - val_loss: 103.5055\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 24354.5879 - val_loss: 102.6893\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9935.9795 - val_loss: 104.8654\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 34985.1328 - val_loss: 105.3052\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 93814.0234 - val_loss: 103.5009\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10188.5176 - val_loss: 103.1509\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 38237.7344 - val_loss: 102.7499\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 48376.7656 - val_loss: 100.4225\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 50540.8281 - val_loss: 99.6466\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 80944.9766 - val_loss: 102.0266\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 41283.5234 - val_loss: 104.7293\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 72548.8125 - val_loss: 105.7618\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 75246.5625 - val_loss: 104.3951\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38527e310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 10 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 77887.2812 - val_loss: 103.9287\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 580166.0000 - val_loss: 102.2854\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 316482.7812 - val_loss: 93.8934\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 171318.2812 - val_loss: 86.1861\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 186776.8750 - val_loss: 88.1051\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 179794.2969 - val_loss: 96.5234\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 230574.4688 - val_loss: 99.7479\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 164281.6094 - val_loss: 96.6767\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 110480.3672 - val_loss: 91.7482\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 54991.7773 - val_loss: 91.6747\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 78555.3047 - val_loss: 95.9213\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 153930.0781 - val_loss: 96.7217\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 117141.7344 - val_loss: 94.5440\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 76091.3516 - val_loss: 93.0896\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 103765.5234 - val_loss: 94.3232\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 55079.3008 - val_loss: 96.2461\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 44877.7227 - val_loss: 95.0311\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 56174.6367 - val_loss: 91.2916\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 251883.9531 - val_loss: 91.4830\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 214013.7969 - val_loss: 92.7064\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 108661.8516 - val_loss: 96.0145\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 38934.6094 - val_loss: 96.6134\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45708.3477 - val_loss: 95.5460\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23276.6602 - val_loss: 94.9961\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 55530.3008 - val_loss: 95.8920\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 57049.1445 - val_loss: 96.1039\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21716.6738 - val_loss: 96.3188\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46427.6172 - val_loss: 95.7825\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 29213.1289 - val_loss: 95.0941\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 56923.7773 - val_loss: 95.2948\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19118.4629 - val_loss: 97.4455\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 99516.6641 - val_loss: 97.6628\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 78625.8516 - val_loss: 95.6137\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 54536.3633 - val_loss: 95.2589\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 46756.7578 - val_loss: 97.4473\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 107086.3984 - val_loss: 98.0780\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 97847.6484 - val_loss: 96.1395\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26704.9355 - val_loss: 94.4264\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 91849.6797 - val_loss: 94.4523\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 76036.8594 - val_loss: 96.1100\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47464.6641 - val_loss: 96.4285\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16949.2148 - val_loss: 96.0641\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 24461.6875 - val_loss: 95.4381\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 42505.2461 - val_loss: 96.8428\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 65067.2969 - val_loss: 97.4730\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8760.4551 - val_loss: 97.2443\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 59383.7422 - val_loss: 94.6073\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 106846.7656 - val_loss: 95.2127\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 32216.6406 - val_loss: 96.6776\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 54996.3555 - val_loss: 96.1712\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3aa69caf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 11 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 182308.3125 - val_loss: 94.1604\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 251510.1562 - val_loss: 101.8160\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 122658.9219 - val_loss: 95.9071\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 106514.6562 - val_loss: 98.2274\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18966.9746 - val_loss: 97.3162\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 39694.6836 - val_loss: 98.0349\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 45436.8789 - val_loss: 98.9064\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 59623.6523 - val_loss: 98.7949\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 36717.0625 - val_loss: 100.1819\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 38558.5977 - val_loss: 97.3128\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 102360.7031 - val_loss: 96.4131\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 79164.1562 - val_loss: 97.9034\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 65380.3086 - val_loss: 96.7931\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 33499.5234 - val_loss: 95.9454\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18857.8926 - val_loss: 97.5175\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 65073.8008 - val_loss: 98.5089\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 155669.5469 - val_loss: 96.7808\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32414.2871 - val_loss: 97.4016\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 38338.9766 - val_loss: 97.9113\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 49716.6523 - val_loss: 95.8916\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51341.8828 - val_loss: 96.6810\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35241.0938 - val_loss: 98.1156\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 69744.8359 - val_loss: 96.6106\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 61426.1445 - val_loss: 96.7517\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 90531.8438 - val_loss: 99.2378\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23263.4707 - val_loss: 97.2597\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 75999.2734 - val_loss: 95.2556\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 185499.4219 - val_loss: 96.3335\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 66919.2500 - val_loss: 99.2649\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 27806.9746 - val_loss: 99.9450\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 81358.9766 - val_loss: 97.6041\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 111815.8672 - val_loss: 97.5174\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5799.7803 - val_loss: 99.3425\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20449.3789 - val_loss: 101.8609\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 156168.7031 - val_loss: 101.9561\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 119576.4453 - val_loss: 99.5844\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 60593.2773 - val_loss: 97.3361\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 153117.2500 - val_loss: 98.6052\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 88353.5625 - val_loss: 101.1688\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19685.6719 - val_loss: 99.5576\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 36916.9062 - val_loss: 100.4850\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 23045.3066 - val_loss: 101.0705\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 76751.3203 - val_loss: 100.7560\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 79384.8594 - val_loss: 99.3866\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4988.2671 - val_loss: 101.4707\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 105836.5312 - val_loss: 102.4692\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 92709.8672 - val_loss: 101.4665\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20843.8066 - val_loss: 99.0769\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 101781.9766 - val_loss: 98.3275\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 160191.7344 - val_loss: 99.1879\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37a03b280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 12 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 163ms/step - loss: 468150.2188 - val_loss: 122.1572\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 551042.1250 - val_loss: 107.9876\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 152799.4844 - val_loss: 96.5687\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 157653.1250 - val_loss: 99.4738\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 47688.9688 - val_loss: 101.0012\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 92823.8984 - val_loss: 99.8612\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 77302.3906 - val_loss: 100.7646\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10411.3584 - val_loss: 98.5268\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 65247.2109 - val_loss: 99.8392\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 52092.5781 - val_loss: 101.6902\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 38460.9453 - val_loss: 98.8593\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 143390.3594 - val_loss: 98.5201\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15319.5703 - val_loss: 103.5079\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 156156.4531 - val_loss: 105.1890\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 158374.9531 - val_loss: 101.7023\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 58537.9023 - val_loss: 100.9363\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17264.4609 - val_loss: 102.2819\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 37759.9883 - val_loss: 102.1497\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 69051.6016 - val_loss: 99.6000\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 171002.7031 - val_loss: 99.9957\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 58352.5000 - val_loss: 102.9601\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26077.1758 - val_loss: 103.2867\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16391.4941 - val_loss: 102.2967\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 38248.4141 - val_loss: 103.3614\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56031.5000 - val_loss: 103.7875\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 39404.7852 - val_loss: 100.9543\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 89245.9141 - val_loss: 100.8050\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45507.4648 - val_loss: 102.8557\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 50541.6367 - val_loss: 102.5275\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25142.3281 - val_loss: 101.6311\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 51767.1133 - val_loss: 101.5265\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47875.5078 - val_loss: 101.7090\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20982.1035 - val_loss: 101.1655\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 66834.2969 - val_loss: 101.0021\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 38323.2930 - val_loss: 100.2247\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25564.7461 - val_loss: 98.5544\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 119948.5156 - val_loss: 97.9618\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 110673.7344 - val_loss: 101.7554\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 159438.4219 - val_loss: 102.6937\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 57801.7500 - val_loss: 101.1012\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36962.9492 - val_loss: 98.6338\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 47202.9961 - val_loss: 99.4695\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28922.8184 - val_loss: 101.3416\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 124230.1562 - val_loss: 101.8812\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 85397.1562 - val_loss: 99.2141\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 48643.9805 - val_loss: 98.9295\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38195.5664 - val_loss: 101.4705\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 114507.0234 - val_loss: 104.1218\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 162381.2812 - val_loss: 103.7922\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 154600.8906 - val_loss: 101.1842\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff367d409d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 13 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 152ms/step - loss: 748.3137 - val_loss: 62.6490\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 412568.1875 - val_loss: 69.5497\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 156816.6719 - val_loss: 76.7923\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 133748.6875 - val_loss: 87.9251\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 160147.7344 - val_loss: 93.1350\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 80007.1953 - val_loss: 89.3193\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 34950.5781 - val_loss: 88.5869\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4238.4551 - val_loss: 87.2185\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 35547.0430 - val_loss: 88.2048\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20204.7070 - val_loss: 91.0454\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 38576.1250 - val_loss: 92.7936\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 64092.6836 - val_loss: 90.8525\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 35593.1367 - val_loss: 87.9979\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 61780.7109 - val_loss: 86.5497\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 93224.9062 - val_loss: 87.5784\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55891.6914 - val_loss: 91.1098\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 51483.7852 - val_loss: 91.6822\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41797.0938 - val_loss: 90.9671\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3092.4600 - val_loss: 90.3643\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20469.9102 - val_loss: 93.2088\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 79534.3125 - val_loss: 94.1465\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 58051.8672 - val_loss: 90.9842\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48942.4688 - val_loss: 91.7401\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 42534.8867 - val_loss: 90.8913\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 2736.5015 - val_loss: 91.4711\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5916.6885 - val_loss: 90.4663\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32836.7812 - val_loss: 92.3158\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37358.3125 - val_loss: 95.4311\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 75360.1562 - val_loss: 96.0164\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 59430.7969 - val_loss: 92.5725\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 59109.9023 - val_loss: 91.5691\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10539.0215 - val_loss: 93.5771\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6723.0356 - val_loss: 93.4062\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8911.3564 - val_loss: 92.3294\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26275.7812 - val_loss: 92.3594\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 39823.7461 - val_loss: 91.8059\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12709.0518 - val_loss: 91.6982\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 4005.3770 - val_loss: 91.5954\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1828.4667 - val_loss: 88.0748\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 130373.7734 - val_loss: 87.7335\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 164155.2031 - val_loss: 89.3253\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45112.9062 - val_loss: 92.9770\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19989.0605 - val_loss: 96.9245\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 104183.3359 - val_loss: 97.7864\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 93516.4219 - val_loss: 96.4566\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 50135.8906 - val_loss: 95.0749\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14071.3564 - val_loss: 91.0707\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 54926.9883 - val_loss: 90.4110\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 57034.5664 - val_loss: 91.6185\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10622.3672 - val_loss: 94.4245\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff35a776a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 14 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 207224.9375 - val_loss: 95.4314\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11661.3828 - val_loss: 102.7363\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8898.8740 - val_loss: 97.7051\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 159985.2812 - val_loss: 94.1354\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 143674.1250 - val_loss: 97.6705\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 69642.9844 - val_loss: 100.9405\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 42109.6133 - val_loss: 101.2101\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37002.6133 - val_loss: 98.8022\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 22966.3027 - val_loss: 98.8612\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4314.0503 - val_loss: 101.0781\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35036.9766 - val_loss: 101.8121\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15024.0332 - val_loss: 100.5847\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17615.0684 - val_loss: 99.3896\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13569.5391 - val_loss: 99.6335\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 6617.1431 - val_loss: 96.3775\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 136995.8906 - val_loss: 97.0779\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 50941.3750 - val_loss: 98.5826\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14026.6152 - val_loss: 98.4309\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25489.4004 - val_loss: 99.2887\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16350.8779 - val_loss: 99.3127\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1490.4811 - val_loss: 98.1123\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 91184.1484 - val_loss: 97.0524\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 124761.4375 - val_loss: 100.2997\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32698.7598 - val_loss: 99.9530\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17011.7891 - val_loss: 98.1759\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 110626.5625 - val_loss: 96.5924\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 96284.4453 - val_loss: 100.2806\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 55356.6562 - val_loss: 100.9945\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 39941.4648 - val_loss: 99.2067\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20765.2793 - val_loss: 98.8912\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4080.0461 - val_loss: 100.2283\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23332.7559 - val_loss: 101.7344\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 40726.9062 - val_loss: 100.6288\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 29875.6348 - val_loss: 98.2670\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 120294.3516 - val_loss: 97.8034\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 79777.4297 - val_loss: 99.5226\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3765.7307 - val_loss: 99.7202\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72486.3828 - val_loss: 99.4298\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13087.9570 - val_loss: 99.0158\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 26992.7695 - val_loss: 96.8085\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 131295.5156 - val_loss: 96.0594\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 116391.5625 - val_loss: 97.8723\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19301.7754 - val_loss: 99.6297\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44876.9062 - val_loss: 100.0486\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 54384.9219 - val_loss: 99.3972\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 4043.6345 - val_loss: 99.0568\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28646.5293 - val_loss: 100.2728\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31034.9941 - val_loss: 100.4908\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68387.0312 - val_loss: 99.2475\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4980.2603 - val_loss: 97.4015\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff362732160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 15 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 220104.2188 - val_loss: 95.9950\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 224029.9531 - val_loss: 99.8667\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 284737.6875 - val_loss: 94.7138\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 59611.6445 - val_loss: 94.9312\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40800.3203 - val_loss: 99.0578\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 171819.2344 - val_loss: 100.2210\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 146468.2500 - val_loss: 97.7476\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11516.3750 - val_loss: 97.1231\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43216.5312 - val_loss: 97.3070\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19428.6855 - val_loss: 97.2693\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21343.8496 - val_loss: 95.8616\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 53349.9805 - val_loss: 96.5844\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 39471.8164 - val_loss: 97.0846\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 46389.9297 - val_loss: 93.1899\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 293772.9688 - val_loss: 92.7461\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 129854.7500 - val_loss: 96.3794\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 27261.9844 - val_loss: 101.7423\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 197242.8281 - val_loss: 102.6552\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 192519.6875 - val_loss: 100.5971\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46927.0859 - val_loss: 97.7450\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18481.8340 - val_loss: 98.8960\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 82902.4453 - val_loss: 98.8217\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 60127.3945 - val_loss: 98.1247\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 48356.4688 - val_loss: 96.5724\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 79230.7891 - val_loss: 95.7780\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 80618.1953 - val_loss: 97.6174\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 67530.0781 - val_loss: 100.9037\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 160199.5312 - val_loss: 100.3165\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 111862.8047 - val_loss: 98.3036\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 78021.1016 - val_loss: 98.2907\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72314.6328 - val_loss: 97.6176\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 53290.1602 - val_loss: 98.2107\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34046.7305 - val_loss: 99.0304\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 72546.7266 - val_loss: 100.0184\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55162.9883 - val_loss: 99.5093\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20642.6191 - val_loss: 98.9027\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28825.8652 - val_loss: 99.4292\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38685.9062 - val_loss: 98.7622\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14245.0332 - val_loss: 99.2654\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 28099.7637 - val_loss: 100.8851\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 134292.8750 - val_loss: 100.8301\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 47117.3359 - val_loss: 99.4688\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3277.6399 - val_loss: 100.3187\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 58046.5977 - val_loss: 101.3314\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 94730.3359 - val_loss: 100.3660\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36575.2344 - val_loss: 99.1404\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47783.3242 - val_loss: 99.7587\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21797.9219 - val_loss: 101.9252\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 115698.5234 - val_loss: 102.1441\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 144063.3125 - val_loss: 100.6118\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4155181f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 16 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 65.9525 - val_loss: 42.7921\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 52.3489 - val_loss: 36.4743\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 38.2041 - val_loss: 42.9240\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33.0639 - val_loss: 29.3603\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27.5693 - val_loss: 18.4686\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24.7995 - val_loss: 19.3728\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 20.7851 - val_loss: 4.8213\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 23.1084 - val_loss: 14.0269\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18.9992 - val_loss: 11.3590\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.8902 - val_loss: 9.6395\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19.8368 - val_loss: 11.0169\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17.6069 - val_loss: 2.3255\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.8891 - val_loss: 7.2349\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.0545 - val_loss: 3.2873\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.9592 - val_loss: 6.8077\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.1039 - val_loss: 3.2108\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.3144 - val_loss: 3.5836\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.7383 - val_loss: 3.3214\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.6076 - val_loss: 6.2919\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.5256 - val_loss: 2.6636\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.1282 - val_loss: 2.6406\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.8838 - val_loss: 3.7204\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.8115 - val_loss: 3.2121\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.8296 - val_loss: 4.5503\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.4714 - val_loss: 3.8620\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.9921 - val_loss: 2.9684\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.4745 - val_loss: 5.1031\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.1389 - val_loss: 3.1191\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.4001 - val_loss: 4.9690\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.2569 - val_loss: 2.7343\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.4283 - val_loss: 4.8224\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.4304 - val_loss: 4.6762\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.3740 - val_loss: 5.1897\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.1210 - val_loss: 2.2688\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.6462 - val_loss: 8.3279\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.0203 - val_loss: 5.8581\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.8504 - val_loss: 4.9973\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.4453 - val_loss: 5.8594\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.4322 - val_loss: 3.5638\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3089 - val_loss: 5.6869\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.8049 - val_loss: 4.1930\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.7978 - val_loss: 4.4498\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.8701 - val_loss: 5.3987\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.5376 - val_loss: 2.7863\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.0177 - val_loss: 10.3246\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.9349 - val_loss: 2.2372\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.1364 - val_loss: 6.9030\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0839 - val_loss: 3.8153\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3015 - val_loss: 7.1251\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1253 - val_loss: 2.3867\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff414c889d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 17 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 151ms/step - loss: 78.1846 - val_loss: 53.4134\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33.0243 - val_loss: 16.1419\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31.4999 - val_loss: 36.4665\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23.2107 - val_loss: 37.9396\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22.4684 - val_loss: 22.7382\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.2688 - val_loss: 20.9743\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.5461 - val_loss: 24.2916\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.4844 - val_loss: 13.1035\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.7054 - val_loss: 12.6920\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.8619 - val_loss: 5.1324\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.9112 - val_loss: 5.3812\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.4382 - val_loss: 2.7322\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.0327 - val_loss: 8.4893\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.4697 - val_loss: 5.6282\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.0215 - val_loss: 7.0552\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.5264 - val_loss: 2.9502\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.9048 - val_loss: 2.2707\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.2549 - val_loss: 3.5517\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.0188 - val_loss: 3.0993\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.7154 - val_loss: 2.4125\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.8322 - val_loss: 6.7064\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.9602 - val_loss: 3.0626\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0169 - val_loss: 6.0172\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.7993 - val_loss: 2.7377\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.2799 - val_loss: 3.8321\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.5645 - val_loss: 5.8144\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6594 - val_loss: 3.1470\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.3996 - val_loss: 3.2681\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.6619 - val_loss: 2.7295\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.3442 - val_loss: 3.5864\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.7581 - val_loss: 4.1173\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7769 - val_loss: 2.8652\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.6027 - val_loss: 2.9179\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3189 - val_loss: 2.6238\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9894 - val_loss: 7.4607\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.2622 - val_loss: 2.6653\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.0618 - val_loss: 2.3067\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4331 - val_loss: 2.5386\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.4932 - val_loss: 4.0218\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.2144 - val_loss: 2.9339\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1801 - val_loss: 5.5237\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6976 - val_loss: 2.7770\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.0089 - val_loss: 4.7023\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 8.0761 - val_loss: 2.8651\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.7691 - val_loss: 4.2347\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.2565 - val_loss: 2.8109\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.6190 - val_loss: 2.8244\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.6477 - val_loss: 2.4229\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.5647 - val_loss: 3.5244\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.1828 - val_loss: 5.6032\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3974a1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 18 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 34605.7461 - val_loss: 80.7629\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 497527.0625 - val_loss: 83.9589\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 390130.1250 - val_loss: 93.7627\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86464.4766 - val_loss: 100.6476\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31640.2832 - val_loss: 101.8713\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25627.1387 - val_loss: 99.3270\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 39804.7188 - val_loss: 101.1333\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6930.0337 - val_loss: 99.8610\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 76886.1172 - val_loss: 99.3125\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 47556.8242 - val_loss: 103.3376\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45138.2617 - val_loss: 102.7307\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 22874.7910 - val_loss: 101.3794\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 61307.0664 - val_loss: 99.5967\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 52933.2031 - val_loss: 101.4842\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 3240.6194 - val_loss: 105.1620\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 117892.1562 - val_loss: 105.3751\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 95589.2109 - val_loss: 103.0705\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 44890.3164 - val_loss: 98.8613\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 118738.4453 - val_loss: 98.1640\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 83803.4062 - val_loss: 100.0021\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 64557.2500 - val_loss: 104.3376\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 156949.4688 - val_loss: 105.9051\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 96606.9141 - val_loss: 103.4039\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24981.3496 - val_loss: 100.8111\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 94445.7812 - val_loss: 99.2658\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 111078.8984 - val_loss: 101.0232\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 94485.9766 - val_loss: 103.0345\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 60759.9414 - val_loss: 102.7016\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 57646.0391 - val_loss: 100.7873\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 22697.7168 - val_loss: 100.2273\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 261.0143 - val_loss: 101.6591\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 56569.2383 - val_loss: 102.7973\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 73868.3906 - val_loss: 102.3126\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5770.9673 - val_loss: 101.6754\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35447.5938 - val_loss: 102.3536\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 65598.7656 - val_loss: 101.0077\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 102845.6797 - val_loss: 100.0919\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 63038.7031 - val_loss: 100.9716\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 62195.5781 - val_loss: 102.2998\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 53822.6328 - val_loss: 101.0630\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21729.5352 - val_loss: 100.9392\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18525.9219 - val_loss: 100.5223\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 37737.8750 - val_loss: 99.6220\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 39844.8008 - val_loss: 100.3852\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33404.2070 - val_loss: 100.6343\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5001.6411 - val_loss: 99.9168\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 53014.3203 - val_loss: 99.6259\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 45391.8633 - val_loss: 100.3487\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 38326.4180 - val_loss: 101.9715\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 119785.8281 - val_loss: 102.6684\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a258f310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 19 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 322927.7812 - val_loss: 88.3698\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 84031.5078 - val_loss: 108.6248\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 287163.6562 - val_loss: 109.4888\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 237488.5469 - val_loss: 104.4976\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 118936.9375 - val_loss: 97.7112\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 44209.0586 - val_loss: 95.5380\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 47864.5859 - val_loss: 98.9224\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 87142.6641 - val_loss: 99.7330\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 60064.5938 - val_loss: 97.2368\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10966.1738 - val_loss: 92.4597\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 206862.4688 - val_loss: 91.4015\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 178150.1250 - val_loss: 95.8727\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15320.4141 - val_loss: 98.8174\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20807.5977 - val_loss: 99.9288\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32639.2832 - val_loss: 99.3584\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4217.1313 - val_loss: 96.4008\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50897.7383 - val_loss: 96.2147\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 47595.1250 - val_loss: 98.5872\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 43041.5312 - val_loss: 98.2556\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25089.7227 - val_loss: 100.0636\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 104678.9766 - val_loss: 99.1587\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 26095.1562 - val_loss: 99.7666\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 50853.3242 - val_loss: 98.5383\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 26634.7949 - val_loss: 98.4600\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14461.0742 - val_loss: 98.6280\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 33737.2344 - val_loss: 98.2089\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17010.9609 - val_loss: 100.1015\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 50407.7656 - val_loss: 100.9715\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 82762.7734 - val_loss: 100.8344\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 42691.5117 - val_loss: 97.9875\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 75062.0469 - val_loss: 96.4393\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 63324.9492 - val_loss: 98.8397\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28284.7598 - val_loss: 98.9150\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15697.1680 - val_loss: 100.0370\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 52442.2930 - val_loss: 99.7085\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 35611.3555 - val_loss: 97.5883\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 53273.8242 - val_loss: 96.8748\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22220.9707 - val_loss: 97.5396\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 27802.8359 - val_loss: 98.6720\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32372.6152 - val_loss: 97.4486\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 42132.2852 - val_loss: 97.2198\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12981.3672 - val_loss: 98.2352\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46463.7539 - val_loss: 98.8710\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19322.3203 - val_loss: 98.5716\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 485.9988 - val_loss: 98.4937\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29583.3887 - val_loss: 98.3375\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4274.6455 - val_loss: 98.4552\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23221.8535 - val_loss: 98.7899\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20622.8281 - val_loss: 98.5212\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28294.2129 - val_loss: 97.9117\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff391c2f700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 20 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 85363.6484 - val_loss: 91.7236\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 258248.6250 - val_loss: 90.5245\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 145767.0625 - val_loss: 97.9278\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33337.4883 - val_loss: 101.0766\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19101.7148 - val_loss: 103.3342\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 72735.3594 - val_loss: 102.8530\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 34515.2617 - val_loss: 100.1670\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 60885.6172 - val_loss: 98.3191\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 35943.7891 - val_loss: 101.4130\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 61981.2695 - val_loss: 103.3609\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 35548.9766 - val_loss: 100.1607\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 56882.9336 - val_loss: 98.1802\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 60509.7422 - val_loss: 101.6684\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20816.6875 - val_loss: 100.9593\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 29369.1094 - val_loss: 101.4561\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 81890.4844 - val_loss: 103.6964\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 111375.8984 - val_loss: 99.4350\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 71251.0391 - val_loss: 98.8209\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 49756.0781 - val_loss: 101.4706\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 48532.2188 - val_loss: 101.7786\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6543.0142 - val_loss: 100.1853\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 41347.8711 - val_loss: 100.5968\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 16842.7207 - val_loss: 102.7820\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 49995.1562 - val_loss: 103.2115\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50736.1992 - val_loss: 100.8027\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3098.2605 - val_loss: 97.8932\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 130494.8672 - val_loss: 97.3427\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 123375.4609 - val_loss: 99.4770\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 27574.0156 - val_loss: 102.0056\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 69642.1406 - val_loss: 102.4675\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4238.4414 - val_loss: 102.8569\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 49474.5039 - val_loss: 103.1564\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 35226.6797 - val_loss: 100.9284\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17839.6328 - val_loss: 100.0364\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18654.2422 - val_loss: 98.9371\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 29133.5234 - val_loss: 98.7109\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 75630.6641 - val_loss: 100.6281\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27895.7246 - val_loss: 100.9665\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2742.8755 - val_loss: 102.0532\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 35714.4336 - val_loss: 101.5096\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20189.3359 - val_loss: 99.1783\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 76273.4766 - val_loss: 99.1517\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 45758.6719 - val_loss: 101.2071\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 88756.8906 - val_loss: 101.8089\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19368.2656 - val_loss: 101.1982\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7611.3086 - val_loss: 100.5337\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3055.1289 - val_loss: 100.7705\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5987.8657 - val_loss: 100.3972\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 21713.5508 - val_loss: 100.8482\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 32059.9277 - val_loss: 103.1697\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3947a9310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 21 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 71.1608 - val_loss: 52.0546\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 50.3849 - val_loss: 38.6098\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 39.2040 - val_loss: 52.1648\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 40.0978 - val_loss: 39.2949\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31.8095 - val_loss: 18.7993\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28.2136 - val_loss: 24.2851\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24.5952 - val_loss: 15.6665\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21.9550 - val_loss: 8.0369\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.3173 - val_loss: 5.7674\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19.5956 - val_loss: 3.6730\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.1425 - val_loss: 6.5368\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.5006 - val_loss: 2.7044\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.3717 - val_loss: 6.9657\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.9438 - val_loss: 4.5268\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.4850 - val_loss: 8.6718\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.0877 - val_loss: 4.2394\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.0389 - val_loss: 6.0332\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.5520 - val_loss: 3.6544\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.6933 - val_loss: 5.4790\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.3437 - val_loss: 4.0064\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.1693 - val_loss: 3.2186\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.4400 - val_loss: 3.7567\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.8873 - val_loss: 4.4303\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.6981 - val_loss: 4.0044\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.2519 - val_loss: 4.4200\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.2567 - val_loss: 4.1584\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.9658 - val_loss: 4.4805\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.9865 - val_loss: 3.3115\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.4422 - val_loss: 6.7955\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4411 - val_loss: 2.9979\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0852 - val_loss: 5.0652\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.3940 - val_loss: 8.3508\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.8870 - val_loss: 2.3124\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3985 - val_loss: 3.9893\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.4597 - val_loss: 2.8904\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.3801 - val_loss: 4.3176\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.3103 - val_loss: 2.2502\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.3386 - val_loss: 3.3543\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.4450 - val_loss: 5.3510\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.7337 - val_loss: 2.4600\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.7099 - val_loss: 3.3277\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.5528 - val_loss: 3.0002\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.5898 - val_loss: 3.8454\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.7811 - val_loss: 3.9097\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.1691 - val_loss: 2.5109\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.9282 - val_loss: 4.0031\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.8000 - val_loss: 6.2377\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.2925 - val_loss: 3.9692\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.9107 - val_loss: 3.0186\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.4281 - val_loss: 3.9589\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff373f1a9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 22 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 137328.5781 - val_loss: 106.2004\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 157850.0156 - val_loss: 111.7586\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 61798.0938 - val_loss: 100.9464\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 174000.3750 - val_loss: 96.1841\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 144312.5156 - val_loss: 97.6897\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 80158.7578 - val_loss: 103.2735\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 86379.2734 - val_loss: 106.2431\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 82353.9766 - val_loss: 102.8878\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2473.9841 - val_loss: 98.8537\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 129768.6484 - val_loss: 97.1440\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 73183.5156 - val_loss: 99.3185\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14889.2793 - val_loss: 102.3678\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 25428.5879 - val_loss: 103.6547\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 37796.7305 - val_loss: 100.4177\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2513.3491 - val_loss: 100.1055\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9482.6006 - val_loss: 101.0307\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14947.3799 - val_loss: 99.3408\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 45581.1211 - val_loss: 101.4165\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27941.6543 - val_loss: 105.9099\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 179393.7656 - val_loss: 107.9163\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 170281.4688 - val_loss: 103.5813\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 53229.6133 - val_loss: 99.1305\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1550.0336 - val_loss: 98.2694\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 90480.5234 - val_loss: 98.7471\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 75510.3672 - val_loss: 101.9789\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 39415.4336 - val_loss: 102.0645\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 280.5323 - val_loss: 102.9148\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 123279.0547 - val_loss: 103.5573\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 54248.0938 - val_loss: 101.5878\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14023.1758 - val_loss: 99.4260\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 49875.4844 - val_loss: 98.1353\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 67520.9688 - val_loss: 99.5292\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24323.7031 - val_loss: 99.9846\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18681.6992 - val_loss: 100.7557\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1257.5662 - val_loss: 103.0163\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 90461.3984 - val_loss: 103.5512\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 60467.8359 - val_loss: 102.2401\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 93600.1797 - val_loss: 99.6279\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14653.2695 - val_loss: 99.5678\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18770.1797 - val_loss: 101.0949\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 41238.5859 - val_loss: 101.9071\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 31467.0371 - val_loss: 99.6192\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25325.9023 - val_loss: 99.3753\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 51575.5469 - val_loss: 100.4562\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24155.1992 - val_loss: 101.0636\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23042.8496 - val_loss: 99.3876\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 23185.5605 - val_loss: 99.9054\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 55130.0312 - val_loss: 101.6210\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 32390.5918 - val_loss: 101.2771\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11873.5430 - val_loss: 99.5211\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff34b7020d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 23 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 64.3832 - val_loss: 33.5676\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 32.8264 - val_loss: 21.9596\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28.8303 - val_loss: 33.3762\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25.1656 - val_loss: 29.4134\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.7829 - val_loss: 17.5025\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18.7930 - val_loss: 17.0590\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.9117 - val_loss: 7.6987\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.2297 - val_loss: 6.6301\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.8511 - val_loss: 4.3586\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.0924 - val_loss: 10.8884\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.5082 - val_loss: 4.3011\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.7022 - val_loss: 10.0437\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.6456 - val_loss: 7.0804\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.7711 - val_loss: 10.0380\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.4722 - val_loss: 4.6385\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.8289 - val_loss: 6.1846\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.2144 - val_loss: 3.0849\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.9059 - val_loss: 7.0777\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.2821 - val_loss: 3.6932\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.9852 - val_loss: 5.4070\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.8702 - val_loss: 3.9254\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.3466 - val_loss: 7.3516\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.4574 - val_loss: 2.9042\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.2793 - val_loss: 5.9287\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2699 - val_loss: 2.6211\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.1727 - val_loss: 4.4502\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.5415 - val_loss: 3.1980\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.5917 - val_loss: 5.8264\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7666 - val_loss: 2.9400\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.1330 - val_loss: 6.2515\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.9476 - val_loss: 2.6952\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7872 - val_loss: 4.1331\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.3331 - val_loss: 3.2295\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.3455 - val_loss: 5.4449\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.6910 - val_loss: 3.7671\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.1331 - val_loss: 9.4041\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.0838 - val_loss: 6.1259\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.1615 - val_loss: 8.3587\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.5884 - val_loss: 1.9512\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5014 - val_loss: 3.6460\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4469 - val_loss: 2.2479\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.3660 - val_loss: 4.6188\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.1547 - val_loss: 2.7289\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0110 - val_loss: 2.4112\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.7651 - val_loss: 3.0019\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0504 - val_loss: 2.0887\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.2425 - val_loss: 4.9173\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.0344 - val_loss: 3.8932\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5149 - val_loss: 3.2746\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.9945 - val_loss: 2.3064\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff34ee80790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 24 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 8768522.0000 - val_loss: 92.4801\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6780227.5000 - val_loss: 92.5131\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 5304543.0000 - val_loss: 93.4478\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5024805.5000 - val_loss: 93.9675\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2120671.2500 - val_loss: 94.1473\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 975796.8125 - val_loss: 94.0428\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 891489.2500 - val_loss: 94.0965\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 496926.0000 - val_loss: 94.0010\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 484734.2500 - val_loss: 93.8794\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 406507.8438 - val_loss: 93.7639\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 446368.0938 - val_loss: 93.6891\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 535439.6250 - val_loss: 93.5799\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 352689.7812 - val_loss: 93.4683\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 239720.0000 - val_loss: 93.3517\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 300510.0312 - val_loss: 93.2236\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 302525.3750 - val_loss: 93.1302\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 211556.1406 - val_loss: 92.9874\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 287224.3750 - val_loss: 92.8579\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 438452.0000 - val_loss: 92.7975\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 299440.7500 - val_loss: 92.6887\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 149108.4844 - val_loss: 92.5951\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 286821.0000 - val_loss: 92.4690\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 363935.5312 - val_loss: 92.3566\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 340998.5000 - val_loss: 92.2165\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 336568.7500 - val_loss: 92.1208\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 445716.7812 - val_loss: 92.0474\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 297123.0000 - val_loss: 91.9857\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 312589.9688 - val_loss: 91.9130\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 339720.7188 - val_loss: 91.8009\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 197878.1250 - val_loss: 91.6893\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 178999.0156 - val_loss: 91.5949\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 134197.9688 - val_loss: 91.4298\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 183225.0000 - val_loss: 91.3234\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 205065.9531 - val_loss: 91.1762\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 196450.5938 - val_loss: 91.0664\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 190084.6250 - val_loss: 90.9710\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 175760.9531 - val_loss: 90.8362\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 311246.9375 - val_loss: 90.7378\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 356742.5625 - val_loss: 90.7282\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 241228.6875 - val_loss: 90.6953\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 325780.9375 - val_loss: 90.6366\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 295942.9375 - val_loss: 90.5596\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 314876.0938 - val_loss: 90.4973\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 343637.5312 - val_loss: 90.4531\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 290220.4062 - val_loss: 90.4026\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 301817.5938 - val_loss: 90.3716\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 373861.5938 - val_loss: 90.3305\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 315017.0938 - val_loss: 90.3391\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 182990.3438 - val_loss: 90.2752\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 230982.9531 - val_loss: 90.1904\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b8229d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 25 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 13107.6367 - val_loss: 72.4246\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 283885.0312 - val_loss: 84.1463\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 234367.0000 - val_loss: 82.9829\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 102879.3984 - val_loss: 74.7253\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 82914.3203 - val_loss: 76.2392\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 76599.8359 - val_loss: 82.4922\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 133831.2500 - val_loss: 83.3310\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23104.0801 - val_loss: 80.4378\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 37127.6016 - val_loss: 80.1694\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 52250.9023 - val_loss: 81.7994\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 44574.5469 - val_loss: 82.0151\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17056.1543 - val_loss: 78.4149\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 100995.8047 - val_loss: 79.2012\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 48090.6836 - val_loss: 81.3981\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50261.1719 - val_loss: 88.1275\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 185832.6094 - val_loss: 90.6445\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 185961.7188 - val_loss: 88.8979\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 85516.5469 - val_loss: 87.2054\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 34779.7734 - val_loss: 83.6053\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 53183.0625 - val_loss: 83.5332\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 77957.3750 - val_loss: 85.7824\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2589.8352 - val_loss: 89.3765\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 99299.4453 - val_loss: 89.3962\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 27104.0371 - val_loss: 87.2660\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15210.9307 - val_loss: 83.9464\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 160820.2031 - val_loss: 83.9711\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 89997.8516 - val_loss: 85.6893\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 72921.6953 - val_loss: 88.3686\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 59320.7969 - val_loss: 90.3507\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30501.8652 - val_loss: 89.5778\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14664.3828 - val_loss: 85.9516\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 116727.1016 - val_loss: 85.5993\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 135402.5312 - val_loss: 87.6664\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 71898.6875 - val_loss: 90.1356\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 116284.5000 - val_loss: 93.9284\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 149168.9375 - val_loss: 94.8855\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 128878.2891 - val_loss: 93.0855\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 43258.4414 - val_loss: 90.5276\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29564.9043 - val_loss: 90.1065\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25304.4453 - val_loss: 91.0657\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1464.4508 - val_loss: 93.0885\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 90547.7188 - val_loss: 94.1140\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 75622.0000 - val_loss: 93.0465\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13737.0391 - val_loss: 91.0997\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 39070.2031 - val_loss: 90.5256\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 65994.7969 - val_loss: 91.2589\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 28369.5918 - val_loss: 93.9109\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 67016.8359 - val_loss: 95.2075\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 108036.6484 - val_loss: 94.8513\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 54798.3789 - val_loss: 93.3277\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3813e40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 26 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 119755.0391 - val_loss: 108.6292\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 147396.5156 - val_loss: 104.1917\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 51954.2852 - val_loss: 100.3621\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 67626.5859 - val_loss: 95.0605\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 104720.7266 - val_loss: 95.4773\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 34489.1758 - val_loss: 100.3049\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 85938.1016 - val_loss: 103.0288\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 59836.8672 - val_loss: 102.1811\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 24973.3770 - val_loss: 99.8202\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5947.5015 - val_loss: 100.2624\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 35939.5859 - val_loss: 98.9710\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 31503.9316 - val_loss: 101.1753\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 52610.5781 - val_loss: 101.4999\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 26649.5508 - val_loss: 100.4573\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19748.7285 - val_loss: 99.9911\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19728.0195 - val_loss: 98.2653\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 72711.2734 - val_loss: 98.1637\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 60369.8438 - val_loss: 99.8507\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 46923.0664 - val_loss: 102.2669\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22803.0137 - val_loss: 102.7940\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 62727.1719 - val_loss: 102.6897\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 47349.6367 - val_loss: 99.7964\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12985.8799 - val_loss: 98.7893\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8317.4199 - val_loss: 98.5434\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 39699.9727 - val_loss: 97.3997\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 55224.8867 - val_loss: 99.3652\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18621.9102 - val_loss: 99.7842\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 23912.7598 - val_loss: 98.5245\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 50425.5156 - val_loss: 97.6973\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 63268.9492 - val_loss: 100.4617\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 36421.3164 - val_loss: 102.2172\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 45268.1133 - val_loss: 101.4514\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 4813.5918 - val_loss: 99.7300\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 54418.6914 - val_loss: 97.3183\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 64590.0273 - val_loss: 99.3138\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 4086.5042 - val_loss: 102.5914\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 52988.2656 - val_loss: 103.0967\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 43660.8633 - val_loss: 101.1451\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 72387.3984 - val_loss: 100.4668\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 986.5135 - val_loss: 102.7528\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 54658.7969 - val_loss: 103.0667\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 62220.8438 - val_loss: 101.1533\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9940.0195 - val_loss: 101.3349\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 34375.7578 - val_loss: 100.2939\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3192.6973 - val_loss: 98.1625\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 124776.1953 - val_loss: 97.6105\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 73353.3984 - val_loss: 99.8145\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13619.1064 - val_loss: 103.3516\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 66136.1406 - val_loss: 103.4957\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 56883.9609 - val_loss: 102.1614\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3978fa940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 27 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 169ms/step - loss: 56451.3867 - val_loss: 86.7263\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 136185.7656 - val_loss: 96.4355\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 152183.7656 - val_loss: 94.1367\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 76425.4766 - val_loss: 86.2160\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 71941.8516 - val_loss: 83.4733\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 183646.5000 - val_loss: 85.6320\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 127757.0234 - val_loss: 91.2802\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 5379.5298 - val_loss: 97.5456\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 112900.7891 - val_loss: 97.8234\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 116136.6875 - val_loss: 96.2704\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 62465.4023 - val_loss: 92.7862\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 53503.9805 - val_loss: 92.2835\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 23791.0488 - val_loss: 94.0778\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 6420.1709 - val_loss: 95.2409\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 34015.7852 - val_loss: 92.9723\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 32821.4688 - val_loss: 93.1939\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 32997.4727 - val_loss: 93.8803\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 22608.4531 - val_loss: 94.7299\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 3473.2793 - val_loss: 95.1224\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 62308.8164 - val_loss: 96.1425\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 31876.8984 - val_loss: 96.8630\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 109624.3984 - val_loss: 96.3252\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13638.0713 - val_loss: 94.0166\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1077.4552 - val_loss: 90.2003\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 186696.9844 - val_loss: 88.8521\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 80996.3906 - val_loss: 92.4149\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 48390.4375 - val_loss: 95.4718\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 46434.8242 - val_loss: 96.6238\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 42651.7109 - val_loss: 95.7757\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19036.2305 - val_loss: 95.8920\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 13076.1807 - val_loss: 95.1641\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 41705.0938 - val_loss: 95.6191\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 22465.8105 - val_loss: 96.8003\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 78104.9219 - val_loss: 97.3307\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 91752.5781 - val_loss: 96.5049\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 65066.7031 - val_loss: 93.2788\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 99621.3203 - val_loss: 93.1080\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 85628.3984 - val_loss: 93.9960\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 53102.2266 - val_loss: 96.1733\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8129.3511 - val_loss: 96.7433\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10356.3115 - val_loss: 96.5283\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 37506.1406 - val_loss: 95.8230\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16493.1543 - val_loss: 96.4999\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 21293.3242 - val_loss: 96.5443\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11640.3154 - val_loss: 95.3248\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 40004.4531 - val_loss: 95.4975\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25572.9062 - val_loss: 94.5804\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 65818.5156 - val_loss: 95.2591\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 22430.9180 - val_loss: 96.0530\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 2865.9758 - val_loss: 96.7146\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff39e402940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 28 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 158ms/step - loss: 98910.4219 - val_loss: 76.6655\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 531770.0625 - val_loss: 73.5133\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 240606.4688 - val_loss: 84.5247\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 242154.1250 - val_loss: 103.7493\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 450333.0625 - val_loss: 110.3172\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 289263.9062 - val_loss: 104.7916\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 174332.0000 - val_loss: 98.2084\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 22148.4688 - val_loss: 96.7446\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19538.2227 - val_loss: 98.1054\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 42909.7812 - val_loss: 98.7887\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 51635.0078 - val_loss: 96.2352\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 108103.1953 - val_loss: 95.4855\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 59907.5117 - val_loss: 98.8788\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 51620.6016 - val_loss: 98.8654\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 30985.9141 - val_loss: 96.9868\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 58654.5391 - val_loss: 96.8118\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19892.9883 - val_loss: 99.6977\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 95276.1719 - val_loss: 100.5839\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 54530.1641 - val_loss: 98.9131\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 66185.5469 - val_loss: 93.0083\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 177127.9531 - val_loss: 90.5150\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 51962.6953 - val_loss: 93.4373\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 75823.1875 - val_loss: 99.9334\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 54303.0938 - val_loss: 102.2990\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 76718.7578 - val_loss: 98.1827\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16438.9180 - val_loss: 93.7299\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 112271.7344 - val_loss: 93.1890\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 119016.9062 - val_loss: 94.9426\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 72450.4688 - val_loss: 98.7820\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 43820.0859 - val_loss: 100.5071\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 42843.8242 - val_loss: 98.1968\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9372.4277 - val_loss: 99.0152\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 59363.8281 - val_loss: 98.3373\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 99374.1875 - val_loss: 97.3578\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 43511.1758 - val_loss: 96.7967\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10189.7500 - val_loss: 98.4209\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 79135.0938 - val_loss: 98.6390\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18257.3535 - val_loss: 98.9489\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 49657.0430 - val_loss: 97.4053\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44490.5469 - val_loss: 97.3394\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10146.6064 - val_loss: 98.2833\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 5757.7666 - val_loss: 95.9826\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 49800.5664 - val_loss: 96.6292\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7375.7466 - val_loss: 97.7030\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12795.2529 - val_loss: 101.9166\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 89388.2891 - val_loss: 102.5248\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 91442.7031 - val_loss: 101.8318\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 88556.5078 - val_loss: 99.2188\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12379.8828 - val_loss: 94.5788\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 108746.8438 - val_loss: 94.2139\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff407a55f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 29 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 166ms/step - loss: 160402.1406 - val_loss: 93.4829\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 152401.6875 - val_loss: 99.9255\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 152753.1562 - val_loss: 87.1062\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 57770.5859 - val_loss: 84.9065\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 126637.3516 - val_loss: 92.2845\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 121928.3672 - val_loss: 94.3234\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 110742.3516 - val_loss: 90.2011\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 51947.4492 - val_loss: 89.1887\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 43344.9102 - val_loss: 92.0578\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15925.0342 - val_loss: 93.3552\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6295.0200 - val_loss: 94.2692\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 39241.1562 - val_loss: 94.4231\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 34291.5195 - val_loss: 91.7445\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 38080.0117 - val_loss: 90.8030\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 18981.7129 - val_loss: 93.3235\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 26660.8301 - val_loss: 94.8104\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 46085.5430 - val_loss: 93.1055\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15732.7910 - val_loss: 87.6428\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 172529.1250 - val_loss: 86.8538\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 157209.5312 - val_loss: 91.2635\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 54058.0117 - val_loss: 94.5290\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 33003.0273 - val_loss: 95.6496\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 59124.4492 - val_loss: 95.0183\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 70909.3906 - val_loss: 95.3196\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29779.3262 - val_loss: 94.7235\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25292.5215 - val_loss: 92.2042\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 79101.2500 - val_loss: 92.5159\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 90050.2656 - val_loss: 93.9983\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 32322.9375 - val_loss: 96.8226\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12304.7422 - val_loss: 97.4195\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 55312.4609 - val_loss: 97.0282\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43483.3164 - val_loss: 93.2439\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 45254.5508 - val_loss: 92.8206\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 70911.5469 - val_loss: 93.3648\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10756.1436 - val_loss: 98.3989\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 138331.6406 - val_loss: 98.2300\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 58239.5312 - val_loss: 96.9090\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19638.8652 - val_loss: 92.5323\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 117095.8984 - val_loss: 91.3036\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 51856.7812 - val_loss: 93.2303\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17322.9004 - val_loss: 96.2847\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13349.5205 - val_loss: 96.7043\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17137.2754 - val_loss: 95.3040\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36166.4492 - val_loss: 94.2242\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 81327.6641 - val_loss: 97.2937\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7200.3774 - val_loss: 99.7227\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 87927.1562 - val_loss: 100.4848\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 73827.4688 - val_loss: 99.2675\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33560.2617 - val_loss: 95.9218\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6775.9111 - val_loss: 94.9462\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff36aba8e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 30 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 118193.7734 - val_loss: 109.7222\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 285029.6875 - val_loss: 111.9663\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 150653.2656 - val_loss: 106.6948\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9590.8516 - val_loss: 96.0064\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 145799.3750 - val_loss: 93.5745\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 216685.0312 - val_loss: 93.8950\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 126260.4375 - val_loss: 98.6826\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 24234.0469 - val_loss: 105.1274\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 137152.8906 - val_loss: 108.3706\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 178189.7344 - val_loss: 102.4080\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24307.0332 - val_loss: 96.3001\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 234139.5469 - val_loss: 93.4819\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 173128.6875 - val_loss: 98.3342\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23052.2344 - val_loss: 100.1885\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1030.5304 - val_loss: 99.2747\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 165618.7969 - val_loss: 97.5541\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 75145.8906 - val_loss: 98.1569\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3881.3142 - val_loss: 101.0262\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 53380.7500 - val_loss: 103.3638\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 84344.5391 - val_loss: 102.6201\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42699.7695 - val_loss: 100.8752\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6104.3452 - val_loss: 100.5884\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18139.0332 - val_loss: 102.5891\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 57401.1133 - val_loss: 102.7291\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41615.0898 - val_loss: 100.5300\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 46200.0156 - val_loss: 99.5308\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13062.8779 - val_loss: 100.2329\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27500.0508 - val_loss: 100.2803\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 25898.2500 - val_loss: 99.6383\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24163.7832 - val_loss: 100.8180\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1050.3243 - val_loss: 100.4168\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 917.6702 - val_loss: 100.2337\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50217.1523 - val_loss: 103.5058\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 119960.2266 - val_loss: 104.5955\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 98445.1016 - val_loss: 103.5077\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 60617.3008 - val_loss: 100.0337\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 63553.6641 - val_loss: 99.2958\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12356.6611 - val_loss: 98.3877\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 77575.8125 - val_loss: 98.7246\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 51127.1680 - val_loss: 101.2635\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35367.8867 - val_loss: 101.5371\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47151.9180 - val_loss: 99.7071\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 102687.9375 - val_loss: 98.6975\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50996.9805 - val_loss: 101.3921\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27586.2656 - val_loss: 102.1754\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 72249.9375 - val_loss: 100.5215\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12902.1289 - val_loss: 100.0271\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11838.0938 - val_loss: 101.6749\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 131449.2031 - val_loss: 103.1128\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 53087.1172 - val_loss: 100.1953\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff349dd4940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 31 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 72.5491 - val_loss: 52.5339\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 54.6318 - val_loss: 46.7864\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 47.5813 - val_loss: 50.0088\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 41.5244 - val_loss: 37.7737\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33.6137 - val_loss: 30.3681\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30.8124 - val_loss: 22.4856\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 29.2734 - val_loss: 15.7457\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24.0889 - val_loss: 6.6040\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 23.9773 - val_loss: 7.8633\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21.9032 - val_loss: 8.6739\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20.8220 - val_loss: 6.4326\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20.0569 - val_loss: 8.6036\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22.7169 - val_loss: 8.5804\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 20.3808 - val_loss: 6.6062\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.8000 - val_loss: 3.6129\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.8554 - val_loss: 4.8264\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.6733 - val_loss: 3.3578\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.4296 - val_loss: 6.0044\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.1683 - val_loss: 5.1230\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.0786 - val_loss: 6.3591\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.3488 - val_loss: 3.1462\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.0815 - val_loss: 7.1781\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.6910 - val_loss: 2.6552\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.0935 - val_loss: 2.7222\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.6292 - val_loss: 9.4441\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.8195 - val_loss: 3.2834\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.7502 - val_loss: 6.4733\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.8766 - val_loss: 3.4529\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.1535 - val_loss: 4.9457\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.5295 - val_loss: 7.4145\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.3962 - val_loss: 4.0367\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.8792 - val_loss: 6.1346\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 11.3237 - val_loss: 4.4344\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.1863 - val_loss: 2.8424\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.1665 - val_loss: 6.9809\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.7471 - val_loss: 4.1850\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.4539 - val_loss: 7.6233\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.3670 - val_loss: 2.3647\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.0236 - val_loss: 4.5812\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7712 - val_loss: 4.2110\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.4565 - val_loss: 2.9209\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2968 - val_loss: 2.9281\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.8112 - val_loss: 5.9039\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.0886 - val_loss: 3.2218\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.3173 - val_loss: 7.0252\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.4215 - val_loss: 3.9591\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0617 - val_loss: 2.3372\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.6876 - val_loss: 2.6850\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5381 - val_loss: 2.1340\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.0693 - val_loss: 3.9185\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3627f9040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 32 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 64.9359 - val_loss: 46.8132\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 53.1420 - val_loss: 36.6710\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 40.5619 - val_loss: 50.9387\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 39.0624 - val_loss: 41.7863\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 33.9987 - val_loss: 25.1630\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 27.7526 - val_loss: 20.6443\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 21.9152 - val_loss: 14.8197\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23.4414 - val_loss: 5.1194\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 20.6792 - val_loss: 12.3532\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20.6011 - val_loss: 5.9525\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.2413 - val_loss: 6.9605\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.5464 - val_loss: 6.8354\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19.2748 - val_loss: 7.3471\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.8700 - val_loss: 7.3968\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.9076 - val_loss: 6.2809\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.0423 - val_loss: 6.2733\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.7335 - val_loss: 6.8521\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.4768 - val_loss: 5.9561\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.2290 - val_loss: 5.7985\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.3314 - val_loss: 7.1050\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.8964 - val_loss: 6.7109\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.7952 - val_loss: 4.5407\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.6386 - val_loss: 7.0681\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.7009 - val_loss: 4.0033\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.9791 - val_loss: 4.2787\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.0545 - val_loss: 4.3587\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.2932 - val_loss: 5.8951\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.1755 - val_loss: 4.9874\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.0425 - val_loss: 3.0753\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.2837 - val_loss: 5.7207\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.3253 - val_loss: 5.3617\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.8447 - val_loss: 4.1876\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.9555 - val_loss: 6.1205\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.5505 - val_loss: 7.2003\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.3644 - val_loss: 4.4697\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.3815 - val_loss: 3.6388\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.2957 - val_loss: 4.1143\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.1275 - val_loss: 4.8289\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.5019 - val_loss: 4.6665\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.1565 - val_loss: 2.3675\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 17.0356 - val_loss: 2.3372\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.6190 - val_loss: 4.3893\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.1349 - val_loss: 10.2844\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.6154 - val_loss: 7.8712\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 14.6575 - val_loss: 8.6471\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.8351 - val_loss: 3.4861\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 11.8568 - val_loss: 5.9889\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.7009 - val_loss: 2.4520\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.0590 - val_loss: 3.5636\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8656 - val_loss: 3.0983\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff387144940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 33 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 85.6630 - val_loss: 60.2498\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 39.5313 - val_loss: 23.7581\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 36.3568 - val_loss: 32.9676\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 31.3097 - val_loss: 39.9227\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26.0802 - val_loss: 23.3897\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26.0825 - val_loss: 18.0718\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20.9155 - val_loss: 22.3066\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.3197 - val_loss: 6.2939\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.8372 - val_loss: 10.3096\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.4365 - val_loss: 2.4485\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.4537 - val_loss: 7.1995\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.3067 - val_loss: 6.0534\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.1735 - val_loss: 3.9556\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.5638 - val_loss: 7.1838\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.9588 - val_loss: 2.9977\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 12.3405 - val_loss: 2.8390\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 11.7822 - val_loss: 3.4951\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.6331 - val_loss: 3.6021\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.6058 - val_loss: 7.3388\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.5242 - val_loss: 2.7509\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.1251 - val_loss: 9.0425\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.3654 - val_loss: 2.9252\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.1284 - val_loss: 4.2588\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.9423 - val_loss: 3.4355\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.8862 - val_loss: 3.5448\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.8072 - val_loss: 2.9940\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.0150 - val_loss: 4.0669\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.1677 - val_loss: 2.5709\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.6492 - val_loss: 4.8891\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7574 - val_loss: 3.1145\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9975 - val_loss: 7.0948\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.0620 - val_loss: 2.5443\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7680 - val_loss: 5.9029\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.1978 - val_loss: 2.4549\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.9738 - val_loss: 4.7960\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.9727 - val_loss: 3.2891\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6653 - val_loss: 6.1756\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.0238 - val_loss: 2.3039\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.9201 - val_loss: 2.7965\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.5997 - val_loss: 3.9435\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.0093 - val_loss: 2.6219\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.8164 - val_loss: 2.7659\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4110 - val_loss: 4.2194\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3786 - val_loss: 1.8705\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.5251 - val_loss: 5.8039\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.1482 - val_loss: 1.8607\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.2523 - val_loss: 4.9318\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.0038 - val_loss: 3.1605\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5818 - val_loss: 1.5813\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.5651 - val_loss: 4.9700\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3975051f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 34 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 110873.4453 - val_loss: 112.5936\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 119081.9219 - val_loss: 107.2497\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 149342.8906 - val_loss: 112.3713\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 129916.8047 - val_loss: 112.1579\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 49468.9297 - val_loss: 106.2202\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 131134.2969 - val_loss: 105.4926\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 95613.4531 - val_loss: 107.2883\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18135.6445 - val_loss: 108.0866\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 108152.3516 - val_loss: 106.2026\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33161.7461 - val_loss: 103.5172\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33660.5938 - val_loss: 103.9855\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 24697.3867 - val_loss: 103.2632\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 54560.8867 - val_loss: 102.9964\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 48967.1406 - val_loss: 102.6124\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13230.1943 - val_loss: 101.1602\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 41077.1367 - val_loss: 101.6993\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 20996.9180 - val_loss: 101.4501\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 57399.3945 - val_loss: 100.1368\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 26630.1797 - val_loss: 100.7277\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 38139.3711 - val_loss: 101.0260\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 83971.1016 - val_loss: 99.0298\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 46195.8945 - val_loss: 97.3782\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 41712.5039 - val_loss: 99.1056\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10522.7061 - val_loss: 102.2778\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 154748.1719 - val_loss: 102.9689\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 153814.7969 - val_loss: 101.2604\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 66584.8125 - val_loss: 99.8562\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 132818.2656 - val_loss: 100.3549\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 60059.5078 - val_loss: 103.4251\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 43677.3477 - val_loss: 104.8592\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 74373.0000 - val_loss: 103.9566\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 106161.4375 - val_loss: 101.3971\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 71527.6016 - val_loss: 101.1241\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33602.5781 - val_loss: 102.3567\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 40492.4219 - val_loss: 103.7986\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 28468.1055 - val_loss: 102.4489\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 37010.8711 - val_loss: 99.6376\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 117764.7500 - val_loss: 99.6630\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 79739.5625 - val_loss: 101.8557\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15123.1201 - val_loss: 104.1894\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 108995.9297 - val_loss: 103.1101\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 67665.8125 - val_loss: 101.5243\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 130381.9375 - val_loss: 102.5068\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 34675.3711 - val_loss: 104.5921\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 83656.6484 - val_loss: 104.7022\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 63787.4141 - val_loss: 102.7622\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 31159.6777 - val_loss: 101.9017\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 94661.9375 - val_loss: 101.5767\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 24167.4629 - val_loss: 102.4895\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 48336.7812 - val_loss: 103.3188\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38603f820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 35 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 67.7411 - val_loss: 32.4811\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 38.8865 - val_loss: 19.5856\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 29.0977 - val_loss: 39.5567\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 28.0742 - val_loss: 36.3281\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22.5841 - val_loss: 18.1872\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 23.8703 - val_loss: 18.5166\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21.5512 - val_loss: 27.3399\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.8314 - val_loss: 17.3943\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.5638 - val_loss: 12.5657\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.4555 - val_loss: 16.1686\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.7593 - val_loss: 7.9978\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.7309 - val_loss: 7.7745\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.1997 - val_loss: 9.6254\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.3000 - val_loss: 2.1204\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.7231 - val_loss: 13.3229\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.9372 - val_loss: 4.4960\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.4888 - val_loss: 8.2494\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.2343 - val_loss: 4.8517\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.5493 - val_loss: 4.8479\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.5433 - val_loss: 2.3601\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.5497 - val_loss: 5.3697\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.6663 - val_loss: 3.0813\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6994 - val_loss: 3.5180\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 11.1329 - val_loss: 3.2683\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.2916 - val_loss: 2.8992\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.5086 - val_loss: 6.6082\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.8927 - val_loss: 2.7390\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.7667 - val_loss: 2.3349\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4428 - val_loss: 4.8322\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.0187 - val_loss: 3.0835\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.4644 - val_loss: 3.5727\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.9089 - val_loss: 4.6865\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.9906 - val_loss: 3.3599\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.9698 - val_loss: 3.1334\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.2988 - val_loss: 6.3216\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.9321 - val_loss: 7.9502\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.9125 - val_loss: 3.8039\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7825 - val_loss: 10.0406\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.9420 - val_loss: 3.6339\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.3207 - val_loss: 6.7660\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.4409 - val_loss: 3.1364\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.7570 - val_loss: 5.5624\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.0705 - val_loss: 2.3844\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 9.1610 - val_loss: 2.5407\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.2465 - val_loss: 2.4118\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.4238 - val_loss: 3.3893\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.1522 - val_loss: 2.7904\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1608 - val_loss: 4.9652\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 10.3255 - val_loss: 6.7997\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.3604 - val_loss: 4.9651\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38719df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 36 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 744.0256 - val_loss: 122.5648\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 379835.2812 - val_loss: 117.7733\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 116075.8984 - val_loss: 107.7926\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 65250.1562 - val_loss: 106.4925\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10344.3203 - val_loss: 104.0676\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 111947.9375 - val_loss: 103.1589\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 63641.7109 - val_loss: 108.5647\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 128417.5781 - val_loss: 110.8316\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 113040.3047 - val_loss: 107.5243\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 24308.1855 - val_loss: 103.5537\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 82819.3047 - val_loss: 101.6183\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 133179.8750 - val_loss: 104.6439\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 51149.5742 - val_loss: 105.8439\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 45202.2656 - val_loss: 103.2968\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 51617.8672 - val_loss: 102.9561\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 72280.0625 - val_loss: 103.4632\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 29007.7109 - val_loss: 103.5775\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 19598.5996 - val_loss: 104.5887\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 42498.6055 - val_loss: 104.0384\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 6334.1934 - val_loss: 103.9217\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 36015.2344 - val_loss: 104.2312\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 22099.3203 - val_loss: 101.4153\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 85521.2578 - val_loss: 101.0481\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 85420.8047 - val_loss: 101.8489\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 26646.0449 - val_loss: 104.2256\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 44229.6602 - val_loss: 104.1299\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 45838.3867 - val_loss: 102.9397\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 54045.0742 - val_loss: 100.0441\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 105982.7500 - val_loss: 99.8798\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 80317.3828 - val_loss: 101.1846\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 63847.1367 - val_loss: 105.4744\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 77075.6875 - val_loss: 105.6424\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 33200.9375 - val_loss: 105.2105\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 57357.6172 - val_loss: 101.7161\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 97357.9922 - val_loss: 100.7818\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 59990.4141 - val_loss: 101.5952\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 45351.5078 - val_loss: 104.3848\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 53582.2812 - val_loss: 104.2726\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 55006.5859 - val_loss: 102.9802\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14476.9189 - val_loss: 101.7327\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 20240.3984 - val_loss: 101.2284\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 10294.7363 - val_loss: 101.9327\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21245.0605 - val_loss: 101.5192\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 37634.0547 - val_loss: 101.8129\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 43736.3828 - val_loss: 103.3446\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 87267.2656 - val_loss: 103.2969\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16269.1035 - val_loss: 102.1378\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11834.5215 - val_loss: 100.6900\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 94960.5781 - val_loss: 100.2090\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 32769.7773 - val_loss: 100.5836\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff378689550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 37 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 79.9362 - val_loss: 53.9828\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 29.7315 - val_loss: 3.6676\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 30.0598 - val_loss: 22.7966\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20.2988 - val_loss: 32.9472\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.1968 - val_loss: 21.1879\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18.6202 - val_loss: 13.0286\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.4358 - val_loss: 17.8030\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.3147 - val_loss: 12.3101\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.2277 - val_loss: 8.2141\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.9946 - val_loss: 3.7765\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.1285 - val_loss: 2.7923\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.4462 - val_loss: 3.0657\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.8181 - val_loss: 3.9829\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.3532 - val_loss: 5.6437\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.9586 - val_loss: 5.1504\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.1847 - val_loss: 3.5990\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.4392 - val_loss: 2.7519\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.7950 - val_loss: 2.7349\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6730 - val_loss: 5.5065\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.3530 - val_loss: 2.7202\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.4244 - val_loss: 3.9423\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.3660 - val_loss: 2.5518\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.6086 - val_loss: 4.6976\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.6113 - val_loss: 3.2347\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.6105 - val_loss: 3.5415\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.0232 - val_loss: 2.5555\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.5732 - val_loss: 3.7547\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.4579 - val_loss: 2.6785\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6605 - val_loss: 5.0676\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.9702 - val_loss: 4.5324\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.7791 - val_loss: 2.6024\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.4086 - val_loss: 3.6361\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.6041 - val_loss: 2.7141\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.1080 - val_loss: 3.6516\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.9180 - val_loss: 2.9556\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.8162 - val_loss: 3.2542\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.8828 - val_loss: 2.8564\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.2030 - val_loss: 2.7638\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.5629 - val_loss: 2.5718\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.1477 - val_loss: 2.8618\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.2350 - val_loss: 2.5265\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.5570 - val_loss: 2.6402\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.1956 - val_loss: 2.9932\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.1131 - val_loss: 2.7512\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.4772 - val_loss: 3.0193\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6.9565 - val_loss: 3.4137\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.0997 - val_loss: 2.4714\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.3690 - val_loss: 2.3164\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.2657 - val_loss: 2.1004\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.1276 - val_loss: 2.3687\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff35a21f160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 38 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 60.2345 - val_loss: 34.2200\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 40.5424 - val_loss: 29.7615\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 33.7781 - val_loss: 42.0202\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 30.4377 - val_loss: 26.2493\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 26.0967 - val_loss: 22.1740\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23.0817 - val_loss: 24.4442\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.8092 - val_loss: 5.7162\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.4418 - val_loss: 16.5165\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.5740 - val_loss: 2.6926\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 17.6019 - val_loss: 11.8923\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.2073 - val_loss: 4.7022\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.7475 - val_loss: 7.3403\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.1797 - val_loss: 13.2261\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.8435 - val_loss: 2.8502\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 14.5915 - val_loss: 8.1066\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.1099 - val_loss: 3.5914\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.9158 - val_loss: 5.7908\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 13.1912 - val_loss: 8.3776\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.5016 - val_loss: 3.5985\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.4351 - val_loss: 6.3169\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.8049 - val_loss: 3.3547\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.0756 - val_loss: 5.0901\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.9605 - val_loss: 2.8829\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.7325 - val_loss: 4.5538\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.5511 - val_loss: 5.5725\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.8940 - val_loss: 4.2679\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.9763 - val_loss: 4.8976\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6218 - val_loss: 3.0122\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.3522 - val_loss: 4.3328\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.4410 - val_loss: 3.5968\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6367 - val_loss: 3.2066\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.9099 - val_loss: 5.4061\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.4801 - val_loss: 3.9589\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.8686 - val_loss: 2.9162\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.2300 - val_loss: 3.6217\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.7859 - val_loss: 7.2072\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5474 - val_loss: 3.3377\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.8878 - val_loss: 3.6040\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.5905 - val_loss: 10.9844\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.2972 - val_loss: 3.5748\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.3240 - val_loss: 3.6022\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.9388 - val_loss: 3.1799\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.6160 - val_loss: 5.9654\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.8347 - val_loss: 4.2673\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.6769 - val_loss: 5.0518\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 9.4631 - val_loss: 3.9920\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.9516 - val_loss: 4.3970\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.3455 - val_loss: 5.5215\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0981 - val_loss: 5.3029\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5096 - val_loss: 3.3308\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff34cd36ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 39 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 247855.0312 - val_loss: 87.1295\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 376901.6875 - val_loss: 98.3996\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 64809.8867 - val_loss: 102.8518\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55091.0703 - val_loss: 100.7823\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 89916.2734 - val_loss: 102.6237\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 118289.5000 - val_loss: 104.1261\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 69775.1328 - val_loss: 99.8729\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 195894.1250 - val_loss: 98.7603\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 65931.5391 - val_loss: 101.0819\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 26571.9961 - val_loss: 100.8079\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 34999.5859 - val_loss: 101.9485\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 99759.8516 - val_loss: 101.0892\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3853.6970 - val_loss: 101.3089\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35109.6367 - val_loss: 99.2627\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 80893.5000 - val_loss: 97.5083\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 99589.6875 - val_loss: 100.1749\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33799.3594 - val_loss: 102.6891\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 142770.7500 - val_loss: 100.8599\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14509.4541 - val_loss: 96.4659\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 179329.3594 - val_loss: 95.5060\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 108055.0000 - val_loss: 98.0501\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22863.2715 - val_loss: 100.2666\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 78437.8906 - val_loss: 100.0733\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23561.7812 - val_loss: 96.5730\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 139947.7969 - val_loss: 96.2747\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 157000.5781 - val_loss: 98.9874\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43141.5273 - val_loss: 99.7695\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42364.1992 - val_loss: 98.8603\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 88740.5859 - val_loss: 98.1160\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 87334.7656 - val_loss: 99.8474\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11855.4209 - val_loss: 101.0371\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 44275.0117 - val_loss: 101.3982\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 37108.6562 - val_loss: 97.8286\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 178789.8594 - val_loss: 97.4918\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 172878.8750 - val_loss: 99.6153\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12612.0107 - val_loss: 100.4884\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6893.0293 - val_loss: 99.8895\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 44505.0234 - val_loss: 99.3119\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33660.8047 - val_loss: 99.2736\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 56012.6172 - val_loss: 100.0275\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 69443.3047 - val_loss: 99.5816\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 41357.6797 - val_loss: 98.1758\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 31347.1211 - val_loss: 99.0405\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 72189.4609 - val_loss: 100.3669\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 82560.0234 - val_loss: 99.0230\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 60343.8438 - val_loss: 98.1203\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29033.2266 - val_loss: 97.4020\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 84054.9297 - val_loss: 98.6183\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38110.6094 - val_loss: 100.0943\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 77508.2656 - val_loss: 100.3035\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3608b3ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 40 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 76.8007 - val_loss: 56.6719\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 56.0898 - val_loss: 43.2616\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 50.2326 - val_loss: 24.1293\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42.7792 - val_loss: 34.7042\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 42.9239 - val_loss: 28.5534\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36.7346 - val_loss: 16.0590\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 35.4865 - val_loss: 16.2606\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 34.0637 - val_loss: 10.6071\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 32.5545 - val_loss: 11.6572\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 30.6909 - val_loss: 11.4969\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29.8253 - val_loss: 14.7017\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 27.5887 - val_loss: 10.1883\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 27.7427 - val_loss: 5.8339\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 22.7843 - val_loss: 18.3427\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24.4817 - val_loss: 9.6830\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 26.9253 - val_loss: 13.5588\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 18.9778 - val_loss: 12.9597\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.9967 - val_loss: 3.4510\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.0878 - val_loss: 12.0140\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.6944 - val_loss: 14.4738\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.9463 - val_loss: 11.5008\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 18.1607 - val_loss: 4.7835\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.9543 - val_loss: 12.9411\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.6159 - val_loss: 9.0257\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.7058 - val_loss: 3.8350\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.2451 - val_loss: 11.1460\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.6104 - val_loss: 9.3212\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.5143 - val_loss: 3.6864\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.9018 - val_loss: 7.1638\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.6909 - val_loss: 8.5471\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.7970 - val_loss: 5.6015\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.3965 - val_loss: 6.4815\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.8384 - val_loss: 4.0277\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.6886 - val_loss: 9.2333\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.4723 - val_loss: 2.7293\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.2824 - val_loss: 7.0154\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.9277 - val_loss: 4.3813\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.5019 - val_loss: 5.9214\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.8310 - val_loss: 5.1981\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.4977 - val_loss: 5.6190\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16.8125 - val_loss: 6.8062\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.5103 - val_loss: 2.4859\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.2963 - val_loss: 7.7362\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.0718 - val_loss: 2.6698\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.7410 - val_loss: 6.2876\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.0591 - val_loss: 5.2820\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.5957 - val_loss: 7.6809\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.1642 - val_loss: 4.9216\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 15.6209 - val_loss: 6.7891\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.0865 - val_loss: 12.1010\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff33ab70040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 41 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 74941.5859 - val_loss: 111.1483\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 181171.3281 - val_loss: 105.8152\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 4632.6860 - val_loss: 98.3217\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 173505.8594 - val_loss: 96.0287\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 136696.1875 - val_loss: 102.2651\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 50379.3828 - val_loss: 103.9481\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 59772.2695 - val_loss: 100.2029\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 109444.9609 - val_loss: 97.8220\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 63273.5312 - val_loss: 100.5925\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 46780.7539 - val_loss: 102.7599\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2467.3562 - val_loss: 101.5187\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3791.2937 - val_loss: 101.5258\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 68596.5000 - val_loss: 103.1996\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 47249.3398 - val_loss: 101.1470\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 85936.5625 - val_loss: 98.4228\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 30001.0293 - val_loss: 98.4574\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 34029.7109 - val_loss: 99.2604\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 21107.9902 - val_loss: 98.8354\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 49118.1953 - val_loss: 99.3951\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 60812.3750 - val_loss: 101.2935\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 67039.1250 - val_loss: 101.4632\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 35106.1211 - val_loss: 99.6377\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 32311.6543 - val_loss: 99.6183\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 4491.0264 - val_loss: 101.2710\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 65939.2500 - val_loss: 101.1145\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 37389.6953 - val_loss: 100.0568\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15148.5312 - val_loss: 99.9606\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2065.5583 - val_loss: 98.9494\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 43028.1484 - val_loss: 98.4725\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 43343.1836 - val_loss: 100.1707\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19992.4492 - val_loss: 102.7371\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 171980.5781 - val_loss: 103.6008\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 154092.0156 - val_loss: 101.1891\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 23863.0312 - val_loss: 100.1313\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 41362.1523 - val_loss: 99.7780\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13385.5557 - val_loss: 99.3296\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29393.0000 - val_loss: 100.0305\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6838.0151 - val_loss: 100.2268\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 46646.1484 - val_loss: 99.5523\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6411.4810 - val_loss: 99.6912\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 587.3168 - val_loss: 101.6356\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 91072.3750 - val_loss: 102.1485\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 64734.9609 - val_loss: 100.8897\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 51130.3555 - val_loss: 98.5249\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 50254.9414 - val_loss: 98.4186\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 45756.6719 - val_loss: 99.1612\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10743.1133 - val_loss: 101.0236\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 94965.3438 - val_loss: 101.1387\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19981.3672 - val_loss: 100.2627\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22063.6758 - val_loss: 98.7656\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff367e90670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 42 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 61348.3867 - val_loss: 125.4508\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 98595.6172 - val_loss: 120.5035\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 85337.0547 - val_loss: 122.9182\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 161787.7969 - val_loss: 124.7050\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 137993.5938 - val_loss: 113.9306\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 37119.5156 - val_loss: 112.0992\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7968.8125 - val_loss: 107.9415\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 123531.4844 - val_loss: 106.9438\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 60906.3867 - val_loss: 113.6486\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 43712.4609 - val_loss: 113.7143\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 30075.6484 - val_loss: 109.7916\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 49555.1445 - val_loss: 109.8276\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17383.0156 - val_loss: 109.6789\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 59638.2422 - val_loss: 108.9781\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16373.3057 - val_loss: 115.0670\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 127943.7734 - val_loss: 117.3113\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 50985.5117 - val_loss: 113.8549\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 57308.7422 - val_loss: 108.9565\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 45616.4844 - val_loss: 108.7043\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 90781.4375 - val_loss: 110.4906\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22078.5625 - val_loss: 110.7822\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12894.3818 - val_loss: 110.9026\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 2479.8704 - val_loss: 112.9648\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 93074.4453 - val_loss: 114.6403\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 71775.2500 - val_loss: 111.4179\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15258.2930 - val_loss: 106.9875\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 104395.8438 - val_loss: 104.1787\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 110624.8984 - val_loss: 105.3882\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 59555.5273 - val_loss: 108.4093\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 20502.4219 - val_loss: 108.4699\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8185.8198 - val_loss: 107.2068\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 31967.2344 - val_loss: 107.5376\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6956.9902 - val_loss: 108.5946\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 41708.4648 - val_loss: 109.8528\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 38466.4883 - val_loss: 107.3606\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13718.4072 - val_loss: 106.1907\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1986.1664 - val_loss: 106.8339\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 56999.9492 - val_loss: 107.7751\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42937.4336 - val_loss: 106.9201\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8821.2422 - val_loss: 108.3931\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 45251.0898 - val_loss: 109.0032\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 32933.8398 - val_loss: 105.3796\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 79371.5000 - val_loss: 103.6558\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 72995.8750 - val_loss: 106.6535\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17048.7324 - val_loss: 110.9174\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 77981.1016 - val_loss: 110.9427\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 51221.7031 - val_loss: 108.7568\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 22684.6191 - val_loss: 105.7821\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2610.2649 - val_loss: 100.6675\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 172042.5469 - val_loss: 99.7326\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff40c0ebc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 43 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 71.2347 - val_loss: 46.1516\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 47.7051 - val_loss: 33.3622\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38.3916 - val_loss: 44.0829\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 34.0483 - val_loss: 36.2196\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28.3443 - val_loss: 19.3260\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24.3477 - val_loss: 19.2900\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20.9848 - val_loss: 12.1814\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.8010 - val_loss: 7.0619\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.2132 - val_loss: 9.7721\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.5355 - val_loss: 7.7829\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.3228 - val_loss: 10.4024\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.0357 - val_loss: 4.6962\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.6851 - val_loss: 5.7834\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.6547 - val_loss: 5.3403\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.7221 - val_loss: 4.8104\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.7886 - val_loss: 3.8618\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 14.3235 - val_loss: 7.9142\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.6941 - val_loss: 3.9688\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.5565 - val_loss: 3.8801\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.6177 - val_loss: 3.1789\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.7494 - val_loss: 3.9129\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.6491 - val_loss: 4.3695\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.0089 - val_loss: 2.8834\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 12.8254 - val_loss: 3.7137\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.4943 - val_loss: 3.5609\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.6788 - val_loss: 3.6566\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.8341 - val_loss: 3.4638\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 14.6381 - val_loss: 3.8870\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.7692 - val_loss: 6.9655\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.3992 - val_loss: 8.8349\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 11.8155 - val_loss: 6.8288\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.8363 - val_loss: 6.7455\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.7099 - val_loss: 2.8804\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.9477 - val_loss: 3.3762\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.2979 - val_loss: 2.7537\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.6364 - val_loss: 2.3110\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.1377 - val_loss: 2.7017\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.1583 - val_loss: 1.7003\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.2112 - val_loss: 5.6515\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.0569 - val_loss: 1.9870\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.9328 - val_loss: 6.4053\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.6852 - val_loss: 2.2391\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.6817 - val_loss: 3.5747\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.4930 - val_loss: 2.0470\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.7215 - val_loss: 1.8515\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7.9713 - val_loss: 5.8842\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.2710 - val_loss: 1.5472\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0219 - val_loss: 3.7228\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.8737 - val_loss: 1.9654\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.0356 - val_loss: 3.4436\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3837b94c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 44 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 71.2135 - val_loss: 58.6009\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 57.6353 - val_loss: 43.6325\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 50.2321 - val_loss: 48.0367\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 41.5327 - val_loss: 36.2366\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 37.1955 - val_loss: 29.8566\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31.2663 - val_loss: 27.9708\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 30.2885 - val_loss: 12.2690\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 26.8682 - val_loss: 11.3726\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 23.7467 - val_loss: 7.4286\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23.9753 - val_loss: 10.3700\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 21.1572 - val_loss: 6.6449\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.2296 - val_loss: 10.6213\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 19.6075 - val_loss: 5.0140\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.9185 - val_loss: 9.8084\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 17.3329 - val_loss: 5.2152\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.5221 - val_loss: 6.2840\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.4158 - val_loss: 9.6862\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.9490 - val_loss: 6.4665\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.9325 - val_loss: 4.6527\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.0448 - val_loss: 8.3090\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.4636 - val_loss: 6.9099\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.3474 - val_loss: 4.1667\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.0239 - val_loss: 8.9846\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.2209 - val_loss: 7.3100\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.7564 - val_loss: 4.5820\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.7688 - val_loss: 4.0551\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.3498 - val_loss: 8.8990\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.8690 - val_loss: 5.0462\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.5458 - val_loss: 7.3505\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.9378 - val_loss: 7.0340\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 10.1059 - val_loss: 4.0583\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.6326 - val_loss: 9.8365\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.1964 - val_loss: 5.7354\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.5659 - val_loss: 6.3085\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.1194 - val_loss: 5.6565\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 10.2014 - val_loss: 5.5515\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.0049 - val_loss: 6.6548\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.0441 - val_loss: 4.8844\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.9748 - val_loss: 10.1556\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 12.5063 - val_loss: 4.2835\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.7447 - val_loss: 11.1262\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12.2989 - val_loss: 4.6396\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.0548 - val_loss: 8.6291\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 11.6782 - val_loss: 4.2552\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.4006 - val_loss: 8.4303\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 10.7782 - val_loss: 5.1437\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.9819 - val_loss: 5.7369\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 10.2439 - val_loss: 5.4041\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.0640 - val_loss: 7.2839\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 9.7696 - val_loss: 5.6833\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3bff14940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 45 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 136149.5625 - val_loss: 82.0150\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 127114.3984 - val_loss: 81.4645\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 39972.4492 - val_loss: 88.0524\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12058.4248 - val_loss: 88.4383\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6788.8804 - val_loss: 89.9608\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20121.6484 - val_loss: 90.9494\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 84910.3906 - val_loss: 90.5414\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4662.2710 - val_loss: 84.3852\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 175523.5938 - val_loss: 84.0810\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 161450.6250 - val_loss: 89.9871\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33667.3750 - val_loss: 96.0289\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 57119.3359 - val_loss: 96.1521\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 37766.3359 - val_loss: 94.2412\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 19756.7930 - val_loss: 93.9339\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1981.1287 - val_loss: 95.2899\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 41547.1406 - val_loss: 95.1760\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3916.1768 - val_loss: 93.7880\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 29835.2012 - val_loss: 92.4825\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 54709.8320 - val_loss: 94.5450\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 50080.4805 - val_loss: 95.2620\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38101.7812 - val_loss: 95.3042\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8267.3359 - val_loss: 95.5404\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20527.3945 - val_loss: 95.8720\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 27000.9531 - val_loss: 96.1501\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10637.6133 - val_loss: 97.8931\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 104816.7031 - val_loss: 98.0184\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13000.6689 - val_loss: 95.9432\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15065.0742 - val_loss: 92.7227\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 134883.5625 - val_loss: 91.1649\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 79000.1484 - val_loss: 93.4083\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46679.5312 - val_loss: 95.8090\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 60192.5586 - val_loss: 98.1612\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16273.9404 - val_loss: 96.7191\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7771.2979 - val_loss: 95.5229\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8370.5234 - val_loss: 96.6447\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 23041.8711 - val_loss: 95.6767\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19401.8574 - val_loss: 96.4476\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 30221.2832 - val_loss: 96.2756\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2268.8374 - val_loss: 97.3963\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 32294.1016 - val_loss: 97.3719\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5692.9043 - val_loss: 93.4233\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17689.9609 - val_loss: 93.7253\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13723.9600 - val_loss: 95.5314\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 46087.9062 - val_loss: 99.9524\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 56542.0508 - val_loss: 99.8467\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 132103.1406 - val_loss: 98.9775\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 29932.7207 - val_loss: 97.3010\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 60397.7578 - val_loss: 96.4898\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 26518.8145 - val_loss: 96.9133\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 20083.1836 - val_loss: 98.7776\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3b3e79ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 46 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 95642.7578 - val_loss: 81.3449\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 6164.2842 - val_loss: 85.6851\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 38877.0000 - val_loss: 82.2034\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 131312.0469 - val_loss: 84.3394\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16417.7363 - val_loss: 87.7719\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 62609.6836 - val_loss: 87.1171\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15776.6797 - val_loss: 84.4494\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 103610.2734 - val_loss: 82.7711\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 48399.6562 - val_loss: 88.4362\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 116632.7891 - val_loss: 90.6107\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9085.9092 - val_loss: 87.4955\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26112.9160 - val_loss: 87.6447\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 57075.3086 - val_loss: 87.7191\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 49122.3906 - val_loss: 89.0670\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 70663.9375 - val_loss: 88.1180\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33867.1484 - val_loss: 88.7745\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2967.6660 - val_loss: 88.6956\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 79090.7344 - val_loss: 89.2783\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1767.5839 - val_loss: 91.9008\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 78166.8203 - val_loss: 92.3388\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 103887.8281 - val_loss: 90.1431\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 140342.1250 - val_loss: 89.5067\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3247.0071 - val_loss: 92.4173\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 89782.8594 - val_loss: 95.2538\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55542.2305 - val_loss: 92.4605\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1235.8540 - val_loss: 87.6939\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 115453.8047 - val_loss: 86.1566\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 90781.9766 - val_loss: 90.7481\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 42886.4844 - val_loss: 96.7650\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 167201.9062 - val_loss: 98.5586\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 155544.1719 - val_loss: 96.5463\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 43262.7344 - val_loss: 93.6371\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 23377.1816 - val_loss: 89.0026\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 85244.0234 - val_loss: 87.5656\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 121625.4766 - val_loss: 88.1608\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 109897.8516 - val_loss: 90.1409\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 52398.5312 - val_loss: 93.3137\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 98224.8281 - val_loss: 95.0948\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 58321.9414 - val_loss: 93.3288\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22177.5469 - val_loss: 90.4397\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 101253.9297 - val_loss: 89.9368\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 132290.1250 - val_loss: 90.7596\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 57724.1758 - val_loss: 92.8110\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1041.3103 - val_loss: 93.5206\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25484.3047 - val_loss: 93.0714\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 53117.3242 - val_loss: 92.1937\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 60681.6992 - val_loss: 93.4687\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 2141.8506 - val_loss: 93.6822\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 36054.6953 - val_loss: 92.7863\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 73911.8672 - val_loss: 92.6586\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff4212dd8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 47 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 146ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - val_loss: 96.2255\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff338511d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 48 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 157ms/step - loss: 114128.6328 - val_loss: 87.2224\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 186227.5469 - val_loss: 78.7981\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 86306.3438 - val_loss: 83.7525\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 108260.5859 - val_loss: 97.0355\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 168564.3750 - val_loss: 98.3864\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 121035.0234 - val_loss: 95.5543\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 34535.0625 - val_loss: 91.3797\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 47849.4961 - val_loss: 89.2382\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 25141.0059 - val_loss: 92.6216\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8769.0889 - val_loss: 97.7007\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 144863.9531 - val_loss: 99.0487\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 148113.7969 - val_loss: 96.4435\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3947.8533 - val_loss: 95.3013\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 28715.3359 - val_loss: 94.0079\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 65264.7969 - val_loss: 90.9475\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 117592.0000 - val_loss: 90.1282\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 61222.9336 - val_loss: 94.4611\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33011.1445 - val_loss: 94.8163\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 101645.4531 - val_loss: 93.7296\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 26505.4844 - val_loss: 93.5504\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12947.8770 - val_loss: 93.1796\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10911.3584 - val_loss: 93.4346\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20262.1777 - val_loss: 92.5747\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16028.2090 - val_loss: 93.2200\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10390.7432 - val_loss: 92.8245\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 69775.0391 - val_loss: 93.3093\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4917.1343 - val_loss: 92.7317\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 57321.8086 - val_loss: 93.1623\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7339.1250 - val_loss: 96.0997\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 66449.0234 - val_loss: 96.4268\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 73847.5625 - val_loss: 93.8800\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 5499.8921 - val_loss: 93.4458\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 7491.5747 - val_loss: 93.8779\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15726.0742 - val_loss: 94.9092\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25759.1719 - val_loss: 96.6610\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 76730.2969 - val_loss: 98.2702\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 81509.9844 - val_loss: 97.6273\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1358.3344 - val_loss: 92.8714\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 124730.5391 - val_loss: 90.7317\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 61623.9609 - val_loss: 94.4734\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 45761.2188 - val_loss: 96.2039\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18993.8770 - val_loss: 97.2086\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 52591.5742 - val_loss: 96.7638\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20652.6016 - val_loss: 95.8884\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12426.0547 - val_loss: 91.9104\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 147987.8750 - val_loss: 90.9603\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 132491.5625 - val_loss: 92.5012\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 106002.3516 - val_loss: 95.2355\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15778.4951 - val_loss: 98.6420\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 61754.6328 - val_loss: 99.1366\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff34d897280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 49 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 68.7944 - val_loss: 41.3806\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 52.7813 - val_loss: 34.3073\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36.5250 - val_loss: 41.7020\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 32.0977 - val_loss: 23.9370\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 25.0179 - val_loss: 12.1978\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 22.3441 - val_loss: 12.4700\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 21.6851 - val_loss: 4.7058\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 20.6893 - val_loss: 3.1761\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19.1984 - val_loss: 6.3359\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.2045 - val_loss: 5.7344\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.1512 - val_loss: 5.4322\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.8560 - val_loss: 3.3856\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.4645 - val_loss: 4.4036\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 17.2452 - val_loss: 6.1899\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 17.5463 - val_loss: 4.8173\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.4729 - val_loss: 4.6432\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.7794 - val_loss: 4.1716\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.2963 - val_loss: 3.7998\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.9248 - val_loss: 4.1540\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.2051 - val_loss: 4.2692\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.1179 - val_loss: 4.7235\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.0712 - val_loss: 4.6895\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.9287 - val_loss: 5.8153\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.5883 - val_loss: 4.1887\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.6074 - val_loss: 4.5267\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.6999 - val_loss: 4.3875\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.5495 - val_loss: 4.0616\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.6098 - val_loss: 5.8049\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.0060 - val_loss: 4.5751\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 14.7635 - val_loss: 2.3599\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.4696 - val_loss: 4.2613\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 12.6316 - val_loss: 4.3422\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.9357 - val_loss: 3.3909\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.2283 - val_loss: 3.7045\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14.8432 - val_loss: 6.6137\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.0837 - val_loss: 3.1187\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.7796 - val_loss: 2.7121\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.7768 - val_loss: 3.4709\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.5077 - val_loss: 5.0399\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.6097 - val_loss: 2.9882\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.8151 - val_loss: 2.7166\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.8353 - val_loss: 5.8914\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.5337 - val_loss: 2.8002\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.6749 - val_loss: 3.9572\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.4390 - val_loss: 2.7638\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6578 - val_loss: 2.8694\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.0134 - val_loss: 6.0422\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.6023 - val_loss: 2.3790\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.7509 - val_loss: 4.5545\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.2420 - val_loss: 3.6166\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff341398b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 50 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 165ms/step - loss: 60.7159 - val_loss: 34.1943\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 40.5730 - val_loss: 40.3721\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 33.1021 - val_loss: 37.0762\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 28.1332 - val_loss: 24.5960\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 24.9780 - val_loss: 23.1395\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 19.2969 - val_loss: 17.8245\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 16.6075 - val_loss: 5.4782\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13.9982 - val_loss: 3.9056\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 16.2034 - val_loss: 3.6817\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.5031 - val_loss: 15.0863\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 14.5457 - val_loss: 3.6991\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.4211 - val_loss: 6.9312\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 11.9136 - val_loss: 5.5632\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.4441 - val_loss: 9.1014\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12.3553 - val_loss: 3.8600\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.2184 - val_loss: 7.6476\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 12.1659 - val_loss: 3.5940\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.5437 - val_loss: 8.4753\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 10.8212 - val_loss: 5.0096\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.0188 - val_loss: 6.6291\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.6032 - val_loss: 5.0306\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.5561 - val_loss: 5.7545\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.7264 - val_loss: 5.8702\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.2191 - val_loss: 6.5576\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.7007 - val_loss: 4.1679\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 10.2728 - val_loss: 8.0296\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.7989 - val_loss: 4.5742\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1673 - val_loss: 6.8557\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.0917 - val_loss: 3.6842\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.0569 - val_loss: 8.6772\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.6748 - val_loss: 3.6822\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1500 - val_loss: 3.8091\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.7628 - val_loss: 7.6646\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.5912 - val_loss: 4.5544\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.6264 - val_loss: 3.8520\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.2480 - val_loss: 4.7926\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.8130 - val_loss: 5.4108\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.6136 - val_loss: 5.0928\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 10.9958 - val_loss: 5.9185\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.9928 - val_loss: 3.5202\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5654 - val_loss: 3.9574\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.4693 - val_loss: 4.0527\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.7614 - val_loss: 4.3548\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.6717 - val_loss: 3.4736\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.1112 - val_loss: 4.4617\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.5574 - val_loss: 3.9573\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5154 - val_loss: 5.1714\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.6608 - val_loss: 3.5266\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.6943 - val_loss: 6.8330\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.5685 - val_loss: 3.6727\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff346de5700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 51 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 666716.8750 - val_loss: 86.0782\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 111503.0547 - val_loss: 100.2788\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 42817.4883 - val_loss: 104.3775\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 284535.0000 - val_loss: 101.0973\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 218636.0781 - val_loss: 96.4094\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 201066.5000 - val_loss: 95.1296\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 92914.8906 - val_loss: 96.6949\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9094.6953 - val_loss: 102.3141\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 238881.5781 - val_loss: 104.2080\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 225407.5781 - val_loss: 101.2094\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 39214.8633 - val_loss: 96.1838\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 157716.7031 - val_loss: 95.2244\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 100936.4844 - val_loss: 98.4529\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10045.0273 - val_loss: 97.1239\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 66042.0000 - val_loss: 98.9294\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10406.3936 - val_loss: 103.0842\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 184067.2188 - val_loss: 104.0812\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 196769.6406 - val_loss: 101.9001\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11131.3564 - val_loss: 95.0797\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 209957.6562 - val_loss: 91.7778\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 177983.4688 - val_loss: 94.7823\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 254204.4531 - val_loss: 100.1127\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 102667.7031 - val_loss: 101.5168\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 98912.8359 - val_loss: 99.7533\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 44327.3906 - val_loss: 98.9362\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 132369.5469 - val_loss: 99.1041\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 64784.1367 - val_loss: 97.7318\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 41535.6562 - val_loss: 101.1510\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 89430.7891 - val_loss: 102.3192\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 48427.0117 - val_loss: 101.3335\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 103990.3750 - val_loss: 97.7801\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 113804.1562 - val_loss: 96.7255\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 118819.6953 - val_loss: 99.0966\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 119905.7891 - val_loss: 100.1709\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 74602.2109 - val_loss: 97.1588\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 93239.5469 - val_loss: 96.7365\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 55589.3477 - val_loss: 97.9331\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 39836.8242 - val_loss: 98.3575\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 23308.2637 - val_loss: 96.5516\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 68439.7734 - val_loss: 97.0879\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 73190.7266 - val_loss: 98.2520\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 24413.1016 - val_loss: 100.6778\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 76607.0625 - val_loss: 101.4835\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 677.0103 - val_loss: 102.1846\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 214104.4844 - val_loss: 102.4723\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 46539.9414 - val_loss: 102.1379\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 67840.4297 - val_loss: 99.5420\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8067.9268 - val_loss: 98.4202\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 57401.2188 - val_loss: 98.9366\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 4948.7207 - val_loss: 98.5103\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff338511550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 52 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 18138.1191 - val_loss: 106.6108\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 134823.7969 - val_loss: 104.2958\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 62589.1172 - val_loss: 99.0072\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 86487.6016 - val_loss: 97.6925\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 627.3592 - val_loss: 95.3537\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 102663.6328 - val_loss: 97.4493\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16353.5605 - val_loss: 104.5472\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 194656.4062 - val_loss: 107.6230\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 236611.6875 - val_loss: 98.6583\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 80827.6875 - val_loss: 95.3865\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 65687.4453 - val_loss: 98.5049\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42514.6133 - val_loss: 100.9523\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79883.3672 - val_loss: 98.1262\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9577.6875 - val_loss: 98.6944\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 57959.6641 - val_loss: 98.4628\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 21822.8184 - val_loss: 92.8653\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 124556.2266 - val_loss: 92.3530\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 127084.3828 - val_loss: 95.8866\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14363.1084 - val_loss: 102.2259\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 27494.7383 - val_loss: 103.3968\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 89066.9766 - val_loss: 100.9086\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 4146.3335 - val_loss: 96.8755\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 60765.1250 - val_loss: 95.9797\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15707.3506 - val_loss: 98.7370\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 121773.2500 - val_loss: 99.7468\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 47132.3867 - val_loss: 95.6009\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77541.5469 - val_loss: 95.1340\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 86431.8359 - val_loss: 98.1981\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 101603.6875 - val_loss: 99.0638\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 62843.4414 - val_loss: 96.8197\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56180.2305 - val_loss: 96.6577\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11917.9453 - val_loss: 96.4139\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71681.0859 - val_loss: 96.0354\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10906.9746 - val_loss: 97.1211\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 17492.0527 - val_loss: 98.4088\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 665.0565 - val_loss: 96.7031\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 44147.3281 - val_loss: 96.3784\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 55964.3633 - val_loss: 97.4704\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39941.3984 - val_loss: 98.8530\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3025.1660 - val_loss: 97.3795\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 52056.3242 - val_loss: 97.1538\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11465.9521 - val_loss: 96.8101\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9618.8096 - val_loss: 97.2367\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 18838.6953 - val_loss: 99.4707\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 99677.9453 - val_loss: 99.9311\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 37206.2344 - val_loss: 98.8437\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 2347.1052 - val_loss: 96.3672\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 141165.7969 - val_loss: 93.5275\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 132913.7500 - val_loss: 95.6625\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 126219.7891 - val_loss: 97.4793\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3726e5940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 53 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 86.7951 - val_loss: 59.0233\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.6478 - val_loss: 6.3713\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30.8705 - val_loss: 17.7675\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 21.7466 - val_loss: 31.3781\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21.4651 - val_loss: 25.3823\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 19.1694 - val_loss: 15.6599\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.7931 - val_loss: 11.2202\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.4100 - val_loss: 17.4247\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.5904 - val_loss: 5.5070\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.9355 - val_loss: 4.2728\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9121 - val_loss: 9.1506\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.0977 - val_loss: 3.7899\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.0612 - val_loss: 7.3922\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.0508 - val_loss: 5.8913\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.8997 - val_loss: 8.7288\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.4850 - val_loss: 4.2618\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.3631 - val_loss: 6.5239\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.1785 - val_loss: 3.1803\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.3082 - val_loss: 6.1632\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.5880 - val_loss: 4.0715\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.5371 - val_loss: 2.7915\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.4783 - val_loss: 4.9559\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.1170 - val_loss: 2.9993\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 11.1241 - val_loss: 4.8995\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3575 - val_loss: 4.9432\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.4833 - val_loss: 7.1767\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.1145 - val_loss: 3.1551\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7676 - val_loss: 9.5804\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.0219 - val_loss: 3.6867\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.3301 - val_loss: 5.3243\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.9023 - val_loss: 3.2490\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.2831 - val_loss: 2.4596\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 10.4343 - val_loss: 5.0441\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.4276 - val_loss: 2.6683\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6305 - val_loss: 3.3088\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.7098 - val_loss: 3.5582\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3479 - val_loss: 7.0096\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.9567 - val_loss: 2.6491\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9296 - val_loss: 5.8498\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.4921 - val_loss: 2.7806\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.4547 - val_loss: 4.5913\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0369 - val_loss: 2.7068\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.4279 - val_loss: 3.2797\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0148 - val_loss: 4.7907\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9336 - val_loss: 3.0410\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.0194 - val_loss: 7.9009\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.6888 - val_loss: 2.8308\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.5742 - val_loss: 5.3370\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4878 - val_loss: 2.3296\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.4379 - val_loss: 2.6551\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37c893160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 54 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 161350.7969 - val_loss: 118.2714\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 614377.9375 - val_loss: 121.6058\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 342173.4688 - val_loss: 112.3929\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 55655.3281 - val_loss: 104.5230\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 127973.1328 - val_loss: 104.7851\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 29608.9805 - val_loss: 107.9842\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 177356.8750 - val_loss: 107.9077\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 143012.2031 - val_loss: 104.3785\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23493.2773 - val_loss: 104.0742\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 56883.1250 - val_loss: 104.5141\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 29618.2246 - val_loss: 103.6616\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 50398.5312 - val_loss: 105.7184\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 138618.7344 - val_loss: 105.3568\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 82576.0703 - val_loss: 103.7745\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70685.9219 - val_loss: 103.2188\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 46277.2500 - val_loss: 104.3743\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63772.7227 - val_loss: 103.2112\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 55546.7969 - val_loss: 105.0390\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 184083.3125 - val_loss: 105.9318\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11760.7168 - val_loss: 103.2244\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13260.6025 - val_loss: 101.4688\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 143300.2812 - val_loss: 102.3726\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48681.6094 - val_loss: 106.2581\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 147694.2031 - val_loss: 106.7063\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 166362.0156 - val_loss: 103.3959\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60962.4805 - val_loss: 99.9321\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 193265.7969 - val_loss: 99.1328\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 159581.6719 - val_loss: 100.5551\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 66485.5234 - val_loss: 102.3623\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 32111.2891 - val_loss: 101.6529\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17388.6621 - val_loss: 100.4257\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 90216.2578 - val_loss: 101.1169\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28906.4844 - val_loss: 102.3936\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 59478.8867 - val_loss: 100.6569\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 65028.6445 - val_loss: 100.5812\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31831.7031 - val_loss: 102.3523\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21464.9121 - val_loss: 102.4779\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 63949.0664 - val_loss: 100.6182\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56310.8281 - val_loss: 100.7927\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45217.7500 - val_loss: 100.2253\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 89973.3125 - val_loss: 100.2022\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76375.8125 - val_loss: 102.6464\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 118850.1328 - val_loss: 103.4646\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 53995.9062 - val_loss: 100.4854\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22291.2656 - val_loss: 99.5682\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 140316.7656 - val_loss: 100.4361\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 119678.8828 - val_loss: 102.7669\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 74640.2969 - val_loss: 102.3651\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 29982.6055 - val_loss: 101.4441\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18279.6699 - val_loss: 101.5034\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3831e1430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 55 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 340553.7188 - val_loss: 97.7770\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 123444.1875 - val_loss: 105.4947\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43612.0273 - val_loss: 98.8941\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 52620.8594 - val_loss: 96.8400\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 63864.3945 - val_loss: 98.3277\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3468.4250 - val_loss: 109.3768\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 295904.9062 - val_loss: 112.8006\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 242758.8906 - val_loss: 106.5778\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 105806.0625 - val_loss: 100.6852\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10636.7939 - val_loss: 91.6500\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 149269.4531 - val_loss: 91.5568\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 140100.7812 - val_loss: 92.7926\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 88989.3438 - val_loss: 99.4999\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7413.3633 - val_loss: 100.3110\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45170.0352 - val_loss: 97.7292\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 37498.1797 - val_loss: 99.4058\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10428.2988 - val_loss: 103.2857\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 76700.3125 - val_loss: 102.3479\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 24146.1035 - val_loss: 98.9731\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 36986.9258 - val_loss: 98.3751\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12093.5029 - val_loss: 97.9018\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 30289.9629 - val_loss: 99.1360\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 47723.3047 - val_loss: 99.1458\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39566.3164 - val_loss: 98.6150\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 5990.4019 - val_loss: 102.6218\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 98395.0781 - val_loss: 103.8740\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 81679.6484 - val_loss: 102.1541\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 56974.5312 - val_loss: 96.0215\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 75754.6484 - val_loss: 94.3499\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 80403.0625 - val_loss: 96.2580\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34059.3633 - val_loss: 98.8002\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 41504.5742 - val_loss: 100.3862\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28591.2363 - val_loss: 97.3705\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12710.8652 - val_loss: 96.5638\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 37194.6016 - val_loss: 98.6469\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 25433.6113 - val_loss: 102.2878\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79647.0859 - val_loss: 102.4129\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 44807.5508 - val_loss: 101.3795\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42019.0508 - val_loss: 96.6144\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 146377.7500 - val_loss: 94.6062\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 128846.8984 - val_loss: 97.4011\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45349.6367 - val_loss: 100.0792\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 77017.5859 - val_loss: 101.0808\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45973.2031 - val_loss: 100.3329\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34982.1953 - val_loss: 97.6387\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 74095.3984 - val_loss: 96.0970\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 76887.8281 - val_loss: 98.0346\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12589.1367 - val_loss: 100.8263\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 73482.3125 - val_loss: 101.8930\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 31767.2695 - val_loss: 101.1497\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff34b7023a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 56 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 42147.9961 - val_loss: 61.4616\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 228257.9688 - val_loss: 69.4814\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 85933.3516 - val_loss: 75.8496\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 69712.5391 - val_loss: 84.1644\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37461.8086 - val_loss: 76.3842\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 115239.5156 - val_loss: 77.1055\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 94399.2266 - val_loss: 82.7063\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 55729.1367 - val_loss: 86.4852\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25720.8613 - val_loss: 81.6477\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 143499.9844 - val_loss: 79.1522\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 45448.5234 - val_loss: 85.1796\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9931.7891 - val_loss: 94.1474\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 186887.0938 - val_loss: 97.7089\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 126688.7344 - val_loss: 92.9736\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56110.2227 - val_loss: 85.6359\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 85792.0938 - val_loss: 86.0837\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 45363.2734 - val_loss: 89.1289\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 136004.8906 - val_loss: 91.1307\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 14409.4668 - val_loss: 89.2446\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24802.7852 - val_loss: 89.9184\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22331.1328 - val_loss: 89.0874\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 100363.3125 - val_loss: 88.5517\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25236.7676 - val_loss: 91.2446\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6025.0566 - val_loss: 91.6949\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1633.1755 - val_loss: 91.1489\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32903.2812 - val_loss: 89.5950\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 35481.0430 - val_loss: 92.4065\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 60954.8633 - val_loss: 92.0259\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48947.8867 - val_loss: 93.6950\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 34811.9648 - val_loss: 93.1885\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2486.0645 - val_loss: 91.5703\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10760.6875 - val_loss: 87.5359\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 152635.6250 - val_loss: 87.6892\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 137202.7812 - val_loss: 90.1326\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 65059.1562 - val_loss: 92.0769\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11662.4658 - val_loss: 95.7948\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 117708.6016 - val_loss: 97.4402\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 81249.7188 - val_loss: 95.7106\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 22976.0352 - val_loss: 90.4152\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7618.7910 - val_loss: 81.0395\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 225887.0781 - val_loss: 81.1530\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 274500.9375 - val_loss: 84.4408\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 105725.6562 - val_loss: 89.6456\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 86621.3906 - val_loss: 94.6703\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 85384.7344 - val_loss: 96.6692\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 41788.9102 - val_loss: 95.0884\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9113.0205 - val_loss: 91.9568\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31451.3066 - val_loss: 87.9088\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 175638.3125 - val_loss: 87.0343\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 156141.8125 - val_loss: 89.0300\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff33a0ca790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 57 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 45.9416 - val_loss: 16.9009\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34.3839 - val_loss: 21.7504\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27.1069 - val_loss: 35.3595\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 25.0947 - val_loss: 21.7785\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 21.1226 - val_loss: 9.6845\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18.7851 - val_loss: 19.7612\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.4971 - val_loss: 4.8058\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.6369 - val_loss: 9.5245\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.6859 - val_loss: 3.0087\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.0783 - val_loss: 7.4002\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.4455 - val_loss: 4.0249\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.1897 - val_loss: 4.2688\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.1342 - val_loss: 6.4856\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7460 - val_loss: 3.2331\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1900 - val_loss: 6.2216\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.7656 - val_loss: 3.5255\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.9483 - val_loss: 5.9420\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.5897 - val_loss: 3.9549\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.2415 - val_loss: 7.5081\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.3091 - val_loss: 3.6136\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.5965 - val_loss: 5.8026\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.6830 - val_loss: 5.2032\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.5177 - val_loss: 5.1780\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.7026 - val_loss: 4.3121\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.1869 - val_loss: 5.7281\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.1191 - val_loss: 3.6243\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.2885 - val_loss: 4.2815\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.1884 - val_loss: 7.1890\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6423 - val_loss: 4.9580\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3458 - val_loss: 4.2374\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.6575 - val_loss: 4.4083\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.7786 - val_loss: 3.5184\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.2992 - val_loss: 8.0452\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.2408 - val_loss: 4.2431\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.7081 - val_loss: 7.4080\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.3280 - val_loss: 3.5602\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.4427 - val_loss: 6.3506\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6561 - val_loss: 4.8046\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.6208 - val_loss: 4.9368\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.2709 - val_loss: 4.7350\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3226 - val_loss: 6.4293\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1301 - val_loss: 4.6951\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6639 - val_loss: 5.6334\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0371 - val_loss: 4.4987\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.4019 - val_loss: 3.7188\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 8.2473 - val_loss: 7.1317\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.6331 - val_loss: 3.5014\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.9387 - val_loss: 3.4516\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.5146 - val_loss: 5.7337\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.2850 - val_loss: 3.8535\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff340b75a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 58 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 6485606.0000 - val_loss: 98.2353\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5213491.0000 - val_loss: 98.5527\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 3646318.0000 - val_loss: 98.3447\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 2090046.5000 - val_loss: 98.0993\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1372134.7500 - val_loss: 98.0389\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 948807.2500 - val_loss: 97.8918\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 717920.3750 - val_loss: 97.7134\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 690210.5625 - val_loss: 97.6302\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 396983.9375 - val_loss: 97.5115\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 307411.0000 - val_loss: 97.3925\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 441651.9375 - val_loss: 97.2294\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 625899.1875 - val_loss: 97.1556\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 610420.5000 - val_loss: 97.0436\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 512034.2500 - val_loss: 96.9036\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 388894.2500 - val_loss: 96.7640\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 195799.5469 - val_loss: 96.6258\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 218806.6406 - val_loss: 96.5013\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 126761.3047 - val_loss: 96.3394\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 177632.4219 - val_loss: 96.2151\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 177383.4531 - val_loss: 96.0887\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 194728.8125 - val_loss: 95.9482\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 190610.1406 - val_loss: 95.8014\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 201689.0312 - val_loss: 95.6641\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 233411.1094 - val_loss: 95.5307\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 165647.6719 - val_loss: 95.4093\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 289552.8750 - val_loss: 95.2999\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 339391.4062 - val_loss: 95.2495\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 301760.1875 - val_loss: 95.1943\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 271619.3750 - val_loss: 95.1252\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 264183.7500 - val_loss: 95.0391\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 402901.8438 - val_loss: 94.9987\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 246692.3438 - val_loss: 94.9579\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 247320.8125 - val_loss: 94.8915\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 412706.9062 - val_loss: 94.8492\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 368486.2812 - val_loss: 94.7979\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 338955.5938 - val_loss: 94.7865\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 484065.4688 - val_loss: 94.7662\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 309970.6250 - val_loss: 94.7155\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 466802.3125 - val_loss: 94.6952\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 251064.3750 - val_loss: 94.6642\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 319240.1250 - val_loss: 94.6178\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 220042.9375 - val_loss: 94.5601\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 227054.2656 - val_loss: 94.4763\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 162182.5781 - val_loss: 94.4116\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 251290.2656 - val_loss: 94.3695\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 150809.0625 - val_loss: 94.3148\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 260383.3750 - val_loss: 94.2569\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 373635.7188 - val_loss: 94.2266\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 344957.4375 - val_loss: 94.2161\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 329816.0938 - val_loss: 94.2108\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3287ce160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 59 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 79.0709 - val_loss: 44.3308\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 46.6031 - val_loss: 22.7475\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 38.4121 - val_loss: 46.6252\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 36.3496 - val_loss: 43.9915\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 30.9719 - val_loss: 28.2033\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28.2187 - val_loss: 20.8379\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25.7710 - val_loss: 27.9361\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23.0621 - val_loss: 20.3888\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19.1569 - val_loss: 15.4207\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.4166 - val_loss: 7.4800\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 16.3263 - val_loss: 11.5147\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.2787 - val_loss: 10.2676\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.4755 - val_loss: 13.6816\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.7631 - val_loss: 7.5959\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.4483 - val_loss: 11.2643\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.8134 - val_loss: 3.5283\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14.8046 - val_loss: 12.1975\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.8231 - val_loss: 4.0213\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.6119 - val_loss: 13.1911\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13.9501 - val_loss: 3.5975\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.4382 - val_loss: 14.5015\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.2535 - val_loss: 4.0100\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.8449 - val_loss: 9.8639\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.9574 - val_loss: 6.2825\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.3875 - val_loss: 7.1952\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.3197 - val_loss: 6.5474\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.2381 - val_loss: 4.8287\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.1628 - val_loss: 6.9275\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.8305 - val_loss: 3.8941\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.2606 - val_loss: 8.6243\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.0178 - val_loss: 3.3305\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.3514 - val_loss: 8.6226\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.6725 - val_loss: 3.2009\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.7182 - val_loss: 4.4154\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7572 - val_loss: 3.3235\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.5729 - val_loss: 8.2551\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.1976 - val_loss: 2.8029\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.5368 - val_loss: 6.5528\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.7861 - val_loss: 5.4440\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.8382 - val_loss: 8.5993\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.8476 - val_loss: 4.3250\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.1158 - val_loss: 6.8629\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.3905 - val_loss: 5.2941\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.5788 - val_loss: 7.4032\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.0060 - val_loss: 3.4140\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.3118 - val_loss: 5.4277\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1885 - val_loss: 5.8597\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9680 - val_loss: 3.4361\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.4014 - val_loss: 5.4217\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1345 - val_loss: 3.2432\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff32f613820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 60 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 76.1753 - val_loss: 48.3558\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 42.5145 - val_loss: 22.3848\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 37.1764 - val_loss: 41.6592\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 33.5168 - val_loss: 44.4621\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 28.3278 - val_loss: 30.1824\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26.2144 - val_loss: 16.9756\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22.2071 - val_loss: 23.2087\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20.0653 - val_loss: 18.7599\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.0571 - val_loss: 4.3501\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 16.0178 - val_loss: 7.8441\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.8465 - val_loss: 4.7097\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.8694 - val_loss: 7.5849\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.0647 - val_loss: 7.6354\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 14.2497 - val_loss: 6.1312\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.5170 - val_loss: 10.4612\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 15.0941 - val_loss: 3.4489\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.8591 - val_loss: 5.6329\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 14.1637 - val_loss: 4.6627\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.7739 - val_loss: 3.9562\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 12.6095 - val_loss: 5.4841\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.0634 - val_loss: 4.6344\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.5500 - val_loss: 4.0045\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.7035 - val_loss: 5.4504\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.3129 - val_loss: 4.1289\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.3053 - val_loss: 5.7073\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 12.4726 - val_loss: 4.3228\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.9357 - val_loss: 4.7801\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.0898 - val_loss: 3.8678\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.9163 - val_loss: 3.7401\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.5699 - val_loss: 4.0026\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.8059 - val_loss: 3.8771\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.5952 - val_loss: 4.4415\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.1175 - val_loss: 4.1654\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.5821 - val_loss: 3.8435\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.5224 - val_loss: 4.9729\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.5333 - val_loss: 4.5738\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.7660 - val_loss: 3.9534\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.3542 - val_loss: 4.9102\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 10.2359 - val_loss: 3.8030\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.5539 - val_loss: 3.3234\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.3446 - val_loss: 4.1153\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.2889 - val_loss: 3.5229\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.9041 - val_loss: 3.3268\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.2423 - val_loss: 3.3682\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.8624 - val_loss: 3.2479\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.0360 - val_loss: 3.1604\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.0892 - val_loss: 3.4820\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.2525 - val_loss: 3.4704\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.3920 - val_loss: 3.6316\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7312 - val_loss: 3.1350\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff32a005c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 61 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 34631.7852 - val_loss: 86.7586\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 304674.0938 - val_loss: 92.4367\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 191679.6719 - val_loss: 101.0333\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20601.3691 - val_loss: 102.2447\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 53239.6680 - val_loss: 101.7044\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9180.7344 - val_loss: 104.3172\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 138143.6250 - val_loss: 105.9632\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 132208.4844 - val_loss: 101.9737\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 103759.8672 - val_loss: 95.6559\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 107880.9297 - val_loss: 96.2229\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 25784.7285 - val_loss: 99.3766\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 44645.6992 - val_loss: 99.4638\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5741.5845 - val_loss: 101.2060\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28903.3984 - val_loss: 100.8992\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22718.9004 - val_loss: 98.6922\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 103861.3594 - val_loss: 97.9569\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17796.8301 - val_loss: 100.3655\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 5088.6636 - val_loss: 101.8761\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 84064.0078 - val_loss: 100.6940\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 48192.4180 - val_loss: 99.9840\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28351.1582 - val_loss: 101.1963\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 109766.0859 - val_loss: 103.2615\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 67720.4766 - val_loss: 101.4524\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 59950.0938 - val_loss: 99.6885\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 62926.8633 - val_loss: 98.8583\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 32258.0723 - val_loss: 100.3152\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 5467.4692 - val_loss: 102.9906\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 98476.8438 - val_loss: 103.4813\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43674.8906 - val_loss: 101.4700\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21321.1680 - val_loss: 101.1048\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 2571.2539 - val_loss: 99.7828\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11856.8154 - val_loss: 100.3348\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 39935.1953 - val_loss: 98.9578\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24687.4629 - val_loss: 100.3676\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 18902.2754 - val_loss: 100.4707\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9360.6484 - val_loss: 100.9408\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 60137.0664 - val_loss: 100.4564\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34619.2188 - val_loss: 97.1429\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 82628.3359 - val_loss: 96.3653\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 108472.2812 - val_loss: 98.7659\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16043.7861 - val_loss: 99.1768\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 31476.7305 - val_loss: 99.7413\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 20320.2480 - val_loss: 99.4334\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 56579.0469 - val_loss: 100.0406\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 23826.9004 - val_loss: 99.9295\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 4692.1904 - val_loss: 98.4475\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10567.3779 - val_loss: 98.1210\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 104162.7422 - val_loss: 98.9537\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31119.9609 - val_loss: 101.1178\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7995.4292 - val_loss: 101.4817\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff335e75ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 62 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 71.1214 - val_loss: 41.0088\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 31.6458 - val_loss: 11.5442\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27.0077 - val_loss: 29.7483\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 23.0593 - val_loss: 25.5014\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19.9878 - val_loss: 15.3213\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 18.7168 - val_loss: 21.9824\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 19.8569 - val_loss: 17.2057\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 17.9192 - val_loss: 9.1138\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.1278 - val_loss: 21.9844\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 17.0236 - val_loss: 4.9260\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 15.0631 - val_loss: 14.9125\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.9985 - val_loss: 4.6567\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.4395 - val_loss: 6.1511\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.8342 - val_loss: 5.1842\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.8519 - val_loss: 6.5972\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.9501 - val_loss: 4.8147\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.6062 - val_loss: 10.8588\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.7138 - val_loss: 4.1529\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.0337 - val_loss: 5.9975\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.5485 - val_loss: 5.7591\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.9992 - val_loss: 4.0941\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.6168 - val_loss: 15.1859\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.6699 - val_loss: 3.9361\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.4292 - val_loss: 7.0355\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.8014 - val_loss: 4.7098\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.0962 - val_loss: 3.0963\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.5542 - val_loss: 6.2825\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4101 - val_loss: 6.9097\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.8232 - val_loss: 3.0749\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.3078 - val_loss: 6.2956\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.3775 - val_loss: 2.9949\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.9412 - val_loss: 7.0646\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.4461 - val_loss: 5.5783\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.5227 - val_loss: 3.8419\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.0332 - val_loss: 4.1195\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.0250 - val_loss: 2.9014\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1997 - val_loss: 7.5252\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.1056 - val_loss: 2.8823\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.1489 - val_loss: 3.0893\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.8319 - val_loss: 7.1375\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.0995 - val_loss: 3.3470\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.5245 - val_loss: 9.4375\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6519 - val_loss: 3.3809\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.8313 - val_loss: 7.0829\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1555 - val_loss: 4.7256\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.1718 - val_loss: 8.0911\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.9194 - val_loss: 3.4332\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.2849 - val_loss: 5.3556\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.2449 - val_loss: 3.6796\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.9763 - val_loss: 3.3340\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff377540a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 63 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 8178266.0000 - val_loss: 97.6160\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5798976.5000 - val_loss: 97.5246\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 4162876.2500 - val_loss: 97.8147\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 3438685.2500 - val_loss: 98.2807\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1784485.5000 - val_loss: 98.2683\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1337277.0000 - val_loss: 98.2650\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 966548.8125 - val_loss: 98.2365\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 746890.1250 - val_loss: 98.1839\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 447004.8438 - val_loss: 98.0800\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 253371.4688 - val_loss: 97.9908\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 191216.1250 - val_loss: 97.8594\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 190321.2344 - val_loss: 97.7311\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 176649.5625 - val_loss: 97.6210\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 154011.0469 - val_loss: 97.5013\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 152851.9219 - val_loss: 97.3872\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 202025.5156 - val_loss: 97.2920\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 236286.6875 - val_loss: 97.1583\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 422892.3438 - val_loss: 97.0102\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 260840.1562 - val_loss: 96.8680\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 265036.4062 - val_loss: 96.7562\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 384546.0938 - val_loss: 96.6335\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 323658.6562 - val_loss: 96.5782\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 256534.8906 - val_loss: 96.4831\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 214292.2031 - val_loss: 96.3589\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 287446.2812 - val_loss: 96.2602\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 291061.9688 - val_loss: 96.1455\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 382965.9375 - val_loss: 96.0518\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 270516.8125 - val_loss: 95.9387\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 262743.9688 - val_loss: 95.8017\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 288893.5938 - val_loss: 95.6842\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 440495.5938 - val_loss: 95.6159\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 481986.0625 - val_loss: 95.5541\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 341005.2500 - val_loss: 95.5105\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 318679.1562 - val_loss: 95.4779\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 418700.7500 - val_loss: 95.4416\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 635167.3750 - val_loss: 95.4108\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 665672.7500 - val_loss: 95.3843\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 639791.6875 - val_loss: 95.3703\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 689569.1875 - val_loss: 95.3546\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 719472.0000 - val_loss: 95.4286\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 538198.6875 - val_loss: 95.4437\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 343335.5625 - val_loss: 95.4647\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 339970.8750 - val_loss: 95.4766\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 364859.0000 - val_loss: 95.5076\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 311730.4062 - val_loss: 95.5295\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 236715.1875 - val_loss: 95.5497\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 313443.7500 - val_loss: 95.5764\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 225558.3438 - val_loss: 95.5794\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 331939.6875 - val_loss: 95.5660\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 229196.0000 - val_loss: 95.5399\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a0d12c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 64 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 212473.7031 - val_loss: 98.1915\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 189536.3750 - val_loss: 102.9192\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 105168.2734 - val_loss: 97.1332\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 152025.2500 - val_loss: 94.5020\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 43192.3242 - val_loss: 99.6516\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 110594.3125 - val_loss: 101.1267\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 152506.5469 - val_loss: 98.8293\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8090.1465 - val_loss: 96.8462\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 91537.9375 - val_loss: 95.6910\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 74914.6016 - val_loss: 96.5157\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 58152.5195 - val_loss: 99.7268\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 124891.7266 - val_loss: 100.8683\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 98106.8750 - val_loss: 100.2400\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 111407.7109 - val_loss: 97.1343\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19844.0156 - val_loss: 96.8868\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 37607.9648 - val_loss: 97.5585\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22007.4180 - val_loss: 100.1141\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41516.8906 - val_loss: 100.3879\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 94094.6719 - val_loss: 99.9111\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 61555.0391 - val_loss: 97.6761\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 46300.1680 - val_loss: 95.1413\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 105263.4688 - val_loss: 95.4954\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 75325.0625 - val_loss: 96.2468\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 47285.7188 - val_loss: 99.6774\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24367.7793 - val_loss: 100.2317\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 19313.5352 - val_loss: 98.1779\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 172421.6094 - val_loss: 97.5588\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 90328.2266 - val_loss: 99.1972\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 13734.2236 - val_loss: 100.3854\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 89136.3984 - val_loss: 100.4907\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 60564.5000 - val_loss: 99.2899\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 32836.8125 - val_loss: 97.4246\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 87295.1719 - val_loss: 96.5974\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 36954.1797 - val_loss: 98.1834\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 13697.4629 - val_loss: 100.9297\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 102504.0469 - val_loss: 101.0834\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 107850.5859 - val_loss: 100.3049\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 63565.6445 - val_loss: 98.5131\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8934.3086 - val_loss: 96.4870\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14224.4248 - val_loss: 96.1108\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 25448.9238 - val_loss: 97.2168\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 38360.6758 - val_loss: 96.9057\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 54991.2852 - val_loss: 97.8946\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 20037.6914 - val_loss: 97.8936\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 5852.5029 - val_loss: 97.8269\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6591.8340 - val_loss: 98.9376\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 33262.8906 - val_loss: 99.1941\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 45326.6211 - val_loss: 98.2514\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 33395.6797 - val_loss: 97.5963\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 42085.9102 - val_loss: 99.6562\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff414c889d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 65 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 57.5518 - val_loss: 18.6719\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 36.4082 - val_loss: 20.4647\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 28.3854 - val_loss: 32.8650\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 26.2450 - val_loss: 20.3237\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 24.0562 - val_loss: 18.4192\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 21.6219 - val_loss: 22.2552\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 20.0248 - val_loss: 13.4094\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 18.2114 - val_loss: 18.5494\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.8188 - val_loss: 8.0188\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.0648 - val_loss: 8.9401\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 15.4557 - val_loss: 8.0456\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.8761 - val_loss: 6.7800\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 13.0503 - val_loss: 10.8873\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.8386 - val_loss: 4.6386\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.2773 - val_loss: 7.6528\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.1486 - val_loss: 6.5222\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.0771 - val_loss: 4.3736\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.3828 - val_loss: 2.5476\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.0880 - val_loss: 4.7198\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.3233 - val_loss: 5.4009\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.3095 - val_loss: 2.6933\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 11.3585 - val_loss: 10.6420\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.0429 - val_loss: 2.5202\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.3242 - val_loss: 4.0165\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.1386 - val_loss: 2.7816\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2939 - val_loss: 5.5476\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.8404 - val_loss: 4.6249\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.5986 - val_loss: 3.4682\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.9346 - val_loss: 2.7486\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.3003 - val_loss: 3.2457\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.5698 - val_loss: 4.1441\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.3005 - val_loss: 5.8003\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3435 - val_loss: 3.6097\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.4440 - val_loss: 5.5840\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4567 - val_loss: 2.5778\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.9445 - val_loss: 4.1186\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.7264 - val_loss: 5.8788\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4798 - val_loss: 3.3962\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.9111 - val_loss: 5.5542\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1353 - val_loss: 7.1984\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.3720 - val_loss: 2.3485\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4740 - val_loss: 8.3640\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 8.7578 - val_loss: 2.6069\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5594 - val_loss: 6.0681\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1679 - val_loss: 2.7471\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.8854 - val_loss: 4.3755\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.7303 - val_loss: 4.0129\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.7190 - val_loss: 4.1512\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.7596 - val_loss: 2.9018\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.3148 - val_loss: 4.6254\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff338511040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 66 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 66.9479 - val_loss: 34.0113\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 42.1122 - val_loss: 19.2475\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 31.3163 - val_loss: 39.2513\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 27.1548 - val_loss: 37.4859\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 24.9842 - val_loss: 23.3033\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 22.4381 - val_loss: 19.3242\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 19.2751 - val_loss: 19.2577\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 16.1769 - val_loss: 11.2140\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.2188 - val_loss: 9.2508\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.9394 - val_loss: 6.5574\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.4571 - val_loss: 7.4376\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.6771 - val_loss: 12.2915\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 14.3596 - val_loss: 5.0785\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 13.6124 - val_loss: 10.5631\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 14.5800 - val_loss: 3.2163\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.0813 - val_loss: 11.1865\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.5177 - val_loss: 3.2856\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.9493 - val_loss: 9.3361\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.0722 - val_loss: 5.3230\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.0611 - val_loss: 5.5598\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.6721 - val_loss: 10.3745\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.5787 - val_loss: 3.8672\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.0403 - val_loss: 8.2594\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.6250 - val_loss: 4.1850\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.9301 - val_loss: 4.5662\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.5010 - val_loss: 7.9228\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.5891 - val_loss: 2.7499\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.0993 - val_loss: 9.8923\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.0214 - val_loss: 3.2214\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.6636 - val_loss: 5.9093\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.5532 - val_loss: 5.9761\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.3278 - val_loss: 3.6996\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.1932 - val_loss: 4.3742\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.8964 - val_loss: 2.5521\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.6207 - val_loss: 5.9658\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.1968 - val_loss: 2.5226\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.3679 - val_loss: 9.7334\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 11.0832 - val_loss: 2.3178\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.2291 - val_loss: 6.1278\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.1119 - val_loss: 2.9515\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.0941 - val_loss: 3.3933\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.7118 - val_loss: 3.7144\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.3359 - val_loss: 3.6784\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.4008 - val_loss: 3.2291\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.6512 - val_loss: 2.5576\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.9660 - val_loss: 5.4475\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.5354 - val_loss: 2.9566\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 9.0142 - val_loss: 4.4968\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.8609 - val_loss: 3.5966\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6470 - val_loss: 3.8631\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff332517820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 67 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 86.7468 - val_loss: 55.6722\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.3740 - val_loss: 9.7531\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28.2092 - val_loss: 21.6932\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21.6168 - val_loss: 28.8952\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20.3107 - val_loss: 18.5210\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 18.1151 - val_loss: 11.2578\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.2729 - val_loss: 19.5314\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 15.5965 - val_loss: 7.2722\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.4681 - val_loss: 6.1587\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.0197 - val_loss: 16.1824\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.7297 - val_loss: 6.4816\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.6534 - val_loss: 9.2209\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.5157 - val_loss: 6.4713\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.5892 - val_loss: 5.8023\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.8495 - val_loss: 7.5761\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10.3818 - val_loss: 5.9616\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.0575 - val_loss: 6.5746\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.9904 - val_loss: 6.3164\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.6152 - val_loss: 7.3534\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.5638 - val_loss: 5.7157\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.0025 - val_loss: 7.5094\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.7210 - val_loss: 5.7618\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7083 - val_loss: 7.6216\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.9948 - val_loss: 6.6616\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.8644 - val_loss: 5.8650\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.0211 - val_loss: 7.6538\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.8108 - val_loss: 6.2005\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.5754 - val_loss: 6.1242\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6425 - val_loss: 6.0412\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.5071 - val_loss: 6.5082\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5746 - val_loss: 6.2055\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5014 - val_loss: 6.7884\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.9369 - val_loss: 6.0929\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.5120 - val_loss: 6.2006\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4815 - val_loss: 5.7965\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 8.6534 - val_loss: 6.5043\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.7262 - val_loss: 5.6951\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.9301 - val_loss: 6.7137\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5079 - val_loss: 5.9458\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1255 - val_loss: 7.1106\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.3098 - val_loss: 6.0372\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0629 - val_loss: 5.8995\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.6055 - val_loss: 7.7048\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6020 - val_loss: 6.1505\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.3552 - val_loss: 7.4418\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2242 - val_loss: 5.6259\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.0091 - val_loss: 7.9123\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.6715 - val_loss: 5.5679\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1063 - val_loss: 7.9046\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.9080 - val_loss: 5.5973\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff339a73ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 68 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 70.8277 - val_loss: 35.4691\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31.5045 - val_loss: 4.5285\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 26.1378 - val_loss: 26.3508\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24.0777 - val_loss: 31.6856\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21.5973 - val_loss: 21.3781\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 19.4601 - val_loss: 10.9022\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 18.0092 - val_loss: 16.8419\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 16.1355 - val_loss: 16.2129\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 14.7995 - val_loss: 4.1997\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.4280 - val_loss: 10.6559\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.3467 - val_loss: 3.5998\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1706 - val_loss: 4.4428\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.9416 - val_loss: 4.1508\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6873 - val_loss: 3.1916\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 9.6479 - val_loss: 7.9437\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.5887 - val_loss: 3.2513\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.7361 - val_loss: 3.7523\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0133 - val_loss: 3.8084\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3518 - val_loss: 5.3077\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.6805 - val_loss: 3.7128\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5902 - val_loss: 4.4572\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.1269 - val_loss: 4.0442\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.4065 - val_loss: 3.6272\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.6019 - val_loss: 3.7895\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.6608 - val_loss: 5.6159\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2953 - val_loss: 4.4318\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.8394 - val_loss: 4.0541\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1948 - val_loss: 3.5754\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.5474 - val_loss: 8.0781\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.7568 - val_loss: 9.3894\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.5259 - val_loss: 4.3592\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.1312 - val_loss: 3.5754\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.3839 - val_loss: 4.1884\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6333 - val_loss: 3.6418\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2019 - val_loss: 3.7647\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.7586 - val_loss: 3.6469\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4641 - val_loss: 4.2709\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.7026 - val_loss: 4.1153\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.3115 - val_loss: 3.7843\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2447 - val_loss: 3.7010\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.9908 - val_loss: 3.7104\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.5554 - val_loss: 3.7038\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 7.6263 - val_loss: 3.6091\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.4665 - val_loss: 3.8607\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5545 - val_loss: 4.0766\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.2137 - val_loss: 4.1000\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.3750 - val_loss: 7.1421\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.2702 - val_loss: 3.8056\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.5027 - val_loss: 3.7282\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.9665 - val_loss: 3.7992\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff32e2195e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 69 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 81.9368 - val_loss: 49.9562\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32.1914 - val_loss: 6.6527\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 31.6810 - val_loss: 19.1483\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22.6599 - val_loss: 31.1508\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 20.8347 - val_loss: 19.1441\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.1203 - val_loss: 9.3209\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.6459 - val_loss: 15.9830\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 15.9023 - val_loss: 16.7194\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.2506 - val_loss: 9.4675\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.8945 - val_loss: 8.8011\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.9151 - val_loss: 8.8844\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.5370 - val_loss: 6.2060\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 10.7515 - val_loss: 6.5284\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.5193 - val_loss: 6.7531\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.5176 - val_loss: 10.8289\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.7216 - val_loss: 4.8124\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6518 - val_loss: 6.5833\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.1272 - val_loss: 4.6174\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.5614 - val_loss: 4.6305\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.5092 - val_loss: 4.6910\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6525 - val_loss: 5.2814\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.8768 - val_loss: 5.4392\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3781 - val_loss: 4.5040\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.3507 - val_loss: 5.5604\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.2310 - val_loss: 6.1820\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.6970 - val_loss: 7.2296\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6792 - val_loss: 4.4545\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.3201 - val_loss: 5.3651\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6486 - val_loss: 5.0476\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.0837 - val_loss: 4.9076\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.3992 - val_loss: 4.9738\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.3134 - val_loss: 5.3309\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 9.0570 - val_loss: 6.7035\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.6515 - val_loss: 8.0806\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 8.8071 - val_loss: 5.6026\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.7564 - val_loss: 5.7860\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 7.8916 - val_loss: 6.6267\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.3336 - val_loss: 5.4406\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.1002 - val_loss: 5.1072\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.2278 - val_loss: 5.5550\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.4349 - val_loss: 4.5117\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.4076 - val_loss: 5.6273\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.0577 - val_loss: 5.8281\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.0050 - val_loss: 5.3413\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.9663 - val_loss: 4.7030\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.3908 - val_loss: 5.8421\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.8392 - val_loss: 6.4004\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.9293 - val_loss: 7.3579\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.3893 - val_loss: 9.1932\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.1316 - val_loss: 8.3567\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3348e3430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 70 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 1842004.6250 - val_loss: 87.4263\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 878953.7500 - val_loss: 113.9559\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1012587.3750 - val_loss: 106.5542\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 398899.6875 - val_loss: 97.5395\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 256254.0312 - val_loss: 99.9285\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 225773.1562 - val_loss: 105.4014\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 184926.0156 - val_loss: 103.0799\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26354.4297 - val_loss: 102.4432\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 172782.9531 - val_loss: 101.9156\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 382924.7812 - val_loss: 96.8000\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 199071.2031 - val_loss: 99.4331\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 504266.7500 - val_loss: 105.8293\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 462087.6875 - val_loss: 102.9044\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 223510.0000 - val_loss: 99.2861\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 42483.8438 - val_loss: 100.8837\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 178933.0000 - val_loss: 102.1138\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 156592.7031 - val_loss: 96.2161\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 416266.1562 - val_loss: 94.2704\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 468285.3750 - val_loss: 97.2379\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 145125.7656 - val_loss: 101.9516\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 158371.1250 - val_loss: 101.3807\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 75752.5703 - val_loss: 99.5473\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 130829.0156 - val_loss: 97.7641\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 251767.7344 - val_loss: 97.2764\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 94403.6406 - val_loss: 100.4964\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 387843.6250 - val_loss: 102.1438\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 90680.7578 - val_loss: 100.1852\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 51263.8203 - val_loss: 97.9226\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 108937.9531 - val_loss: 94.6319\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 399919.5625 - val_loss: 94.7115\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 218146.1562 - val_loss: 97.5030\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 65567.7109 - val_loss: 102.0239\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 103593.5469 - val_loss: 101.4485\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 208903.5469 - val_loss: 99.4493\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 174572.2969 - val_loss: 98.7672\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 224186.4219 - val_loss: 101.7493\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 197401.8281 - val_loss: 105.4628\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 246162.0000 - val_loss: 104.3076\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 142776.8125 - val_loss: 101.3767\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 108007.4062 - val_loss: 99.6356\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 155641.7031 - val_loss: 99.8401\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 89536.4062 - val_loss: 102.0643\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 157452.0469 - val_loss: 102.6902\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 197924.2031 - val_loss: 100.7578\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 40648.0742 - val_loss: 97.7535\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 163536.3750 - val_loss: 97.5219\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 255501.8125 - val_loss: 97.4131\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 230877.8906 - val_loss: 102.1389\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 213599.8750 - val_loss: 103.8834\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 57306.0938 - val_loss: 101.7948\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff32e219160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 71 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 109229.8438 - val_loss: 112.9788\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 177973.6250 - val_loss: 113.0220\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 147058.2344 - val_loss: 95.3453\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 72674.8750 - val_loss: 95.0366\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 33526.7070 - val_loss: 99.3984\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 617.5858 - val_loss: 116.1436\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 158953.7031 - val_loss: 118.0872\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 171518.4531 - val_loss: 113.4365\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 128737.1953 - val_loss: 106.5947\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10114.1621 - val_loss: 97.5292\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 148481.1875 - val_loss: 88.8750\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 171099.4844 - val_loss: 95.2466\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 68634.3125 - val_loss: 103.7624\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 61796.7500 - val_loss: 104.3816\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 14257.6680 - val_loss: 97.9433\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28837.7246 - val_loss: 98.9940\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8947.0811 - val_loss: 107.0084\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 79396.4766 - val_loss: 106.4346\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22157.9590 - val_loss: 101.0659\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28077.6875 - val_loss: 90.3153\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 170008.4062 - val_loss: 90.6150\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 156420.5781 - val_loss: 98.3381\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 30407.3594 - val_loss: 101.6041\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11603.7412 - val_loss: 102.3050\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9820.2822 - val_loss: 98.8377\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 104152.8516 - val_loss: 98.1241\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 31213.5430 - val_loss: 100.2350\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12121.2998 - val_loss: 109.5561\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 226774.1094 - val_loss: 112.2386\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 143896.3750 - val_loss: 106.7792\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 66135.3047 - val_loss: 100.4406\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27637.6152 - val_loss: 93.6409\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 62172.1719 - val_loss: 92.1306\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 113356.6016 - val_loss: 94.3537\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 96482.4531 - val_loss: 98.6690\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 50011.0938 - val_loss: 103.7828\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 46774.7422 - val_loss: 107.2385\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 83753.0078 - val_loss: 103.6452\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21237.8340 - val_loss: 104.8293\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14320.5244 - val_loss: 104.3160\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 37098.6172 - val_loss: 97.6068\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 39345.8555 - val_loss: 96.0691\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63595.5938 - val_loss: 99.9857\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 93006.7266 - val_loss: 101.6435\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20269.9473 - val_loss: 100.5640\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 59487.3086 - val_loss: 100.2092\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 79031.1172 - val_loss: 97.9148\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 33942.8477 - val_loss: 102.6057\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 45181.4297 - val_loss: 104.1045\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 41974.6719 - val_loss: 100.0979\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff34d897040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 72 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 223220.4219 - val_loss: 90.8655\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1570083.6250 - val_loss: 94.7290\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 588795.5000 - val_loss: 100.4492\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43628.5625 - val_loss: 105.1370\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 566801.0000 - val_loss: 104.9587\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 313472.7188 - val_loss: 102.0410\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 92784.9766 - val_loss: 99.7497\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 164607.9531 - val_loss: 99.9221\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 248427.8906 - val_loss: 100.9200\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 68358.7500 - val_loss: 101.7770\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 96325.1562 - val_loss: 101.2384\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 112992.6328 - val_loss: 100.2163\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 149808.4688 - val_loss: 102.0837\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 171110.7500 - val_loss: 103.7641\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 310726.5312 - val_loss: 103.2553\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 255000.1875 - val_loss: 101.0963\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 55941.9609 - val_loss: 98.8091\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 422297.5938 - val_loss: 98.8242\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 101466.1953 - val_loss: 100.5505\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 160955.7344 - val_loss: 101.3714\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 55320.0781 - val_loss: 101.2588\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 43512.6953 - val_loss: 100.2397\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 120690.1953 - val_loss: 99.8789\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 118805.5938 - val_loss: 100.9840\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 151200.3750 - val_loss: 101.4179\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 51280.7773 - val_loss: 100.3606\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 48887.0352 - val_loss: 100.2744\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 24421.2539 - val_loss: 100.2329\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 143037.4688 - val_loss: 100.6296\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 33391.8398 - val_loss: 101.3247\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 61489.8359 - val_loss: 100.4500\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 65017.5469 - val_loss: 100.6236\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 110882.8438 - val_loss: 102.4062\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 182452.2188 - val_loss: 102.3479\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 136929.0312 - val_loss: 101.6958\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 69309.2422 - val_loss: 100.9132\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 43231.0977 - val_loss: 100.1376\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 91994.7500 - val_loss: 100.3025\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 90095.0469 - val_loss: 101.4210\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 80287.5625 - val_loss: 101.6621\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 77111.1562 - val_loss: 101.2159\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 154404.4062 - val_loss: 100.2660\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 148275.1406 - val_loss: 100.7397\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 79633.3125 - val_loss: 101.6193\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 101537.5625 - val_loss: 100.9215\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 111601.9219 - val_loss: 100.1414\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 197156.6250 - val_loss: 100.8343\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 92770.3438 - val_loss: 100.9730\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14532.6465 - val_loss: 99.4767\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 215708.3750 - val_loss: 99.4860\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff366c86dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 73 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 63426.8281 - val_loss: 84.8455\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 518846.6250 - val_loss: 91.4061\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 239738.9531 - val_loss: 99.0108\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12728.0391 - val_loss: 104.5105\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 63475.5117 - val_loss: 109.5880\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 210373.9688 - val_loss: 110.4587\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 198972.4375 - val_loss: 103.6971\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 121273.0938 - val_loss: 101.2986\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 55122.0273 - val_loss: 103.4045\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7336.9048 - val_loss: 106.5406\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 59835.9922 - val_loss: 106.8686\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 77151.2578 - val_loss: 104.9672\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21912.9805 - val_loss: 101.2257\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 149931.1250 - val_loss: 100.5263\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 116418.0391 - val_loss: 102.5441\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30581.7070 - val_loss: 105.8440\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 60568.5586 - val_loss: 105.8087\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 72028.3750 - val_loss: 103.7916\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19366.1016 - val_loss: 103.8355\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16508.1641 - val_loss: 102.1931\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 72998.0391 - val_loss: 102.8721\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 10910.2285 - val_loss: 102.9706\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18259.2344 - val_loss: 102.7029\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 24820.7520 - val_loss: 104.2593\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 80528.0781 - val_loss: 104.8418\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10821.5742 - val_loss: 103.0064\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 48917.7109 - val_loss: 102.2808\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35254.7734 - val_loss: 105.0791\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 130230.0234 - val_loss: 106.7853\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 35179.8828 - val_loss: 105.2315\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16528.3008 - val_loss: 103.0409\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 76638.9531 - val_loss: 100.6656\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 126457.8672 - val_loss: 101.5624\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 81323.1953 - val_loss: 103.5308\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18984.0449 - val_loss: 104.1301\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1732.7681 - val_loss: 104.4203\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 34451.3594 - val_loss: 104.6180\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 88734.6406 - val_loss: 103.9851\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 28838.3555 - val_loss: 102.8442\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 55408.7617 - val_loss: 103.5409\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 34144.9844 - val_loss: 103.3035\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 6700.1001 - val_loss: 102.3038\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 22376.8848 - val_loss: 102.6999\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1302.5791 - val_loss: 103.5734\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27633.4434 - val_loss: 103.5093\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 59420.7695 - val_loss: 102.8686\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10891.9141 - val_loss: 103.1528\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 3231.8623 - val_loss: 102.1815\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 38065.6055 - val_loss: 101.7945\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 24993.4512 - val_loss: 104.2057\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a388db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 74 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 67.2611 - val_loss: 39.2016\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 41.2576 - val_loss: 25.6986\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 34.6737 - val_loss: 35.4598\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28.0194 - val_loss: 27.5792\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 23.2805 - val_loss: 20.1180\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 17.6232 - val_loss: 12.4372\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.3032 - val_loss: 7.9086\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.8154 - val_loss: 3.9892\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 13.3392 - val_loss: 5.9011\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.9552 - val_loss: 8.4421\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.8874 - val_loss: 8.9500\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.5471 - val_loss: 4.5236\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.6526 - val_loss: 7.7351\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.3264 - val_loss: 5.8211\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.0580 - val_loss: 7.4107\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.5844 - val_loss: 7.8376\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.2004 - val_loss: 4.6007\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.3337 - val_loss: 6.2919\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.5926 - val_loss: 6.7237\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.7170 - val_loss: 5.5060\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.0877 - val_loss: 6.4166\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.1700 - val_loss: 4.3679\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.6020 - val_loss: 4.2239\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.7191 - val_loss: 6.9251\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 9.1294 - val_loss: 4.8843\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.8689 - val_loss: 8.1612\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.7539 - val_loss: 3.8578\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.6411 - val_loss: 7.1401\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0772 - val_loss: 5.1315\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.8258 - val_loss: 5.9332\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.2672 - val_loss: 5.0153\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.9661 - val_loss: 7.6896\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.2589 - val_loss: 3.8627\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.9540 - val_loss: 8.9338\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.1879 - val_loss: 3.8214\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.9232 - val_loss: 6.8556\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.8611 - val_loss: 4.2914\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4376 - val_loss: 6.1856\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 8.6026 - val_loss: 5.1058\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.6997 - val_loss: 6.3163\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.3077 - val_loss: 7.2105\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.8721 - val_loss: 3.5843\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 8.3297 - val_loss: 4.5883\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.1758 - val_loss: 4.6997\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 9.0748 - val_loss: 9.5015\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.9328 - val_loss: 5.3859\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.5397 - val_loss: 7.9982\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.8116 - val_loss: 3.7038\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 9.9599 - val_loss: 7.4750\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.2472 - val_loss: 6.1480\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff34cd36700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 75 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 66.9765 - val_loss: 42.3471\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 33.2970 - val_loss: 29.5066\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 28.8903 - val_loss: 35.6575\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 28.3507 - val_loss: 38.3530\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25.7467 - val_loss: 21.1494\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 22.3113 - val_loss: 25.4445\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20.5989 - val_loss: 23.4713\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19.8040 - val_loss: 13.9271\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.7113 - val_loss: 14.2738\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.1871 - val_loss: 6.6465\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 15.0253 - val_loss: 9.8529\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.5674 - val_loss: 7.8294\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.8865 - val_loss: 3.4342\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.1023 - val_loss: 7.5500\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.1174 - val_loss: 3.5085\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.4687 - val_loss: 3.9456\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.0675 - val_loss: 3.8865\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.6687 - val_loss: 3.6966\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.0010 - val_loss: 10.1022\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.8744 - val_loss: 3.8222\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.7117 - val_loss: 7.2874\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.2722 - val_loss: 3.3787\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.6672 - val_loss: 5.3676\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.4566 - val_loss: 3.7892\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.2825 - val_loss: 6.0689\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 15.0019 - val_loss: 3.5343\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.1537 - val_loss: 5.7396\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.7240 - val_loss: 7.2398\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.6426 - val_loss: 4.0275\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.8291 - val_loss: 5.3172\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.2886 - val_loss: 4.3294\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.8178 - val_loss: 6.5878\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.1864 - val_loss: 3.5651\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.1073 - val_loss: 5.9299\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.5450 - val_loss: 3.2419\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.8864 - val_loss: 3.7506\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 11.1248 - val_loss: 3.5438\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.8987 - val_loss: 4.6322\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.8981 - val_loss: 3.6231\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.5942 - val_loss: 5.7231\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.8063 - val_loss: 3.3134\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.2790 - val_loss: 8.1888\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.1124 - val_loss: 2.9502\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10.6797 - val_loss: 3.3902\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 10.2675 - val_loss: 2.8901\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.7324 - val_loss: 3.6555\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.7037 - val_loss: 5.6286\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.4276 - val_loss: 2.6907\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4666 - val_loss: 4.1034\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.7517 - val_loss: 3.4802\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3a38bdb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 76 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 4181.9438 - val_loss: 69.4818\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 456109.1562 - val_loss: 66.0461\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 391242.8750 - val_loss: 82.2012\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 32094.2266 - val_loss: 90.9260\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 103351.8672 - val_loss: 93.4703\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 84630.5703 - val_loss: 92.3991\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10000.2119 - val_loss: 87.4690\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 49383.9883 - val_loss: 86.2299\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 50957.5508 - val_loss: 86.5513\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 39498.8438 - val_loss: 91.1454\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 56363.4336 - val_loss: 93.5237\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 52354.1172 - val_loss: 90.1375\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 62754.5742 - val_loss: 89.0719\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 128137.2891 - val_loss: 93.5610\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 23980.2363 - val_loss: 93.1158\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15066.9932 - val_loss: 91.3959\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70016.2422 - val_loss: 90.7868\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 49565.5430 - val_loss: 93.9458\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 16400.9688 - val_loss: 94.3795\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 135066.1094 - val_loss: 93.9493\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16412.6855 - val_loss: 93.8469\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44728.4922 - val_loss: 92.5989\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 63479.8672 - val_loss: 92.6936\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12756.2207 - val_loss: 92.8558\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 60975.9805 - val_loss: 91.8350\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1824.3160 - val_loss: 93.6315\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 30648.3359 - val_loss: 94.6372\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2538.2976 - val_loss: 91.5521\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 62978.3750 - val_loss: 90.5008\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 138917.5312 - val_loss: 92.1253\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 63746.3086 - val_loss: 97.6683\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 74590.3906 - val_loss: 98.5229\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 89497.5391 - val_loss: 97.1865\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12360.5273 - val_loss: 93.9949\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14750.1904 - val_loss: 90.1176\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 165646.3906 - val_loss: 88.4175\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 113715.0156 - val_loss: 91.0697\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 116415.8438 - val_loss: 95.3497\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15403.0967 - val_loss: 95.9397\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 25465.1113 - val_loss: 95.4262\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19518.7871 - val_loss: 92.7034\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 62994.7109 - val_loss: 92.4292\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 74341.2266 - val_loss: 93.5016\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 24015.9121 - val_loss: 95.1098\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 2702.9561 - val_loss: 98.9345\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 148176.3125 - val_loss: 99.5944\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 120196.6875 - val_loss: 98.5739\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 45596.4688 - val_loss: 97.4842\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 74210.4375 - val_loss: 94.4759\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 50751.5898 - val_loss: 93.2916\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff315485820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 77 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 85.8981 - val_loss: 66.7804\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 70.0977 - val_loss: 58.5217\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 52.8684 - val_loss: 58.6552\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 43.3697 - val_loss: 34.9524\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 40.8400 - val_loss: 31.0860\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 36.3377 - val_loss: 35.9918\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34.8548 - val_loss: 22.5019\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 30.4717 - val_loss: 17.7859\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 27.6806 - val_loss: 12.0439\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 26.2165 - val_loss: 5.8317\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 24.8110 - val_loss: 5.7205\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 21.6135 - val_loss: 5.7165\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 23.3389 - val_loss: 6.2014\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 22.7723 - val_loss: 5.1075\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 20.2597 - val_loss: 4.6393\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 21.5624 - val_loss: 5.1760\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 19.0378 - val_loss: 4.9478\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 22.4585 - val_loss: 6.0588\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.3235 - val_loss: 6.4896\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.6295 - val_loss: 6.9243\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.7510 - val_loss: 4.5417\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.5792 - val_loss: 7.0337\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.4067 - val_loss: 9.6003\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.8184 - val_loss: 5.2740\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 19.5938 - val_loss: 3.4945\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 16.0431 - val_loss: 10.0236\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.5128 - val_loss: 4.2162\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 14.8731 - val_loss: 4.2284\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.9739 - val_loss: 5.4045\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 13.4785 - val_loss: 6.4679\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.0123 - val_loss: 4.9458\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.1969 - val_loss: 4.7865\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 14.7043 - val_loss: 4.3192\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.3355 - val_loss: 4.5327\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.1234 - val_loss: 7.0626\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.8152 - val_loss: 4.4752\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 13.0225 - val_loss: 4.3449\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.5167 - val_loss: 6.4025\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 13.4800 - val_loss: 3.7729\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.6596 - val_loss: 4.8216\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 13.1379 - val_loss: 3.5221\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.3901 - val_loss: 8.3664\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 13.2744 - val_loss: 6.8730\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.8252 - val_loss: 4.9535\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.8813 - val_loss: 4.6675\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.6193 - val_loss: 5.0007\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 12.6174 - val_loss: 3.5704\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 12.8975 - val_loss: 3.9332\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.7453 - val_loss: 4.6372\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.5815 - val_loss: 4.7514\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff316c404c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 78 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 77.4534 - val_loss: 58.0321\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37.5254 - val_loss: 21.2338\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 32.7625 - val_loss: 35.2537\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 26.9951 - val_loss: 34.4910\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 25.0241 - val_loss: 25.7166\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 22.4852 - val_loss: 18.1234\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 20.4935 - val_loss: 21.3185\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 19.1994 - val_loss: 5.6370\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.1500 - val_loss: 9.3564\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.8405 - val_loss: 7.4245\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.9846 - val_loss: 4.4763\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 14.0726 - val_loss: 8.1726\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.6209 - val_loss: 4.3024\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.1394 - val_loss: 10.8269\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 14.1260 - val_loss: 3.3009\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.1653 - val_loss: 5.7369\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 11.7779 - val_loss: 2.7696\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.5005 - val_loss: 5.9618\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.1082 - val_loss: 3.0428\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 11.7156 - val_loss: 4.0590\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.5032 - val_loss: 3.1542\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 10.1887 - val_loss: 4.0999\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.9875 - val_loss: 5.0851\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.7692 - val_loss: 5.1571\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.4140 - val_loss: 4.5526\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 8.8883 - val_loss: 3.1249\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.5221 - val_loss: 7.4719\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.3898 - val_loss: 3.9959\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.2308 - val_loss: 4.6656\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.5838 - val_loss: 3.3954\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1552 - val_loss: 3.5585\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.2529 - val_loss: 4.7339\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.6182 - val_loss: 4.5061\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.6337 - val_loss: 6.0910\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.9665 - val_loss: 4.0040\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.9054 - val_loss: 3.6555\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3680 - val_loss: 5.8912\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.0315 - val_loss: 3.7752\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.0562 - val_loss: 5.9996\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.6314 - val_loss: 4.2681\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.9652 - val_loss: 5.6561\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.3599 - val_loss: 4.4158\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.5691 - val_loss: 3.8025\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 8.1852 - val_loss: 5.8390\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.4857 - val_loss: 5.1428\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.3144 - val_loss: 6.4291\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.7865 - val_loss: 3.6171\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.5546 - val_loss: 4.2467\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.3799 - val_loss: 3.8573\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.2309 - val_loss: 5.5128\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff31aa8caf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 79 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 2348933.5000 - val_loss: 91.1707\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8949204.0000 - val_loss: 91.3664\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6802631.0000 - val_loss: 92.8351\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2856941.7500 - val_loss: 93.9853\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1754736.1250 - val_loss: 94.2969\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1111062.7500 - val_loss: 94.5066\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 739834.1875 - val_loss: 94.5216\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 794920.4375 - val_loss: 94.4755\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 591041.1875 - val_loss: 94.3456\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 379310.6875 - val_loss: 94.1874\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 350138.8750 - val_loss: 94.0264\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 347797.8125 - val_loss: 93.8609\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 291028.2188 - val_loss: 93.6941\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 290053.0000 - val_loss: 93.5414\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 328728.2500 - val_loss: 93.3530\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 274726.8125 - val_loss: 93.2065\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 211888.9062 - val_loss: 93.0190\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 352991.6875 - val_loss: 92.8512\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 214115.6875 - val_loss: 92.6751\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 191039.4844 - val_loss: 92.4993\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 246036.1250 - val_loss: 92.2799\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 195298.8750 - val_loss: 92.0567\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 216825.1875 - val_loss: 91.8383\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 253680.1250 - val_loss: 91.6255\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 278905.5625 - val_loss: 91.4059\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 463774.7812 - val_loss: 91.2347\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 459676.1562 - val_loss: 91.1652\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 274517.4062 - val_loss: 91.0908\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 150565.4062 - val_loss: 90.9937\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 270149.5938 - val_loss: 90.8866\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 355468.8750 - val_loss: 90.8467\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 679815.9375 - val_loss: 90.7939\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 504647.4688 - val_loss: 90.7933\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 558950.1250 - val_loss: 90.8071\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 434359.4062 - val_loss: 90.7557\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 490525.9062 - val_loss: 90.8250\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 561519.3750 - val_loss: 90.7656\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 482928.7500 - val_loss: 90.7220\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 343309.3750 - val_loss: 90.7341\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 255077.7969 - val_loss: 90.7607\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 228892.8750 - val_loss: 90.7500\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 320899.2812 - val_loss: 90.7892\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 288701.7812 - val_loss: 90.8004\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 268425.9688 - val_loss: 90.8220\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 389092.6875 - val_loss: 90.8518\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 326771.5312 - val_loss: 90.8897\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 241706.4688 - val_loss: 90.8854\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 216861.8125 - val_loss: 90.8841\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 277166.3125 - val_loss: 90.8555\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 224765.6562 - val_loss: 90.8588\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3219581f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 80 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 60.8361 - val_loss: 27.4380\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 34.5381 - val_loss: 27.4508\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 27.5165 - val_loss: 38.5595\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 26.3633 - val_loss: 25.3708\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 24.1189 - val_loss: 16.7691\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 21.0336 - val_loss: 25.7735\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 19.9033 - val_loss: 13.2144\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.3715 - val_loss: 14.3917\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.4224 - val_loss: 3.3486\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.1651 - val_loss: 10.8514\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 13.6836 - val_loss: 3.9424\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.1144 - val_loss: 12.2007\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 12.8960 - val_loss: 4.3542\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.9731 - val_loss: 7.5219\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 14.1595 - val_loss: 2.5968\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.9837 - val_loss: 7.6841\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.7254 - val_loss: 3.4557\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 12.1000 - val_loss: 4.1444\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 11.7170 - val_loss: 4.4301\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 12.6026 - val_loss: 6.3137\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.5813 - val_loss: 4.7689\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 11.1239 - val_loss: 3.4318\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 10.4472 - val_loss: 4.1441\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 11.8664 - val_loss: 10.4509\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.7268 - val_loss: 8.2145\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 12.3719 - val_loss: 7.5850\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 11.5868 - val_loss: 11.7778\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 13.8023 - val_loss: 3.2618\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 12.3786 - val_loss: 2.6083\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.8181 - val_loss: 7.2571\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 11.1482 - val_loss: 3.8069\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 11.2152 - val_loss: 5.0159\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.2320 - val_loss: 3.9374\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7132 - val_loss: 6.0068\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 10.7488 - val_loss: 4.2736\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6813 - val_loss: 2.9766\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.0026 - val_loss: 2.5535\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.2979 - val_loss: 3.2418\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3087 - val_loss: 3.0126\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 9.6559 - val_loss: 4.0940\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.4160 - val_loss: 3.8645\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.9623 - val_loss: 4.7327\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 10.0506 - val_loss: 5.2982\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 9.9485 - val_loss: 5.3753\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 9.9996 - val_loss: 7.0967\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 9.5879 - val_loss: 2.9562\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 9.3604 - val_loss: 4.6754\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7726 - val_loss: 2.5275\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.1190 - val_loss: 2.2413\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.1819 - val_loss: 4.5528\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff316c404c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 81 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 7148488.5000 - val_loss: 102.0972\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5835350.5000 - val_loss: 101.3467\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 4675998.5000 - val_loss: 101.4394\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3641550.2500 - val_loss: 100.9195\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2571488.7500 - val_loss: 100.5461\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1951645.2500 - val_loss: 100.2080\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1296180.0000 - val_loss: 99.9800\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1015391.1875 - val_loss: 99.7403\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 815498.8125 - val_loss: 99.5566\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 618859.1875 - val_loss: 99.3972\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 586117.3750 - val_loss: 99.2493\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 511626.0938 - val_loss: 99.1065\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 347833.7812 - val_loss: 98.9843\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 289844.2500 - val_loss: 98.8510\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 318892.8438 - val_loss: 98.7184\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 213994.8906 - val_loss: 98.6150\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 204811.0312 - val_loss: 98.4871\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 211915.6719 - val_loss: 98.3712\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 188802.4375 - val_loss: 98.2426\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 208296.3438 - val_loss: 98.1171\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 213026.0469 - val_loss: 98.0213\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 189095.4375 - val_loss: 97.9117\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 213616.0469 - val_loss: 97.8063\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 369636.4688 - val_loss: 97.7060\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 219569.8750 - val_loss: 97.6199\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 234978.9531 - val_loss: 97.5009\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 200852.7969 - val_loss: 97.4211\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 233617.0312 - val_loss: 97.3233\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 325649.9375 - val_loss: 97.2205\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 576011.1875 - val_loss: 97.1583\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 649741.6250 - val_loss: 97.0955\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 500874.5312 - val_loss: 97.0456\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 629428.8125 - val_loss: 96.9596\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 606727.2500 - val_loss: 96.8819\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 721945.1875 - val_loss: 96.9195\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 694675.4375 - val_loss: 96.8620\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 645915.3125 - val_loss: 96.7911\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 519173.7812 - val_loss: 96.7655\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 562521.4375 - val_loss: 96.6752\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 613880.7500 - val_loss: 96.6826\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 395879.3438 - val_loss: 96.6527\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 371979.2188 - val_loss: 96.6181\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 251023.1250 - val_loss: 96.5795\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 168952.2188 - val_loss: 96.5090\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 241100.0781 - val_loss: 96.4637\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 223660.1562 - val_loss: 96.4217\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 316210.1562 - val_loss: 96.3237\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 395243.6875 - val_loss: 96.2581\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 402208.0938 - val_loss: 96.2258\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 213931.6875 - val_loss: 96.2075\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff33e921040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 82 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 47251.1172 - val_loss: 80.8927\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 317702.7500 - val_loss: 78.5153\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 236943.1250 - val_loss: 90.3957\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 35437.9922 - val_loss: 100.8079\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 177450.0000 - val_loss: 105.6677\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 243718.2031 - val_loss: 102.2449\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 70426.8672 - val_loss: 99.2022\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17315.7422 - val_loss: 93.0212\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 172996.5625 - val_loss: 92.5720\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 147442.6094 - val_loss: 95.9579\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 61671.6992 - val_loss: 100.5354\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 75734.7109 - val_loss: 102.3736\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 74282.1641 - val_loss: 99.1778\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 34356.3672 - val_loss: 98.6180\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43892.7812 - val_loss: 98.1504\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7913.6851 - val_loss: 96.7258\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 106350.2734 - val_loss: 95.8074\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 66237.7578 - val_loss: 96.4304\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16338.2930 - val_loss: 99.5238\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 68207.9609 - val_loss: 100.8059\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 88637.5234 - val_loss: 100.2636\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 24613.8984 - val_loss: 96.5717\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 127356.4609 - val_loss: 94.3032\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 124588.1875 - val_loss: 95.6499\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1158.8953 - val_loss: 96.8993\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 30384.5820 - val_loss: 97.7717\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 2524.6411 - val_loss: 96.2515\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 86421.0078 - val_loss: 96.3724\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 49874.5781 - val_loss: 98.1973\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 56912.9883 - val_loss: 98.9928\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 77183.5312 - val_loss: 98.9023\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 10307.4570 - val_loss: 98.2631\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16366.4785 - val_loss: 97.8600\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6209.5449 - val_loss: 97.9334\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 39098.7617 - val_loss: 98.3180\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 71679.8281 - val_loss: 98.4989\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7562.3677 - val_loss: 96.3537\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 39816.2930 - val_loss: 95.2117\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 118234.5391 - val_loss: 96.5649\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 37480.3438 - val_loss: 98.8410\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 63113.1758 - val_loss: 99.4233\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 43761.9492 - val_loss: 99.4424\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 57257.7578 - val_loss: 99.1563\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 44939.7188 - val_loss: 97.9660\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 39191.6445 - val_loss: 97.9061\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 24573.4941 - val_loss: 98.9527\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17929.9121 - val_loss: 99.3420\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 36889.6445 - val_loss: 99.3856\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 151979.3438 - val_loss: 100.1153\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1443.4062 - val_loss: 98.8827\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff35a21fca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 83 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 60.3760 - val_loss: 21.8097\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 22.6085 - val_loss: 6.3960\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.6867 - val_loss: 25.0605\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.3043 - val_loss: 18.8576\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 12.8058 - val_loss: 6.4062\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.8395 - val_loss: 13.3874\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 11.8705 - val_loss: 17.4424\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.2368 - val_loss: 10.0098\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.4684 - val_loss: 10.0631\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.7028 - val_loss: 9.4533\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 9.5461 - val_loss: 10.0854\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.8584 - val_loss: 8.9657\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 8.5323 - val_loss: 6.4593\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.6414 - val_loss: 6.7206\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.8424 - val_loss: 5.7203\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.2440 - val_loss: 7.2410\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 8.8076 - val_loss: 3.8595\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 8.0078 - val_loss: 7.7570\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.5027 - val_loss: 4.2074\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1545 - val_loss: 6.6384\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 7.5596 - val_loss: 4.2333\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 6.8364 - val_loss: 3.6985\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.1759 - val_loss: 4.6883\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8996 - val_loss: 4.6553\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 8.0466 - val_loss: 3.5241\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 7.6665 - val_loss: 9.7920\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 7.9700 - val_loss: 3.5975\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.0495 - val_loss: 5.0442\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 7.0260 - val_loss: 3.8379\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.9399 - val_loss: 3.4438\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.7985 - val_loss: 4.7677\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 5.9626 - val_loss: 3.4503\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.3380 - val_loss: 4.5117\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8600 - val_loss: 3.5289\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.0617 - val_loss: 3.6517\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 7.4968 - val_loss: 7.7814\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 7.2074 - val_loss: 4.7181\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 7.4961 - val_loss: 9.1986\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 7.4055 - val_loss: 3.4771\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.3456 - val_loss: 3.4788\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.9217 - val_loss: 5.8186\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.2407 - val_loss: 4.5608\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 7.3511 - val_loss: 4.2293\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.5612 - val_loss: 6.9719\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 6.8391 - val_loss: 3.4149\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.9790 - val_loss: 6.9904\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.5038 - val_loss: 3.3605\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 6.3126 - val_loss: 6.7203\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 8.1972 - val_loss: 3.6542\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 6.5788 - val_loss: 4.8078\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37e37b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 84 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 79.3349 - val_loss: 58.3257\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 54.3192 - val_loss: 33.8169\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 42.3310 - val_loss: 45.8455\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 41.3375 - val_loss: 48.5411\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 36.4720 - val_loss: 32.0612\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 31.7545 - val_loss: 19.1612\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 27.5416 - val_loss: 23.1165\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 23.8809 - val_loss: 13.4554\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 19.0429 - val_loss: 11.8582\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19.5120 - val_loss: 10.0461\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20.7822 - val_loss: 10.9492\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19.9558 - val_loss: 9.6163\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 19.4979 - val_loss: 13.2539\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 20.2420 - val_loss: 9.0323\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 19.2709 - val_loss: 13.4285\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.0146 - val_loss: 10.7082\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 18.3657 - val_loss: 12.5748\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 18.9944 - val_loss: 9.6145\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 18.5418 - val_loss: 11.6858\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.0776 - val_loss: 10.0400\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 18.6732 - val_loss: 12.2218\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 18.5933 - val_loss: 10.4046\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 17.2718 - val_loss: 10.3125\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 17.8807 - val_loss: 10.9118\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.3983 - val_loss: 10.2102\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.5783 - val_loss: 10.3312\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.7555 - val_loss: 10.4496\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 16.0623 - val_loss: 10.1933\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.9395 - val_loss: 10.5037\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.6087 - val_loss: 11.8282\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 16.6817 - val_loss: 10.2869\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 17.2962 - val_loss: 10.5620\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 18.0642 - val_loss: 12.2788\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 19.2183 - val_loss: 10.3731\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.9498 - val_loss: 11.7025\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 16.4653 - val_loss: 10.1226\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.3460 - val_loss: 10.3201\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.8808 - val_loss: 10.9866\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.8169 - val_loss: 9.8417\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.9950 - val_loss: 10.4193\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 16.5172 - val_loss: 10.1643\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.8747 - val_loss: 10.2481\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 16.2851 - val_loss: 10.8306\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 17.0365 - val_loss: 11.6293\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 15.9523 - val_loss: 12.6577\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.3188 - val_loss: 11.2289\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 17.6117 - val_loss: 10.4051\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 16.5966 - val_loss: 11.0592\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 15.9454 - val_loss: 10.3832\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 15.6465 - val_loss: 12.1221\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3627329d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 85 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 244ms/step - loss: 75.6510 - val_loss: 43.9653\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 31.7422 - val_loss: 9.3400\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 30.3790 - val_loss: 26.9958\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 23.8803 - val_loss: 31.1198\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 21.8227 - val_loss: 15.4651\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 19.7374 - val_loss: 13.9496\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 16.6318 - val_loss: 17.8507\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 15.8471 - val_loss: 11.0708\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 12.6504 - val_loss: 10.5003\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 11.7206 - val_loss: 12.1823\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 13.1398 - val_loss: 6.1573\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 11.9979 - val_loss: 9.0594\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 13.8182 - val_loss: 7.5904\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 11.4278 - val_loss: 8.2641\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 10.9062 - val_loss: 7.4806\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.6373 - val_loss: 7.3771\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 9.1984 - val_loss: 6.5936\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 8.3650 - val_loss: 7.2580\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 9.8569 - val_loss: 6.2764\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.6567 - val_loss: 6.7452\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 8.8581 - val_loss: 7.8647\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 8.2058 - val_loss: 6.5442\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 8.3715 - val_loss: 6.4153\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 9.0691 - val_loss: 7.5867\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 9.4354 - val_loss: 8.0383\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 8.8379 - val_loss: 6.7170\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 8.8080 - val_loss: 6.9244\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.0906 - val_loss: 6.9485\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 8.3037 - val_loss: 6.8707\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 7.8189 - val_loss: 7.5431\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 8.9390 - val_loss: 7.4854\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 8.5554 - val_loss: 7.6160\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 8.1446 - val_loss: 7.5588\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 8.6498 - val_loss: 6.4459\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 7.2784 - val_loss: 7.3181\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 8.2333 - val_loss: 6.3446\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 7.7598 - val_loss: 6.5246\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 8.1802 - val_loss: 6.5349\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 7.7002 - val_loss: 6.9921\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 7.8486 - val_loss: 8.3308\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 7.3608 - val_loss: 5.9268\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 7.7099 - val_loss: 6.6086\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 7.3982 - val_loss: 6.1966\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 8.1020 - val_loss: 6.7074\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 8.4049 - val_loss: 6.3275\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 7.2850 - val_loss: 6.5935\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 6.7499 - val_loss: 6.4779\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 7.4676 - val_loss: 6.4567\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 8.0371 - val_loss: 8.0086\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 8.3146 - val_loss: 6.2904\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3286a7310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 86 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 94.1104 - val_loss: 63.7677\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 40.2278 - val_loss: 14.6907\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 32.4043 - val_loss: 24.2669\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 26.3874 - val_loss: 35.5294\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 24.6924 - val_loss: 23.2424\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 19.6234 - val_loss: 12.6885\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 18.6690 - val_loss: 17.5013\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 18.5505 - val_loss: 20.6030\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 15.4990 - val_loss: 9.4233\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 15.3844 - val_loss: 10.5235\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 13.4240 - val_loss: 10.3527\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 12.4620 - val_loss: 6.6571\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 12.0364 - val_loss: 7.9735\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 11.9770 - val_loss: 6.4800\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 11.1649 - val_loss: 9.2663\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 10.7138 - val_loss: 6.8516\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 13.1772 - val_loss: 9.1320\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 11.2584 - val_loss: 6.4331\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 11.7794 - val_loss: 7.5915\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 11.2819 - val_loss: 6.6797\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 11.2887 - val_loss: 6.9889\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 10.7605 - val_loss: 7.1116\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 9.8907 - val_loss: 6.9543\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 9.9541 - val_loss: 6.6791\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 9.7107 - val_loss: 6.6298\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 10.8151 - val_loss: 7.0413\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 10.7086 - val_loss: 7.0191\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 10.3465 - val_loss: 8.7206\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 10.5869 - val_loss: 7.1075\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 11.5528 - val_loss: 7.9448\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 10.4351 - val_loss: 8.2704\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 10.3898 - val_loss: 6.3885\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 10.4830 - val_loss: 6.1978\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 10.3343 - val_loss: 6.2988\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 10.4342 - val_loss: 6.4879\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.0802 - val_loss: 6.7901\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 10.0239 - val_loss: 6.5780\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 10.5434 - val_loss: 6.5803\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 10.2547 - val_loss: 6.3587\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 10.0122 - val_loss: 6.1894\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 10.1521 - val_loss: 6.1831\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 9.7761 - val_loss: 6.2134\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 10.3057 - val_loss: 6.1499\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 9.3769 - val_loss: 6.0866\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 9.4360 - val_loss: 6.3777\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 10.7559 - val_loss: 6.8027\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 9.7946 - val_loss: 6.1123\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 10.0732 - val_loss: 5.7404\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 8.8326 - val_loss: 5.9340\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 10.2202 - val_loss: 5.7514\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38719d8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 87 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 32357.9766 - val_loss: 82.4876\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 271793.5625 - val_loss: 92.4922\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 141188.3438 - val_loss: 86.8985\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 13686.7344 - val_loss: 85.5950\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 22435.5801 - val_loss: 83.7385\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 5145.0820 - val_loss: 85.7587\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 21186.3398 - val_loss: 88.1512\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 28719.1309 - val_loss: 89.6619\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 27807.1055 - val_loss: 86.4560\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 46579.0391 - val_loss: 86.5797\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 67579.2891 - val_loss: 90.2626\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 102746.2734 - val_loss: 92.5732\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 10203.7949 - val_loss: 88.9302\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 59710.1328 - val_loss: 87.0246\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 50106.9883 - val_loss: 89.0913\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 22739.0195 - val_loss: 97.3562\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 139885.5938 - val_loss: 101.2208\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 172502.5625 - val_loss: 97.2115\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 108272.2734 - val_loss: 94.3185\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 42846.7148 - val_loss: 88.0360\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 91662.5938 - val_loss: 87.1440\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 91975.3594 - val_loss: 89.6311\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 73231.7422 - val_loss: 93.2596\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 48500.4414 - val_loss: 93.7524\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 44327.6094 - val_loss: 92.2541\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 25647.9629 - val_loss: 93.2920\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 2025.1229 - val_loss: 92.9485\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 48253.5312 - val_loss: 92.2080\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 19884.2754 - val_loss: 94.5561\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 19308.1191 - val_loss: 99.0007\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 101338.7500 - val_loss: 99.2501\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 98252.1641 - val_loss: 98.1741\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 30618.8887 - val_loss: 94.1737\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 11733.2158 - val_loss: 94.2688\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 14495.4043 - val_loss: 97.8620\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 33099.1562 - val_loss: 101.9352\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 101703.1875 - val_loss: 103.9724\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 208363.7656 - val_loss: 100.1428\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 83955.0781 - val_loss: 97.4751\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 32664.1445 - val_loss: 94.6291\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 21918.9707 - val_loss: 97.4968\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 12721.8984 - val_loss: 99.6274\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 104032.1094 - val_loss: 100.5820\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 119249.1328 - val_loss: 99.4818\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 29154.9082 - val_loss: 97.4717\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 57135.6641 - val_loss: 94.5385\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 49202.2422 - val_loss: 93.8136\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 50350.1484 - val_loss: 95.4333\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 14251.8604 - val_loss: 97.6829\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 100940.7344 - val_loss: 98.9230\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3196fa160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 88 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 22252.5566 - val_loss: 114.1073\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 708038.9375 - val_loss: 121.4589\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 662696.8125 - val_loss: 107.2597\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 136123.7031 - val_loss: 100.5649\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 56893.9883 - val_loss: 96.9020\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 58077.4492 - val_loss: 99.6303\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 103714.7266 - val_loss: 99.5553\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 39083.7188 - val_loss: 97.8764\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 10433.6973 - val_loss: 97.7412\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1798.3022 - val_loss: 99.8388\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 111177.8672 - val_loss: 100.2310\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 116453.1875 - val_loss: 97.3267\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 35268.9219 - val_loss: 96.4061\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 52070.1680 - val_loss: 97.6531\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 57642.5781 - val_loss: 98.2880\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 11839.9541 - val_loss: 96.9957\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 21887.0508 - val_loss: 98.3033\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 65670.0391 - val_loss: 98.1567\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 530.0789 - val_loss: 99.6123\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 89135.3438 - val_loss: 99.8921\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 59252.8164 - val_loss: 96.6598\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 97810.5625 - val_loss: 96.2963\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 72622.1719 - val_loss: 97.9959\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 42037.8359 - val_loss: 100.8097\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 95276.1094 - val_loss: 101.0472\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 90236.6406 - val_loss: 99.3649\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 32598.6094 - val_loss: 95.6589\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 80121.6562 - val_loss: 95.5080\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 90892.8516 - val_loss: 97.5167\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 7285.8423 - val_loss: 100.2285\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 95359.3438 - val_loss: 101.5739\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 71776.0312 - val_loss: 99.9190\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 58788.3750 - val_loss: 95.7152\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 141587.6562 - val_loss: 94.5229\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 111532.7266 - val_loss: 95.0607\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 95776.1875 - val_loss: 96.9434\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 67765.8516 - val_loss: 99.6841\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 39987.1680 - val_loss: 100.0700\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 22341.5840 - val_loss: 98.9806\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 38322.2500 - val_loss: 97.2291\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 46867.6875 - val_loss: 98.0653\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 4557.6108 - val_loss: 100.2263\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 45718.3672 - val_loss: 100.8179\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 56985.1523 - val_loss: 100.1388\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 35767.6836 - val_loss: 97.9464\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 47351.8008 - val_loss: 97.5735\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 66797.0234 - val_loss: 99.5831\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 7425.9473 - val_loss: 101.1268\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 52559.2227 - val_loss: 102.4685\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 127161.3047 - val_loss: 102.4215\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3064681f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 89 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 85.7866 - val_loss: 64.0120\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 37.1644 - val_loss: 15.8229\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 36.9546 - val_loss: 31.3470\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 28.7222 - val_loss: 34.3627\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 27.8951 - val_loss: 24.6194\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 23.8370 - val_loss: 15.2498\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 21.5834 - val_loss: 18.7241\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 19.0387 - val_loss: 17.9614\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 17.1129 - val_loss: 7.4686\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 17.7439 - val_loss: 11.9507\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 15.2525 - val_loss: 5.9545\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 15.6424 - val_loss: 9.3621\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 15.6283 - val_loss: 7.1626\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 16.2836 - val_loss: 9.8772\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 15.6513 - val_loss: 7.2470\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 14.9990 - val_loss: 8.2423\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 14.4095 - val_loss: 10.4421\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 14.8424 - val_loss: 8.0546\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 14.6101 - val_loss: 7.2133\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 13.0465 - val_loss: 7.7788\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 14.1394 - val_loss: 5.2185\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 14.0221 - val_loss: 9.2413\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 14.4385 - val_loss: 6.5052\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 14.4854 - val_loss: 9.1872\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 12.7766 - val_loss: 5.7911\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 13.6123 - val_loss: 9.6664\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 13.5052 - val_loss: 5.4229\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 12.9865 - val_loss: 7.9669\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 12.8753 - val_loss: 6.3119\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 12.1805 - val_loss: 6.4049\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 12.4248 - val_loss: 9.3120\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 14.0653 - val_loss: 5.0714\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 12.4850 - val_loss: 9.7438\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 12.6707 - val_loss: 5.2144\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 12.0284 - val_loss: 9.9982\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 12.3251 - val_loss: 5.4936\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 11.3220 - val_loss: 7.0143\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 12.1290 - val_loss: 5.5307\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 11.6740 - val_loss: 6.6986\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 12.2653 - val_loss: 7.4750\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 10.6036 - val_loss: 4.7769\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 11.1260 - val_loss: 7.1851\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 12.6729 - val_loss: 4.7278\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 10.8374 - val_loss: 9.3371\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 11.0849 - val_loss: 5.9946\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.8906 - val_loss: 6.1512\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 11.3543 - val_loss: 5.9799\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 10.1631 - val_loss: 5.6745\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 10.8202 - val_loss: 5.3709\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 11.2826 - val_loss: 5.6930\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff308873ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 90 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 132591.7500 - val_loss: 106.0462\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 289537.2500 - val_loss: 110.1029\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 164209.7500 - val_loss: 99.4438\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 3357.5171 - val_loss: 97.8629\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 14870.9932 - val_loss: 94.2529\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 80743.5547 - val_loss: 95.1885\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 13101.7529 - val_loss: 101.6443\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 116082.7266 - val_loss: 101.0512\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 77616.2969 - val_loss: 97.8773\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 33187.0547 - val_loss: 96.6348\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 14225.7744 - val_loss: 101.4364\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 128113.4219 - val_loss: 101.0473\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 80406.8203 - val_loss: 95.7869\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 37832.8047 - val_loss: 95.6146\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 19446.0371 - val_loss: 99.3298\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 24000.6289 - val_loss: 99.6260\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 26454.2246 - val_loss: 95.6975\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 17728.8281 - val_loss: 94.3826\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 27380.3203 - val_loss: 93.6391\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 118050.7344 - val_loss: 96.4089\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 29977.4316 - val_loss: 96.8073\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 11405.4668 - val_loss: 98.5497\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 70469.5234 - val_loss: 97.7840\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 14898.0391 - val_loss: 93.0663\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 95627.9141 - val_loss: 93.3193\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 82908.7109 - val_loss: 97.7357\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 3980.5505 - val_loss: 97.1998\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 10090.8486 - val_loss: 98.0121\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 41684.7109 - val_loss: 98.6101\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 21287.3047 - val_loss: 99.9258\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 114832.7891 - val_loss: 102.6539\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 51597.5625 - val_loss: 98.9971\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 3852.8352 - val_loss: 95.0621\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 55421.9805 - val_loss: 94.6713\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 57798.0391 - val_loss: 96.1140\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 53717.0117 - val_loss: 97.7889\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 33133.0859 - val_loss: 93.0287\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 75769.1328 - val_loss: 91.3396\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 108097.5859 - val_loss: 94.5152\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 17819.1797 - val_loss: 96.2230\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 46429.4883 - val_loss: 98.0855\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 16110.6084 - val_loss: 98.1833\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 2565.5923 - val_loss: 96.2067\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 75458.7109 - val_loss: 95.4979\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 9711.8770 - val_loss: 94.9377\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 73531.4141 - val_loss: 95.3958\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 15038.2842 - val_loss: 97.8346\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 23015.6348 - val_loss: 97.2762\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 16278.9658 - val_loss: 98.4304\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 44698.3320 - val_loss: 98.5752\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff394c16700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 91 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 62.2296 - val_loss: 46.2542\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 58.0841 - val_loss: 51.4828\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 40.7604 - val_loss: 40.9152\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 33.7662 - val_loss: 20.0071\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 23.7884 - val_loss: 20.8402\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 18.6746 - val_loss: 8.3502\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 19.4589 - val_loss: 7.8589\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 19.3005 - val_loss: 7.5257\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 20.0763 - val_loss: 9.9414\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 20.5660 - val_loss: 6.2787\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 19.0245 - val_loss: 11.3220\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 19.1560 - val_loss: 7.2936\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 17.4159 - val_loss: 7.2804\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 17.0445 - val_loss: 7.0685\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 16.5810 - val_loss: 8.8100\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 14.9493 - val_loss: 7.1072\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 16.7123 - val_loss: 10.5338\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 16.2104 - val_loss: 6.3099\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 16.2543 - val_loss: 9.2455\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 14.3612 - val_loss: 6.8615\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 15.6300 - val_loss: 7.1529\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 16.7498 - val_loss: 6.7293\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 17.5188 - val_loss: 7.0889\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 14.9350 - val_loss: 6.3640\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 15.5067 - val_loss: 6.5053\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 15.0512 - val_loss: 9.6262\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 16.2795 - val_loss: 6.2834\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 16.0995 - val_loss: 7.8437\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 15.4970 - val_loss: 6.7920\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 16.9389 - val_loss: 7.0012\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 15.6014 - val_loss: 6.2778\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 13.6948 - val_loss: 8.7220\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 17.5349 - val_loss: 5.8019\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 17.1302 - val_loss: 8.7411\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 18.0544 - val_loss: 9.3828\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 14.4878 - val_loss: 5.4758\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 14.1052 - val_loss: 7.3254\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 14.5589 - val_loss: 6.2447\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 14.9529 - val_loss: 6.3385\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 15.3528 - val_loss: 5.9655\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 14.1208 - val_loss: 9.2744\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 15.2471 - val_loss: 5.6383\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 15.2687 - val_loss: 7.3192\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 15.7494 - val_loss: 5.4541\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 16.1043 - val_loss: 5.6725\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 14.0630 - val_loss: 7.5516\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 13.7315 - val_loss: 5.8102\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 14.8195 - val_loss: 7.4647\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 14.1100 - val_loss: 5.7274\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 14.6196 - val_loss: 6.4849\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38719db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 92 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 261ms/step - loss: 90.1842 - val_loss: 53.5857\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 32.4676 - val_loss: 3.7587\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 32.3653 - val_loss: 20.7575\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 27.1511 - val_loss: 35.2333\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 24.4584 - val_loss: 14.1809\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 21.6232 - val_loss: 6.1120\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 18.4260 - val_loss: 14.2782\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 19.1115 - val_loss: 16.8997\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 18.1969 - val_loss: 7.4891\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 16.5342 - val_loss: 6.4618\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 14.3618 - val_loss: 4.0387\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 14.6224 - val_loss: 5.2391\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 13.3375 - val_loss: 4.8177\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 14.7294 - val_loss: 5.3376\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 13.5512 - val_loss: 4.8511\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 12.5923 - val_loss: 4.6657\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 11.4519 - val_loss: 4.6908\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 12.8007 - val_loss: 5.0975\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 11.8955 - val_loss: 4.4489\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 11.3710 - val_loss: 4.9777\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 11.6420 - val_loss: 4.6400\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 11.7540 - val_loss: 6.1630\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 11.5266 - val_loss: 6.3993\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 11.6063 - val_loss: 7.2571\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 10.3523 - val_loss: 5.3431\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 10.8290 - val_loss: 4.8531\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 11.1871 - val_loss: 4.7580\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 10.6703 - val_loss: 4.7181\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 9.5670 - val_loss: 4.6495\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 9.9824 - val_loss: 4.7073\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.8306 - val_loss: 4.7787\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.7787 - val_loss: 5.5521\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 10.2167 - val_loss: 5.6257\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 9.3168 - val_loss: 4.6828\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 8.9764 - val_loss: 7.2729\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.7182 - val_loss: 5.9614\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 10.3057 - val_loss: 4.3823\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 9.4455 - val_loss: 4.6000\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.0670 - val_loss: 4.4969\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 8.6390 - val_loss: 5.3499\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.4024 - val_loss: 4.4169\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 9.2765 - val_loss: 4.3846\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 9.4938 - val_loss: 4.2278\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 9.5629 - val_loss: 4.0851\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 8.7615 - val_loss: 5.5294\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.0206 - val_loss: 4.1010\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 8.6310 - val_loss: 4.0038\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.1272 - val_loss: 3.9629\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 8.1673 - val_loss: 6.5412\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 9.4679 - val_loss: 6.2865\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff37a0d7940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 93 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 255ms/step - loss: 76.8080 - val_loss: 56.5530\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 47.9784 - val_loss: 40.8421\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 42.5057 - val_loss: 48.8484\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 37.9737 - val_loss: 35.9238\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 32.1664 - val_loss: 19.0873\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 24.3851 - val_loss: 20.2141\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 25.4395 - val_loss: 4.3579\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 24.3904 - val_loss: 11.6539\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 21.9175 - val_loss: 10.1530\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 22.2894 - val_loss: 7.9782\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 18.7322 - val_loss: 13.4734\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 19.8650 - val_loss: 5.4808\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 17.8214 - val_loss: 7.2824\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 17.3980 - val_loss: 5.1253\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 18.6798 - val_loss: 4.3141\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 17.5473 - val_loss: 4.2158\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 18.0090 - val_loss: 5.0055\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 17.4306 - val_loss: 3.7817\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 16.5307 - val_loss: 4.8210\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 14.9877 - val_loss: 5.3662\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 15.4758 - val_loss: 4.4801\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 15.6782 - val_loss: 5.5088\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 14.1467 - val_loss: 4.8579\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 15.8548 - val_loss: 4.1495\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 13.4721 - val_loss: 4.1177\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 13.1509 - val_loss: 3.5212\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 14.4716 - val_loss: 7.5848\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 13.7332 - val_loss: 3.9519\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 14.8169 - val_loss: 3.2749\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 13.4058 - val_loss: 3.5015\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 12.8051 - val_loss: 6.1321\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 12.6564 - val_loss: 3.0120\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 12.0878 - val_loss: 6.8625\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 13.6778 - val_loss: 2.9818\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 12.4544 - val_loss: 4.2256\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 12.0909 - val_loss: 6.3136\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 11.8158 - val_loss: 4.8698\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 11.3077 - val_loss: 4.5230\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 12.0021 - val_loss: 2.5110\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 11.8717 - val_loss: 9.9073\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 12.2835 - val_loss: 5.3679\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 10.7689 - val_loss: 2.4881\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 11.8887 - val_loss: 3.1586\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 11.5921 - val_loss: 9.7882\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 12.3520 - val_loss: 5.0626\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 11.2629 - val_loss: 3.0855\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 11.9848 - val_loss: 3.9690\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 9.5541 - val_loss: 5.8530\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 11.5243 - val_loss: 5.1208\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 10.6601 - val_loss: 3.3970\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff35a7270d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 94 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 270ms/step - loss: 72.3438 - val_loss: 25.6506\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 37.4493 - val_loss: 9.2026\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 34.3242 - val_loss: 25.9142\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 29.4030 - val_loss: 26.9625\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 24.8424 - val_loss: 10.0520\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 22.1712 - val_loss: 8.1427\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 19.3618 - val_loss: 10.1244\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 16.8437 - val_loss: 8.9856\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 14.0119 - val_loss: 7.4203\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 15.3081 - val_loss: 8.3702\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 13.8730 - val_loss: 7.7246\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 13.0390 - val_loss: 7.4398\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 13.5604 - val_loss: 6.9061\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 12.3740 - val_loss: 6.8095\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 12.1153 - val_loss: 6.3309\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 11.5217 - val_loss: 6.2635\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 10.4316 - val_loss: 7.4379\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 10.8255 - val_loss: 5.8496\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 9.5400 - val_loss: 7.5098\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 10.4707 - val_loss: 6.5823\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 12.3733 - val_loss: 6.5510\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 10.3920 - val_loss: 5.4157\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 10.3220 - val_loss: 6.2947\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 10.1323 - val_loss: 5.3632\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 10.7093 - val_loss: 5.8670\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 10.4125 - val_loss: 5.4773\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 9.8467 - val_loss: 5.1236\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 9.6455 - val_loss: 5.3913\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 11.0167 - val_loss: 5.0682\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 8.7203 - val_loss: 8.1238\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.7438 - val_loss: 5.7524\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 10.0524 - val_loss: 5.5197\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 10.7195 - val_loss: 6.6409\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 9.9993 - val_loss: 5.0432\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 10.8251 - val_loss: 6.7910\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 10.3187 - val_loss: 4.6801\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 9.8929 - val_loss: 5.8071\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 9.0280 - val_loss: 4.6801\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.9044 - val_loss: 4.6068\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 9.2518 - val_loss: 4.6788\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.0532 - val_loss: 4.8171\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 9.3025 - val_loss: 5.3758\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.9454 - val_loss: 4.7749\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 10.0335 - val_loss: 5.2314\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 9.6324 - val_loss: 4.3509\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.8534 - val_loss: 4.2943\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 8.7014 - val_loss: 4.3471\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 9.8753 - val_loss: 5.5847\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 8.8396 - val_loss: 4.2997\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 8.9932 - val_loss: 5.0547\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff38a590820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 95 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 275ms/step - loss: 74.2774 - val_loss: 39.4615\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 38.6626 - val_loss: 29.9489\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 33.9888 - val_loss: 35.0831\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 25.9518 - val_loss: 20.6309\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 23.5637 - val_loss: 17.3959\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 20.0728 - val_loss: 7.4070\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 18.5503 - val_loss: 13.8329\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 21.5568 - val_loss: 6.0290\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 20.1880 - val_loss: 9.1768\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 18.7960 - val_loss: 6.5669\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 18.7531 - val_loss: 9.8134\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 17.6468 - val_loss: 5.7947\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 18.0859 - val_loss: 8.9464\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 16.7033 - val_loss: 5.7049\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 17.1134 - val_loss: 7.7110\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 17.1852 - val_loss: 6.2241\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 17.8738 - val_loss: 7.4350\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 15.6580 - val_loss: 5.7770\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 15.6218 - val_loss: 7.5969\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 15.8890 - val_loss: 7.0258\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 16.4778 - val_loss: 7.4880\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 15.6776 - val_loss: 6.8659\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 14.4987 - val_loss: 6.2306\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 15.2062 - val_loss: 5.4486\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 15.0374 - val_loss: 6.5788\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 14.1653 - val_loss: 6.4507\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 14.3391 - val_loss: 5.3554\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 14.3340 - val_loss: 8.6717\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 15.1970 - val_loss: 7.7993\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 14.2942 - val_loss: 6.2406\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 14.8618 - val_loss: 5.6319\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 15.2798 - val_loss: 8.1693\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 15.2292 - val_loss: 4.9344\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 14.3197 - val_loss: 8.4687\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 14.2219 - val_loss: 4.8669\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 14.1697 - val_loss: 7.5904\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 13.4729 - val_loss: 5.1724\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 14.0242 - val_loss: 5.5556\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 12.9421 - val_loss: 6.0582\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 12.6560 - val_loss: 4.7961\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 14.0763 - val_loss: 7.2343\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 13.8233 - val_loss: 4.8562\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 13.6090 - val_loss: 6.9982\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 12.3747 - val_loss: 5.1973\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 12.2288 - val_loss: 6.0798\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 13.4239 - val_loss: 6.5207\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 12.4715 - val_loss: 6.9783\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 12.5895 - val_loss: 4.9486\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 12.6535 - val_loss: 5.3904\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 12.2181 - val_loss: 4.6322\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff3c79a2160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 96 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 269ms/step - loss: 67.7310 - val_loss: 33.3957\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 31.5573 - val_loss: 8.3855\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 24.4955 - val_loss: 37.9024\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 25.8863 - val_loss: 35.8474\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 21.4022 - val_loss: 19.2639\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 20.6666 - val_loss: 21.6193\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 19.3312 - val_loss: 29.1404\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 18.4479 - val_loss: 23.4070\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 16.6700 - val_loss: 13.1676\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 16.7322 - val_loss: 19.3233\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 15.4372 - val_loss: 21.9844\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 13.6976 - val_loss: 11.8155\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 13.1063 - val_loss: 16.4441\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 11.8228 - val_loss: 9.5217\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 9.9719 - val_loss: 9.6319\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 10.3443 - val_loss: 7.7782\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.5149 - val_loss: 4.5036\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 9.4217 - val_loss: 4.9611\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 9.3292 - val_loss: 3.9021\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 9.5661 - val_loss: 4.5255\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 8.8808 - val_loss: 3.0477\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 10.5258 - val_loss: 8.9250\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 10.0494 - val_loss: 3.1936\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 10.3823 - val_loss: 6.4759\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.3137 - val_loss: 3.5919\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 9.5146 - val_loss: 7.4811\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 8.8849 - val_loss: 3.4154\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 8.7958 - val_loss: 3.3134\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.1554 - val_loss: 4.0847\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.0460 - val_loss: 3.2195\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 8.4666 - val_loss: 4.5455\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.6489 - val_loss: 3.6979\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 9.2758 - val_loss: 8.7542\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 9.4197 - val_loss: 3.8020\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 9.2033 - val_loss: 3.9003\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.8067 - val_loss: 3.5176\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 8.8281 - val_loss: 3.5780\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.9456 - val_loss: 3.4701\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 8.4988 - val_loss: 3.4793\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 8.8889 - val_loss: 4.6209\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 8.1788 - val_loss: 3.2674\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 7.6346 - val_loss: 3.6087\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 7.4854 - val_loss: 3.4373\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 7.9917 - val_loss: 3.2927\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 7.5913 - val_loss: 3.2215\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.0773 - val_loss: 3.4587\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 7.7029 - val_loss: 4.2904\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 7.6934 - val_loss: 3.4839\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 7.2877 - val_loss: 3.4108\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 8.2027 - val_loss: 3.8811\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff332221160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 97 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 268ms/step - loss: 68.0923 - val_loss: 20.8593\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 30.9202 - val_loss: 6.6891\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 22.0522 - val_loss: 20.4414\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 22.9741 - val_loss: 24.1275\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 18.9002 - val_loss: 8.2678\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 19.0499 - val_loss: 2.0543\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 16.7896 - val_loss: 14.2288\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 13.5574 - val_loss: 6.4235\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 11.5690 - val_loss: 2.6925\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 9.4654 - val_loss: 2.5025\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 8.5448 - val_loss: 2.6291\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 8.5811 - val_loss: 2.7671\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 8.8759 - val_loss: 3.6236\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 9.2468 - val_loss: 6.3552\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 9.8924 - val_loss: 3.4155\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 8.5938 - val_loss: 2.2846\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 8.0499 - val_loss: 2.8995\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 8.6872 - val_loss: 4.7004\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 7.5079 - val_loss: 2.3234\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 7.8768 - val_loss: 2.6879\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 8.3164 - val_loss: 3.1051\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 7.3083 - val_loss: 5.3125\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 7.7004 - val_loss: 2.6191\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.0789 - val_loss: 5.6638\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 9.1546 - val_loss: 3.1911\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 7.0239 - val_loss: 2.6684\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 7.4788 - val_loss: 7.2054\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 7.6120 - val_loss: 3.3618\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 8.0036 - val_loss: 7.7154\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 7.8763 - val_loss: 2.7219\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.0043 - val_loss: 3.1045\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 6.7388 - val_loss: 4.0580\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 7.3538 - val_loss: 3.4206\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 7.1117 - val_loss: 2.3182\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 7.8882 - val_loss: 2.4692\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 8.1529 - val_loss: 3.8466\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 6.9581 - val_loss: 3.2857\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 7.0495 - val_loss: 2.7654\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 7.4835 - val_loss: 3.9883\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 8.1088 - val_loss: 6.5021\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 7.4697 - val_loss: 3.5548\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 8.3077 - val_loss: 6.0759\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 7.3986 - val_loss: 3.2600\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 7.3884 - val_loss: 4.6740\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 6.6609 - val_loss: 4.8005\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 7.2089 - val_loss: 3.2339\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 8.3692 - val_loss: 5.1414\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 7.7475 - val_loss: 2.2547\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 7.1689 - val_loss: 8.8097\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.0987 - val_loss: 3.1482\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff30ced5af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 98 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 270ms/step - loss: 80.1645 - val_loss: 44.4996\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 51.7101 - val_loss: 19.9335\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 40.6614 - val_loss: 35.4213\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 31.5101 - val_loss: 32.8380\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 24.7391 - val_loss: 16.2098\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 22.1596 - val_loss: 22.6020\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 21.4673 - val_loss: 13.9915\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 18.5370 - val_loss: 11.6397\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 18.2868 - val_loss: 12.4378\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 17.7329 - val_loss: 12.0699\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 17.7172 - val_loss: 13.6387\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 16.3875 - val_loss: 11.7437\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 16.4004 - val_loss: 13.9812\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 17.4735 - val_loss: 12.3985\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 16.0071 - val_loss: 13.0573\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 16.2855 - val_loss: 11.4917\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 17.0239 - val_loss: 14.4100\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 17.1121 - val_loss: 14.4365\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 15.4711 - val_loss: 11.9905\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 16.1340 - val_loss: 12.1521\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 14.9007 - val_loss: 11.5020\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 14.5036 - val_loss: 12.1458\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 16.1311 - val_loss: 13.7466\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 15.9799 - val_loss: 10.8399\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 17.5342 - val_loss: 12.1823\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 16.6324 - val_loss: 16.6549\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 16.3828 - val_loss: 10.8566\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 14.3742 - val_loss: 10.6079\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 13.8942 - val_loss: 10.6535\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 14.5743 - val_loss: 11.1428\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 13.8705 - val_loss: 10.4660\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 14.7399 - val_loss: 12.9912\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 15.7298 - val_loss: 10.4172\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 16.3100 - val_loss: 10.2865\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 15.7859 - val_loss: 11.0468\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 15.1074 - val_loss: 10.3475\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 13.9568 - val_loss: 14.1650\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 14.7695 - val_loss: 10.1059\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 13.9050 - val_loss: 11.2425\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 13.9188 - val_loss: 10.2136\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 13.5135 - val_loss: 9.9726\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 13.7134 - val_loss: 12.1151\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 14.4384 - val_loss: 11.1028\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 12.7769 - val_loss: 10.2671\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 13.1261 - val_loss: 10.3320\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 14.1034 - val_loss: 10.1039\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 12.1938 - val_loss: 9.6172\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 13.4043 - val_loss: 10.0005\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 13.6347 - val_loss: 10.4415\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 12.6489 - val_loss: 9.8224\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff319886280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 99 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 256ms/step - loss: 79070.8594 - val_loss: 76.4910\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 224866.3438 - val_loss: 78.1087\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 123365.1719 - val_loss: 91.8248\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 130404.9375 - val_loss: 98.4226\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 121950.0391 - val_loss: 90.7289\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 117298.7266 - val_loss: 88.8227\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 33175.8516 - val_loss: 93.3516\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 9323.6035 - val_loss: 99.6982\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 199954.4062 - val_loss: 101.5552\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 156831.6094 - val_loss: 98.0423\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 83867.9531 - val_loss: 92.7109\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 156301.8750 - val_loss: 90.4769\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 115231.7344 - val_loss: 94.2069\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 17013.3066 - val_loss: 96.9581\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 1390.5116 - val_loss: 94.9718\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 132174.4531 - val_loss: 93.0398\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 99474.8984 - val_loss: 93.6181\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 25497.6992 - val_loss: 96.1231\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 29546.5156 - val_loss: 100.3400\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 141308.8281 - val_loss: 101.6176\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 80048.0234 - val_loss: 100.1786\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 92124.3125 - val_loss: 97.9117\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 48345.5391 - val_loss: 95.8204\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 13285.5703 - val_loss: 97.7795\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 85673.1094 - val_loss: 98.6114\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 5065.6353 - val_loss: 98.3237\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 61210.5859 - val_loss: 97.4332\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 44483.0508 - val_loss: 94.6987\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 66742.1406 - val_loss: 93.5641\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 51841.2500 - val_loss: 94.7284\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 22557.9453 - val_loss: 98.3291\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 34824.3047 - val_loss: 98.6515\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 55565.6523 - val_loss: 96.4143\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 119453.5625 - val_loss: 95.6491\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 28451.5059 - val_loss: 98.5712\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 59851.9141 - val_loss: 99.8062\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 58606.8008 - val_loss: 97.2361\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 51551.9961 - val_loss: 96.1241\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 5259.1089 - val_loss: 99.8231\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 105526.8984 - val_loss: 101.6955\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 48024.8203 - val_loss: 99.4906\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 45012.7227 - val_loss: 96.7155\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 96153.4766 - val_loss: 95.3369\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 92072.8281 - val_loss: 96.3051\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 8480.9014 - val_loss: 99.5551\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 102902.7969 - val_loss: 101.4683\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 73715.4766 - val_loss: 98.9192\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 21369.0957 - val_loss: 97.7872\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 94292.5234 - val_loss: 99.5844\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 126220.8828 - val_loss: 99.5025\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff30815ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 100 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 257ms/step - loss: 47.7671 - val_loss: 5.3456\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 26.7485 - val_loss: 6.8234\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 15.7753 - val_loss: 26.7163\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 16.6351 - val_loss: 14.8350\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 15.7753 - val_loss: 7.7806\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 12.8150 - val_loss: 17.2392\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 13.6414 - val_loss: 15.8383\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 12.1883 - val_loss: 8.9772\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 12.7004 - val_loss: 12.3086\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 11.1226 - val_loss: 12.5195\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 9.9400 - val_loss: 10.4359\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 10.7162 - val_loss: 10.4028\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 9.4489 - val_loss: 9.2087\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 9.4878 - val_loss: 6.1500\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 7.4333 - val_loss: 9.2035\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 6.6258 - val_loss: 5.4237\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 7.9376 - val_loss: 4.0355\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 7.7077 - val_loss: 6.9945\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 6.8362 - val_loss: 4.3271\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 8.0733 - val_loss: 6.3839\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 7.7990 - val_loss: 5.9140\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 7.3600 - val_loss: 4.0617\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 7.5468 - val_loss: 3.8080\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 7.0986 - val_loss: 4.8446\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 6.7066 - val_loss: 4.8934\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 6.3546 - val_loss: 3.9963\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 6.7726 - val_loss: 4.7194\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 6.4327 - val_loss: 5.0432\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 8.4102 - val_loss: 6.1621\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 7.0190 - val_loss: 4.1371\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 6.3628 - val_loss: 3.9200\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 6.5652 - val_loss: 3.9381\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 7.3639 - val_loss: 5.6040\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 6.9388 - val_loss: 3.9961\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 6.2680 - val_loss: 3.9614\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 7.4445 - val_loss: 5.5805\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.3477 - val_loss: 10.7007\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 8.2053 - val_loss: 6.1716\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 8.6528 - val_loss: 8.3366\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 6.8563 - val_loss: 4.2409\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 7.0152 - val_loss: 9.3209\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 7.4012 - val_loss: 3.7311\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 6.7526 - val_loss: 5.4769\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 6.6761 - val_loss: 3.9535\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 6.2593 - val_loss: 4.9197\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 6.7141 - val_loss: 3.8101\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 6.5031 - val_loss: 6.0323\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 5.6976 - val_loss: 3.5834\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 6.0206 - val_loss: 5.1789\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 6.0253 - val_loss: 5.7294\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff310d69160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 101 finished\n",
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 266ms/step - loss: 69.0771 - val_loss: 44.4144\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 46.9213 - val_loss: 27.6241\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 34.2117 - val_loss: 47.2330\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 33.3440 - val_loss: 38.7038\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 27.0431 - val_loss: 21.5759\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 24.0606 - val_loss: 23.0873\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 21.2318 - val_loss: 22.1727\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 17.9737 - val_loss: 11.1651\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 16.6026 - val_loss: 13.4691\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 17.2303 - val_loss: 5.9543\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 15.1211 - val_loss: 12.1986\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 14.7996 - val_loss: 8.8275\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 14.4866 - val_loss: 9.3286\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 13.9133 - val_loss: 8.5237\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 13.9805 - val_loss: 5.6391\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 13.9117 - val_loss: 3.1404\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 12.0343 - val_loss: 5.6476\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 12.2949 - val_loss: 3.3380\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 11.5845 - val_loss: 3.4330\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 13.4395 - val_loss: 6.1663\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 12.2066 - val_loss: 1.9235\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 11.8727 - val_loss: 4.3098\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 11.2287 - val_loss: 3.2361\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 11.1287 - val_loss: 6.4110\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 12.1851 - val_loss: 4.0802\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 12.2579 - val_loss: 5.9718\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 10.7631 - val_loss: 3.2305\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 11.4776 - val_loss: 4.3844\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 10.9356 - val_loss: 3.7935\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 10.7042 - val_loss: 2.5455\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 10.4955 - val_loss: 1.9412\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 11.0660 - val_loss: 7.7221\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 11.3597 - val_loss: 4.7230\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 11.8877 - val_loss: 7.5252\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 11.2303 - val_loss: 4.0462\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 9.9533 - val_loss: 4.8499\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 9.2398 - val_loss: 2.0313\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 8.4831 - val_loss: 3.7178\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 9.3900 - val_loss: 2.3740\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 8.6935 - val_loss: 1.5887\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 8.7155 - val_loss: 3.7955\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 10.1976 - val_loss: 3.1883\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.9030 - val_loss: 4.4251\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.4315 - val_loss: 1.6329\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 9.1841 - val_loss: 6.0714\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 9.4239 - val_loss: 1.7570\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 8.6721 - val_loss: 4.1348\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 9.5634 - val_loss: 4.4617\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 9.9002 - val_loss: 4.8191\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 9.4450 - val_loss: 1.9163\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff30ae7df70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration number 102 finished\n"
     ]
    }
   ],
   "source": [
    "zipcodes = nv_zipcodes\n",
    "dict_mape4 = {}\n",
    "dict_pred4 = {}\n",
    "\n",
    "for zipcode in range(len(zipcodes)):\n",
    "\n",
    "    # init a RMM model\n",
    "    rnn_model = Sequential()\n",
    "    # add 4 layers of RNN and a last layer\n",
    "\n",
    "    # we define shape on first layer, (60,1) because we use 60 inputs per prediction\n",
    "    rnn_model.add(LSTM(units= 60, return_sequences = True, input_shape=((60,1))))\n",
    "    rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # another layer\n",
    "    rnn_model.add(LSTM(units= 30, return_sequences = False))\n",
    "    rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # return_sequence is False because we want only 1 output after this layer\n",
    "    #rnn_model.add(LSTM(units= 60, return_sequences = False))\n",
    "    #rnn_model.add(Dropout(.1))\n",
    "\n",
    "    # last layer \n",
    "\n",
    "    rnn_model.add(Dense(units=1))\n",
    "\n",
    "    # compile - because this is a regression model we want to minimize MSE\n",
    "\n",
    "    rnn_model.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "\n",
    "    # We get only the specific column(Zipcode from our train and test datas)\n",
    "    train_data = train.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    test_data = test.iloc[:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # We are using normalizaion rather than standascaler. \n",
    "    # In a upward trending timeseries it is better to not start from negative\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    train_data_scaled = scaler.fit_transform(train_data)\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Because we are using 60 previous values to model and predict the next value, \n",
    "    # We set X_train from arrays of 60 for each y_train value\n",
    "    # Same idea for test data sets\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(60,len(train_data_scaled)):\n",
    "        X_train.append(train_data_scaled[i-60:i])\n",
    "        y_train.append(train_data_scaled[i])\n",
    "\n",
    "    data_total = pd.concat((train.iloc[:,zipcode:zipcode+1], test.iloc[:,zipcode:zipcode+1]),axis=0)\n",
    "    inputs = data_total[len(train)-60:].values\n",
    "    inputs = scaler.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for i in range(60,len(inputs)):\n",
    "        X_test.append(inputs[i-60:i])\n",
    "        y_test.append(inputs[i])\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(test_data)\n",
    "\n",
    "    # We need numpy arrays for our model\n",
    "    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "    \n",
    "    # We fit our data to our zipcode specific data\n",
    "    rnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, scaler.transform(y_test)))\n",
    "\n",
    "    # Make predictions on the data\n",
    "\n",
    "    y_hat_raw = rnn_model.predict(X_test)\n",
    "    y_hat = scaler.inverse_transform(y_hat_raw)\n",
    "\n",
    "    # Use the score on unseen test data to calculate the MAPE\n",
    "\n",
    "    dict_mape4[zipcodes[zipcode]] = np.mean(np.absolute((y_hat-y_test)/y_test))      \n",
    "\n",
    "    # We get the last 60 values from our test data which is basically last 60 values in the data set\n",
    "    last_60 = df_time_series.iloc[-60:,zipcode:zipcode+1].values.astype(int)\n",
    "    \n",
    "    # Before we use our data we scale it\n",
    "    last_60 = scaler.transform(last_60)\n",
    "    \n",
    "    # Our input should be in (x,60,1) format\n",
    "    x_new_pred = last_60[-60:].reshape(1,60,1)\n",
    "\n",
    "    # make a prediction, add to the last_60 for the next prediction and \n",
    "    y_pred = rnn_model.predict(x_new_pred)\n",
    "\n",
    "    # We add our predition to our list of predictions for zipcode specific predictions list\n",
    "    dict_pred4[zipcodes[zipcode]]=scaler.inverse_transform(y_pred)\n",
    "    \n",
    "    print(f'Iteration number {zipcode} finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_keys4 = list(dict_mape4.keys())\n",
    "rnn_mape4 = list(dict_mape4.values())\n",
    "rnn_pred4 = []\n",
    "rnn_dict4 = {}\n",
    "for zipcode in dict_pred4.keys():\n",
    "    rnn_pred4.append(dict_pred3[zipcode].astype(int)[0][0])\n",
    "for zc in rnn_keys4:\n",
    "    a = []\n",
    "    a.append(dict_mape4[zc])\n",
    "    a.append(dict_pred4[zc].astype(float)[0][0])\n",
    "    a.append('RNN_2_layer_w/_D.o.')\n",
    "    rnn_dict4[zc] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21225589746965626"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rnn_mape4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rnn_dict, rnn_dict2, rnn_dict3, rnn_dict4]\n",
    "best_model_dict = {}\n",
    "for zipcode in dict_pred.keys():\n",
    "    best_model = [1,1]\n",
    "    for model in models:\n",
    "        if model[zipcode][0]<best_model[0]:\n",
    "            best_model = model[zipcode]\n",
    "    best_model_dict[zipcode] = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95804: [0.4911381270271113, 81137.2421875, 'RNN_2_Layers'],\n",
       " 95817: [0.4872030385214798, 81155.828125, 'RNN'],\n",
       " 95813: [0.008052491635078938, 343416.90625, 'RNN'],\n",
       " 95785: [0.012099913373751303, 416440.96875, 'RNN_2_Layers'],\n",
       " 95819: [0.012136574706638245, 305058.125, 'RNN_w/_D.o.'],\n",
       " 95770: [0.42498984012899077, 110461.828125, 'RNN_2_Layers'],\n",
       " 95806: [0.5233816981583644, 68937.5234375, 'RNN_2_Layers'],\n",
       " 95790: [0.00971025137494739, 316477.625, 'RNN_2_Layers'],\n",
       " 95799: [0.3888265561869724, 120022.625, 'RNN_w/_D.o.'],\n",
       " 95844: [0.008911624409661253, 305458.875, 'RNN_w/_D.o.'],\n",
       " 95843: [0.39383061728555874, 133019.71875, 'RNN'],\n",
       " 95815: [0.4556841022163915, 97081.1015625, 'RNN_2_layer_w/_D.o.'],\n",
       " 95825: [0.3742488465291584, 145177.390625, 'RNN_w/_D.o.'],\n",
       " 95818: [0.4399410165041235, 94415.8046875, 'RNN'],\n",
       " 95811: [0.4545158547574294, 78562.640625, 'RNN'],\n",
       " 95931: [0.4469864096516115, 115641.796875, 'RNN'],\n",
       " 95753: [0.367702129081654, 151804.90625, 'RNN'],\n",
       " 95827: [0.007114763283562857, 338214.21875, 'RNN_w/_D.o.'],\n",
       " 95937: [0.007952664904275772, 450947.3125, 'RNN_w/_D.o.'],\n",
       " 95914: [0.3962134958245149, 186625.390625, 'RNN'],\n",
       " 95754: [0.38858440349825074, 122805.0390625, 'RNN'],\n",
       " 95824: [0.40141507893827755, 134626.546875, 'RNN_2_Layers'],\n",
       " 95945: [0.012972172888305546, 397519.875, 'RNN_w/_D.o.'],\n",
       " 95800: [0.5342762690880433, 67908.625, 'RNN_2_layer_w/_D.o.'],\n",
       " 95751: [0.010374702903072571, 346076.6875, 'RNN_2_layer_w/_D.o.'],\n",
       " 95769: [0.2101280418951514, 84635.015625, 'RNN_w/_D.o.'],\n",
       " 95909: [0.4736750189217418, 101884.4375, 'RNN'],\n",
       " 95771: [0.4483536146492791, 96108.7734375, 'RNN'],\n",
       " 95935: [0.4663703066610316, 115812.265625, 'RNN_2_layer_w/_D.o.'],\n",
       " 95798: [0.4292759466549264, 100036.8046875, 'RNN'],\n",
       " 95835: [0.3317170549565676, 162893.34375, 'RNN_w/_D.o.'],\n",
       " 95845: [0.40230643009334144, 147156.15625, 'RNN_2_layer_w/_D.o.'],\n",
       " 95865: [0.006950994861642115, 294969.0625, 'RNN'],\n",
       " 95809: [0.0103706304773791, 303950.53125, 'RNN'],\n",
       " 95944: [0.00766392256932853, 419489.5625, 'RNN_w/_D.o.'],\n",
       " 399671: [0.39091408876629247, 131324.1875, 'RNN_2_Layers'],\n",
       " 95831: [0.007776241631509558, 426532.34375, 'RNN'],\n",
       " 95803: [0.5253989114726544, 68783.0078125, 'RNN_2_Layers'],\n",
       " 95939: [0.009068167814745441, 656712.25, 'RNN'],\n",
       " 399665: [0.01366619767102287, 309130.6875, 'RNN_w/_D.o.'],\n",
       " 95826: [0.40527579748533116, 127564.046875, 'RNN'],\n",
       " 95830: [0.01155801068183575, 318444.09375, 'RNN'],\n",
       " 95932: [0.46670214159374085, 124765.875, 'RNN_2_Layers'],\n",
       " 95792: [0.3797880149456615, 126183.0859375, 'RNN_w/_D.o.'],\n",
       " 95837: [0.008590925900175631, 315318.90625, 'RNN'],\n",
       " 95750: [0.013593019952360367, 266347.5625, 'RNN_2_Layers'],\n",
       " 95838: [0.4629914576219886, 88311.875, 'RNN_w/_D.o.'],\n",
       " 95912: [0.43227159732678616, 139095.0, 'RNN_2_layer_w/_D.o.'],\n",
       " 95940: [0.2804989489024769, 115600.3515625, 'RNN_2_layer_w/_D.o.'],\n",
       " 95841: [0.4119015224054596, 112776.1328125, 'RNN'],\n",
       " 95793: [0.01081627666331684, 299161.46875, 'RNN'],\n",
       " 95952: [0.011467006187995876, 265843.34375, 'RNN_2_Layers'],\n",
       " 95963: [0.09982480165100077, 210254.015625, 'RNN'],\n",
       " 95816: [0.4210158842165424, 119499.453125, 'RNN_w/_D.o.'],\n",
       " 95779: [0.008916532210573824, 356233.5, 'RNN_w/_D.o.'],\n",
       " 95852: [0.4483304887711713, 88581.8359375, 'RNN_w/_D.o.'],\n",
       " 95783: [0.30532257510450905, 114232.0, 'RNN'],\n",
       " 95814: [0.3261871025380606, 154928.890625, 'RNN'],\n",
       " 95957: [0.014312274288334835, 263559.1875, 'RNN_w/_D.o.'],\n",
       " 95888: [0.15829581651374572, 150898.125, 'RNN_w/_D.o.'],\n",
       " 95861: [0.010756883153635951, 288260.0625, 'RNN'],\n",
       " 95840: [0.009716248202977836, 351459.4375, 'RNN_w/_D.o.'],\n",
       " 95842: [0.3907977533130183, 160567.1875, 'RNN_w/_D.o.'],\n",
       " 95766: [0.009283903352492488, 238973.828125, 'RNN_2_Layers'],\n",
       " 95883: [0.14146181014236883, 179078.5625, 'RNN_w/_D.o.'],\n",
       " 95911: [0.47797922855479613, 109065.421875, 'RNN'],\n",
       " 95744: [0.010473932170971098, 318112.03125, 'RNN'],\n",
       " 95834: [0.009394672482179175, 436116.71875, 'RNN'],\n",
       " 95928: [0.021138152233605073, 321487.03125, 'RNN'],\n",
       " 95901: [0.015500266138529232, 398981.40625, 'RNN_w/_D.o.'],\n",
       " 95890: [0.017911963964382834, 370710.75, 'RNN'],\n",
       " 95966: [0.07900841390322466, 216244.03125, 'RNN_w/_D.o.'],\n",
       " 95768: [0.1733520922342198, 131972.71875, 'RNN'],\n",
       " 95805: [0.33669101538872087, 157623.96875, 'RNN_2_layer_w/_D.o.'],\n",
       " 399673: [0.44854637171077116, 128122.109375, 'RNN_w/_D.o.'],\n",
       " 95954: [0.010580071578349318, 401904.875, 'RNN'],\n",
       " 399672: [0.012968756991867574, 429064.90625, 'RNN_w/_D.o.'],\n",
       " 95787: [0.33323494240442375, 78555.546875, 'RNN_2_layer_w/_D.o.'],\n",
       " 95839: [0.017919257828032824, 276303.84375, 'RNN'],\n",
       " 399674: [0.009868474953755129, 540381.5625, 'RNN'],\n",
       " 95922: [0.09176846528710561, 122019.7890625, 'RNN_w/_D.o.'],\n",
       " 95866: [0.00846236418835034, 309080.03125, 'RNN_w/_D.o.'],\n",
       " 95907: [0.16051137567180201, 110492.0546875, 'RNN_w/_D.o.'],\n",
       " 95788: [0.3868782573250403, 106090.9765625, 'RNN'],\n",
       " 95926: [0.018466005514636286, 940217.8125, 'RNN'],\n",
       " 95930: [0.038486938289727726, 340051.125, 'RNN_w/_D.o.'],\n",
       " 95956: [0.02267846591755282, 323574.34375, 'RNN_w/_D.o.'],\n",
       " 95938: [0.0253975958046679, 414122.34375, 'RNN'],\n",
       " 95795: [0.36879644487670243, 143378.0, 'RNN_w/_D.o.'],\n",
       " 95923: [0.3100881329980668, 425945.625, 'RNN_w/_D.o.'],\n",
       " 95955: [0.018945583709221687, 416612.0, 'RNN'],\n",
       " 95924: [0.24600876160122867, 251795.875, 'RNN_2_Layers'],\n",
       " 95775: [0.013901971524148082, 211011.375, 'RNN'],\n",
       " 95919: [0.017901753903209344, 280901.21875, 'RNN_2_Layers'],\n",
       " 95794: [0.009283127428990465, 326745.4375, 'RNN_w/_D.o.'],\n",
       " 399666: [0.012761330007475953, 326569.8125, 'RNN_2_Layers'],\n",
       " 95760: [0.015311716869128513, 305169.40625, 'RNN_2_layer_w/_D.o.'],\n",
       " 95916: [0.010283915515249062, 454169.15625, 'RNN'],\n",
       " 95891: [0.015973275966231323, 631484.0625, 'RNN_2_layer_w/_D.o.'],\n",
       " 95820: [0.026546641662656644, 333096.4375, 'RNN'],\n",
       " 95917: [0.38148026851000305, 110806.203125, 'RNN_w/_D.o.'],\n",
       " 95893: [0.025635352695454836, 2101477.25, 'RNN'],\n",
       " 95851: [0.005617965905931265, 360632.53125, 'RNN']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'RNN', 'RNN_2_Layers', 'RNN_2_layer_w/_D.o.', 'RNN_w/_D.o.'},\n",
       " [34, 11, 43, 15])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_types = []\n",
    "for item in best_model_dict.values():\n",
    "    model_types.append([item[2]])\n",
    "list = []\n",
    "for item in model_types:\n",
    "    list.append(item[0])\n",
    "labels = set(list)\n",
    "sizes = []\n",
    "#list.count(labels[0])\n",
    "for i in labels:\n",
    "    sizes.append(list.count(i))\n",
    "labels, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADnCAYAAADVXQcoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABCxklEQVR4nO3dd3xb1fn48c+jLdmS7HhkkjiAiZ1ggoHgsKGMUqBpgTJaaAOU0vUtlA6ghV+/KZsvbWmBQmmhEEZbCmUEwijQlBkCBGfbibPIjhMvyZatdc/vj6sQx/FMbF/JPu/Xyy+kO3QfBfvR0bnnOUeUUmiapmmZwWZ1AJqmaVrv6aStaZqWQXTS1jRNyyA6aWuapmUQnbQ1TdMyiE7amqZpGUQnbU3TtAyik7amaVoG0Ulb0zQtg+ikrWmalkF00tY0TcsgOmlrmqZlEJ20NU3TMohO2pqW4UQkKSKLRGSZiLwkIjmp7UUiokTkR+2OvV9ELks9fkxENouIO/U8X0TWd3Odw0VkvogsF5ElInJRD3H9V0SO6oe3qLWjk7amZb5WpdThSqlDgXrgh+321QLXiIiri3OTwBW9vE4E+JZSagpwJvD7XR8QVhIRu9UxDCaH1QFoWrqoKimdBtwFxDv8NAAbgI3t/ruxtLoqZlGo3ZkPHNbu+Q7gfWAm8JdOjv89cK2IdLZvD0qpVe0ebxGRWqAAaOxtcCJSBDwBZKU2/Y9S6gMReQJ4Vin1Yuq4p4CngbnAncDJgBv4o1LqIRE5GfhfYCtwuIhMA/4JjAPswC1Kqad7G1cm0UlbG/ZO8ftHAAdfkTti2lE+3ym9PE1VlZTW0i6JAzWYSXNxaXVVcmCi7VqqxXkq8EiHXXcCr4rIXzs5bQPwHvBN4KU+XOtowAWs6WOYtcDpSqk2ESkG/g4cBTwMXAu8KCJB4FjMD5pvA01KqWmpbpz3ReTfqdc6GjhUKbVORM4Htiilzk7FF+xjXBlDJ21Ng9OA86uibcGjfL7eniPAyNTPtA77mqtKSj/EbOG+B3xYWl3V3F/BdsIrIouAImAh8Eb7namk9hHwjS7Ovx2Yg9mq7ZGIjMZsLc9UShl9jNUJ3C8ih2N2zRySivFtEfmjiBQC5wH/UkolROQM4DAR+Vrq/CBQDMSAj5RS61LblwK/EZG7gJeVUu/2Ma6MoZO2ppkJuNEjtv7q7sjG/CA4LfU8WVVSuhgzgb8PvFNaXbWtn64FqT7tVOvyZcw+7Xs7HHM78CzwTseTlVKrU0n/wp4uJCIBzOR+k1Lqw32I9VpgOzAV855aW7t9TwCXABezu59dgB8ppV7vEMfJQEu797BKRI4EzgLuEJF/K6Vu3of40p5O2po28OzAEamfqzG7Vt4BngSeLa2uauyPiyilmkTkaswuhgc77KsWkRXAOcBHnZx+Gz20tFM3M58HHldKPbOPYQaBTUopQ0RmYv7b7PJYKrZtSqnlqW2vA98Xkf8opeIicgiwuZPYxgD1SqknRaQZuGwf40t7Omlr2uAT4KTUz/1VJaVzgaeAuaXVVdH9eWGlVKWILMZsrXbsIrgNqOzivOUi8inmB0tXLgROBPJ2DRsELlNKLermnLkiEk89ng/8EviXiFwAzGPP1vJ2EakCXmh3/sOY3T6fiohg3lj9aifXKQPuFhED8+bx97uJKaOJXo1dG+5O8fsvAr5wSla274KcnEstDKURswvjKeDt0uqqYfXHKSI+zL7pI5RSTVbHk670OG1NSx85wJWYLdDPqkpKb6kqKS20NqTBISKnAdXAfTphd093j2hDUtENc0cBhUAuZjLc9d8czKFqdmDF+jvPnm1NhD06ALgJ+FlVSemjwN2l1VXrejinX4hIGeZNwfaiSqmKLo5/HpjYYfP1HW8edkcp9SYwvk+BDlM6aWsZq+iGuYWYfbClwIGYieNAzD5Qby9e4gUgXZP2Lh7M/tmrqkpKnwZuK62uWjGQF1RKLQUO78Px5w5cNFpHOmlrGaHohrkjMAsujgSOVEodISJjLQ5rMNkxx1lfXFVS+g/gf0urq1ZbHJNmAZ20tbRUdMNcD3A8cJpS6jSgXEQ+vwdjDiQYlmyYyfvCqpLS2cDNpdVVGyyOSRtEOmlraSPV3XF+6uv2CSLigWGdoLvjwCzxvrSqpPQ24M7S6qp4D+doQ4BO2pqlim6Ymw+crwzjYkROEBG7TtJ94gZuBi6oKim9srS6qrPCGW0I0UlbG3RFN8y1AWcrw/g+IqeLiENsevTpfioD5leVlP4BuKm0uipidUDawNBJWxs0RTfMHamM5FXA98VmH60Tdb+zYc7t8dWqktKrSqur3rQ6IK3/6aStDbiiG+aWq2T8JmyOGWKz69+5gTcReKOqpPQx4Cel1VUNFsej9SPd1NEGzITrXqoY/5N/zQM+FbvzPBHRCXtwXQZUVZWU6nHUQ4j+I9L63YSfv3iiSibutLk8x4jLY3U4w91I4LmqktI7gRtLq6v6Ov+1lmZ00tb6zfifPjcVZTxgc3mPFd0Lkm5uAA6tKim9pLS6KmR1MNq+039Z2n4bf+0zI1Uy8YDN6z9X9Hi9dHYO8GFVSekMXU2ZuXSftrbPim6Y6xj3P0/cKg7XersvcJ5O2BmhFPioqqT0tB6P1NKSTtraPhl71UMnGdGWtY7sETeK3aE7rjNLLvBaVUnpNVYHovWd7h7R+mTUpXd77Fm5f3HkjvmG6IHWmcwO/L6qpPQw4Pul1VX9tT6mNsD0H53Wa2Muv/dMV/74z5y5oy/VCXvIuAJ4s6qkNNvqQLTe0X94Wo9yT77cOfY7Dz3hLJz4is2TPSxWUhlmTgBeriop9VkdiNYznbS1buV/+eeHZU05pdqZN+5SEZu+0Th0nQS8WFVSqu9PpDmdtLVO+YorZORFN3/PV1wx3+HPO9DqeLRBcRrwbFVJqcvqQLSu6aSt7SV76hnu4LFff9pTVP6AzeXVX5mHl7OBf1SVlOpBCmlKJ21tD8HpXxsfrDj/E/fo4gt0d8iwdS7wZFVJqd3qQLS96aStfS7nxG8e6z/inAXOEeMOtToWzXIXAY9WlZTqHJFm9FcgDV9xhXiKDv+6v/zsB+1ef8DqeLS08U0gCnzH6kC03fSn6DDnK66w+4qP+UX2YV/8q07YWieurCopvcHqILTddNIexnzFFR7vQUfflTXl5F/bnG631fFoaeu2qpLSM60OQjPppD1M+YorsjwTj7w3u+y0a8Tu1N1kWndswN+qSkoPsjoQTSftYclXXJHlPfCo+/xTv3i52B06YWu9kQu8UFVSmmV1IMOdTtrDjK+4Itt70LT7sw8741s6YWu9pZQygGeBVqtjGe70H+0w4iuu8LsPOPS32WWnXyp2hx6Dq/VKm2FE32gOP3jdli2/tjoWTbe0hw1fcUWWs6DoVn/52d/ULez9c+PWrRy/uoYZ69bute+v9XVMXllNQyLR6bmhZJIfb97M2evWcs66tSxqNRuuv91Ry1fXreOGrVs+P3ZOUxNPNNQPzJvopdpEovY3O3Y8/Wo4/JClgWif00l7GPAVV7jsgYKfB48+73Kb060nBNpP5waD/HncAXtt3xqPM78lwuhuPhPvqN3O8VlZzJ14IM8VTeRAl4twMkllaysvTJxIUsGqaBtthsHzoSYuzskdyLfSrUWtrdV31G5/YEsi/pN54XC1ZYFoe9BJe4jzFVfYbF7/VcFjLvofmyfbb3U8Q8FRPh9B+95/OnfV1vLTggK6qv1vTib5pLWV84NBAFwiBOx2bAJxpVBKEVUGDoS/1tdzaU4uTgtWcIsrFf9XU+O7f66vuzmq1B3zwuG6QQ9C65L+mjyE+YorBOT84PQLr3dkj8izOp6h7D/NYQodDko8XX+R2RiPM8Ju58ZtW6mORpni8fCLwpFk2eycke3nvM/WM93nw2+3s6ytlR/k5w/iOzA1JpMNj9TXvbUmFrsLWDgvHFaDHoTWLZ20h7Yv+I84+0bniLHjrA5kKGs1DB6qq+PhTrpM2kuiWNHWxi8LRzLV6+X27dt5uL6Oq/ML+HZeHt/OMz9X/9+2rfxPfgHPNjbyfqSFSW4338sb+AS+Khpd+3B93XPNhnHPvHB4S89naFbQ3SNDlK+4otRTdPgvPEXlh1kdy1C3MR5jczzOuevXcdqa1WxPJDj/s/Xs6HAzcqTDyUiHg6leLwBn+P2saGvb45hdz4tcLl4MNXHPmLHURKOsjw3cEo5JpZKvh0Mf/X7njjubDeNXOmGnN93SHoJ8xRX5jpzRv/BPPfM4EQs6RYeZQ9we3ju4+PPnp61ZzTMTisjtcEOywOFglNPJuliUiS43H0ZaOMi15+wB9+3cwa9HjSKhFEaqY8KG0GYYAxJ7i5EMP97Q8PbStrbfAm+37w4pm112PjBy6cylDwzIxbV9klEtbRFJisgiEVkmIi+JSE5qe5GIKBH5Ubtj7xeRy1KPHxORzSLiTj3PF5H1/RDPQyJyXBf7HhORdSKyWERWicjjIjJ2f6/ZE19xhUuc7quD0y/4kjhceqTIAPjZls18/bPPWB+Lccqa1fyrsbHLY2sTcb67aePnz28sHMl1W7by1XXrqI5GuSpv962GN8NhDvV4KXQ4CdjtTPV6+cq6dQDd9pXvq42x2KY7amufXNrWds28cPi/uxJ2wdkFOaX3lz6GWUzz+7LZZRX9fnFtn2VaS7tVKXU4gIjMBn4I3JbaVwtcIyIPKaU6+y6ZxFx5+sF+jKcC+EE3+3+ulHo21dr9MTBPRA7tIr79Zt545GL/kTPOt2flDP5drGHiN2O6/+x986CDP39c6HDyULu+7lKPh2eKijo97zS/n9P8uwf4XFc4MGsoK6XUB5HIkr83Nsw24JF54XBo175xV407Ou/0vOccfseuN+kEni6bXVa+dObShgEJSOuTjGppdzAfaP/XswN4C5jZxfG/B64VkR4/qETkARGZkXr8vIj8NfX42yJya+pxKbBKKZXs6fWU6R5gG/ClTq53uIh8KCJLUtfb18G5090HHHqJe0zJ5H08XxvioobR9kRjw1tPNTbcZMC9uxJ2oDwgRT8p+nHwqODbzlxnx0+lCfRvY0fbDxmZtEXEDpwKzOmw607gp6n9HW0A3sOc2L0n7wAnpB6PBXYlweOBd1OPvwS81oewAT4FSjrZ/jhwvVLqMGAp8L99fF18xRX54s76jv/wL03X3dhaZ2oTidq7d+z454eRyDXzwuGX54XDSYDcE3I9BTMKns0uy/6dzW3rqh/morLZZV8exHC1LmRa0vaKyCKgDhgBvNF+p1JqHfAR8I0uzr8d+Dk9v+93gRNEZDKwAtguIqOBY4APUsd8kb4n7b2yqYgEgRyl1NupTbOBE/vyor7iChtweXDaV4+xubx6IQNtLx2qG1fs2j728rGTCr9auMR3oO88sfX4af9g2ewy/ftlsUxL2rv6tCcALsw+7Y5uB66nk/emlFoNLAIu7O4iSqnNmFNRnonZ6n43dU6zUiosIj7MRNvXoVHlQFUfz+mNkzwTjzjTNfKgzlrx2jCWUCr+XBfVjROumXBJ8Ojgx658V3F3r9HOWOD/BiZSrbcyLWkDoJRqAq4GfiYizg77qjFbx+d0cfptwM96cZn5mDcPdyXtn7G7a+QUYF5v4xXT1cBoOrTOU++lQUR2dcd8E3ibXvIVV4wWp2dm9qGnHtXbc7ThoTGZbPjDzh0vvtnc/BPgH/PC4RhAoDzgPPDGAx/yT/U/bvfZ+zq1wVVls8tO6v9otd7KyKQNoJSqBBYDF3ey+zag0ypApdRyzL7lnrwLOFKt808xu2P62p99t4gsBlYB04BTdo0cEZGHRWRXop2ZOnYJcDhwc+qYm3fdEO2Mr7jCDlzhP+Lsw3S3iNbeqmh07e212x9ZE4tdMy8c/mTXcL7R3xg9dtRFoz7MOiTrKrHLvvz9C/CXstllejipRTJqyJ9SKrvD8/Y3Rg5tt30x7T6QlFKXdTjvvF5c6xHgkdTjONB+xY5jgWt7OP+yHvZf2e7xImB6J8f8qocwpztHjDvKPbZ0ag/HacNEUqnkW83hhS+EQg8DT84Lhz9ftGD8/4w/M+fYnCcdfsf+zkNTDNyU+tEGWca2tK2klDoilcgt4yuuCACX+I84e6qITf9/1GgxjPCf6+tefSEUuh54eFfCDpQHbBOvm3ib/3D/nH5I2Lv8pGx22Zh+ei2tDzKqpd3fRKQMeKLD5qhSqtcVYCLyR6BjVeQflFKP7m98PZjhmXjEgY7gyIkDfB0tA2yMxTb9ub7upbpk8jfzwuHPV2co+HJBcOT5I5/3HOA5pZ8v6cUcmvrdfn5drQfDOmkrpZZi9iHvz2t0NoJlQPmKKw4ATs0qPal8sK+tpZd21Y2PG2bres/qxlPznuukWKa/XFE2u+y3S2cuXTVAr691Ylgn7Uy0q1Tdd8ixY+xe/8DUOWsZIWoYbU83Nb73YSTyB+DVXcUygfKAjDhlxDXBo4J3dFMs0x8cmDf9LxjAa2gd6KSdeQ5BZIq3eLpuZQ9jOxKJ2j/X1722OR6/q32xTKq68SlvkffcXhTL9Ievlc0um7Z05tKPB+FaGjppZ5RUK/trvkOOG233ZBdYHY9mjUWtrdWzG+r/EVXq/vbFMmMvHzup8CuFL7kKel0s01/uxJxWQhsEetRBZilBpNh3cMURVgeiDb5uqxt/POEbwaODH1uQsAG+UDa77HgLrjss6ZZ2hvi8lV187EibJ0tPuzrMtFu78f+Az4tlAuUBZ/5Z+ff7D/NfuY/FMv3lGswJ2bQBppN25pgMHOQ98IgpVgeiDa6aaHTtXzpZu3HURaPGjLpo1Evu0e50+OZ1btnssvFLZy7dYHUgQ51O2hkg1cr+smtUsceeldv96rHakNFtdeMPx38x94Tcp/qxWGZ/2TEncLve6kCGOt2nnRnGApN8k47Ts/gNEz1WN5b7X0qjhL3Ld8pml/msDmKo0y3tzHCKzZdjd44Yd2jPh2qZzoLqxv6SizlL5UNWBzKU6aSd5nzFFX7gpKzJJ40Tm62zFXm0IUIppeZHIkv+1ll143fHTcs7Ne/5Aaxu7C9Xo5P2gNLdI+nvaMDmHnnwYVYHog2cXWs3Pmmu3fiHDms3XhM8stO1G9PR5LLZZXvNWKn1H93STmOpZcTOco2Z5LB5sgas/1IlYmz72/WoRBwMA9+k48g54RIa33mCyOoFIILdl0PeWT/G4d87jNa1C6l/689gGGRPPYPgdLOqueG/j9K6diGuwonkn/NTAJqX/QejLUzgqK8M1NvJOGlU3dhfLgI+tDqIoUq3tNPbRGCEd+IRA1swYXcy8uLbGXPF/Yy+/F5a1y0kurmaQMX5jLnifsZcfh/eg6bR9MHf9zpVGUnq33iQwgt+zZgrH6BlxdvEdm7AiLYQ3VzFmCvuRymD2I71GPEoLcvexF9+9oC+nUyyuLW1+vba7Q9sjsd/utfajV/p9dqN6eaCstllmRZzxtBJO71NQyThzDtgQMdmiwg2lxcAZSTASIIINvfugQAq3kYn6xIT27oKR85onDmjELuTrNITaa35EBBUMoFSCpWIITY7oY+ew3/kDMSuv+Dtqm58aHd1485d+yZcM+HrFlY39oexgK6QHCD6rydN+YornMCJnqJyn83p6es6fn2mjCRbZ/+YRMNW/EecjXvMJAAa3nmclmX/web2MfLrd+x1XiJchyOwexoUuz+f2NaV2Nw+fJOOZetjV+OZMBVxZxHbuoqc474+0G8l7TWlqhtXd1XdONXy6sb+cDG7l+fT+pFO2umrGPB4xk05ZDAuJjY7Yy6/D6OtmdrnbyO2Yz2ugiJyT/wWuSd+i6b5/yS88GVyTrikN68GQLDiawQrvgZA3av3knPCpYQXv07bukqchUXkHNvZ8p5DW4ZUN/aHr5XNLrt66cylSasDGWoy/dN8KDsGiDlyRg3qV2SbJxvPAWW0rt1z7eOsyScTWfX+Xsc7/HkkQjs+f54M78SePWKPY2Lb15jH5o6lZdl/KPjqDcR3fEa8fvMAvIP0ZChl/Dsc/vienTvuajaMX7VP2KnqxiVDKGEDFAInWx3EUKSTdhpKdY0c7Sw8UNlc3uBAXy8ZacJoawbAiEdp+2wRzrxxeyTVyOoFOEfsvcC9a/QhJBq2EG/chkrGaal6B+/Be67W1vjukwSPvwSMBCjD3Cg2VCI6cG8qjaSqG195IdR0PfCXDtWNt6ZpdWN/OMfqAIYi3T2SnsYDDs+4KYMyLjfZXM/OufeYCVUZ+EpOwHfw0ex4/nbi9ZtAbDgCBYz4ormyWiJcR91r9zLygl8jNjsjTv8etf/8FSiD7LLTcRVM+Py1I6vm4xpV/PlQQfeYErY88kOchUW4Cg8cjLdnqR6qG5/zHOD5gpXxDbB0rdzMaKKUsjoGrQNfccU5wLkjTv/+SY5AwUFWxzOEvbD+zrPPPcXvvwj4wilZ2b4LcnIu7Y8X7qm6Mbs0OxOqG/eXAvKXzlxab3UgQ4luaaeno8XpbrZnj5jQ86FauokaRts/mxrfnR+J3MveazdeHTwyeIfNbfNaHOZgEOBE4AWL4xhSdNJOM77iihxgnHvcFJvY9IDmTNOuuvH/5oXDy3dtT1U3Pukt8mZiscz+OBmdtPuVTgrp5yAAZ94BQ/2r85CzuLW1+jFz7cY/ti+WGTNzzCGptRsHZfhmmtH92v1Mjx5JPyVA3BEo1Ek7Q/RU3ZgzPeeTYZqwAcrKZpeN6Pkwrbd0Szv9lAIhe3bu3uPrtLSTqm58c3Usdjd7Vzfe55/q/84QqG7cH4JZczDX6kCGCp2004ivuMIDjHEERzYMRum6tn+6rG68eNToUReNenmIFcvsj0PRSbvf6KSdXsYCyjWqWHeNpDFDKePN5uaFL4SaHgae6LB24xm5x+c+5fA78i0MMd1MtjqAoUQn7fQyDhBHoKCgxyM1S7QYRviJhvq3l7S1/Q74b7vuEFve6Xm/9pf7r7c5bU6Lw0w3AzpL5XCjk3Z6KQFabb7gUCxpznibYrHND5nVjXcPw+rG/VFSNrtMls5cqiv5+oFO2unlACBi93ayPIxmGaUU8yORxX9rbHjCMOcO2V3d+J1xR6XWbtQ3jruWBRQB6yyOY0jQSTtNpJYWGwlstbmz9BCpNJGqbnwvVd34Sofqxh8FpwXvHCbVjftrMjpp9wudtNNHELDZfEGXOFy+Ho/WBtyORKL2z3V1r29OxO/S1Y37bTJ6BEm/0Ek7feQByjlinG5lpwFd3djvRlsdwFChk3b6yANsdl9Qt7ItlFAq/lKoacEbzc0PAs/OC4dju/ZNuGbCRTnTc/5s99kDFoaYqfSIqH6ik3b6KASUzZ2VZXUgw9XmeNx+784dL3axduN9qbUb7RaHmal00u4nOmmnjxFATNw+3dK2RuGqWLQauE9XNw6IQqsDGCp00k4fuUDc5vLqpD34NmPeJHuqQ3Xj6bnH5/5NVzf2C93S7ic6aaePIBAXp0cn7UE2Lxx+D3hv1/NUdeMsf7n/Bl3d2G900u4nw3n2sXQTAGI2p1snbQsVfLkgWHhe4RvZU7L/n07Y/cpdNrtMT4LWD3TSTgO+4goB/EAcvVqNZVLVjcu84726HH1gBK0OYCjQCSI9OAAnYCA2/f9kkKWqG/8nOC14l65uHFD6d7sf6H/E9ODAXLkaEZseUjaIUtWNT3iLvOfr6sYBp3+3+4FO2ulh9y+z6MQxaFSdt/ArhYt1deOg0fmmH+g+7fRgJ9XS1gaeMgyVaNzwmt19xwE6YQ8q/TveD/QnX3rQretBEm/Ysqp58d/rVHJR8oDvjj7I6niGmaTVAQwFOmmnGZVMxHo+SuurZEvD5ualb1ZGNy/fZveuG5V7st9hc9rcVsc1zCSsDmAo0Ek7Pez+2mjopN2fjGikoWXle5+01ny4Cfi33btuu9hj38qaVPAlq2MbhnTS7gc6aaeHGKkuEt3S7h8qEWttXVf5SfOyN9dhJBcAzzmyq7YDs3yH+HyObMdIq2MchhqsDmAo0Ek7PbRL2vGoxbFkNGUkE9EtKyvDi16tUdGWKuDvkZoFawAC5YGJwPjAEQG9OvjgiyyduTRidRBDgU7aaSBSsyDpK65IADaViOuW9j5QShGv27g8XPlKVTJUuw74G7AkUrPAaHfYKY6gw+4qdJVaFOZwtsPqAIYKnbTTRxtgV4lom9WBZJpEaOf65iWvLY5tX7sZeAZ4P1KzIN7+mEB5IAgcm3NMznix6TmxLaCTdj/RSTt9tAJ2o3X3St9a95Kt4dqWFW9/2rb+083Ay8AbkZoFLV0cfjQ27N6JXj0vtjVqrQ5gqNBJO300A8FkS4NO2j0w4m3h1tUfL2ypevszlPEO8GKkZkFdV8cHygMO4KzAEYFcm9umZ5qzhm5p9xOdtNNHLVCYCO9ssjqQdKWSiVjbpuWfNi9+bY2KRxcB/4zULNjQi1NLgZzsKdlTBzZCrRs6afcTnbTTRy3gTjRu2251IOlGKcOIbV+3JFw5d5URaazBvMlYFalZ0Nuy6C+6x7ldzlxn0cBFqfVgk9UBDBU6aaePWsCh4m0JlYi1isOlpwgF4g1ba5oXv7osXrdpI/B34ONIzYJel0MHygOjgEOD04LFAxak1hsrrA5gqNBJO300AQaAEWttsA/zpJ1sadzSvOytyuim5VuA54F5kZoFXY+smRX0ASOY1dSxRXeCzWsTz1iP7hqxlk7a/UQn7fTRRKqcPRlp3G73BcdYHI8ljFikMbLyg4WRVR9sAN4AXonULOi6n39W0G4odblN5JfA0e13BcoDXuDUYEVwpDjENaCBa11SSjUtu2zZZqvjGCp00k4fDaSmyk2Gdm4nf4LF4QwulYi3tq6vXNi87M11JBMLgOciNQu2dndO3XX+89wOuSfbJeOVUo/Lr0M7OxxSDrizirP0MD8LiYhuZfcjnbTTR3PqxxVv3Lp9uPSNKMNIxrauqgwveqXGaGuuAv4BrO7uJmPD9YFpNuGhPJ+tfNc2Eflj+2MC5QEBzs6anJVlz7LrlcCttdzqAIYSnbTTRKRmgfIVV6wDJsa2r9lmdTwDTSlFon7TinDlKysSTds/wxwRsqhD2fkeIjcGJrQl1AO5Hjmr/QI/0YRa6r419FGHww8CxvgP9x86IG9A6wvd0u5HOmmnl9XAFCPSVG/E20I2pydgdUADIRGu+6x58euLYttXb8UsO38vUrOgyzlXWn4ZCLYm1N05Hrnc59x74WOnnd91ctqpzjyn05XvmtSPoWv7ZqnVAQwlOmmnl02kZvtLtjRsseWMHlJJO9nWvCNS9fanrWsXbgZeAV6P1Cxo7vKEWUHnjhbjhoBbrs/32bI6OyRhqCaHTf7RflugPJALHB2cHhwvNtFL6llIKZUQkQ+tjmMo0Uk7vXzeLZJo2LremTO6xMpg+osRjza3rvl4YcuK/36GMt4FXojULOh403APddf5Z3qdcldBlq3bea+V4hFmNXUcCjhdHGL3TtDzjKSBhUtnLu36g1nrM52000st5uoejujWmvXeiZmdc5SRiEc3rlgYXvzaWhVvWww8HalZ8Fl35zRcHzjFbuOBPJ+txw8spZThtMt97bcFygNO4EuBIwMjbK7OW+fa4BGReVbHMNTopJ1GUvNqrwAOjm1duV0l4q3icGbcQBKllIrXrlsSrpy7MtnSsAbzJuPy7kaENP8yUBJP8qdcr5zU2+vEkrzpvrVpfYfNUwB/1uSsw/cldq3f/dfqAIYanbTTz2JgKlCXaK7b4MwZlVE30uKN21Y3L35taXznhk2Yw/c+itQs6HJtwLabAgXNMfWHEV65yObqW/+z2yH3tH+eGub3Jc8Ej8cZdB6wT29A6zep/uz3rI5jqNFJO/2sI1UZmWjYsi5TknYy0rS1edlbldGNyzYDLwL/idQsaO3yhFlB744WY1aOR67O99k8fb1eLKk2uOzyeofNY4FDgtOCh/T19bQB8fHSmUu7mt9c20c6aaefzaT6tds2LK3xTjziTKsD6o4Ra22KrJr/SWTlexuBt4CXIzULGrs8YVbQtjNifD/LKbcUZNly9/W6duFeZjV17G450Z5lt7lHu8v29XW1/qP7sweGTtppJlKzIOErrqgCDorv/Kwu2da8w+7JTruKPpWIt7VuWLyweckb60jGPwGeidQs2NLdOXXX+b/sdsi9+T5b0f5cO2moNrtNHmm/LVAeyAJODk4PjhG7OPfn9bV+86LVAQxFOmmnpwWk+rXjOzdU2cdNTpukrQwjGdu2alG48tUaoy1cjTldak13NxmbbggcqeBPeT7bUf0RQ8LgafvNTY0dNh8JOH0H+zJ7yM0QoQz12bLLl3WsUtX6gU7a6akas19bohuXVXnGTT7R6oDMsvPNVWbZ+bZdZeeV3ZWdt/wycEA0qf6Y45FzbO3rzveT2yG/b/88UB6wAWdnl2X77V77iP66jrYfhH/0fJC2L3TSTkORmgUNqXlIRkS3VG8zYq2NNpc3x6p4Es11G5oX/3tRbFvNFuBZ4N3uys6ZFQzsjBh35njkyiyXrV+7KqIJtdB9a2hRh82HAIX+qf6M6ctWhmLNrDU4c51MuHYCTR81UftCLdGtUQ761UF4J+490jO6NcrGBzZ+/jy2I0bhuYXkfzGfbf/cRnhJGO94L+OuGgdAw/sNJFuS5J+RP2jvaxcReXrQLzpM6KSdvt4Dvgk0xes2rnCPPuTYwQ7AaGve2VL17qetaz/eBLyKWXYe7vIEs+z8ZwG3/DLfZ8seiJi6mmfEVeByOvOcGbM6Td2/63CPcWO0ml9U3OPcjP/ReDY/1vW00+7Rbg6+5WDATPorf7ySwJEBkpEkkdURim8tZuOfNtK2sQ3XSBeN7zVS9NOiwXg7e1CGWrvs8mWVg37hYUIn7fS1nNQ8JK1rPl40mEnbiEdbWtd+srBlxX/XYyTfxyw7r+3unLrr/Jd4HPKbgizbqIGKK2GoOodNnm2/LVAeyAOODE4PTpR+7IIZSPH6OOHFYQq+XEDd6+Yi8p4xfRv12LyiGVehC1e+i2RrEpVQKKVQcYXYhZ2v7iTv9DzEYcE/ifC3wb/o8KGTdvragTmBVCC2fc2OZEvDRntW7oAWjCgjGY9uWvFpePFra1SsdSlm2fm67s5pvCFwok14IM9nmzKQsQEoxZ+Z1dSxW+ZYcYrNM95T3ulJaWjr37Yy6qJRJFt7vdTlXpoWNBGcHgTA7rUTOCrAml+tIWtyFjafjda1rRR+pbC/Qu4TEdH92QNIJ+00lZpf+3Xg20Aourn6U98hxwxI0lZKqfiO9UvDlXOrk831azFvMi7roez8kFiSB0d45QsDEVMnMRpOuzzQflugPOACvhicFsy3OW0ZUe4fWhTCEXDgLfLSXLVv8ygZCYNwZZhRX9v9pabgrAIKzjIHGW3+62YKzyuk/u16mpc14znAQ+GMwUngKqk+XnbFMr3owQDSSTu9LQKSgL1l5XvLvQdNO1PsDnd/XiDRtH1NeNFrS+I7P9sMPA182F3ZeeuNgbyWuLon1yOXZPex7Hx/xJK84r51r0V7y4CsrJKsjGllR2oihCpDhBeHUXFFsi3Jxoc2csB3e/953LykGc8ED47g3n++rZ+ZRajuUW62PrWVA395IBsf2Eh0WxT3qH791emU2OW3A36RYU4n7TQWqVnQ7Cuu+ACoULHWrfG6jctchROP7I/XTkZC25qXv/VpdMPSzcAczLLzSJcnzAp6drQYvwp65Np9KTvfX13MM3KW9yCv1xFwZMwiyKMuGMWoC8wWcnNVM3Wv1fUpYQM0fdhEzvScTvfVPlfLmMvGoBIKdg3GtIER63JkZr9RSVUrdvnXgF9omNNJO/29C5wAEFk1f4GzoOjI/bnfZsRamyI1Hy6MVL/7GeYMbC9FahY0dHnCrKDsjBjfy3LKrQVZNkvGQMeSarXrltB/OmweDxwUODIwJOYcDy0MseXJLSTDSdbfsx7veC9FPysi3hBn86ObKfpJEQBG1KB5eTNjLtv7cyq0MIR3ohdnrjnK0nuwl5qbavCM8+AdPyi9R/ctnbm0y29pWv8QpbrsttTSgK+4wgbchTmSpHnEad/9uiM4ss8TIqlkPNr22ZJPmpe+sU4lYp8Az0ZqFnQ9vgyovz5wtsvOvdkuOXDfou8fhlI/sv06dH/7bYHywLfsfvtpYy8f+w2xid2q2DSTMlRUbDJ26cyldVbHMtTplnaai9QsMHzFFS8BlwHNkVXz3wtM+2qvk7ZShhHbtnpRuPKVVUZraCXmdKkreyg7L1fw4AivVOz3G9hPSUNF7DaZ3X5boDzgB07MOSZnrE7Y6UEl1dPLLl+mE/Yg0Ek7M3wEXAx42jYs2ZhVeuIGe/aI8T2dFK/fXB2ufGV5onHrBsw5Qj6N1CzocpxZ7P8FxoSj6o+5XvlKf5ad74+k4in7rKaOBT3TEGzeA/VyYulAKaVsTtvdVscxXOiknQEiNQvafMUVc4ALgQ2RtQvf8x92+je6Oj7ZXL8xvPSNytiWlVvZXXYe7fICs4L+HS3G7ble+W6er3/LzveXy77XPCN24Cx/uT/H7rHnWBKUtgcVU3OXXbVsmdVxDBc6aWeO94HzAGdrzfwaX3HFNrs3sEf1oRFtqWupfvfT1tUfbQReA17roezcsaPF+EnALTcVZNn8Axr9Pogm1Hz3raEVHTaXAHn+Kf7DrIhJ25MylCEO+YnVcQwnOmlniEjNgnCq2OZLwKbIqvlv+ad+8RIAlYhFWtcu/KR5+X/WYyQ/wCw7397d6+28zn+x1yG/Lciype1wOaedzsb8nu4a7XI5RjgOGvSAtL0kW5P/rPpBVY3VcQwnOmlnlnmYSdvZunrBam9ReU0iVNsQXvTqahVrXQ78I1KzYG13L9BwfeA4m/Bgvs+W1jPixZOq1mmXPSbRD5QHCoGpORU5B6ZJl/uwppIqZnPbdCt7kOmknUEiNQvqfcUVrwJnATvr3/zTB8B2zLLzJd2NCAn/InBw3OCBXA+nZ0LCE+EBZjV1HPN7vLhE3OPch1sRk7anZGvyz1U/rNpqdRzDjU7ameffwBeALOCvwPxIzYJ4Vwe33hgY0RJXv8v1yKX2DBkeZyiVcNjkofbbAuUBD3B6zvScQptj8CsytT2phGpxZDtusjqO4Ugn7QyT6tueBbT0UHbu3hkxbgq45af5vsyYTGmXeJI57lubtnXYPBXw+A7Ry4mlg2Rb8o6qH1Y1WR3HcKSTdgaK1CzY0eVOs+z8yiyn3J7vsw3+kiX9wO2QPRY62DXPiG+SL8uR7RhpUVhaSrIludqR7bjD6jiGK520h5C66/xnuuxyX77PdrDVseyrWFJVu24Jvd9h80RgfKA8UGpFTNpuylBGvDH+zRU/WDHwM1BpndJJewgI/SJQljR4KM9nO8bqWPaXXbink82nOHIcdleha/KgB6TtIb4zPrvmlzUfWh3HcKaTdgaL3hQY1RxT9+d65bx9LTu/4sVWXl6VoDBLWPYDc1nH+lbFRc9GWN+oKMoR/vk1H7nePV9+5c4kFz3b+vnztQ0GN5/i5sfT3Vz/Rhuvrk5w+Cg7j59rdqc/sThGfavimuldz+mcNFTYbpMn228LlAeCwDE503PGi23w5u/W9paMJLcbMeP7Vscx3Ok/gkw0K5i14+f+39ttfJbns52/P/OEXHa4k9cu9e2x7c73opw60UHNj7I5daKDO9/buwJ+Ur6dRd/LZtH3sll4VRY+p3BuiZOmNsUHm5Is+X42SaVYuj1Ja1zx2OI4P5jm6jaWpGI2s5o63lytwIbdO1HPM2IlpZSK18cvr7mxpuvpELRBoZN2JpkVtO+8zv+TtoTaXJBlu8Zhk+6zYC+cOMHBiA6t6BdXJpg51ZyCZOZUJy+s7H6K5LfWJTlohI0JOTZsArGkuchsaxycdrj7gxhXH+3Cae/6s0UppVx2+UP7bYHygAM4K3BkINfmTr8y++EkXhd/vubGmletjkPTSTtj7LzOf0FzTK3P99l+63FIcCCvtb3ZYLTf/NUY7bdR29L9Pad/LIvz9UPNJO93C+eXOil/qIWJOTaCbuHjLUm+UtL9PFSxJG8zq2l1h82TgWD25Oyp+/petP2XCCe2xXbEvml1HJpJ92mnucYbAhUCD+X7bGmZuGJJxZyVCe44dXdf9XXHubnuOPP5lXNauflkNw9/GuPfaxIcNtLOTSfu3a/dcZhfyhc94zxuZ66zaIDC13pgJIx469rWC9f/bn3XNQHaoNIt7TQVuTFQVH994NWgmw+DHhnUhD0y28bWsNm63ho2KMzq+tfk1ZoER4y2MTJ772Mqt5pTdx+SZ+PxxXH+eYGPZbVJaur2nNI7nlRbgLnttwXKA6OByYGjAxk7fHEoaF3Tetf6361/1+o4tN100k4zkRsDOTuv8z/stlMzwitnWjFPyIxDHMxebFbGz14c5yuTuv5C9vd2XSMd/b95UW4+xU3cgGRqVhSbQKRD0b0I9zOrqWMfzIk2r83mGeNJy28Yw0HbxrZ5O1/d+b9Wx6HtSSftNLL+x/4rHTY25/ts37bbZFC6rr7+rwjHPNLCyjqDcb8L88inMW443sUbaxMU39fMG2sT3HC82Z2xJWxw1lO7vyVH4oo31iY5r3TvpP1CdZxpY+yM8dvI8QjHjLNT9mAzIjB11O4pUAylYg6b/KX9uYHygBc4JWd6zkhx7P/NVq3v4vXxjY3zG88LVYa6vaEhIkkRWSQiy0TkJRHJSW0vEhElIj9qd+z9InJZ6vFjIrJZRNyp5/kisn7A3tAQohf2TQMzJjlzgHOOHG278Fcnub+cCbPw9ZdoQv3NfWvokvbbAuWB44Arx31n3Dn2LHtGluJnsmRrsqVpQdNJmx/dvLCnY0WkWSmVnXo8G1illLpNRIqABUAYmKyUionI/cAnSqnHROQxzInP7lBKPSgi+al9RQP0toYM3dJOD9cApy/caiyu3mkssTqYweR27LWcmABnZU3JytYJe/AZMSPa9FHTd3qTsDsxHxjb7vkO4C1gZhfH/x64VmRwvlUOFTppp4cPAANI/umT2JvxpOpyqtWhJJpQS5jV9HGHzQcDYwJTA1OsiGk4UwmVaPyg8fZwZfgffT1XROzAqcCcDrvuBH6a2t/RBuA9QA8n7AOdtNPD20AdEFjXqML/XZ+cZ3VAg8Fpp7Nhfqc685wOZ4GzZNADGsaUoVTjgsa/hBeFbw9VhvrSZ+oVkUWYv78jgDf2eF2l1gEfAV0tRH078HN0Luo1/Q+VBuasjMeAJ4E8QP74cezDbc3GRovDGlAJQzXaRJ5uvy1QHsgFpgWnByfIcOrYt5hSitCnoWdCH4d+EqoMdV/+urdWpdThwATABfywk2NuB66nk3yjlFoNLAIu7ON1hy2dtNPHYuBTYJShUPd/FHsxYai+/gFlDKV4mFlNbR02HysOsXkn6HlGBlPz8uY3G99r/HaoMtTx/0evKaWagKuBn4mIs8O+amAFcE4Xp98G/Gxfrz3c6KSdJuasjCvgCUAB3iXbjbr/rk/+x+KwBoRSynDa5Y/ttwXKA07gzMBRgTyby5ZlUWjDTnNV8wf1b9ZfFKoMNe/vaymlKjEbHxd3svs2YFwX5y3HbLBovaCH/KWZGZOcxwDfB9bZBB46x3PFyGxbp7/smSqaUP923xr6YvttgfJAOXD1mMvHnOoMOg+wKLRhQylFuDL8bsM7DReFKkN6cd4Molva6edDYCG7u0leGGrdJF0sJ/YlT5HHrRP2wFOGMprmN73V8E7Dt3TCzjw6aaeZjt0ki7cbdW+uTb5pcVj9JpZUn2GuKN/eWKA4eFRwkgUhDSsqqZIN7zbMbfqo6bJQZWi91fFofaeTdhqaszJeDzwOjAbkgY9jC1buTC61OKx+YRf+wKymjn1yJ9mz7Db3aHeZJUENE0bCiNe9VfdMuDJ8ZagytMnqeLR9o5N2+poPfEyqwuzmt6Mv1UWMbdaGtH+Shmqz2+TR9tsC5YEs4OTgMcExYpfuJ93W9lmyNdmy89Wdj7esaPlBqDJUa3U82r7TSTtNpbpJHsUsWsgPx4jf9X7s6WhCtfZwatpKKv7BrKbGDpuPAhy+g3x6mN8Aie2Mbd32z233tq5pvTZUGWqwOh5t/+ikncbmrIw3A/cCbsBXvdNonL04/i8jQ4f8uOx7zTNiA87OPizbb/faR1gT1dDWsqplxda/bb070ZC4JVQZClsdj7b/dNJOc3NWxjcDfwJGAfaXVyXWvJ2B47ejCfUJs5oWd9h8CFDgP8yv+7L7mUqqeP079e/sfGXnjRjcG6oMZew3NG1POmlngDkr4wuBF4EDAO75MPZept2YdNr5bSebT3cVupzOPGfxoAc0hCUjyabaF2pfDH8avjpUGXohVBlK9nyWlil00s4cLwJLSd2Y/OVb0RfWNxqrrA2pdxKGqrOJ/Kv9tkB5IB84Ijg9OFHPM9J/Imsj1Vue3PJw28a2q0OVoY7fbLQhQCftDDFnZTwB/BmoB0bGDYwb3mx7ZnPIWGdxaL3xJ2Y1dZxu9lhxingO8JRbEtEQk2xLNu18becbO+bsuNeIGL/SRTNDl07aGWTOyngYuBtoA/IjcRI3vNn2j9oWY7PFoXXJUCrpsMmD7bcFygMu4IvBo4P5NqfNa1FoQ4JSisi6yIotj215vqW65XbgoVBlSK+cPoTppJ1h5qyM7wT+D7NiMrcpSuzGt6JP1beqtBx7G0/yCrOaOn6oHAZkZZVk6Vb2fki2plrXL+6YbbQZ14cqQ//taU1HLfPppJ2B5qyMb8VscXuA4PYW1fqreW1PhKKq3uLQ9uJ2yD3tn6fmGTnbd7DP4/A7xlgUVkZTSRVvrmpeuOWxLc9HVkZuB36jC2aGDz3LXwabMcl5MHAD0Ag0T8wR/6yTPd/M9UqBtZGZYklV47oldEj7bYHywATg16MuHFXuHuM+zKLQMpJSSkU3RZfV/aeuOtGQ+BiYrZP18KNb2hlszsr4auB3mCveZK1rVOHr3mh7NF36uB02/tDJ5pMdAYfNNcql14Dsg1hdbF3tc7Uvbv/X9ncSDYk/AL/VCXt40i3tIWDGJOehwLVAExAKuHHefqrnovFB20FWxZQ0VMRuk1HMavq8Ci9QHvAD9+SdkXdg9uTsU6yKLZMkwoltTR82LWpe3rwJc9Hct/SNxuFNJ+0hItVV8jMgBtQ7bdhuPsV9zpRCuyU3+2JJ9ZDrltD32m8LlAdORbhk3HfHnWf32INWxJUpYnWx1aGFoaqWFS31wDzgpVBlKO3uWWiDTyftIWTGJOcBmCtbO4HtAD8/1nXSCRMcJ1sQzmRmNVXtehIoD9iB//Mf4Z844sQR51oQT9pThkpGt0SXNn7YuCq6KdoKLAGeCVWGhvQiz1rf6KQ9xMyY5CwAfgwUApsBLprimHzBFOcMl13cgxFDNKHed98aOr79tkB5YArw8+zDsiVwZOAUvULNbkbMiLR+1lrZ+H7jZ4nGRBT4BHgdWBuqDOk/UG0PPSZtEUlilk87gHXAN5VSjSJSlHp+tVLqvtSx9wOfKKUeE5HHgNOBA5VSURHJT+0r6uI6hwMPAgEgCdymlHq6m7j+C/xMKfVJr9/tIBGR0cBspdQZnewrAqqAaswhe2Hgj0qp2f11/RmTnNnAD4DJwAbAmFJgG/GzY10X5Plso/rrOl0xlDrf9uvQc+23BcoD12JOELUdwFvkLfSX+490j3ZPGY4L+aqkisdqY9UtK1tWhpeEmzGIA/8B5oUqQ9utjk9LX45eHNOqlDocQERmAz/EXFkZoBa4RkQeUkrFOjk3CVyBmYx7EgG+pZSqEZExwEIReV0p1diLc/udiNiVUvs60c6ZmC2lrqxRSpWnrnMg8JyI2JRSj3ZzTq/NWRlvnjHJ+XvgIswPzq3Ldxj1P3yl7ZEbT3B/qWykfcDmro4n1XanXV7sZNdnwBRgPNDQur61tnV966vYeC17cvYEX7Gv1D3KXWpz2/wDFZvVlKGMeEN8beua1mWhhaEdRtRwAC3Ay8AHeupUrTf6OuRvPqkJi1J2AG8BM7s4/vfAtSLS44eDUmqVUqom9XgL5gdCr8Ybi8iDIvKJiCwXkV+ntp0qIs+3O+Z0EXku9fgMEZkvIp+KyDMikp3avl5EfiUi7wEXdHKdQhFZmHo8VUSUiIxPPV8jIr7UoWcCr/YmdqXUWuAnwNWdXE9E5G4RWSYiS0Xkot68JsCclfEY8CRwPzCCVNn7jf+JvvTM8vhz8aTqOBdIvxDhAWY17fVhF6oMPYfZbTMb82bpeOAADHzNy5rX1z5f++rGBzf+budrOx+JrIvMT7YlGwcivsGmEioaq41VhypDL2+ZveWvW5/Y+m7jB411RtSoxPz7+GmoMvS6Tthab/WmpQ2YLU/gVOCRDrvuBF4Vkb92ctoG4D3gm8BLfbjW0YALWNPLU25UStWnYnxLRA7D/Kr5RxEpUErtAC4HHk1109wEnKaUahGR6zGT5s2p12pTSh3f2UWUUrUi4hGRAHACZt/jCakkX6uUiqRimKSUWtHb9wt8CpR0sv084HBgKpAPfCwi7yilejUZUGr1m49mTHJuwvyGNB7Y9MSS+NJltcmt10x3XzDCK4V9iLNbhlIJh00e6mp/qDLUDLwdKA+8A4zDfF8npOICaGipbtnUUt2yCfi3Z7wn31vkHe8a5RrvzHWOt3vtuf0V60BRhkomQolNsR2x9W3r29Y1Vzc3kSSQ2r0acyTI8lBlqMXCMLUM1puk7RWRRUARsBB4o/1OpdQ6EfkI+EYX59+OOb50bm8CSvUHPwHMVEr1dh6FC0XkKsz3MxqYrJRaIiJPAJeKyKPAMcC3MFvBk4H3UzOCujC/QezSZT96ygfAccCJqfd2JiDAu6n9FcCCXsa9S1dTkx4P/D3VTbNdRN4GpmH+e/banJXxLTMmOW/B/H90MrClcpux86qXWh/60dGu444bbz/RYev521BP4klecN/a1GN/bOrm2kZgY6A8MBfz/1kZuxO4AJG2DW1NbRvaPsX8UMOZ7/T7DvaNd492j3fmOsfZffZ8cYhrf+PeVyqpEslIsjYRStTGG+LbY9tiW1tWtdSpmPJjjuAB2In5/2uRHrKn9Yde92mLSBCz7+2HmEtgtXc78CzwTseTlVKrU0n/wp4ulGrBzgVuUkp92IvYEJGJmOOTpymlGlI3QD2p3Y9itvDbgGeUUonU3M1vKKW+3sVL9tQCehczuUzAnOP6eszJm15O7f8S8FpvYm+nHPPmZEf9Ns/0nJXxthmTnI8CK4HLgGQsybbfzo+9+/oa2/IfTnN9eWzAVrQ/1+g4z0hvpBL4FmBLoDzwb8xRLwdjJvEpgA/z3yEe3xlvatrZtBxYvut8Z54z2z3anefMc+Y7chx5Dr8jz+6z59lctmzsuPd3qm4jbrSqmGo2okazETWaE82JhvjO+Pboluj2tk1tjSh8QDa7k/SuD/AlmKM/mvcrAE3roNetK6VUk4hcDbwosudUm0qpahFZAZwDfNTJ6bfRQ0tbRFzA88DjSqlnehsX5miTFqBJREZiJs3/puLaIiJbMLtDTk8d/yFmt8nBqQ8UHzBOKdXbBQXeAW4F3lFKGSJSD5wF/CK1/1TMyZx6JTWa5DfAfV1c67upG8AjMFv3P+/ta3eU6i55f8Yk5xrMLqtDge3Lao36789tm3354c7Dzyp2nOF2SJ+nS40lVZXrltAH+xobfJ7At6d+3k9NLlWA2fouxZwdcDzmhyQA8bp4JF4X34HZFbfnUCgb4vA7PPZsu9eebffafXavzWPz2Jw2p1JKYWAoQxkoPn+sDGUkW5KRREMiHG+It6i4SmImYg+QhfkholL/dQObML8JVAPrgXo9TE8bSH36SqyUqhSRxcDF7O4O2OU2oLKL85aLyKdAd6MWLsRMSnkicllq22VKqUU9xLRYRCoxW19rgfc7HPIUULCrj1kptSP1+n8X+Xzc8k1Ar5K2Ump9qvW261vFe5hJv0FECjD7xEM9vMxBqZh3Dfm7b9fIERE5CvieUupKzA+xY4DFmIniOqXUttTomoeVUmf1JuaO5qyMb5sxyflb4GjMLqNcYMuji+KLXl+TWHXtdNeZk/LtfVq30WHjd/sSS3dSya829fMJfF4Kn48538pozCQ+LvUDuxO3YGBLNCVUoimRwLz52YqZgOXzY/b8cWDenLdhNgYCqccKqANWADXAVswPlnq9lJc22IZ8cU1q7HilUqrjDdSBuNalmAn8zoG+Vn+ZMckZxPzAPB5zVZwmgOPH28dcfKjzC72ZvyRhqLDDnGfEsjkxAuUBB+aHTzbgTf3sah0HMROwDzBSP8nUT/vHIaABaMb8MG1O/bTqeaq1dDGkk3ZqeF4LcLpSKmp1POlqxiSnYHY/XIHZgt2OeR+A0w+0T/jaZOcXRvtt47s6P55U9zpvCV0zKMFq2jA36ElbRMowR4e0F1VKVXRx/PPAxA6br1dKdVe8st9E5I+Yo0Ta+0NvC2D6+j7TwYxJTg9mi/t8zP7abZjdCsyY5Dj4qyWOL+T7bKPbn6OUUiJyCLOaVg96wJo2DA3plra2b2ZMcmYBpwBfxuzn3QbEBbhgiqP09AMdx47Mto0DiCbUPPetoS9YF62mDS86aWtdmjHJGcAcdXMm5g25rUACoGKsffKFUxwHF+fZb2RWU6+qPzVN2386aWs9mjHJOQI4A3M4ox2zYKQAuGfOyvgSK2PTtOFGJ22t12ZMcvoxKz7Pwezr/uWclfGEtVFp2vCik7bWZzMmOR2Ac87KeKvVsWjacKOTtqZpWgbRq7FrmqZlEJ20NU3TMohO2pqmaRlEJ21N07QMopO2pmlaBtFJW9M0LYPopK1pmpZBdNLWNE3LIDppa5qmZRCdtDVN0zKITtqapmkZRCdtTdO0DKKTtqZpWgb5/7YrJfK/AWLaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explode = (0., 0.2, 0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_05_18 = []\n",
    "for zipcode in df_time_series.columns:\n",
    "    predictions_05_18.append(best_model_dict[zipcode][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_05_18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding our best predictions to the Nevada DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ferityikar/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "<ipython-input-122-025623a86f9b>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time_series.loc['2018-05-01_pred'] = predictions_05_18\n"
     ]
    }
   ],
   "source": [
    "df_time_series.loc['2018-05-01_pred'] = predictions_05_18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>95804</th>\n",
       "      <th>95817</th>\n",
       "      <th>95813</th>\n",
       "      <th>95785</th>\n",
       "      <th>95819</th>\n",
       "      <th>95770</th>\n",
       "      <th>95806</th>\n",
       "      <th>95790</th>\n",
       "      <th>95799</th>\n",
       "      <th>95844</th>\n",
       "      <th>...</th>\n",
       "      <th>95919</th>\n",
       "      <th>95794</th>\n",
       "      <th>399666</th>\n",
       "      <th>95760</th>\n",
       "      <th>95916</th>\n",
       "      <th>95891</th>\n",
       "      <th>95820</th>\n",
       "      <th>95917</th>\n",
       "      <th>95893</th>\n",
       "      <th>95851</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-04-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>106800.000000</td>\n",
       "      <td>165100.00000</td>\n",
       "      <td>185700.00000</td>\n",
       "      <td>144000.000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>148000.000</td>\n",
       "      <td>118900.000</td>\n",
       "      <td>157300.000</td>\n",
       "      <td>...</td>\n",
       "      <td>116800.00000</td>\n",
       "      <td>170900.0000</td>\n",
       "      <td>196000.0000</td>\n",
       "      <td>153200.00000</td>\n",
       "      <td>184200.00000</td>\n",
       "      <td>299200.0000</td>\n",
       "      <td>166100.0000</td>\n",
       "      <td>293200.000000</td>\n",
       "      <td>562400.00</td>\n",
       "      <td>176400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107000.000000</td>\n",
       "      <td>164500.00000</td>\n",
       "      <td>186300.00000</td>\n",
       "      <td>143500.000</td>\n",
       "      <td>122800.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147800.000</td>\n",
       "      <td>119000.000</td>\n",
       "      <td>156000.000</td>\n",
       "      <td>...</td>\n",
       "      <td>117000.00000</td>\n",
       "      <td>170800.0000</td>\n",
       "      <td>196000.0000</td>\n",
       "      <td>153700.00000</td>\n",
       "      <td>185000.00000</td>\n",
       "      <td>299600.0000</td>\n",
       "      <td>166600.0000</td>\n",
       "      <td>293200.000000</td>\n",
       "      <td>562800.00</td>\n",
       "      <td>176300.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-01 00:00:00</th>\n",
       "      <td>102500.000000</td>\n",
       "      <td>107200.000000</td>\n",
       "      <td>164000.00000</td>\n",
       "      <td>186900.00000</td>\n",
       "      <td>143100.000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95800.000000</td>\n",
       "      <td>147600.000</td>\n",
       "      <td>119000.000</td>\n",
       "      <td>154700.000</td>\n",
       "      <td>...</td>\n",
       "      <td>117200.00000</td>\n",
       "      <td>170700.0000</td>\n",
       "      <td>195900.0000</td>\n",
       "      <td>154100.00000</td>\n",
       "      <td>185800.00000</td>\n",
       "      <td>299900.0000</td>\n",
       "      <td>167300.0000</td>\n",
       "      <td>293200.000000</td>\n",
       "      <td>562700.00</td>\n",
       "      <td>176100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-01 00:00:00</th>\n",
       "      <td>102600.000000</td>\n",
       "      <td>107400.000000</td>\n",
       "      <td>163500.00000</td>\n",
       "      <td>187400.00000</td>\n",
       "      <td>142700.000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>95900.000000</td>\n",
       "      <td>147300.000</td>\n",
       "      <td>119100.000</td>\n",
       "      <td>153500.000</td>\n",
       "      <td>...</td>\n",
       "      <td>117400.00000</td>\n",
       "      <td>170700.0000</td>\n",
       "      <td>195700.0000</td>\n",
       "      <td>154400.00000</td>\n",
       "      <td>186400.00000</td>\n",
       "      <td>300200.0000</td>\n",
       "      <td>167900.0000</td>\n",
       "      <td>293200.000000</td>\n",
       "      <td>562400.00</td>\n",
       "      <td>176000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-08-01 00:00:00</th>\n",
       "      <td>102700.000000</td>\n",
       "      <td>107600.000000</td>\n",
       "      <td>163200.00000</td>\n",
       "      <td>187700.00000</td>\n",
       "      <td>142400.000</td>\n",
       "      <td>122700.000000</td>\n",
       "      <td>96100.000000</td>\n",
       "      <td>147100.000</td>\n",
       "      <td>119200.000</td>\n",
       "      <td>152600.000</td>\n",
       "      <td>...</td>\n",
       "      <td>117600.00000</td>\n",
       "      <td>170700.0000</td>\n",
       "      <td>195400.0000</td>\n",
       "      <td>154700.00000</td>\n",
       "      <td>186900.00000</td>\n",
       "      <td>300500.0000</td>\n",
       "      <td>168600.0000</td>\n",
       "      <td>293200.000000</td>\n",
       "      <td>562300.00</td>\n",
       "      <td>175900.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>200700.000000</td>\n",
       "      <td>201500.000000</td>\n",
       "      <td>330700.00000</td>\n",
       "      <td>407300.00000</td>\n",
       "      <td>294300.000</td>\n",
       "      <td>234600.000000</td>\n",
       "      <td>189200.000000</td>\n",
       "      <td>303500.000</td>\n",
       "      <td>243700.000</td>\n",
       "      <td>294100.000</td>\n",
       "      <td>...</td>\n",
       "      <td>270000.00000</td>\n",
       "      <td>316500.0000</td>\n",
       "      <td>315500.0000</td>\n",
       "      <td>299900.00000</td>\n",
       "      <td>449500.00000</td>\n",
       "      <td>642500.0000</td>\n",
       "      <td>317600.0000</td>\n",
       "      <td>201600.000000</td>\n",
       "      <td>2121300.00</td>\n",
       "      <td>350400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>203500.000000</td>\n",
       "      <td>204000.000000</td>\n",
       "      <td>334600.00000</td>\n",
       "      <td>410400.00000</td>\n",
       "      <td>297400.000</td>\n",
       "      <td>237200.000000</td>\n",
       "      <td>191700.000000</td>\n",
       "      <td>306700.000</td>\n",
       "      <td>246300.000</td>\n",
       "      <td>296900.000</td>\n",
       "      <td>...</td>\n",
       "      <td>275600.00000</td>\n",
       "      <td>319500.0000</td>\n",
       "      <td>319500.0000</td>\n",
       "      <td>302500.00000</td>\n",
       "      <td>450100.00000</td>\n",
       "      <td>653800.0000</td>\n",
       "      <td>323400.0000</td>\n",
       "      <td>207000.000000</td>\n",
       "      <td>2153600.00</td>\n",
       "      <td>353000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>206600.000000</td>\n",
       "      <td>206700.000000</td>\n",
       "      <td>338800.00000</td>\n",
       "      <td>413700.00000</td>\n",
       "      <td>300200.000</td>\n",
       "      <td>239800.000000</td>\n",
       "      <td>194500.000000</td>\n",
       "      <td>309800.000</td>\n",
       "      <td>249500.000</td>\n",
       "      <td>299400.000</td>\n",
       "      <td>...</td>\n",
       "      <td>282100.00000</td>\n",
       "      <td>322400.0000</td>\n",
       "      <td>323600.0000</td>\n",
       "      <td>305700.00000</td>\n",
       "      <td>451100.00000</td>\n",
       "      <td>666000.0000</td>\n",
       "      <td>334700.0000</td>\n",
       "      <td>216500.000000</td>\n",
       "      <td>2167100.00</td>\n",
       "      <td>356000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>209300.000000</td>\n",
       "      <td>208600.000000</td>\n",
       "      <td>342000.00000</td>\n",
       "      <td>416100.00000</td>\n",
       "      <td>302400.000</td>\n",
       "      <td>241900.000000</td>\n",
       "      <td>196600.000000</td>\n",
       "      <td>312200.000</td>\n",
       "      <td>252000.000</td>\n",
       "      <td>300800.000</td>\n",
       "      <td>...</td>\n",
       "      <td>286000.00000</td>\n",
       "      <td>324700.0000</td>\n",
       "      <td>326600.0000</td>\n",
       "      <td>307800.00000</td>\n",
       "      <td>455300.00000</td>\n",
       "      <td>672600.0000</td>\n",
       "      <td>344300.0000</td>\n",
       "      <td>222800.000000</td>\n",
       "      <td>2161900.00</td>\n",
       "      <td>357200.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01_pred</th>\n",
       "      <td>81137.242188</td>\n",
       "      <td>81155.828125</td>\n",
       "      <td>343416.90625</td>\n",
       "      <td>416440.96875</td>\n",
       "      <td>305058.125</td>\n",
       "      <td>110461.828125</td>\n",
       "      <td>68937.523438</td>\n",
       "      <td>316477.625</td>\n",
       "      <td>120022.625</td>\n",
       "      <td>305458.875</td>\n",
       "      <td>...</td>\n",
       "      <td>280901.21875</td>\n",
       "      <td>326745.4375</td>\n",
       "      <td>326569.8125</td>\n",
       "      <td>305169.40625</td>\n",
       "      <td>454169.15625</td>\n",
       "      <td>631484.0625</td>\n",
       "      <td>333096.4375</td>\n",
       "      <td>110806.203125</td>\n",
       "      <td>2101477.25</td>\n",
       "      <td>360632.53125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            95804          95817         95813         95785   \\\n",
       "1996-04-01 00:00:00  102500.000000  106800.000000  165100.00000  185700.00000   \n",
       "1996-05-01 00:00:00  102500.000000  107000.000000  164500.00000  186300.00000   \n",
       "1996-06-01 00:00:00  102500.000000  107200.000000  164000.00000  186900.00000   \n",
       "1996-07-01 00:00:00  102600.000000  107400.000000  163500.00000  187400.00000   \n",
       "1996-08-01 00:00:00  102700.000000  107600.000000  163200.00000  187700.00000   \n",
       "...                            ...            ...           ...           ...   \n",
       "2018-01-01 00:00:00  200700.000000  201500.000000  330700.00000  407300.00000   \n",
       "2018-02-01 00:00:00  203500.000000  204000.000000  334600.00000  410400.00000   \n",
       "2018-03-01 00:00:00  206600.000000  206700.000000  338800.00000  413700.00000   \n",
       "2018-04-01 00:00:00  209300.000000  208600.000000  342000.00000  416100.00000   \n",
       "2018-05-01_pred       81137.242188   81155.828125  343416.90625  416440.96875   \n",
       "\n",
       "                         95819          95770          95806       95790   \\\n",
       "1996-04-01 00:00:00  144000.000  122800.000000   95800.000000  148000.000   \n",
       "1996-05-01 00:00:00  143500.000  122800.000000   95800.000000  147800.000   \n",
       "1996-06-01 00:00:00  143100.000  122700.000000   95800.000000  147600.000   \n",
       "1996-07-01 00:00:00  142700.000  122700.000000   95900.000000  147300.000   \n",
       "1996-08-01 00:00:00  142400.000  122700.000000   96100.000000  147100.000   \n",
       "...                         ...            ...            ...         ...   \n",
       "2018-01-01 00:00:00  294300.000  234600.000000  189200.000000  303500.000   \n",
       "2018-02-01 00:00:00  297400.000  237200.000000  191700.000000  306700.000   \n",
       "2018-03-01 00:00:00  300200.000  239800.000000  194500.000000  309800.000   \n",
       "2018-04-01 00:00:00  302400.000  241900.000000  196600.000000  312200.000   \n",
       "2018-05-01_pred      305058.125  110461.828125   68937.523438  316477.625   \n",
       "\n",
       "                         95799       95844   ...        95919        95794   \\\n",
       "1996-04-01 00:00:00  118900.000  157300.000  ...  116800.00000  170900.0000   \n",
       "1996-05-01 00:00:00  119000.000  156000.000  ...  117000.00000  170800.0000   \n",
       "1996-06-01 00:00:00  119000.000  154700.000  ...  117200.00000  170700.0000   \n",
       "1996-07-01 00:00:00  119100.000  153500.000  ...  117400.00000  170700.0000   \n",
       "1996-08-01 00:00:00  119200.000  152600.000  ...  117600.00000  170700.0000   \n",
       "...                         ...         ...  ...           ...          ...   \n",
       "2018-01-01 00:00:00  243700.000  294100.000  ...  270000.00000  316500.0000   \n",
       "2018-02-01 00:00:00  246300.000  296900.000  ...  275600.00000  319500.0000   \n",
       "2018-03-01 00:00:00  249500.000  299400.000  ...  282100.00000  322400.0000   \n",
       "2018-04-01 00:00:00  252000.000  300800.000  ...  286000.00000  324700.0000   \n",
       "2018-05-01_pred      120022.625  305458.875  ...  280901.21875  326745.4375   \n",
       "\n",
       "                          399666        95760         95916        95891   \\\n",
       "1996-04-01 00:00:00  196000.0000  153200.00000  184200.00000  299200.0000   \n",
       "1996-05-01 00:00:00  196000.0000  153700.00000  185000.00000  299600.0000   \n",
       "1996-06-01 00:00:00  195900.0000  154100.00000  185800.00000  299900.0000   \n",
       "1996-07-01 00:00:00  195700.0000  154400.00000  186400.00000  300200.0000   \n",
       "1996-08-01 00:00:00  195400.0000  154700.00000  186900.00000  300500.0000   \n",
       "...                          ...           ...           ...          ...   \n",
       "2018-01-01 00:00:00  315500.0000  299900.00000  449500.00000  642500.0000   \n",
       "2018-02-01 00:00:00  319500.0000  302500.00000  450100.00000  653800.0000   \n",
       "2018-03-01 00:00:00  323600.0000  305700.00000  451100.00000  666000.0000   \n",
       "2018-04-01 00:00:00  326600.0000  307800.00000  455300.00000  672600.0000   \n",
       "2018-05-01_pred      326569.8125  305169.40625  454169.15625  631484.0625   \n",
       "\n",
       "                          95820          95917       95893         95851   \n",
       "1996-04-01 00:00:00  166100.0000  293200.000000   562400.00  176400.00000  \n",
       "1996-05-01 00:00:00  166600.0000  293200.000000   562800.00  176300.00000  \n",
       "1996-06-01 00:00:00  167300.0000  293200.000000   562700.00  176100.00000  \n",
       "1996-07-01 00:00:00  167900.0000  293200.000000   562400.00  176000.00000  \n",
       "1996-08-01 00:00:00  168600.0000  293200.000000   562300.00  175900.00000  \n",
       "...                          ...            ...         ...           ...  \n",
       "2018-01-01 00:00:00  317600.0000  201600.000000  2121300.00  350400.00000  \n",
       "2018-02-01 00:00:00  323400.0000  207000.000000  2153600.00  353000.00000  \n",
       "2018-03-01 00:00:00  334700.0000  216500.000000  2167100.00  356000.00000  \n",
       "2018-04-01 00:00:00  344300.0000  222800.000000  2161900.00  357200.00000  \n",
       "2018-05-01_pred      333096.4375  110806.203125  2101477.25  360632.53125  \n",
       "\n",
       "[266 rows x 103 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_return = {}\n",
    "for i in df_time_series.columns:\n",
    "    investment_return[i] = (df_time_series[i][-1]-df_time_series[i][-2])/df_time_series[i][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95800: -0.6742991606714628,\n",
       " 95803: -0.6494240172655453,\n",
       " 95806: -0.6493513558621566,\n",
       " 95804: -0.6123399799928333,\n",
       " 95817: -0.6109500089884947,\n",
       " 95911: -0.5999067429383712,\n",
       " 95932: -0.5977889264990329,\n",
       " 95909: -0.5939241231566361,\n",
       " 95815: -0.5902021884233853,\n",
       " 95931: -0.5887560566322901,\n",
       " 95935: -0.5854965439334288,\n",
       " 95838: -0.5818566524621213,\n",
       " 95771: -0.580677253763089,\n",
       " 399673: -0.5726413963475651,\n",
       " 95852: -0.5670487002077224,\n",
       " 95818: -0.5577714066159251,\n",
       " 95811: -0.5536213600852272,\n",
       " 95816: -0.5464916389943074,\n",
       " 95770: -0.5433574695121951,\n",
       " 95798: -0.5432109375,\n",
       " 95912: -0.5388096816976128,\n",
       " 95841: -0.5357096220152326,\n",
       " 95826: -0.5301508402394107,\n",
       " 95805: -0.524225871566556,\n",
       " 95799: -0.523719742063492,\n",
       " 95788: -0.5199503322963801,\n",
       " 95824: -0.518330780411449,\n",
       " 399671: -0.516835218910964,\n",
       " 95845: -0.5151362232289951,\n",
       " 95754: -0.5105418929354324,\n",
       " 95843: -0.5066034170994065,\n",
       " 95917: -0.5026651565305207,\n",
       " 95940: -0.5021518020564169,\n",
       " 95792: -0.49526765625,\n",
       " 95914: -0.49519775324587506,\n",
       " 95842: -0.4942765748031496,\n",
       " 95825: -0.4870056868374558,\n",
       " 95787: -0.4811390563077939,\n",
       " 95795: -0.47691353520612917,\n",
       " 95753: -0.4721665290333797,\n",
       " 95769: -0.4406145695637806,\n",
       " 95783: -0.4313987058237929,\n",
       " 95835: -0.4282437916812917,\n",
       " 95814: -0.4278844511632201,\n",
       " 95923: -0.42501940469762417,\n",
       " 95907: -0.4072314662687768,\n",
       " 95888: -0.377996187139324,\n",
       " 95883: -0.35397343975468976,\n",
       " 95924: -0.34852296248382925,\n",
       " 95922: -0.2758469491839763,\n",
       " 95768: -0.27167373758278146,\n",
       " 95963: -0.13900894502457004,\n",
       " 95966: -0.10863960737840066,\n",
       " 95891: -0.061129850579839426,\n",
       " 95820: -0.03254011762997386,\n",
       " 95893: -0.027948910680420002,\n",
       " 95957: -0.022043831168831168,\n",
       " 95955: -0.020427933223606864,\n",
       " 95901: -0.01849592558425584,\n",
       " 95919: -0.017827906468531468,\n",
       " 95952: -0.017578182742054693,\n",
       " 95890: -0.01616042993630573,\n",
       " 399674: -0.013181953067932798,\n",
       " 95939: -0.012759696331930246,\n",
       " 95839: -0.011081446850393702,\n",
       " 95926: -0.01092172049232064,\n",
       " 95954: -0.010330275794139374,\n",
       " 95760: -0.008546438434048084,\n",
       " 95834: -0.0045270058205889065,\n",
       " 95809: -0.0034408811475409836,\n",
       " 95938: -0.003315658844765343,\n",
       " 95928: -0.0031409883720930234,\n",
       " 95937: -0.002990686491266858,\n",
       " 95916: -0.0024837332528003515,\n",
       " 95837: -0.0005739896988906498,\n",
       " 399666: -9.242957746478873e-05,\n",
       " 95840: 0.0007387172551252848,\n",
       " 95785: 0.0008194394376351839,\n",
       " 95830: 0.0013965212264150943,\n",
       " 95813: 0.004143000730994152,\n",
       " 95945: 0.005361342943854324,\n",
       " 95794: 0.006299468740375731,\n",
       " 95930: 0.006366158626812666,\n",
       " 95944: 0.007177821128451381,\n",
       " 95819: 0.0087900958994709,\n",
       " 95751: 0.009558598308051341,\n",
       " 95851: 0.009609549972004479,\n",
       " 95861: 0.01002124211632796,\n",
       " 95750: 0.010423226479514415,\n",
       " 95827: 0.011406156549043062,\n",
       " 95779: 0.011739562624254473,\n",
       " 95865: 0.01190072898799314,\n",
       " 95766: 0.012172080156713257,\n",
       " 95956: 0.013069329211020664,\n",
       " 95831: 0.013622489900190113,\n",
       " 95790: 0.013701553491351697,\n",
       " 95793: 0.01410667372881356,\n",
       " 95844: 0.01548828125,\n",
       " 95775: 0.018394666988416988,\n",
       " 399672: 0.020125787565382785,\n",
       " 95744: 0.020243846215522773,\n",
       " 95866: 0.02209005042989418,\n",
       " 399665: 0.027353564307078762}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_return = dict(sorted(investment_return.items(), key=lambda item: item[1]))\n",
    "investment_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in investment_return.keys():\n",
    "    list.append(i)\n",
    "best_5_investments = list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95775, 399672, 95744, 95866, 399665]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_5_investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>95775</th>\n",
       "      <th>399672</th>\n",
       "      <th>95744</th>\n",
       "      <th>95866</th>\n",
       "      <th>399665</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-01 00:00:00</th>\n",
       "      <td>184400.000</td>\n",
       "      <td>377900.00000</td>\n",
       "      <td>281800.00000</td>\n",
       "      <td>270700.00000</td>\n",
       "      <td>270800.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-01 00:00:00</th>\n",
       "      <td>186300.000</td>\n",
       "      <td>381300.00000</td>\n",
       "      <td>284300.00000</td>\n",
       "      <td>272300.00000</td>\n",
       "      <td>273800.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-01 00:00:00</th>\n",
       "      <td>188500.000</td>\n",
       "      <td>384400.00000</td>\n",
       "      <td>287000.00000</td>\n",
       "      <td>274700.00000</td>\n",
       "      <td>276600.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01 00:00:00</th>\n",
       "      <td>190600.000</td>\n",
       "      <td>388200.00000</td>\n",
       "      <td>290100.00000</td>\n",
       "      <td>278200.00000</td>\n",
       "      <td>280400.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01 00:00:00</th>\n",
       "      <td>192600.000</td>\n",
       "      <td>392900.00000</td>\n",
       "      <td>294100.00000</td>\n",
       "      <td>282100.00000</td>\n",
       "      <td>285200.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01 00:00:00</th>\n",
       "      <td>194400.000</td>\n",
       "      <td>397700.00000</td>\n",
       "      <td>297300.00000</td>\n",
       "      <td>285800.00000</td>\n",
       "      <td>289000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 00:00:00</th>\n",
       "      <td>196100.000</td>\n",
       "      <td>402200.00000</td>\n",
       "      <td>300900.00000</td>\n",
       "      <td>290300.00000</td>\n",
       "      <td>292000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>197600.000</td>\n",
       "      <td>406300.00000</td>\n",
       "      <td>304400.00000</td>\n",
       "      <td>294400.00000</td>\n",
       "      <td>294800.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01 00:00:00</th>\n",
       "      <td>200200.000</td>\n",
       "      <td>410300.00000</td>\n",
       "      <td>307500.00000</td>\n",
       "      <td>297700.00000</td>\n",
       "      <td>297200.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01 00:00:00</th>\n",
       "      <td>204300.000</td>\n",
       "      <td>416000.00000</td>\n",
       "      <td>310200.00000</td>\n",
       "      <td>300600.00000</td>\n",
       "      <td>299500.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>207200.000</td>\n",
       "      <td>420600.00000</td>\n",
       "      <td>311800.00000</td>\n",
       "      <td>302400.00000</td>\n",
       "      <td>300900.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01_pred</th>\n",
       "      <td>211011.375</td>\n",
       "      <td>429064.90625</td>\n",
       "      <td>318112.03125</td>\n",
       "      <td>309080.03125</td>\n",
       "      <td>309130.6875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         95775         399672        95744         95866   \\\n",
       "2017-06-01 00:00:00  184400.000  377900.00000  281800.00000  270700.00000   \n",
       "2017-07-01 00:00:00  186300.000  381300.00000  284300.00000  272300.00000   \n",
       "2017-08-01 00:00:00  188500.000  384400.00000  287000.00000  274700.00000   \n",
       "2017-09-01 00:00:00  190600.000  388200.00000  290100.00000  278200.00000   \n",
       "2017-10-01 00:00:00  192600.000  392900.00000  294100.00000  282100.00000   \n",
       "2017-11-01 00:00:00  194400.000  397700.00000  297300.00000  285800.00000   \n",
       "2017-12-01 00:00:00  196100.000  402200.00000  300900.00000  290300.00000   \n",
       "2018-01-01 00:00:00  197600.000  406300.00000  304400.00000  294400.00000   \n",
       "2018-02-01 00:00:00  200200.000  410300.00000  307500.00000  297700.00000   \n",
       "2018-03-01 00:00:00  204300.000  416000.00000  310200.00000  300600.00000   \n",
       "2018-04-01 00:00:00  207200.000  420600.00000  311800.00000  302400.00000   \n",
       "2018-05-01_pred      211011.375  429064.90625  318112.03125  309080.03125   \n",
       "\n",
       "                          399665  \n",
       "2017-06-01 00:00:00  270800.0000  \n",
       "2017-07-01 00:00:00  273800.0000  \n",
       "2017-08-01 00:00:00  276600.0000  \n",
       "2017-09-01 00:00:00  280400.0000  \n",
       "2017-10-01 00:00:00  285200.0000  \n",
       "2017-11-01 00:00:00  289000.0000  \n",
       "2017-12-01 00:00:00  292000.0000  \n",
       "2018-01-01 00:00:00  294800.0000  \n",
       "2018-02-01 00:00:00  297200.0000  \n",
       "2018-03-01 00:00:00  299500.0000  \n",
       "2018-04-01 00:00:00  300900.0000  \n",
       "2018-05-01_pred      309130.6875  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_chart_data = df_time_series[best_5_investments][-12:]\n",
    "investment_chart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "months = [\"June '17\", \"July '17\",\"Aug '17\",\"Sep '17\",\"Oct '17\",\"Nov '17\",\"Dec '18\",\"Jan '18\",\"Feb '18\",\"Mar '18\",\"Apr '18\", \"May '18\"]\n",
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "fig = plt.figure()\n",
    "\n",
    "ax.plot(months, investment_chart_data[95775])\n",
    "ax.plot(months, investment_chart_data[399672])\n",
    "ax.plot(months, investment_chart_data[95744])\n",
    "ax.plot(months, investment_chart_data[95866])\n",
    "ax.plot(months, investment_chart_data[399665])\n",
    "\n",
    "\n",
    "\n",
    "ax.set_title('Top 5 Profitable Zipcodes')\n",
    "ax.legend(['95775','399672','95744','95866','399665'], loc=('upper left'));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e81d9768a2937af9514d7fa33aa30feb69a40df5b58c34cfa60b871c6c10885"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
